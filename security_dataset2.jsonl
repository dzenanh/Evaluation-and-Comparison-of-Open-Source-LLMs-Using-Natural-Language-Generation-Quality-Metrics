{"page_content": "PENTESTGPT: Evaluating and Harnessing Large Language Models for Automated\nPenetration Testing\nGelei Deng1, Yi Liu1, V\u00edctor Mayoral-Vilches23, Peng Liu4, Yuekang Li5, Yuan Xu1,\nTianwei Zhang1, Yang Liu1, Martin Pinzger3, Stefan Rass6\n1Nanyang Technological University, 2Alias Robotics, 3Alpen-Adria-Universit\u00e4t Klagenfurt,\n4Institute for Infocomm Research (I2R), A*STAR, Singapore, 5University of New South Wales, 6Johannes\nKepler University Linz\nAbstract\nPenetration testing, a crucial industrial practice for ensur-\ning system security, has traditionally resisted automation due\nto the extensive expertise required by human professionals.\nLarge Language Models (LLMs) have shown significant ad-\nvancements in various domains, and their emergent abilities\nsuggest their potential to revolutionize industries. In this work,\nwe establish a comprehensive benchmark using real-world\npenetration testing targets and further use it to explore the\ncapabilities of LLMs in this domain. Our findings reveal that\nwhile LLMs demonstrate proficiency in specific sub-tasks\nwithin the penetration testing process, such as using testing\ntools, interpreting outputs, and proposing subsequent actions,\nthey also encounter difficulties maintaining a whole context\nof the overall testing scenario.\nBased on these insights, we introduce PENTESTGPT, an\nLLM-empowered automated penetration testing framework\nthat leverages the abundant domain knowledge inherent in\nLLMs. PENTESTGPT is meticulously designed with three\nself-interacting modules, each addressing individual sub-tasks\nof penetration testing, to mitigate the challenges related to\ncontext loss. Our evaluation shows that PENTESTGPT not\nonly outperforms LLMs with a task-completion increase of\n228.6% compared to the GPT-3.5 model among the bench-\nmark targets, but also proves effective in tackling real-world\npenetration testing targets and CTF challenges. Having been\nopen-sourced on GitHub, PENTESTGPT has garnered over\n6,200 stars in 9 months and fostered active community engage-\nment, attesting to its value and impact in both the academic\nand industrial spheres.\n1\nIntroduction\nSecuring a system presents a formidable challenge. Offensive\nsecurity methods like penetration testing (pen-testing) and\nred teaming are now essential in the security lifecycle. As ex-\nplained by Applebaum [1], these approaches involve security\nteams attempting breaches to reveal vulnerabilities, providing\nadvantages over traditional defenses, which rely on incom-\nplete system knowledge and modeling. This study, guided by\nthe principle \u201cthe best defense is a good offense\u201d, focuses on\noffensive strategies, specifically penetration testing.\nPenetration testing is a proactive offensive technique for\nidentifying, assessing, and mitigating security vulnerabili-\nties [2]. It involves targeted attacks to confirm flaws, yielding\na comprehensive inventory of vulnerabilities with actionable\nrecommendations. This widely-used practice empowers orga-\nnizations to detect and neutralize network and system vulner-\nabilities before malicious exploitation. However, it typically\nrelies on manual effort and specialized knowledge [3], result-\ning in a labor-intensive process, creating a gap in meeting the\ngrowing demand for efficient security evaluations.\nLarge Language Models (LLMs) have demonstrated pro-\nfound capabilities, showcasing intricate comprehension of\nhuman-like text and achieving remarkable results across a\nmultitude of tasks [4, 5]. An outstanding characteristic of\nLLMs is their emergent abilities [6], cultivated during training,\nwhich empower them to undertake intricate tasks such as rea-\nsoning, summarization, and domain-specific problem-solving\nwithout task-specific fine-tuning. This versatility posits LLMs\nas potential game-changers in various fields, notably cyber-\nsecurity. Although recent works [7\u20139] posit the potential of\nLLMs to reshape cybersecurity practices, including the con-\ntext of penetration testing, there is an absence of a systematic,\nquantitative assessment of their aptitude in this regard. Con-\nsequently, an imperative question presents: To what extend\ncan LLMs automate penetration testing?\nMotivated by this question, we set out to explore the ca-\npability boundary of LLMs on real-world penetration test-\ning tasks. Unfortunately, the current benchmarks for pen-\netration testing [10, 11] are not comprehensive and fail to\nassess progressive accomplishments fairly during the pro-\ncess. To address this limitation, we construct a robust bench-\nmark that includes test machines from HackTheBox [12] and\nVulnHub [13]\u2014two leading platforms for penetration test-\ning challenges. Comprising 13 targets with 182 sub-tasks,\nour benchmark encompasses all vulnerabilities appearing in\n1\narXiv:2308.06782v2  [cs.SE]  2 Jun 2024\nOWASP\u2019s top 10 vulnerability list [14] and 18 Common\nWeakness Enumeration (CWE) items [15]. The benchmark\noffers a more detailed evaluation of the tester\u2019s performance\nby monitoring the completion status for each sub-task.\nWith this benchmark, we perform an exploratory study\nusing GPT-3.5 [16], GPT-4 [17], and Bard [18] as representa-\ntive LLMs. Our test strategy is interactive and iterative. We\ncraft tailored prompts to guide the LLMs through penetration\ntesting. Each LLM, presented with prompts and target ma-\nchine information, generates step-by-step penetration testing\noperations. We then execute the suggested operations in a\ncontrolled environment, document the results, and feed them\nback to the LLM to inform and refine its next steps. This\ncycle (prompting, executing, and feedback) is repeated un-\ntil the LLM completes the entire penetration testing process\nautonomously. To evaluate LLMs, we compare their results\nagainst baseline solutions from official walkthroughs and\ncertified penetration testers. By analyzing similarities and\ndifferences in their problem-solving approaches, we aim to\nbetter understand LLMs\u2019 capabilities in penetration testing\nand how their strategies differ from human experts.\nOur investigation yields intriguing insights into the capa-\nbilities and limitations of LLMs in penetration testing. We\ndiscover that LLMs demonstrate proficiency in managing spe-\ncific sub-tasks within the testing process, such as utilizing\ntesting tools, interpreting their outputs, and suggesting subse-\nquent actions. Compared to human experts, LLMs are espe-\ncially adept at executing complex commands and options with\ntesting tools, while models like GPT-4 excel in comprehend-\ning source code and pinpointing vulnerabilities. Furthermore,\nLLMs can craft appropriate test commands and accurately de-\nscribe graphical user-interface operations needed for specific\ntasks. Leveraging their vast knowledge base, they can design\ninventive testing procedures to unveil potential vulnerabili-\nties in real-world systems and CTF challenges. However, we\nalso note that LLMs have difficulty in maintaining a coherent\ngrasp of the overarching testing scenario, a vital aspect for\nattaining the testing goal. As the dialogue advances, they may\nlose sight of earlier discoveries and struggle to apply their\nreasoning consistently toward the final objective. Addition-\nally, LLMs overemphasize recent tasks in the conversation\nhistory, regardless of their vulnerability status. As a result,\nthey tend to neglect other potential attack surfaces exposed in\nprior tests and fail to complete the penetration testing task.\nBuilding on our insights into LLMs\u2019 capabilities in pen-\netration testing, we present PENTESTGPT1, an interactive\nsystem designed to enhance the application of LLMs in this\ndomain. Drawing inspiration from the collaborative dynamics\ncommonly observed in real-world human penetration testing\nteams, PENTESTGPT is particularly tailored to manage large\nand intricate projects. It features a tripartite architecture com-\nprising Reasoning, Generation, and Parsing Modules, each\n1PENTESTGPT is King Arthur\u2019s legendary sword, known for its excep-\ntional cutting power and the ability to pierce armor.\nreflecting specific roles within penetration testing teams. The\nReasoning Module emulates the function of a lead tester,\nfocusing on maintaining a high-level overview of the penetra-\ntion testing status. We introduce a novel representation, the\nPentesting Task Tree (PTT), based on the cybersecurity attack\ntree [19]. This structure encodes the testing process\u2019s ongoing\nstatus and steers subsequent actions. Uniquely, this representa-\ntion can be translated into natural language and interpreted by\nthe LLM, thereby comprehended by the Generation Module\nand directing the testing procedure. The Generation Module,\nmirroring a junior tester\u2019s role, is responsible for construct-\ning detailed procedures for specific sub-tasks. Translating\nthese into exact testing operations augments the generation\nprocess\u2019s accuracy. Meanwhile, the Parsing Module deals\nwith diverse text data encountered during penetration testing,\nsuch as tool outputs, source codes, and HTTP web pages. It\ncondenses and emphasizes these texts, extracting essential\ninformation. Collectively, these modules function as an inte-\ngrated system. PENTESTGPT completes complex penetration\ntesting tasks by bridging high-level strategies with precise exe-\ncution and intelligent data interpretation, thereby maintaining\na coherent and effective testing process.\nWe assessed PENTESTGPT across diverse testing scenar-\nios to validate its effectiveness and breadth. In our custom\nbenchmarks, PENTESTGPT significantly outperformed di-\nrect applications of GPT-3.5 and GPT-4, showing increases\nin sub-task completion rates of 228.6% and 58.6%, respec-\ntively. Furthermore, when applied to real-world challenges\nsuch as the HackTheBox active machine penetration tests [20]\nand picoMini [21] CTF competition, PENTESTGPT demon-\nstrated its practical utility. It successfully resolved 4 out of\n10 penetration testing challenges, incurring a total cost of\n131.5 US Dollars for the OpenAI API usage. In the CTF\ncompetition, PENTESTGPT achieved a score of 1500 out of a\npossible 4200, placing 24th among 248 participating teams.\nThis evaluation underscores PENTESTGPT\u2019s practical value\nin enhancing penetration testing tasks\u2019 efficiency and pre-\ncision. The solution has been made publicly available on\nGitHub2, receiving widespread acclaim with over 6,200 stars\nto the date of writing, active community engagement, and\nongoing collaboration with multiple industrial partners.\nAs a long term research goal, we aim to contribute to un-\nlocking the potential of modern machine learning approaches\nand develop a fully automated penetration testing framework\nthat helps produce cybersecurity cognitive engines. Our over-\nall architecture is depicted in Figure 1, showing our current\nwork and future planned contributions. Our proposed frame-\nwork, MALISM, is designed to enable a user without in-depth\nsecurity domain knowledge to produce its cybersecurity cog-\nnitive engine that helps conduct penetration testing over an\nextensive range of targets. This framework comprises three\nprimary components:\n2The project is at: https://github.com/GreyDGL/PentestGPT.\n2\nUser\n1. ExploitFlow\n2. PentestGPT\n3. PentestPerf\nTarget\nexploit\nflow\ngraph\nadapters\nmodels\nstate\nparsing\nreasoning\ngeneration\nprogramatically in Python\ngoal description in text\nexchange exploit tree\nBenchmarks an exploit flow\n4. Malism\n2. PentestGPT\nExternal entity\nOther future papers\nThis paper\nInner Component\nFigure 1: Architecture of our framework to develop a fully automated penetration testing tools, MALISM. Figure depicts the\nvarious interaction flows that an arbitrary User could follow using MALISM to pentest a given Target. 1. Corresponds with\nEXPLOITFLOW, a modular library to produce security exploitation routes (exploit flows) that caputures the state of the system\nbeing tested in a flow after every discrete action. 2. (this paper) Corresponds with PENTESTGPT, a testing tool that leverages\nthe power of LLMs to produce testing guidance (heuristics) for every given discrete state. 3. PENTESTPERF is a comprehensive\npenetration testing benchmark to evaluate the performances of penetration testers and automated tools across a wide array\nof testing targets. 4. captures MALISM, our framework to develop fully automated penetration testing tools which we name\ncybersecurity cognitive engines.\n1. EXPLOITFLOW [22]: A modular library to produce cy-\nber security exploitation routes (exploit flows). EXPLOIT-\nFLOW aims to combine and compose exploits from dif-\nferent sources and frameworks, capturing the state of\nthe system being tested in a flow after every discrete\naction, which allows learning attack trees that affect a\ngiven system. EXPLOITFLOW\u2019s main motivation is to\nfacilitate and empower Game Theory and Artificial In-\ntelligence (AI) research in cyber security. It uniquely\nrepresents the exploitation process that encodes every\nfacet within it. Its representation can be effectively inte-\ngrated with various penetration testing tools and scripts,\nsuch as Metasploit [23] to perform end-to-end penetra-\ntion testing. Such representation can be further visual-\nized to guide the human experts to reproduce the testing\nprocess.\n2. PENTESTGPT (this paper): An automated penetration\ntesting system that leverages the power of LLMs to pro-\nduce testing guidance and intuition at every given dis-\ncrete state. It functions as the core component of the\nMALISM framework, guiding the LLMs to utilize their\ndomain knowledge in real-world testing scenarios effi-\nciently.\n3. PENTESTPERF: A comprehensive penetration testing\nbenchmark developed to evaluate the performances of\npenetration testers and automated tools across a wide\narray of testing targets. It offers a fair and robust platform\nfor performance comparison.\nThe harmonious integration of these three components\nforms an automated, self-evolving penetration testing frame-\nwork capable of executing penetration tests over various tar-\ngets, MALISM. This framework to develop fully automated\npenetration testing tools, which we name cybersecurity cog-\nnitive engines, aims to revolutionize the field of penetration\ntesting by significantly reducing the need for domain expertise\nand enabling more comprehensive and reliable testing.\nIn summary, we make the following contributions:\n\u2022 Development of a Comprehensive Penetration Testing\nBenchmark. We craft a robust and representative penetra-\ntion testing benchmark, encompassing a multitude of test\nmachines from leading platforms such as HackTheBox and\nVulnHub. This benchmark includes 182 sub-tasks covering\nOWASP\u2019s top 10 vulnerabilities, offering fair and compre-\nhensive evaluation of penetration testing. To the best of\n3\nour knowledge, this is the first benchmark in the field that\ncan provide progressive accomplishments assessments and\ncomparisons.\n\u2022 Comprehensive Evaluation of LLMs for Penetration\nTesting Tasks. By employing models like GPT-3.5, GPT-\n4, and Bard, our exploratory study rigorously investigates\nthe strengths and limitations of LLMs in penetration testing.\nTo the best of our knowledge, this is the first systematic and\nquantitative study for the capability of LLMs in performing\nautomated penetration testing. The insights gleaned from\nthis study shed valuable light on the capabilities and chal-\nlenges faced by LLMs, enriching our understanding of their\napplicability in this specialized domain.\n\u2022 Development of an Innovative LLM-powered Penetra-\ntion Testing System. We engineer PENTESTGPT, a novel\ninteractive system that leverages the strengths of LLMs\nto carry out penetration testing tasks automatically. Draw-\ning inspiration from real-world human penetration testing\nteams, PENTESTGPT integrates a tripartite design that mir-\nrors the collaborative dynamics between senior and junior\ntesters. This architecture optimizes LLMs\u2019 usage, signifi-\ncantly enhancing the efficiency and effectiveness of auto-\nmated penetration testing. We have open-sourced PENTEST-\nGPT and it has received over 6,500 stars on GitHub, active\ncommunity contributions, and industry partners including\nAWS, Huawei, and ByteDance to collaborate.\n2\nBackground & Related Work\n2.1\nPenetration Testing\nPenetration testing, or \u201cpentesting\u201d, is a critical practice to\nenhance organizational systems\u2019 security. In a typical penetra-\ntion test, security professionals, known as penetration testers,\nanalyze the target system, often leveraging automated tools.\nThe standard process is divided into five key phases [24]:\nReconnaissance, Scanning, Vulnerability Assessment, Ex-\nploitation, and Post Exploitation (including reporting). These\nphases enable testers to understand the target system, identify\nvulnerabilities, and exploit them to gain access.\nDespite significant advancements [11,25,26], a fully auto-\nmated penetration testing system remains out of reach. This\ngap results from the need for deep vulnerability understanding\nand a strategic action plan. Typically, testers combine depth-\nfirst and breadth-first search techniques [24]. They first grasp\nthe target environment\u2019s scope, then drill down into specific\nvulnerabilities. This method ensures comprehensive analysis,\nleaning on expertise and experience. The multitude of spe-\ncialized tools further complicate the automation. Thus, even\nwith artificial intelligence, achieving a seamless automated\npenetration testing solution is a daunting task.\n2.2\nLarge Language Models\nLarge Language Models (LLMs), including OpenAI\u2019s GPT-\n3.5 and GPT-4, are prominent tools with applications ex-\ntending to various cybersecurity-related fields, such as code\nanalysis [27] and vulnerability repairment [28]. These models\nare equipped with wide-ranging general knowledge and the\ncapacity for elementary reasoning. They can comprehend,\ninfer, and produce text resembling human communication,\naided by a training corpus encompassing diverse domains\nlike computer science and cybersecurity. Their ability to in-\nterpret context and recognize patterns enables them to adapt\nknowledge to new scenarios. This adaptability, coupled with\ntheir proficiency in interacting with systems in a human-like\nway, positions them as valuable assets in enhancing penetra-\ntion testing processes. Despite inherent limitations, LLMs\noffer distinct attributes that can substantially aid in the au-\ntomation and improvement of penetration testing tasks. The\nrealization of this potential, however, requires the creation\nand application of a specialized and rigorous benchmark.\n3\nPenetration Testing Benchmark\n3.1\nMotivation\nThe comprehensive evaluation of LLMs in penetration testing\nnecessitates a robust and representative benchmark. Existing\nbenchmarks in this domain [10,11] have several limitations.\nFirst, they are often restricted in scope, focusing on a narrow\nrange of potential vulnerabilities, and thus fail to capture the\ncomplexity and diversity of real-world cyber threats. For in-\nstance, the OWASP juiceshop project [29] is the most widely\nadopted benchmark for web vulnerability evaluation. How-\never, it does not include privilege escalation vulnerabilities,\nwhich is an essential aspect of penetration testing. Second, ex-\nisting benchmarks may not recognize the cumulative value of\nprogress through the different stages of penetration testing, as\nthey tend to evaluate only the final exploitation success. This\napproach overlooks the nuanced value each step contributes\nto the overall process, resulting in metrics that might not accu-\nrately represent actual performance in real-world scenarios.\nTo address these concerns, we propose the construction of\na comprehensive penetration testing benchmark that meets\nthe following criteria:\nTask Variety. The benchmark must encompass diverse tasks,\nreflecting various operating systems and emulating the di-\nversity of scenarios encountered in real-world penetration\ntesting.\nChallenge Levels. To ensure broad applicability, the bench-\nmark must include tasks of varying difficulty levels suitable\nfor challenging novice and expert testers.\nProgress Tracking. Beyond mere success or failure met-\nrics, the benchmark must facilitate tracking of incremental\nprogress, thereby recognizing and scoring the value added at\n4\neach stage of the penetration testing process.\n3.2\nBenchmark Design\nFollowing the criteria outlined previously, we develop a com-\nprehensive benchmark that closely reflects real-world pene-\ntration testing tasks. The design process progresses through\nseveral stages.\nTask Selection. We begin by selecting tasks from HackThe-\nBox [12] and VulnHub [13], two leading penetration testing\ntraining platforms. Our selection criteria are designed to en-\nsure that our benchmark accurately reflects the challenges\nencountered in practical penetration testing environments. We\nmeticulously review the latest machines available on both\nplatforms, aiming to identify and select a subset that compre-\nhensively covers all vulnerabilities listed in the OWASP [14]\nTop 10 Project. Additionally, we choose machines that repre-\nsent a mix of difficulties, classified according to traditional\nstandards in the penetration testing domain into easy, medium,\nand hard categories. This process guarantees that our bench-\nmark spans the full spectrum of vulnerabilities and difficulties.\nNote that our benchmark does not include benign targets to\nassess false positives. In penetration testing, benign targets are\nsometimes explored. Our main objective remains identifying\ntrue vulnerabilities.\nTask Decomposition. We further parse the testing process of\neach target into a series of sub-tasks, following the standard\nsolution commonly referred to as the \u201cwalkthrough\u201d in pen-\netration testing. Each sub-task corresponds to a unique step\nin the overall process. We decompose sub-tasks following\nNIST 800-115 [30], the Technical Guide to Security Testing.\nEach sub-task is one step declared in the Guide (e.g., network\ndiscovery, password cracking), or an operation that exploits a\nunique vulnerability categorised in the Common Weakness\nEnumeration (CWE) [15] (e.g., exploiting SQL injection -\nCWE-89 [31]). In the end, we formulate an exhaustive list of\nsub-tasks for every benchmark target. We provide the com-\nplete list of the decomposed sub-tasks in Appendix Table 7.\nBenchmark Validation. The final stage of our benchmark\ndevelopment involves rigorous validation, which ensures the\nreproducibility of these benchmark machines. To do this, three\ncertified penetration testers independently attempt the pene-\ntration testing targets and write their walkthrough. We then\nadjust our task decomposition accordingly because some tar-\ngets may have multiple valid solutions.\nUltimately, we have compiled a benchmark that effec-\ntively encompasses all types of vulnerabilities listed in the\nOWASP [14] Top 10 Project. It comprises 13 penetration\ntesting targets, each at varying levels of difficulty. These tar-\ngets are broken down into 182 sub-tasks across 26 categories,\ncovering 18 distinct CWE items. This number of targets is\ndeemed sufficient to represent a broad spectrum of vulnerabil-\nities, difficulty levels, and varieties essential for comprehen-\nsive penetration testing training. Detailed information about\nthe included categories can be found in the Appendix Sec-\ntion 7. To foster community development, we have made this\nbenchmark publicly available online at our anonymous project\nwebsite [32].\n4\nExploratory Study\nWe conduct an exploratory study to assess the capabilities\nof LLMs in penetration testing, with the primary objective\nof determining how well LLMs can adapt to the real-world\ncomplexities and challenges in this task. Specifically, we aim\nto address the following two research questions:\nRQ1 (Capability): To what extent can LLMs perform pene-\ntration testing tasks?\nRQ2 (Comparative Analysis): How do the problem-solving\nstrategies of human penetration testers and LLMs differ?\nWe utilize the benchmark described in Section 3 to evaluate\nthe performance of LLMs on penetration testing tasks. In the\nfollowing, we first delineate our testing strategy for this study.\nSubsequently, we present the testing results and an analytical\ndiscussion to address the above research questions.\n4.1\nTesting Strategy\nLLMs are text-based and cannot independently perform pen-\netration testing operations. To address this, we develop a\nhuman-in-the-loop testing strategy, serving as an intermediary\nmethod to accurately assess LLMs\u2019 capabilities. This strategy\nfeatures an interactive loop where a human expert executes\nthe LLM\u2019s penetration testing directives. Importantly, the hu-\nman expert functions purely as an executor, strictly following\nthe LLM\u2019s instructions without adding any expert insights or\nmaking independent decisions.\nFigure 2 decipits the testing strategy with the following\nsteps: \u2776We initiate the looped testing procedure by pre-\nsenting the target specifics to the LLM, seeking its guidance\non potential penetration testing steps. \u2777The human expert\nstrictly follows the LLM\u2019s recommendations and conducts the\nsuggested actions in the penetration testing environment. \u2778\nOutcomes of the testing actions are collected and summarized:\ndirect text outputs such as terminal outputs or source code\nare documented; non-textual results, such as graphical repre-\nsentations, are translated by the human expert into succinct\ntextual summaries. The data is then fed back to the LLM,\nsetting the stage for its subsequent recommendations. \u2779This\niterative process persists either until a conclusive solution\nis identified or an deadlock is reached. We then compile a\nrecord of the testing procedures, encompassing successful\nsub-tasks, ineffective actions, and any reasons for failure, if\napplicable. For a more tangible grasp of this strategy, we offer\nillustrative examples of prompts and corresponding outputs\nfrom GPT-4 related to one of our benchmark targets in the\nAppendix Section A.\n5\nPenetration\nTesting Goal\nLarge Language\nModel\nOperations to\nPerform\nTesting Outputs\nTesting\nEnvironment\nFlag and\nConclusion\n1\n2\n3\n4\nHuman Expert\nInteractive Loop\nData\nEntity\nFigure 2: Overview of strategy to use LLMs for penetration\ntesting.\nTo ensure the evaluation\u2019s fairness and accuracy, we em-\nploy several strategies. First, we involve expert-level penetra-\ntion testers3 as the human testers. With their deep pentesting\nknowledge, these testers can precisely comprehend and ex-\necute LLM-generated operations, thus accurately assessing\nLLMs\u2019 true capabilities. Second, we instruct the penetration\ntesters to strictly execute the commands given by the LLMs,\nwithout altering any content or information, even upon identi-\nfying clear errors. They are also instructed to faithfully report\nthe testing results back to the LLM without any additional\ncommentary. Third, for managing UI-based operations and\ngraphical results, we have adopted specific measures. Initially,\nwe instruct the LLMs to minimize the use of GUI-based tools.\nFor indispensable tools that cannot be avoided (e.g., Burp-\nSuite), we propose a result-oriented approach: upon receiving\na GUI operation instruction, the testers first execute the oper-\nation based on their expert knowledge. Subsequently, they are\nrequired to provide detailed, step-by-step textual descriptions\nof their actions and the observed responses at each step, which\nare then communicated back to the LLM. Should the LLM\nexpress any objections or comments concerning a particular\nstep, the operation is to be repeated. This protocol ensures\nthe integrity of the feedback loop, guaranteeing that the LLM\nobtains a comprehensive understanding of the testing results.\n4.2\nEvaluation Settings\nWe proceed to assess the performances of various LLMs in\npenetration testing tasks using the strategy mentioned above.\nModel Selection. Our study focuses on three cutting-edge\nLLMs that are currently accessible: GPT-3.5 with 8k to-\nken limit, GPT-4 with 32k token limit from OpenAI, and\nLaMDA [33] from Google. These models are selected based\non their prominence in the research community and consis-\ntent availability. To interact with the LLMs mentioned above,\nwe utilize chatbot services provided by OpenAI and Google,\nnamely ChatGPT [34] and Bard [18]. For this paper, the terms\nGPT-3.5, GPT-4, and Bard will represent these three LLMs.\nExperimental Setup. Our experiments occur in a local setting\nwith both target and testing machines on the same private\nnetwork. The testing machine runs on Kali Linux [35], version\n2023.1.\n3We selected Offensive Security Certified Professionals (OSCP) testers.\nTool Usage. Our study aims to assess the innate capabilities\nof LLMs on penetration testing, without reliance on end-to-\nend automated vulnerability scanners such as Nexus [36]\nand OpenVAS [37]. Consequently, we explicitly instruct the\nLLMs to refrain from using these tools. We follow the LLMs\u2019\nrecommendations for utilizing other tools designed to validate\nspecific vulnerability types (e.g., sqlmap [38] for SQL injec-\ntions). Occasionally, versioning discrepancies may lead the\nLLMs to provide incorrect instructions for tool usage. In such\ninstances, our penetration testing experts evaluate whether the\ninstructions would have been valid for a previous version of\nthe tool. They then make any necessary adjustments to ensure\nthe tool\u2019s correct operation.\n4.3\nCapability Evaluation (RQ1)\nTo address RQ1, we evaluate the performance of three lead-\ning LLMs: GPT-4, Bard, and GPT-3.5. We summarize these\nfindings in Table 1. Each LLM successfully completes at least\none end-to-end penetration test, highlighting their versatility\nin simpler environments. Of these, GPT-4 excels, achieving\nsuccess on 4 easy and 1 medium difficulty targets. Bard and\nGPT-3.5 follow with success on 2 and 1 easy targets, respec-\ntively. In sub-tasks, GPT-4 completes 55 out of 77 on easy\ntargets and 30 out of 71 on medium. Bard and GPT-3.5 also\nshow potential, finishing 16 (22.54%) and 13 (18.31%) of\nmedium difficulty sub-tasks, respectively. However, on hard\ntargets, all models\u2019 performance declines. Though they can\ninitiate the reconnaissance phase, they struggle to exploit iden-\ntified vulnerabilities. This is anticipated since hard targets\nare designed to be especially challenging. They often fea-\nture seemingly vulnerable services that are non-exploitable,\nknown as rabbit holes [39]. The pathways to exploit these\nmachines are unique and unpredictable, resisting automated\ntool replication. For example, the target Falafel has special-\nized SQL injection vulnerabilities resistant to sqlmap. Current\nLLMs cannot tackle these without human expert input.\nFinding 1: Large Language Models (LLMs) have shown\nproficiency in conducting end-to-end penetration testing\ntasks but struggle to overcome challenges presented by\nmore difficult targets.\nWe further examine the detailed sub-task completion per-\nformances of the three LLMs compared to the walkthrough\n(WT), as presented in Table 2. Analyzing the completion sta-\ntus, we identify several areas where LLMs excel. First, they\nadeptly utilize common penetration testing tools to interpret\nthe corresponding outputs, especially in enumeration tasks\ncorrectly. For example, all three evaluated LLMs successfully\nperform nine Port Scanning sub-tasks. They can configure\nthe widely-used port scanning tool, nmap [40], comprehend\nthe scan results, and formulate subsequent actions. Second,\nthe LLMs reveal a deep understanding of prevalent vulner-\n6\nTable 1: Overall performance of LLMs on Penetration Testing Benchmark.\nEasy\nMedium\nHard\nAverage\nTools\nOverall (7)\nSub-task (77)\nOverall (4)\nSub-task (71)\nOverall (2)\nSub-task (34)\nOverall (13)\nSub-task (182)\nGPT-3.5\n1 (14.29%)\n24 (31.17%)\n0 (0.00%)\n13 (18.31%)\n0 (0.00%)\n5 (14.71%)\n1 (7.69%)\n42 (23.07%)\nGPT-4\n4 (57.14%)\n55 (71.43%)\n1 (25.00%)\n30 (42.25%)\n0 (0.00%)\n10 (29.41%)\n5 (38.46%)\n95 (52.20%)\nBard\n2 (28.57%)\n29 (37.66%)\n0 (0.00%)\n16 (22.54%)\n0 (0.00%)\n5 (14.71%)\n2 (15.38%)\n50 (27.47%)\nAverage\n2.3 (33.33%)\n36 (46.75%)\n0.33 (8.33%)\n19.7 (27.70%)\n0 (0.00%)\n6.7 (19.61%)\n2.7 (20.5%)\n62.3 (34.25%)\nTable 2: Top 10 Types of Sub-tasks completed by each tool.\nSub-Tasks\nWT\nGPT-3.5\nGPT-4\nBard\nWeb Enumeration\n18\n4 (22.2%)\n8 (44.4%)\n4 (22.2%)\nCode Analysis\n18\n4 (22.2%)\n5 (27.2%)\n4 (22.2%)\nPort Scanning\n12\n9 (75.0%)\n9 (75.0%)\n9 (75.0%)\nShell Construction\n11\n3 (27.3%)\n8 (72.7%)\n4 (36.4%)\nFile Enumeration\n11\n1 (9.1%)\n7 (63.6%)\n1 (9.1%)\nConfiguration Enumeration\n8\n2 (25.0%)\n4 (50.0%)\n3 (37.5%)\nCryptanalysis\n8\n2 (25.0%)\n3 (37.5%)\n1 (12.5%)\nNetwork Enumeration\n7\n1 (14.3%)\n3 (42.9%)\n2 (28.6%)\nCommand Injection\n6\n1 (16.7%)\n4 (66.7%)\n2 (33.3%)\nKnown Exploits\n6\n2 (33.3%)\n3 (50.0%)\n1 (16.7%)\nTable 3: Top Unnecessary Operations Prompted by LLMs on\nthe Benchmark Targets\nUnnecessary Operations\nGPT-3.5\nGPT-4\nBard\nTotal\nBrute-Force\n75\n92\n68\n235\nExploit Known Vulnerabilities (CVEs)\n29\n24\n28\n81\nSQL Injection\n14\n21\n16\n51\nCommand Injection\n18\n7\n12\n37\nability types, connecting them to the services on the target\nsystem. This understanding is evidenced by the successful\ncompletion of sub-tasks related to various vulnerability types.\nFinally, LLMs demonstrate their effectiveness in code analy-\nsis and generation, particularly in the tasks of Code Analysis\nand Shell Construction. These tasks require the models to\nread and generate codes in different programming languages.\nThis often culminates in identifying potential vulnerabilities\nfrom code snippets and crafting the corresponding exploits.\nNotably, GPT-4 outperforms the other two models regard-\ning code interpretation and generation, marking it the most\nsuitable candidate for penetration testing tasks.\nFinding 2: LLMs can efficiently use penetration test-\ning tools, identify common vulnerabilities, and interpret\nsource codes to identify vulnerabilities.\n4.4\nComparative Analysis (RQ2)\nTo address RQ2, we examine the problem-solving strategies\nthat LLMs employ, contrasting them with human penetration\ntesters. In each penetration testing trial, we concentrate on\nTable 4: Top causes for failed penetration testing trials\nFailure Reasons\nGPT3.5\nGPT4\nBard\nTotal\nSession context lost\n25\n18\n31\n74\nFalse Command Generation\n23\n12\n20\n55\nDeadlock operations\n19\n10\n16\n45\nFalse Scanning Output Interpretation\n13\n9\n18\n40\nFalse Source Code Interpretation\n16\n11\n10\n37\nCannot craft valid exploit\n11\n15\n8\n34\ntwo main aspects: (1) Identifying the unnecessary operations\nthat LLMs prompt, which are not conducive to successful\npenetration testing, as compared to a standard walkthrough;\nand (2) Understanding the specific factors that prevent LLMs\nfrom successfully executing penetration tests.\nWe analyze the unnecessary operations prompted by LLMs\nby breaking down the recorded testing procedures into sub-\ntasks. We employ the same method to formulate benchmark\nsub-tasks, as Section 3 outlines. By comparing this to a stan-\ndard walkthrough, we identify the primary sub-task trials that\nfall outside the standard walkthrough and are thus irrelevant to\nthe penetration testing process. The results are summarized in\nTable 3. We find that the most prevalent unnecessary operation\nprompted by LLMs is brute force. For all services requiring\npassword authentication, LLMs typically advise brute-forcing\nit. This is an ineffective strategy in penetration testing. We\nsurmise that many hacking incidents in enterprises involve\npassword cracking and brute force. LLMs learn these reports\nfrom accident reports and are consequently considered viable\nsolutions. Besides brute force, LLMs suggest that testers en-\ngage in CVE studies, SQL injections, and command injections.\nThese recommendations are common, as real-world penetra-\ntion testers often prioritize these techniques, even though they\nmay not always provide the exact solution.\nTo understand penetration testing trial failures, we cate-\ngorize the reasons for the 195 trials, as shown in Table 4.\nThe primary failure cause is loss of session context. This\nmeans models often lose awareness of previous test outcomes,\nmissing essential past results. This issue arises from LLMs\u2019\nchallenge in handling conversation context. Each LLM has a\nfixed token window, such as GPT-4 with a capacity of 8,000\ntokens [41]. If critical information for a complex task exceeds\nthis limit, trimming it causes the loss of important details.\nThis is problematic in intricate tests where identifying vul-\n7\nnerabilities across services and forming a cohesive exploit\nstrategy is vital. This design flaw impacts the model\u2019s efficacy\nin dealing with layered, detailed tasks.\nFinding 3: LLMs struggle to maintain long-term memory,\nwhich is vital to link vulnerabilities and develop exploita-\ntion strategies effectively.\nSecondly, LLMs strongly prefer the most recent tasks, ad-\nhering rigorously to a depth-first search approach. They tend\nto immerse deeply into resolving the issues mentioned in\nthe most recent conversation, seldom branching out to new\ntargets until the ongoing path is exhaustively explored. This\nbehavior aligns with the studies [42,43] that LLMs primar-\nily concentrate their attention at the prompt\u2019s beginning and\nend. In contrast, seasoned penetration testers adopt a more\nholistic approach, strategically plotting moves that promise\nthe highest potential outcomes. When coupled with the afore-\nmentioned session context loss, this proclivity drives LLMs to\nbecome excessively anchored to one specific service. As the\ntesting advances, the models often neglect prior discoveries,\nleading to an impasse.\nFinding 4: LLMs strongly prefer recent tasks and a depth-\nfirst search approach, often resulting in an over-focus on\none service and forgetting previous findings.\nLastly, LLMs have inaccurate result generation and halluci-\nnation issues, as noted in [44]. This phenomenon ranks as the\nsecond most frequent cause of failures and is characterized by\nthe generation of false commands. In our study, we observe\nthat LLMs frequently identify the appropriate tool for the task\nbut stumble in configuring the tools with the correct settings.\nIn some cases, they even concoct non-existent testing tools or\ntool modules.\nFinding 5: LLMs may generate inaccurate operations or\ncommands, often stemming from inherent inaccuracies\nand hallucinations.\nOur exploratory study on three LLMs in penetration testing\nhighlights their capability to complete sub-tasks. However,\nthey face issues with long-term memory retention, reliance\non a depth-first strategy, and ensuring operation accuracy. In\nthe subsequent section, we detail our approach to mitigate\nthese challenges and describe the design of our LLM-based\npenetration testing tool.\n5\nMethodology\n5.1\nOverview\nIn light of the challenges identified in the preceding section,\nwe present our proposed solution, PENTESTGPT, which lever-\nages the synergistic interplay of three LLM-powered modules.\nAs illustrated in Figure 3, PENTESTGPT incorporates three\ncore modules: the Reasoning Module, the Generation Mod-\nule, and the Parsing Module. Each module reserves one LLM\nsession with its conversation and context. The user interacts\nseamlessly with PENTESTGPT, where distinct modules pro-\ncess different types of messages. This interaction culminates\nin a final decision, suggesting the subsequent step of the pen-\netration testing process that the user should undertake. In the\nfollowing sections, we elucidate our design reasoning and\nprovide a detailed breakdown of the engineering processes\nbehind PENTESTGPT.\n5.2\nDesign Rationale\nOur central design considerations emerged from the three\nchallenges observed in the previous Exploratory Study (Sec-\ntion 4): The first challenge (Finding 3) pertains to the issue\nof penetration testing context loss due to memory retention.\nLLMs in their original form struggle to maintain such long-\nterm memory due to token size limits. The second obstacle\n(Finding 4) arises from the LLM chatbots\u2019 tendency to em-\nphasize recent conversation content. In penetration testing\ntasks, this focuses on optimizing the immediate task. This\napproach falls short in the complex, interconnected task envi-\nronment of penetration testing. The third obstacle (Finding 5)\nis tied to the inaccurate results generation by LLMs. When\ntasked to produce specific operations for a step in penetration\ntesting directly, the outputs are often imprecise, sometimes\neven leading to false directions.\nPENTESTGPT has been engineered to address these chal-\nlenges, rendering it more apt for penetration testing tasks.\nWe draw inspiration from the methodologies employed by\nreal-world penetration testing teams, where directors plan\noverarching procedures, subdividing them into subtasks for\nindividual testers. Each tester independently performs their\ntask, reporting results without an exhaustive understanding\nof the broader context. The director then determines the fol-\nlowing steps, possibly redefining tasks, and triggers the subse-\nquent round of testing. Essentially, the director manages the\noverall strategy without becoming entrenched in the minutiae\nof the tests. This approach is mirrored in PENTESTGPT\u2019s\nfunctionality, enhancing its efficiency and adaptability in con-\nducting penetration tests. Our strategy divides penetration\ntesting into two processes: identifying the next task and gen-\nerating the concrete operation to complete the task. Each\nprocess is powered by one LLM session. In this setup, the\nLLM session responsible for task identification retains the\ncomplete context of the ongoing penetration testing status.\nAt the same time, the generation of detailed operations and\nparsing of information is managed by other sessions. This\ndivision of responsibilities fosters effective task execution\nwhile preserving the overarching context.\nTo assist LLMs in effectively carrying out penetration test-\ning tasks, we design a series of prompts that align with user\n8\nParsing Module\nToken\nCompression\nCondenced\nInformation\nReasoning Module\nTask Tree\nUpdate\nTask Tree\nVerification\nTask\nIdentification\nCandidate\nTasks\nSubsequent\nTask\nTask Decision\nGeneration Module\nTask Expansion\nOperation\nGeneration\nOperations\nTesting Tools\nTesting Targets\nUser Intention\nTesting Outputs\n(Optional) User\nVerification\nTesting Envrionment\nPentestGPT\n1\n2\n3\n4\n5\n6\nCompleted by LLM\nUser Controlled Message\nHidden Information\nInformation to User\n\u00a75.5\nFinding 3 & 4\n\u00a75.3\nFinding 5\n\u00a75.4\nFigure 3: Overview of PENTESTGPT.\ninputs. We utilize the Chain-of-Thought (CoT) [45] methodol-\nogy during this process. As CoT reveals, LLMs\u2019 performance\nand reasoning capabilities can be significantly enhanced using\nthe input, chain-of-thought, output prompting format. Here,\nthe chain-of-thought represents a series of intermediate nat-\nural language reasoning steps leading to the outcome. We\ndissect the penetration testing tasks into micro-steps and de-\nsign prompts with examples to guide LLMs through process-\ning penetration testing information step-by-step, ultimately\nleading to the desired outcomes. The complete prompts are\navailable at our anonymized open-source project [32].\n5.3\nReasoning Module\nThe Reasoning Module plays a pivotal role in our system,\nanalogous to a team lead overseeing the penetration testing\ntask from a macro perspective. It obtains testing results or\nintentions from the user and prepares the testing strategy for\nthe next step. This testing strategy is passed to the generation\nmodule for further planning.\nTo effectively supervise the penetration testing process and\nprovide precise guidance, it is crucial to translate the test-\ning procedures and outcomes into a natural language format.\nDrawing inspiration from the concept of an attack tree [46],\nwhich is often used to outline penetration testing procedures,\nwe introduce the notion of a pentesting task tree (PTT). This\nnovel approach to testing status representation is rooted in the\nconcept of an attributed tree [47]:\nDefinition 1 (Attributed Tree) A attributed tree is an edge-\nlabeled, attributed polytree G = (V,E,\u03bb,\u00b5) where V is a set\nof nodes (or vertices), E is a set of directed edges, \u03bb : E \u2192\u03a3 is\nan edge labeling function assigning a label from the alphabet\n\u03a3 to each edge and \u00b5 : (V \u222aE)\u00d7K \u2192S is a function assigning\nkey(from K)-value(from S) pairs of properties to the edges\nand nodes.\nGiven the definition of attributed tree, PTT is defined as\nfollows:\nDefinition 2 (Pentesting Task Tree) A PTT T is a pair\n(N,A), where: (1) N is a set of nodes organized in a tree\nstructure. Each node has a unique identifier, and there is a\nspecial node called the root that has no parent. Each node,\nother than the root, has exactly one parent and zero or more\nchildren. (2) A is a function that assigns to each node n \u2208N\na set of attributes A(n). Each attribute is a pair (a,v), where\na is the attribute name and v is the attribute value. The set of\nattributes can be different for each node.\nAs outlined in Figure 3, the Reasoning Module\u2019s operation\nunfolds over four key steps operating over the PTT. \u2776The\nmodule begins by interpreting the user\u2019s objectives to create\nan initial PTT, formatted in natural language. This involves\ninstructing the LLM with designed prompts that contain the\nabove PTT definition and real-world examples. The outputs\nfrom the LLM are parsed to ensure that the tree structure\nis correctly represented, which can be formatted in natural\nlanguage through layered bullets, as shown in Figure 4. The\nReasoning Module effectively overcomes the memory-loss\nissue by maintaining a task tree that encompasses the entire\npenetration testing process. \u2777After updating the tree infor-\nmation, a verification step is conducted on the newly updated\nPTT to ascertain its correctness. This process checks explic-\nitly that only the leaf nodes of the PTT have been modified,\naligning with the principle that atomic operations in the pen-\netration testing process should only influence the status of\nthe lowest-level sub-tasks. This step confirms the correctness\nof the reasoning process, safeguarding against any potential\nalterations to the overall tree structure due to hallucination by\nthe LLM. If discrepancies arise, the information is reverted to\nthe LLM for correction and regeneration. \u2778With the updated\nPTT, the Reasoning Module evaluates the current tree state\nand pinpoints viable sub-tasks that can serve as candidate\n9\nPort Scanning\nSSH Service\nFTP Service\nWeb Service\nDirect\nEnumeration\nInjection Point\nIdentification\nAnonymous\nLogin (Succ)\nArbitrary File\nUpload (Succ)\nBrute Force\n(Fail)\nHidden Admin\nPage Login\na) PTT Representation\nTask Tree:\n1. Perform port scanning (completed)\n\u00a0 - Port 21, 22 and 80 are open.\n\u00a0 - Services are FTP, SSH, and Web Service.\n2. Perform the testing\n\u00a0 2.1 Test FTP Service\u00a0\n\u00a0 \u00a0 2.1.1 Test Anonymous Login (success)\n\u00a0 \u00a0 \u00a0 2.1.1.1 Test Anonymous Upload (success)\n\u00a0 2.2 Test SSH Service\u00a0\n\u00a0 \u00a0 2.2.1 Brute-force (failed)\n\u00a0 2.3 Test Web Service (ongoing)\n\u00a0 \u00a0 2.3.1 Directory Enumeration\n\u00a0 \u00a0 \u00a0 2.3.1.1 Find hidden admin (to-do)\n\u00a0 \u00a0 2.3.2 Injection Identification (todo)\nb) PTT Representation in Natural Language\nFigure 4: Pentesting Task Tree in a) visualized tree format,\nand b) natural language format encoded in LLM.\nsteps for further testing. \u2779Finally, the module evaluates the\nlikelihood of these sub-tasks leading to successful penetra-\ntion testing outcomes. It then recommends the top task as\nthe output. The expected results of this task are subsequently\nforwarded to the Generation Module for an in-depth analy-\nsis. This is feasible, as demonstrated in the exploratory study,\nsince LLMs, particularly GPT-4, can identify potential vul-\nnerabilities when provided with system status information.\nThis procedural approach enables the Reasoning Module to\naddress one of the inherent limitations of LLMs, precisely\ntheir tendency to concentrate solely on the most recent task.\nNote that in cases where the tester identifies that the correct\ntask is incorrect or not completed in a preferred way, he could\nalso manually revise the PTT through the interactive handle\nfurther discussed in Section 5.6.\nWe devise four sets of prompts to sequentially guide the\nReasoning Module through the completion of each stage.\nTo bolster the reproducibility of our results, we optimize\nthese prompts further with a technique known as hint gener-\nation [48]. From our practical experience, we observe that\nLLMs are adept at interpreting the tree-structured information\npertinent to penetration testing and can update it accurately\nin response to test outputs.\n5.4\nGeneration Module\nThe Generation Module translates specific sub-tasks from\nthe Reasoning Module into concrete commands or instruc-\ntions. Each time a new sub-task is received, a fresh session is\ninitiated in the Generation Module. This strategy effectively\nisolates the context of the overarching penetration task from\nthe immediate task under execution, enabling the LLM to\nfocus entirely on generating specific commands.\nInstead of directly transforming the received sub-task into\nspecific operations, our design employs the CoT strategy [45]\nto partition this process into two sequential steps. This design\ndecision directly addresses the challenges associated with\nmodel inaccuracy and hallucination by enhancing the model\u2019s\nreasoning capability. In particular, \u277aupon the receipt of a\nconcise sub-task from the Reasoning Module, the Generation\nModule begins by expanding it into a sequence of detailed\nsteps. Notably, the prompt associated with this sub-task re-\nquires the LLM to consider the possible tools and operations\navailable within the testing environment. \u277bSubsequently, the\nGeneration Module transforms each of these expanded steps\ninto precise terminal commands ready for execution or into de-\ntailed descriptions of specific Graphical User Interface (GUI)\noperations to be carried out. This stage-by-stage translation\neliminates potential ambiguities, enabling testers to follow the\ninstructions directly and seamlessly. Implementing this two-\nstep process effectively precludes the LLM from generating\noperations that may not be feasible in real-world scenarios,\nthereby improving the success rate of the penetration testing\nprocedure.\nBy acting as a bridge between the strategic insights pro-\nvided by the Reasoning Module and the actionable steps\nrequired for conducting a penetration test, the Generation\nModule ensures that high-level plans are converted into pre-\ncise and actionable steps. This transformation process sig-\nnificantly bolsters the overall efficiency of the penetration\ntesting procedure, and also provides human-readable outputs\nof the complete testing process. We present a detailed PTT\ngeneration process for a complete penetration testing target in\nAppendix Figure 9, accompanied by an illustrative example\nto aid understanding.\nAn Illustrative Example. We utilize a real-world running\nexample to illuminate how the Reasoning Module and the\nGeneration Module collaboratively operate to complete pene-\ntration testing tasks. Figure 5 illustrates a single iteration of\nPENTESTGPT working on the HackTheBox machine Car-\nrier [49], a medium-difficulty target. As depicted in a-1), the\nPTT, in natural language format, encodes the testing status,\nrevealing the open ports (21, 22, 80) with running services.\nThe Reasoning Module is subsequently instructed to identify\nthe available tasks. As highlighted in red, service scanning is\nthe only available task on the leaf node of the PTT. This task\nis therefore chosen and forwarded to the Generation Module\nfor command generation. The generated command is exe-\n10\nReasoning Module\nTask Tree:\n1. Perform reconnaissance tasks (on-\ngoing)\n\u00a0 \u00a0 1.1. Scan for open ports on the\ntarget machine (completed)\n\u00a0 \u00a0 \u00a0- Port 21, 22 and 80 are open.\n\u00a0 \u00a0 1.2. Identify services running on\nopen ports.\n2. Perform the testing\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\nAvailable Tasks\n1.\u00a0Identify services running on open\nports.\nDecided Task\nIdentify services running on open\nports.\n- Port 21, 22 and 80 are open.\nReasoning Module\nb-1) Available Leaf-node Tasks\na-1) Task Tree\nc-1) Decided Task\nCommand to Execute\nUse nmap to determine service\nversions on open ports. The command\nis `nmap -sV -p21,22,80 <ip-\naddress>`.\nGeneration Module\nd-1) Command to Execute\nTesting Environment\nNmap Output\nPORT\u00a0 \u00a0 STATE\u00a0 \u00a0 \u00a0SERVICE VERSION\n21/tcp\u00a0 filtered\u00a0 ftp\n22/tcp\u00a0 open\u00a0 \u00a0 \u00a0 ssh\u00a0 OpenSSH 7.6p1\u00a0\n...\u00a0\nTask Tree:\n1. Perform reconnaissance tasks\u00a0\n\u00a0 \u00a0 1.1. ...\n\u00a0 \u00a0 1.2. Identify services running on\nopen ports.\n\u00a0 \u00a0 - FTP filtered, OpenSSH 7.6p1,\nApache 2.4.18\n2. Perform the testing\n\u00a0 \u00a0 2.1 Scan the web port\n\u00a0 \u00a0 2.2 Check if the SSH service\ncontain known vulnerabilities.\nAvailable Tasks\n1.\u00a0Scan the web port\n2. Check if the SSH service contain\nknown vulnerabilities.\nDecided Task\nReasoning: the web services are\nusually more vulnerable; Decide to\nwork on web service\n- Web is running Apache 2.4.18.\na-2) Updated Task Tree\nb-2) Available Leaf-node Tasks\nc-2) Decided Task\nCommand to Execute\nUse nikto to scan the target web\nservice. The command is `nikto -h\n<ip-address>`.\nGeneration Module\nd-2) Command to Execute\nNikto Output\n+ Server: Apache/2.4.18 (Ubuntu)\n+ The anti-clickjacking X-Frame-\nOptions header is not present.\n...\ne-1) Execution Result\ne-2) Execution Result\nCross\nCheck\u00a0\nFigure 5: A demonstration of the task-tree update process on the testing target HTB-Carrier\ncuted in the testing environment, and the execution result is\nconveyed to the Reasoning Module to update the PTT. In\na-2), the Reasoning Module integrates the previous scanning\nresult into the PTT, cross-referencing it with the earlier PTT\nto update only the leaf nodes. It then looks for the available\ntasks to execute. In this case, two tasks emerge: scanning\nthe web service on port 80 and checking the SSH service for\nknown vulnerabilities. The LLM evaluates which task is more\npromising and chooses to investigate the web service, often\nseen as more vulnerable. This task is passed to the Generation\nModule. The Generation Module turns this general task into\na detailed process, employing nikto [50], a commonly used\nweb scanning script. The iterative process continues until the\ntester completes the penetration testing task.\n5.5\nParsing Module\nThe Parsing Module operates as a supportive interface, en-\nabling effective processing of the natural language informa-\ntion exchanged between the user and the other two core mod-\nules. Two needs can primarily justify the existence of this\nmodule. First, security testing tool outputs are typically ver-\nbose, laden with extraneous details, making it computationally\nexpensive and unnecessarily redundant to feed these extended\noutputs directly into the LLMs. Second, users without spe-\ncialized knowledge in the security domain may struggle to\nextract key insights from security testing outputs, presenting\nchallenges in summarizing crucial testing information. Con-\nsequently, the Parsing Module is essential in streamlining and\ncondensing this information.\nIn PENTESTGPT, the Parsing Module is devised to handle\nfour distinct types of information: (1) user intentions, which\nare directives provided by the user to dictate the next course\nof action, (2) security testing tool outputs, which represent the\nraw outputs generated by an array of security testing tools, (3)\nraw HTTP web information, which encompasses all raw in-\nformation derived from HTTP web interfaces, and (4) source\ncodes extracted during the penetration testing process. Users\nmust specify the category of the information they provide,\nand each category is paired with a set of carefully designed\nprompts. For source code analysis, we integrate the GPT-4\ncode interpreter [51] to execute the task.\n5.6\nActive Feedback\nWhile LLMs can produce insightful outputs, their outcomes\nsometimes require revisions. To facilitate this, we introduce\nan interactive handle in PENTESTGPT, known as active feed-\nback, which allows the user to interact directly with the Rea-\nsoning Module. A vital feature of this process is that it does\nnot alter the context within the Reasoning Module unless the\nuser explicitly desires to update some information. The rea-\nsoning context, including the PTT, is stored as a fixed chunk\nof tokens. This chunk of tokens is provided to a new LLM\nsession during an active feedback interaction, and users can\npose questions regarding them. This ensures that the original\nsession remains unaffected, and users can always query the\nreasoning context without making unnecessary changes. If\nthe user believes it necessary to update the PTT, they can\nexplicitly instruct the model to update the reasoning context\nhistory accordingly. This provides a robust and flexible frame-\nwork for the user to participate in the decision-making process\nactively.\n5.7\nDiscussion\nWe explore various design alternatives for PENTESTGPT\nto tackle the challenges identified in Exploratory Study. We\nhave experimented with different designs, and here we discuss\nsome key decisions.\n11\nAddressing Context Loss with Token Size: a straight-\nforward solution to alleviate context loss is the employment\nof LLM models with an extended token size. For instance,\nGPT-4 provides versions with 8k and 32k token size limits.\nThis approach, however, confronts two substantial challenges.\nFirst, even a 32k token size might be inadequate for penetra-\ntion testing scenarios, as the output of a single testing tool\nlike dirbuster [52] may comprise thousands of tokens. Con-\nsequently, GPT-4 with a 32k limit cannot retain the entire\ntesting context. Second, even when the entire conversation his-\ntory fits within the 32k token boundary, the API may still skew\ntowards recent content, focusing on local tasks and overlook-\ning broader context. These issues guided us in formulating\nthe design for the Reasoning Module and the Parsing Module.\nVector Database to Improve Context Length: Another\ntechnique to enhance the context length of LLMs involves\na vector database [53, 54]. By transmuting data into vector\nembeddings, LLMs can efficiently store and retrieve informa-\ntion, practically creating long-term memory. Theoretically,\npenetration testing tool outputs could be archived in the vector\ndatabase. In practice, though, we observe that many results\nclosely resemble and vary in only nuanced ways. This sim-\nilarity often leads to confused information retrieval. Solely\nrelying on a vector database fails to overcome context loss in\npenetration testing tasks. Integrating the vector database into\nthe design of PENTESTGPT is an avenue for future research.\nPrecision in Information Extraction: Precise information\nextraction is crucial for conserving token usage and avoiding\nverbosity in LLMs [55, 56]. Rule-based methods are com-\nmonly employed to extract diverse information. However,\nrule-based techniques are engineeringly expensive given nat-\nural language\u2019s inherent complexity and the variety of infor-\nmation types in penetration testing. We devise the Parsing\nModule to manage several general input information types, a\nstrategy found to be both feasible and efficient.\nLimitations of LLMs: LLMs are not an all-encompassing\nsolution. Present LLMs exhibit flaws, including hallucina-\ntion [57,58] and outdated knowledge. Our mitigation efforts,\nsuch as implementing task tree verification to ward off hallu-\ncination, might not completely prevent the Reasoning Module\nfrom producing erroneous outcomes. Thus, a human-in-the-\nloop strategy becomes vital, facilitating the input of necessary\nexpertise and guidance to steer LLMs effectively.\n6\nEvaluation\nIn this section, we assess the performance of PENTESTGPT,\nfocusing on the following four research questions:\nRQ3 (Performance): How does the performance of PEN-\nTESTGPT compare with that of native LLM models and hu-\nman experts?\nRQ4 (Strategy): Does PENTESTGPT employ different\nproblem-solving strategies compared to those utilized by\nLLMs or human experts?\nRQ5 (Ablation): How does each module within PENTEST-\nGPT contribute to the overall penetration testing perfor-\nmance?\nRQ6 (Practicality): Is PENTESTGPT practical and effective\nin real-world penetration testing tasks?\n6.1\nEvaluation Settings\nWe implement PENTESTGPT with 1,900 lines of Python3\ncode and 740 lines of prompts, available at our anonymized\nproject website [32]. We evaluate its performance over the\nbenchmark constructed in Section 3, and additional real-world\npenetration testing machines (Section 6.5). In this evaluation,\nwe integrate PENTESTGPT with GPT-3.5 and GPT-4 to\nform two working versions: PENTESTGPT-GPT-3.5 and\nPENTESTGPT-GPT-4. Due to the lack of API access, we\ndo not select other LLM models, such as Bard. In line with\nour previous experiments, we use the same experiment envi-\nronment setting and instruct PENTESTGPT to only use the\nnon-automated penetration testing tools.\n6.2\nPerformance Evaluation (RQ3)\nThe overall task completion status of PENTESTGPT-GPT-\n3.5, PENTESTGPT-GPT-4, and the naive usage of LLMs\nis illustrated in Figure 6a. As the Figure shows, our solu-\ntions powered by LLMs demonstrate superior penetration test-\ning capabilities compared to the naive application of LLMs.\nSpecifically, PENTESTGPT-GPT-4 surpasses the other three\nsolutions, successfully solving 6 out of 7 easy difficulty targets\nand 2 out of 4 medium difficulty targets. This performance\nindicates that PENTESTGPT-GPT-4 can handle penetration\ntesting targets ranging from easy to medium difficulty lev-\nels. Meanwhile, PENTESTGPT-GPT-3.5 manages to solve\nonly two challenges of easy difficulty, a discrepancy that can\nbe attributed to GPT-3.5 lacking the knowledge related to\npenetration testing found in GPT-4.\nThe sub-task completion status of PENTESTGPT-GPT-3.5,\nPENTESTGPT-GPT-4, and the naive usage of LLM is shown\nin Figure 6b. As the Figure illustrates, both PENTESTGPT-\nGPT-3.5 and PENTESTGPT-GPT-4 perform better than\nthe standard utilization of LLMs. It is noteworthy that\nPENTESTGPT-GPT-4 not only solves one more medium\ndifficulty target compared to naive GPT-4 but also accom-\nplishes 111% more sub-tasks (57 vs. 27). This highlights that\nour design effectively addresses context loss challenges and\nleads to more promising testing results. Nevertheless, all the\nsolutions struggle with hard difficulty testing targets. As elab-\norated in Section 4, hard difficulty targets typically demand\na deep understanding from the penetration tester. To reach\ntesting objectives, they may require modifications to existing\npenetration testing tools or scripts. Our design does not ex-\npand the LLMs\u2019 knowledge of vulnerabilities, so it does not\nnotably enhance performance on these more complex targets.\n12\nEasy\nMedium\nHard\n1\n0\n0\n4\n1\n0\n2\n0\n0\n6\n2\n0\nGPT-3.5\nGPT-4\nPentestGPT-GPT-3.5\nPentestGPT-GPT-4\n(a) Overall completion status.\nEasy\nMedium\nHard\n24\n13\n5\n52\n27\n8\n31\n14\n5\n69\n57\n12\nGPT-3.5\nGPT-4\nPentestGPT-GPT-3.5\nPentestGPT-GPT-4\n(b) Subtask completion status.\nFigure\n6:\nThe\nperformance\nof\nGPT-3.5, GPT-4,\nPENTESTGPT-GPT-3.5,\nand\nPENTESTGPT-GPT-4\non overall target completion and sub-task completion.\n6.3\nStrategy Evaluation (RQ4)\nWe analyze PENTESTGPT\u2019s problem-solving methods, com-\nparing them with LLMs and human experts. Through manual\nexamination, we identify PENTESTGPT\u2019s approach to pen-\netration testing. Notably, PENTESTGPT breaks down tasks\nsimilarly to human experts and prioritizes effectively. Rather\nthan just addressing the latest identified task, PENTESTGPT\nidentifies key sub-tasks that can result in success.\nFigure 7 contrasts the strategies of GPT-4 and PENTEST-\nGPT on the VulnHub machine, Hackable II [59]. This ma-\nchine features two vulnerabilities: an FTP service for file\nuploads and a web service to view FTP files. A valid exploit\nrequires both services. The figure shows GPT-4 starting with\nthe FTP service and identifying the upload vulnerability (\u2776-\n\u2778). Yet, it does not link this to the web service, causing an\nincomplete exploit. In contrast, PENTESTGPT shifts between\nthe FTP and web services. It first explores both services (\u2776-\n\u2777), then focuses on the FTP (\u2778-\u2779), realizing the FTP and\nweb files are identical. With this insight, PENTESTGPT in-\nstructs the tester to upload a shell (\u277a), achieving a successful\nreverse shell (\u277b). This matches the solution guide and un-\nderscores PENTESTGPT\u2019s adeptness at integrating various\ntesting aspects.\nOur second observation is that although PENTESTGPT be-\nhaves more similarly to human experts, it still exhibits some\nstrategies that humans will not apply. For instance, PENTEST-\nPort\nScanning\nFTP\nService\nWeb\nService\nWeb\nScanning\nFile\nBrowsing\nArbitrary\nFile Upload\n1\n2\n3\n4\n5\nPort\nScanning\nFTP\nService\nWeb\nService\nShell\nUpload\nFile\nBrowsing\nArbitrary\nFile Upload\n1\n3\n4\n2\n5\nReverse\nShell\n6\n5\nFlow 1\nFlow 2\nFlow 1\nFlow 2\nFlow 1 & 2 are independent\nFlow 1 & 2 are interrelated\nGPT-4\nExcalibur\nFigure 7: Penetration testing strategy comparison between\nGPT-3.5 and PENTESTGPT on VulnHub-Hackable II.\nGPT still prioritizes brute-force attacks before vulnerability\nscanning. This is obvious in cases where PENTESTGPT al-\nways tries to brute-force the SSH service on target machines.\nWe analyze cases where penetration testing with PENTEST-\nGPT failed, identifying three primary limitations. First, PEN-\nTESTGPT struggles with image interpretation. LLMs are\nunable to process images, which are crucial in certain penetra-\ntion testing scenarios. Addressing this limitation may require\nthe development of advanced multimodal models that can\ninterpret both text and visual data. Second, PENTESTGPT\nlacks the ability to employ certain social engineering tech-\nniques and to detect subtle cues. For example, while a human\ntester might generate a brute-force wordlist from information\nextracted from a target service, PENTESTGPT can retrieve\nnames from a web service but fails to guide the usage of\ntools needed to create a wordlist from these names. Third, the\nmodels struggle with accurate exploitation code construction\nwithin a limited number of trials. Despite some proficiency in\ncode comprehension and generation, the LLM falls short in\nproducing detailed exploitation scripts, particularly with low-\nlevel bytecode operations. These limitations underline the\nnecessity for improvement in areas where human insight and\nintricate reasoning are still more proficient than automated\nsolutions.\n6.4\nAblation Study (RQ5)\nWe perform an ablation study on how the three modules:\nReasoning Module, Generation Module, and Parsing Module,\ncontribute to the performance of PENTESTGPT. We imple-\nment three variants:\n1. PENTESTGPT-NO-PARSING: the Parsing Module is de-\nactivated, causing all data to be directly fed into the\nsystem.\n2. PENTESTGPT-NO-GENERATION: the Generation Mod-\nule is deactivated, leading to the completion of task gen-\n13\nEasy\nMedium\nHard\n5\n1\n0\n4\n0\n0\n4\n1\n0\n6\n2\n0\nPentestGPT-no-Parsing\nPentestGPT-no-Reasoning\nPentestGPT-no-Generation\nPentestGPT\n(a) Overall completion status\nEasy\nMedium\nHard\n62\n44\n9\n44\n23\n7\n56\n35\n9\n69\n57\n12\nPentestGPT-no-Parsing\nPentestGPT-no-Reasoning\nPentestGPT-no-Generation\nPentestGPT\n(b) Sub-task completion status\nFigure 8: The performance of PENTESTGPT, PENTESTGPT-\nNO-ANNOTATION, PENTESTGPT-OPERATION-ONLY, and\nPENTESTGPT-PARAMETER-ONLY on both normalized aver-\nage code coverage (\u00b5LOC) and bug detection.\neration within the Reasoning Module itself. The prompts\nfor task generation remain consistent.\n3. PENTESTGPT-NO-REASONING: the Reasoning Module\nis disabled. Instead of PTT, this variant adopts the same\nmethodology utilized with LLMs for penetration testing,\nas delineated in the Exploratory Study.\nAll the variants are integrated with GPT-4 API for testing.\nFigure 8 presents the outcomes of three tested variants on\nour benchmarks. Among these, PENTESTGPT consistently\noutperforms the ablation baselines in both target and sub-task\ncompletion. Our primary observations include: (1) Without\nits Parsing Module, PENTESTGPT-NO-PARSING sees only a\nslight drop in performance for task and sub-task completion.\nThough parsing aids in penetration testing, the 32k token limit\ngenerally covers diverse outputs. The Reasoning Module\u2019s\ndesign, which retains the full testing context, compensates for\nthe absence of the Parsing Module, ensuring minimal perfor-\nmance reduction. (2) PENTESTGPT-NO-REASONING has the\nlowest success, achieving just 53.6% of the sub-tasks of the\nfull variant. This is even lower than the basic GPT-4 setup.\nThe Generation Module\u2019s added sub-tasks distort the LLM\ncontext. The mismatched prompts and extended generation\noutput cloud the original context, causing the test\u2019s failure.\n(3) PENTESTGPT-NO-GENERATION slightly surpasses the\nbasic GPT-4. Without the Generation Module, the process\nTable 5: PENTESTGPT performance over the active Hack-\nTheBox Challenges.\nMachine\nDifficulty\nCompletions\nCompleted Users\nCost (USD)\nSau\nEasy\n5/5 (\u2713)\n4798\n15.2\nPilgramage\nEasy\n3/5 (\u2713)\n5474\n12.6\nTopology\nEasy\n0/5 (\u2717)\n4500\n8.3\nPC\nEasy\n4/5 (\u2713)\n6061\n16.1\nMonitorsTwo\nEasy\n3/5 (\u2713)\n8684\n9.2\nAuthority\nMedium\n0/5 (\u2717)\n1209\n11.5\nSandworm\nMedium\n0/5 (\u2717)\n2106\n10.2\nJupiter\nMedium\n0/5 (\u2717)\n1494\n6.6\nAgile\nMedium\n2/5 (\u2713)\n4395\n22.5\nOnlyForYou\nMedium\n0/5 (\u2717)\n2296\n19.3\nTotal\n-\n17/50 (6)\n-\n131.5\nTable 6: PENTESTGPT performance over picoMini CTF.\nChallenge\nCategory\nScore\nCompletions\nlogin\nweb\n100\n5/5 (\u2713)\nadvance-potion-making\nforensics\n100\n3/5 (\u2713)\nspelling-quiz\ncrypto\n100\n4/5 (\u2713)\ncaas\nweb\n150\n2/5 (\u2713)\nXtrOrdinary\ncrypto\n150\n5/5 (\u2713)\ntripplesecure\ncrypto\n150\n3/5 (\u2713)\nclutteroverflow\nbinary\n150\n1/5 (\u2713)\nnot crypto\nreverse\n150\n0/5 (\u2717)\nscrambled-bytes\nforensics\n200\n0/5 (\u2717)\nbreadth\nreverse\n200\n0/5 (\u2717)\nnotepad\nweb\n250\n1/5 (\u2713)\ncollege-rowing-team\ncrypto\n250\n2/5 (\u2713)\nfermat-strings\nbinary\n250\n0/5 (\u2717)\ncorrupt-key-1\ncrypto\n350\n0/5 (\u2717)\nSaaS\nbinary\n350\n0/5 (\u2717)\nriscy business\nreverse\n350\n0/5 (\u2717)\nhomework\nbinary\n400\n0/5 (\u2717)\nlockdown-horses\nbinary\n450\n0/5 (\u2717)\ncorrupt-key-2\ncrypto\n500\n0/5 (\u2717)\nvr-school\nbinary\n500\n0/5 (\u2717)\nMATRIX\nreverse\n500\n0/5 (\u2717)\nmirrors standard LLM usage. The module\u2019s main role is guid-\ning precise testing operations. Without it, testers might require\nadditional information to use essential tools or scripts.\n6.5\nPracticality Study (RQ6)\nWe demonstrate PENTESTGPT\u2019s applicability in real-world\npenetration testing scenarios, extending beyond standardized\nbenchmarks. For this analysis, we deploy PENTESTGPT in\ntwo distinct challenge formats: (1) HackTheBox (HTB) ac-\ntive machine challenges, which present a series of real-world\npenetration testing scenarios accessible to a global audience.\nWe selected 10 machines from the active list, comprising five\ntargets of easy difficulty and five of intermediate difficulty.\n(2) picoMini [21], a jeopardy-style Capture The Flag (CTF)\ncompetition organized by Carnegie Mellon University and\nredpwn [60]. The competition featured 21 unique CTF chal-\n14\nlenges and drew participation from 248 teams in its initial\nround. These challenges are now freely accessible online\nfor practice and reattempts. Our evaluation employed PEN-\nTESTGPT in conjunction with the GPT-4 32k token length\nAPI, defining the capture of the root flag as the metric for\na successful trial. We conduct five trials on each target and\ndocumented the number of successful captures. Note that we\nconsider single successful capture out of five trials as success-\nful attempt over the target. This criterion reflects the iterative\nnature of real-world penetration testing and CTF challenges,\nwhere multiple attempts are allowed, and success is ultimately\ndetermined by achieving the objective at least once.\nTables 5 presents PENTESTGPT\u2019s performance across both\nsets of challenges. In the HackTheBox challenges, PENTEST-\nGPT successfully completed four easy and one medium diffi-\nculty challenges, incurring a total cost of 131.5 USD\u2014an aver-\nage of 21.9 USD per target. This performance indicates PEN-\nTESTGPT\u2019s effectiveness in tackling easy to intermediate-\nlevel penetration tests at a reasonable cost. Table 6 demon-\nstrates the performance of PENTESTGPT in the picoMini\nCTF. In particular, PENTESTGPT managed to solve 9 out\nof 21 challenges, with the average cost per attempt being\n5.1 USD. Ultimately, PENTESTGPT accumulated a total of\n1400 points4 and ranked 24th out of 248 teams with valid\nsubmissions [61]. These outcomes suggest a promising per-\nformance of PENTESTGPT on real-world penetration testing\ntasks among various types of challenges.\n7\nDiscussion\nIt is possible that LLMs used by PENTESTGPT were trained\non walkthroughs of the benchmark machines, which could\ninvalidate evaluation results. To counter this, we employ two\nmethods. First, We ensure the LLM lacks prior knowledge of\nthe target machine. We ascertain this by querying LLMs about\nthe tested machine\u2019s familiarity. Secondly, our benchmark\ncomprises machines launched post-2021, ensuring they are\nbeyond OpenAI models\u2019 training data. Our study on recent\nHackTheBox challenges confirms PENTESTGPT\u2019s ability to\nsolve without pre-existing target knowledge.\nWhile we aim for universally applicable prompts, certain\nLLMs avoid producing specific hacking content. For instance,\nOpenAI has implement model alignments [62] to ensure the\nGPT model outputs do not violate usage policies, including\ngenerating malicious exploitation contents. We incorporate\njailbreak techniques [63\u201369] to coax LLMs into producing\nrelevant data. Improving reproducibility of PENTESTGPT\nremains a focus area.\nLLMs occasionally \"hallucinate\" [57], producing outputs\ndeviating from training data. This impacts our tool\u2019s depend-\nability. To combat this, we\u2019re researching methods [70] to\nminimize hallucination, anticipating this will boost our tool\u2019s\n4Each challenge\u2019s points were assigned based on its difficulty level\nefficiency and reliability.\nThe ethical implications of employing PENTESTGPT in\npenetration testing are significant and warrant careful consid-\neration. While PENTESTGPT can greatly enhance security by\nidentifying vulnerabilities, its capabilities also pose potential\nrisks of misuse. To mitigate these risks, we have implemented\nseveral strategies. We actively promote ethical guidelines for\nthe use of PENTESTGPT and collaborate closely with cy-\nbersecurity communities to prevent misuse. Moreover, we\nhave incorporated monitoring modules [71] to track the tool\u2019s\nusage and are committed to ensuring that it is not used in-\nappropriately. These measures are designed to balance the\nadvantages of advanced penetration testing tools with ethi-\ncal considerations, ensuring that PENTESTGPT serves as a\npositive contribution to cybersecurity defenses.\n8\nConclusion\nThis work delves into the potential and constraints of LLMs\nfor penetration testing. Building a novel benchmark, we shed\nlight on LLM performance in this complex area. While LLMs\nmanage basic tasks and use testing tools effectively, they\nstruggle with task-specific context and attention challenges. In\nresponse, we present PENTESTGPT, a tool emulating human\npenetration testing actions. Influenced by real-world testing\nteams, PENTESTGPT comprises Reasoning, Generation, and\nParsing Modules, promoting a segmented problem-solving\nstrategy. Our comprehensive evaluation of PENTESTGPT\nunderscores its promise, but also areas where human skills\nsurpass present technology. This work paves the way for\nfuture advancements in the crucial realm of cybersecurity.\n15\nReferences\n[1] A. Applebaum, D. Miller, B. Strom, H. Foster, and\nC. Thomas, \u201cAnalysis of automated adversary emulation\ntechniques,\u201d in Proceedings of the Summer Simulation\nMulti-Conference.\nSociety for Computer Simulation\nInternational, 2017, p. 16.\n[2] B. Arkin, S. Stender, and G. McGraw, \u201cSoftware pene-\ntration testing,\u201d IEEE Security & Privacy, vol. 3, no. 1,\npp. 84\u201387, 2005.\n[3] G. Deng, Z. Zhang, Y. Li, Y. Liu, T. Zhang, Y. Liu, G. Yu,\nand D. Wang, \u201cNautilus: Automated restful api vulnera-\nbility detection.\u201d\n[4] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang,\nY. Hou, Y. Min, B. Zhang, J. Zhang, Z. Dong et al.,\n\u201cA survey of large language models,\u201d arXiv preprint\narXiv:2303.18223, 2023.\n[5] Y. Liu, T. Han, S. Ma, J. Zhang, Y. Yang, J. Tian, H. He,\nA. Li, M. He, Z. Liu et al., \u201cSummary of chatgpt/gpt-\n4 research and perspective towards the future of large\nlanguage models,\u201d arXiv preprint arXiv:2304.01852,\n2023.\n[6] J. Wei, Y. Tay, R. Bommasani, C. Raffel, B. Zoph,\nS. Borgeaud, D. Yogatama, M. Bosma, D. Zhou, D. Met-\nzler et al., \u201cEmergent abilities of large language models,\u201d\narXiv preprint arXiv:2206.07682, 2022.\n[7] V. Mayoral-Vilches, G. Deng, Y. Liu, M. Pinzger, and\nS. Rass, \u201cExploitflow, cyber security exploitation routes\nfor game theory and ai research in robotics,\u201d 2023.\n[8] Y. Zhang, W. Song, Z. Ji, Danfeng, Yao, and N. Meng,\n\u201cHow well does llm generate security tests?\u201d 2023.\n[9] Z. He, Z. Li, S. Yang, A. Qiao, X. Zhang, X. Luo, and\nT. Chen, \u201cLarge language models for blockchain secu-\nrity: A systematic literature review,\u201d 2024.\n[10] N. Antunes and M. Vieira, \u201cBenchmarking vulnerability\ndetection tools for web services,\u201d in 2010 IEEE Interna-\ntional Conference on Web Services.\nIEEE, 2010, pp.\n203\u2013210.\n[11] P. Xiong and L. Peyton, \u201cA model-driven penetration\ntest framework for web applications,\u201d in 2010 Eighth\nInternational Conference on Privacy, Security and Trust.\nIEEE, 2010, pp. 173\u2013180.\n[12] \u201cHackthebox: Hacking training for the best.\u201d [Online].\nAvailable: http://www.hackthebox.com/\n[13] [Online]. Available: https://www.vulnhub.com/\n[14] \u201cOWASP Foundation,\u201d https://owasp.org/.\n[15] MITRE, \u201cCommon Weakness Enumeration (CWE),\u201d\nhttps://cwe.mitre.org/index.html, 2021.\n[16] \u201cModels - openai api,\u201d https://platform.openai.com/\ndocs/models/, (Accessed on 02/02/2023).\n[17] \u201cGpt-4,\u201d https://openai.com/research/gpt-4, (Accessed\non 06/30/2023).\n[18] Google, \u201cBard,\u201d https://bard.google.com/?hl=en.\n[19] S. Mauw and M. Oostdijk, \u201cFoundations of attack trees,\u201d\nvol. 3935, 07 2006, pp. 186\u2013198.\n[20] [Online].\nAvailable:\nhttps://app.hackthebox.com/\nmachines/list/active\n[21] [Online]. Available: https://picoctf.org/competitions/\n2021-redpwn.html\n[22] V. Mayoral-Vilches, G. Deng, Y. Liu, M. Pinzger, and\nS. Rass, \u201cExploitflow, cyber security exploitation routes\nfor game theory and ai research in robotics,\u201d arXiv\npreprint arXiv:2308.02152, 2023.\n[23] Rapid7, \u201cMetasploit framework,\u201d 2023, accessed: 30-07-\n2023. [Online]. Available: https://www.metasploit.com/\n[24] G. Weidman, Penetration testing: a hands-on introduc-\ntion to hacking.\nNo starch press, 2014.\n[25] F. Abu-Dabaseh and E. Alshammari, \u201cAutomated pene-\ntration testing: An overview,\u201d in The 4th International\nConference on Natural Language Computing, Copen-\nhagen, Denmark, 2018, pp. 121\u2013129.\n[26] J. Schwartz and H. Kurniawati, \u201cAutonomous pene-\ntration testing using reinforcement learning,\u201d arXiv\npreprint arXiv:1905.05965, 2019.\n[27] H. Pearce, B. Ahmad, B. Tan, B. Dolan-Gavitt, and\nR. Karri, \u201cAsleep at the keyboard? assessing the security\nof github copilot\u2019s code contributions,\u201d in 2022 IEEE\nSymposium on Security and Privacy (SP).\nIEEE, 2022,\npp. 754\u2013768.\n[28] H. Pearce, B. Tan, B. Ahmad, R. Karri, and B. Dolan-\nGavitt, \u201cExamining zero-shot vulnerability repair with\nlarge language models,\u201d in 2023 IEEE Symposium on\nSecurity and Privacy (SP). IEEE, 2023, pp. 2339\u20132356.\n[29] \u201cOWASP\nJuice-Shop\nProject,\u201d\nhttps://owasp.org/\nwww-project-juice-shop/, 2022.\n[30] NIST and E. Aroms, \u201cNist special publication 800-115\ntechnical guide to information security testing and as-\nsessment,\u201d 2012.\n[31] [Online].\nAvailable:\nhttps://cwe.mitre.org/data/\ndefinitions/89.html\n16\n[32] A.\nAuthors,\n\u201cExcalibur:\nAutomated\npenetra-\ntion\ntesting,\u201d\nhttps://anonymous.4open.science/\nr/EXCALIBUR-Automated-Penetration-Testing/\nREADME.md, 2023.\n[33] E. Collins, \u201cLamda: Our breakthrough conversation\ntechnology,\u201d May 2021. [Online]. Available: https:\n//blog.google/technology/ai/lamda/\n[34] \u201cChatgpt,\u201d\nhttps://chat.openai.com/, (Accessed on\n02/02/2023).\n[35] \u201cThe most advanced penetration testing distribution.\u201d\n[Online]. Available: https://www.kali.org/\n[36] S.\nInc.,\n\u201cNexus\nvulnerability\nscanner.\u201d\n[On-\nline]. Available: https://www.sonatype.com/products/\nvulnerability-scanner-upload\n[37] S. Rahalkar and S. Rahalkar, \u201cOpenvas,\u201d Quick Start\nGuide to Penetration Testing: With NMAP, OpenVAS\nand Metasploit, pp. 47\u201371, 2019.\n[38] B. Guimaraes and M. Stampar, \u201csqlmap: Automatic SQL\ninjection and database takeover tool,\u201d https://sqlmap.\norg/, 2022.\n[39] J. Yeo, \u201cUsing penetration testing to enhance your com-\npany\u2019s security,\u201d Computer Fraud & Security, vol. 2013,\nno. 4, pp. 17\u201320, 2013.\n[40] [Online]. Available: https://nmap.org/\n[41] [Online]. Available: https://help.openai.com/en/articles/\n7127966-what-is-the-difference-between-the-gpt-4-models\n[42] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit,\nL. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin,\n\u201cAttention is all you need,\u201d 2023.\n[43] L. Yang, H. Chen, Z. Li, X. Ding, and X. Wu, \u201cChatgpt\nis not enough: Enhancing large language models with\nknowledge graphs for fact-aware language modeling,\u201d\n2023.\n[44] Y. Bang, S. Cahyawijaya, N. Lee, W. Dai, D. Su,\nB. Wilie, H. Lovenia, Z. Ji, T. Yu, W. Chung et al., \u201cA\nmultitask, multilingual, multimodal evaluation of chat-\ngpt on reasoning, hallucination, and interactivity,\u201d arXiv\npreprint arXiv:2302.04023, 2023.\n[45] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter,\nF. Xia, E. Chi, Q. Le, and D. Zhou, \u201cChain-of-thought\nprompting elicits reasoning in large language models,\u201d\n2023.\n[46] H. S. Lallie, K. Debattista, and J. Bal, \u201cA review of\nattack graph and attack tree visual syntax in cyber\nsecurity,\u201d Computer Science Review, vol. 35, p. 100219,\n2020. [Online]. Available: https://www.sciencedirect.\ncom/science/article/pii/S1574013719300772\n[47] K. Barbar, \u201cAttributed tree grammars,\u201d Theoretical\nComputer Science, vol. 119, no. 1, pp. 3\u201322, 1993.\n[Online]. Available: https://www.sciencedirect.com/\nscience/article/pii/030439759390337S\n[48] H. Sun, X. Li, Y. Xu, Y. Homma, Q. Cao, M. Wu, J. Jiao,\nand D. Charles, \u201cAutohint: Automatic prompt optimiza-\ntion with hint generation,\u201d 2023.\n[49] Sep\n2018.\n[Online].\nAvailable:\nhttps://forum.\nhackthebox.com/t/carrier/963\n[50] \u201cNikto web server scanner.\u201d [Online]. Available:\nhttps://github.com/sullo/nikto\n[51] [Online].\nAvailable:\nhttps://openai.com/blog/\nchatgpt-plugins#code-interpreter\n[52] KajanM, \u201cKajanm/dirbuster: a multi threaded java\napplication designed to brute force directories and files\nnames on web/application servers.\u201d [Online]. Available:\nhttps://github.com/KajanM/DirBuster\n[53] J. Wang, X. Yi, R. Guo, H. Jin, P. Xu, S. Li, X. Wang,\nX. Guo, C. Li, X. Xu et al., \u201cMilvus: A purpose-built\nvector data management system,\u201d in Proceedings of the\n2021 International Conference on Management of Data,\n2021, pp. 2614\u20132627.\n[54] R. Guo, X. Luan, L. Xiang, X. Yan, X. Yi, J. Luo,\nQ. Cheng, W. Xu, J. Luo, F. Liu et al., \u201cManu: a cloud na-\ntive vector database management system,\u201d Proceedings\nof the VLDB Endowment, vol. 15, no. 12, pp. 3548\u20133561,\n2022.\n[55] G. Wang, Y. Li, Y. Liu, G. Deng, T. Li, G. Xu, Y. Liu,\nH. Wang, and K. Wang, \u201cMetmap: Metamorphic test-\ning for detecting false vector matching problems in llm\naugmented generation,\u201d 2024.\n[56] Y. Li, Y. Liu, G. Deng, Y. Zhang, W. Song, L. Shi,\nK. Wang, Y. Li, Y. Liu, and H. Wang, \u201cGlitch tokens in\nlarge language models: Categorization taxonomy and\neffective detection,\u201d 2024.\n[57] M. Zhang, O. Press, W. Merrill, A. Liu, and N. A.\nSmith, \u201cHow language model hallucinations can snow-\nball,\u201d arXiv preprint arXiv:2305.13534, 2023.\n[58] N. Li, Y. Li, Y. Liu, L. Shi, K. Wang, and H. Wang, \u201cHal-\nluvault: A novel logic programming-aided metamorphic\ntesting framework for detecting fact-conflicting halluci-\nnations in large language models,\u201d 2024.\n[59] [Online]. Available: https://www.vulnhub.com/entry/\nhackable-ii,711/\n17\n[60] [Online]. Available: https://redpwn.net/\n[61] [Online].\nAvailable:\nplay.picoctf.org/events/67/\nscoreboards\n[62] Y. Liu, Y. Yao, J.-F. Ton, X. Zhang, R. Guo, H. Cheng,\nY. Klochkov, M. F. Taufiq, and H. Li, \u201cTrustworthy llms:\na survey and guideline for evaluating large language\nmodels\u2019 alignment,\u201d 2023.\n[63] Y. Liu, G. Deng, Z. Xu, Y. Li, Y. Zheng, Y. Zhang,\nL. Zhao, T. Zhang, and Y. Liu, \u201cJailbreaking chatgpt via\nprompt engineering: An empirical study,\u201d arXiv preprint\narXiv:2305.13860, 2023.\n[64] G. Deng, Y. Liu, Y. Li, K. Wang, Y. Zhang, Z. Li,\nH. Wang, T. Zhang, and Y. Liu, \u201cMasterkey: Automated\njailbreaking of large language model chatbots,\u201d in\nProceedings 2024 Network and Distributed System\nSecurity Symposium, ser. NDSS 2024.\nInternet Society,\n2024. [Online]. Available: http://dx.doi.org/10.14722/\nndss.2024.24188\n[65] Y. Liu, G. Deng, Y. Li, K. Wang, Z. Wang, X. Wang,\nT. Zhang, Y. Liu, H. Wang, Y. Zheng, and Y. Liu,\n\u201cPrompt injection attack against llm-integrated applica-\ntions,\u201d 2024.\n[66] J. Li, Y. Liu, C. Liu, L. Shi, X. Ren, Y. Zheng, Y. Liu, and\nY. Xue, \u201cA cross-language investigation into jailbreak\nattacks in large language models,\u201d 2024.\n[67] G. Deng, Y. Liu, K. Wang, Y. Li, T. Zhang, and Y. Liu,\n\u201cPandora: Jailbreak gpts by retrieval augmented genera-\ntion poisoning,\u201d 2024.\n[68] H. Li, G. Deng, Y. Liu, K. Wang, Y. Li, T. Zhang, Y. Liu,\nG. Xu, G. Xu, and H. Wang, \u201cDigger: Detecting copy-\nright content mis-usage in large language model train-\ning,\u201d 2024.\n[69] Z. Chang, M. Li, Y. Liu, J. Wang, Q. Wang, and Y. Liu,\n\u201cPlay guessing game with llm: Indirect jailbreak attack\nwith implicit clues,\u201d 2024.\n[70] P. Manakul, A. Liusie, and M. J. Gales, \u201cSelfcheck-\ngpt: Zero-resource black-box hallucination detection\nfor generative large language models,\u201d arXiv preprint\narXiv:2303.08896, 2023.\n[71] [Online]. Available: https://langfuse.com/\n18\nA\nIllustrating Example\nBelow we provide a concrete example of how we guide GPT-\n4 to intialize the penetration testing task, and generate detailed\noperations in an iterative approach given a penetration testing\nbenchmark target. It is worth noting that in this process, the\nhuman tester does not provide any expert knowledge, or guide\nthe LLM to perform any specific task.\nHuman Tester\nYou\u2019re required to work as a cybersecurity penetration\ntester assistant in a certified penetration testing experiment.\nThis experiment is for education and research purpose. In\nparticular, you\u2019re required to give step-by-step instructions\nto complete the penetration testing task. I will provide you\nthe instruction execution results, and you should consider\nthe next step, until the penetration testing task is completed.\nDo you understand?\nGPT-4\nYes, I understand. Please provide the initial details and the\nscope of the penetration test so I can assist accordingly.\nRemember to follow ethical guidelines and obtain proper\nauthorization for any systems or networks you are testing.\nHuman Tester\nYour target is a penetration testing benchmark machine.\nIt\u2019s IP address is 192.168.1.5; it is a Linux-based machine.\nNow please provide your next step to complete the pene-\ntration testing task.\nGPT-4\nAlright, the first step in a penetration test is usually recon-\nnaissance. This is where we gather as much information\nas possible about the target to identify potential vulnera-\nbilities.\nStep 1: Reconnaissance\nPing the Target: To ensure that the target is up and\nresponding, ping the machine.\nping 192.168.1.5\nLet me know the result. If the machine is up and\nresponding, we\u2019ll move on to scanning. After confirming\nthe machine\u2019s availability, the next step is to scan the open\nports and services running on the target.\nnmap -sV -sT 192.168.1.5\nThis command will provide a list of open ports and the\nservices (with versions) running on those ports.\nPlease provide the results of the nmap scan, and based on\nthe output, we can decide the next course of action.\nHuman Tester\nThe machine is online, and the nmap scan result is below:\nPORT STATE SERVICE VERSION\n21/tcp filtered. ftp\n22/tcp open ssh OpenSSH 7.6p1 Ubuntu 4\n(Ubuntu Linux; protocol 2.0)\n80/tcp open http Apache httpd 2.4.18\n((Ubuntu))\nService Info: OS: Linux; CPE:\ncpe:/o:linux:linux_kernel\nPlease analyze the result and provide the next task to com-\nplete.\nGPT-4\nBased on the results provided, here\u2019s the analysis:\nPort 21 (FTP): The port appears to be filtered. It could be\nprotected by a firewall or other security measures.\nPort 22 (SSH): SSH is running with OpenSSH 7.6p1. This\nversion could have potential vulnerabilities. Additionally,\nSSH could be brute-forced if password policies are weak.\nPort 80 (HTTP): An Apache HTTP server (version\n2.4.18) is running on the target machine. This is quite\ninteresting, as web servers can often have vulnerabilities\nin their configurations, default pages, or in web applica-\ntions running on them. Given these results, here\u2019s the\nrecommended next course of action:\nWeb Server Enumeration: Start with the web server as it\noften presents a larger attack surface. Visit the website in\na browser or use tools like curl or wget to view the source\ncode and check for any comments, hidden fields, or any\nother potential information leaks.\nUse a tool like nikto to perform a deeper scan of the web\nserver:\nnikto -h http://192.168.1.5\nThis will check for potential misconfigurations, default\nfiles, or any known vulnerabilities in the web server.\nAlso, use a tool like dirb or dirbuster to perform directory\nbrute-forcing, which might reveal hidden directories or\nfiles.\ndirb http://192.168.1.5\nB\nPTT Generation Process\nTo demonstrate the PTT Generation Process in its entirety, we\ndeploy PENTESTGPT on the benchmark system Hackable\nII. Figure 9 illustrates the complete PTT. In the figure, solid\n19\nboxes depict the penetration testing operations generated by\nPENTESTGPT, whereas dotted boxes outline the findings de-\nrived from these operations. Red boxes indicate operations\nthat do not yield significant findings, green boxes denote op-\nerations that lead to useful findings, and blue boxes represent\noperations generated by PENTESTGPT but not executed due\nto lower priority. For clearer presentation, we label the op-\nerations with numbers based on the operation sequences as\nprioritized by PENTESTGPT.\nAs depicted in Figure 9, PENTESTGPT emulates the strate-\ngic approach typically employed by human penetration testers,\nencompassing four steps including enumeration, web user ac-\ncess via reverse shell, and privilege escalation to both normal\nuser and root levels on this particular benchmark machine.\nNotably, PENTESTGPT demonstrates human-like reasoning\nby linking findings across different stages. During the Web\nUser Access phase, it connects a vulnerability in the FTP ser-\nvice with earlier findings from the web service to facilitate\nan attack by uploading and triggering a reverse shell via FTP.\nSimilarly, in the Privilege Escalation to Normal User phase,\nPENTESTGPT identifies a user named \"shrek\" on the sys-\ntem, which it then exploits to crack the password and escalate\nprivileges. These instances illustrate PENTESTGPT\u2019s capabil-\nity to integrate and leverage disparate pieces of information,\nmirroring the cognitive processes of human testers.\nTable 7: Summarized 26 types of sub-tasks in the proposed penetration testing benchmark.\nPhase\nTechnique\nDescription\nRelated CWEs\nReconnaissance\nPort Scanning\nIdentify the open ports and related information on the target machine.\nCWE-668\nWeb Enumeration\nGather detailed information about the target\u2019s web applications.\nFTP Enumeration\nIdentify potential vulnerabilities in FTP (File Transfer Protocol) services to gain unauthorized access or data extraction.\nAD Enumeration\nIdentify potential vulnerabilities or mis-configurations in Active Directory Services\nNetwork Enumeration\nIdentify potential vulnerabilities within the network infrastructure to gain unauthorized access or disrupt services.\nOther enumerations\nObtain information of other services, such as smb service, custom protocols, etc.\nExploitation\nCommand Injection\nInject arbitrary commands to be run on a host machine, often leading to unauthorized system control.\nCWE-77, CWE-78\nCryptanalysis\nAnalyze the weak cryptographic methods or hash methods to obtain sensitive information\nCWE-310\nPassword Cracking\nCrack Passwords using rainbow tables or cracking tools\nCWE-326\nSQL Injection\nExploit SQL vulnerabilities, particularly SQL injection to manipulate databases and extract sensitive information.\nCWE-78\nXSS\nInject malicious scripts into web pages viewed by others, allowing for unauthorized access or data theft.\nCWE-79\nCSRF/SSRF\nExploit cross-site request forgery or server-site request fogery vulnerabilities\nCWE-352, CWE-918\nKnown Vulnerabilities\nExploit services with known vulnerabilities, particularly CVEs.\nCWE-1395\nXXE\nExploit XML extenral entitiy vulnerabilities to achieve code execution.\nCWE-611\nBrute-Force\nLeverage brute-force attacks to gain malicious access to target services\nCWE-799, CWE-770\nDeserialization\nExploit insecure deserialization processes to execute arbitrary code or manipulate object data.\nCWE-502\nOther Exploitations\nOther exploitations such as AD specific exploitation, prototype pollution, etc.\nPrivilege Escalation\nFile Analysis\nEnumerate system/service files to gain malicious information for privilege escalation\nCWE-200, CWE-538\nSystem Configuration Analysis\nEnumerate system/service configurations to gain malicious information for privilege escalation\nCWE-15, CWE-16\nCronjob Analysis\nAnalyze and manipulate scheduled tasks (cron jobs) to execute unauthorized commands or disrupt normal operations.\nCWE-250\nUser Access Exploitation\nExploit the improper settings of user access in combination with system properties to conduct privilege escalation\nCWE-284\nOther techniques\nOther general techniques, such as exploiting running processes with known vulnerabilities\nGeneral Techniques\nCode Analysis\nAnalyze source codes for potential vulnerabilities\nShell Construction\nCraft and utilize shell codes to manipulate the target system, often enabling control or extraction of data.\nSocial Engineering\nA various range of techniques to gain information to target system, such as construct custom password dictionary.\nOthers\nOther techniques\n20\n1 -Port Scanning\nSSH Service\nFTP Service\nWeb Service\n2 -Directory\nEnumeration\n4 -Injection Point\nIdentification (no\ninjection point)\n7 -Anonymous\nLogin\nArbitrary File\nUpload (Succ)\n6 -Brute Force\n(Fail)\nHidden Directory\n`/Files`\n3 -Vulnerbale\nFile Enumeration\n(not vulnerable)\n5 -Sensitive\nInformation\nEnumeration (Fail)\n8 -Examine\nuploaded file\nFile Uploaded to\nWeb Service\n9 -Reverse Shell\nConstruction and\nUpload\n10 -Trigger\nReverse Shell\nWeb user (www-\ndata)\u00a0access\n11 -System\nConfiguration\nEnumeration\n14\u00a0-cron\nenumeration (not\nuseful)\n15\u00a0-Local File\nEnumeration\nAn interesting\n\"runme.sh\"\n16\u00a0-Crach the\nhash in the file\nGet Password; use\n\"shrek\" as username\n17\u00a0-Privilege\nEscalation to\nuser \"shrek\"\nA user named\n\"shrek\" is presented\nthe user controls\nApache service\n12\u00a0-enumerate\n\"shrek\" files (no\naccess)\nUser \"shrek\"\naccess obtained\n13\u00a0-enumerate\nApache Service\n(not vulnerable)\n18\u00a0-System\nConfiguration\nEnumeration\ncron\nenumeration\nLocal File\nEnumeration\n\"shrek\" can run\nPython with sudo\naccess\n19\u00a0-Privilege\nEscalation to root\nVulnerable\nService\nEnumeration\nVulnerable\nService\nEnumeration\nEnumeration\nWeb User\nAccess\nPrivilege\nEscalation to\nNormal User\nPrivilege\nEscalation to\nroot\nFigure 9: A complete PTT example on the testing target Vulnhub-Hackable II\n21\n", "metadata": {"Published": "2024-06-02", "Title": "PentestGPT: An LLM-empowered Automatic Penetration Testing Tool", "Authors": "Gelei Deng, Yi Liu, V\u00edctor Mayoral-Vilches, Peng Liu, Yuekang Li, Yuan Xu, Tianwei Zhang, Yang Liu, Martin Pinzger, Stefan Rass", "Summary": "Penetration testing, a crucial industrial practice for ensuring system\nsecurity, has traditionally resisted automation due to the extensive expertise\nrequired by human professionals. Large Language Models (LLMs) have shown\nsignificant advancements in various domains, and their emergent abilities\nsuggest their potential to revolutionize industries. In this research, we\nevaluate the performance of LLMs on real-world penetration testing tasks using\na robust benchmark created from test machines with platforms. Our findings\nreveal that while LLMs demonstrate proficiency in specific sub-tasks within the\npenetration testing process, such as using testing tools, interpreting outputs,\nand proposing subsequent actions, they also encounter difficulties maintaining\nan integrated understanding of the overall testing scenario.\n  In response to these insights, we introduce PentestGPT, an LLM-empowered\nautomatic penetration testing tool that leverages the abundant domain knowledge\ninherent in LLMs. PentestGPT is meticulously designed with three\nself-interacting modules, each addressing individual sub-tasks of penetration\ntesting, to mitigate the challenges related to context loss. Our evaluation\nshows that PentestGPT not only outperforms LLMs with a task-completion increase\nof 228.6\\% compared to the \\gptthree model among the benchmark targets but also\nproves effective in tackling real-world penetration testing challenges. Having\nbeen open-sourced on GitHub, PentestGPT has garnered over 4,700 stars and\nfostered active community engagement, attesting to its value and impact in both\nthe academic and industrial spheres.", "entry_id": "http://arxiv.org/abs/2308.06782v2", "published_first_time": "2023-08-13", "comment": null, "journal_ref": null, "doi": null, "primary_category": "cs.SE", "categories": ["cs.SE", "cs.CR"], "links": ["http://arxiv.org/abs/2308.06782v2", "http://arxiv.org/pdf/2308.06782v2"]}, "type": "Document"}
{"page_content": "PTHELPER: AN OPEN SOURCE TOOL TO SUPPORT THE\nPENETRATION TESTING PROCESS\nA PREPRINT\nJacobo Casado de Gracia\nUniversidad Carlos III de Madrid\nAvda de la Universidad 30\nLegan\u00e9s, Madrid, Spain\n100488452@alumnos.uc3m.es,\nAlfonso S\u00e1nchez-Maci\u00e1n\nUniversidad Carlos III de Madrid\nAvda de la Universidad 30\nLegan\u00e9s, Madrid, Spain\nalfonsan@it.uc3m.es,\nJune 13, 2024\nABSTRACT\nOffensive security is one of the state of the art measures to protect enterprises and organizations.\nPenetration testing, broadly called pentesting, is a branch of offensive security designed to find, rate\nand exploit these vulnerabilities, in order to assess the security posture of an organization. This\nprocess is often time-consuming and the quantity of information that pentesters need to manage\nmight also be difficult to handle. This project takes a practical approach to solve the automation of\npentesting and proposes a usable tool, called PTHelper. This open-source tool has been designed in a\nmodular way to be easily upgradable by the pentesting community, and uses state of the art tools and\nartificial intelligence to achieve its objective.\nKeywords Offensive security \u00b7 penetration testing (pentesting) \u00b7 scan \u00b7 exploit \u00b7 vulnerability \u00b7 CVE \u00b7 artificial\nintelligence (AI).\n1\nIntroduction\nInternet is nowadays one of the core components of society\u2019s critical infraestructure. The fast and exponential\ndevelopment of the Internet and hardware and software technologies has also extended the attack surface available to\nmalicious agents. Popular examples of this situation are the WannaCry [1] or Mirai worms [2]. Wannacry ransomware\naffected more than 230,000 devices causing losses over 4 billon dollars . Mirai [2] infected more than 300,000 Internet\nof Thing and embedded devices. Indeed, the attack surface increments in size and depth, as more electronic devices are\nused, as well as new attack techniques are discovered.\nIn order to protect systems organizations have developed several security measures to protect their assets and people,\nincluding Offensive Security measures such as penetration testing (pentesting).\nPenetration testers are security professionals whose objective is to look for flaws in the whole context of an organization,\nmimicking a real attacker in order to fix them and prevent real security incidents. Another of their goals is to evaluate the\nefficiency of the defense methodologies, policies and tools used by an organization. In order to achieve their results they\nuse a wide variety of offensive security tools, like network scanners as nmap [3] or exploit frameworks as Metasploit.[4].\nMost of the time, the vulnerabilities found on pentesting assessments are publicly known and stored in databases such\nas the National Vulnerability Database created by MITRE[5] or the Common vulnerabilities and Exposures created by\nNIST[6].\nOne of the main problems regarding the pentesting assessments is that the data needed to create and deliver the technical\nand executive report often lies in distinct and heterogeneous sources and goes through different phases in the pentest. In\na brief summary, the data must first be collected during the pentesting assessment, then used in an intelligent way by the\npentester to find flaws, to be finally added into the report using a technical and executive format. These actions are very\narXiv:2406.08242v1  [cs.CR]  12 Jun 2024\narXiv Template\nA PREPRINT\ncommon nowadays and they have transformed the role of the pentester from a technical role into a role that involves\norganization and knowledge management, apart from technical skills.\nFurthermore, pentesting assessments are expensive time and money-consuming activities as it is a typically human-\ndriven procedure that requires an in-depth knowledge of the possible attack methodologies and the available hacking\ntools Therefore, automated tools to assist the pentester in his activity are increasingly needed, and often become crucial\nto the success of the pentest in the short time period previously specified by the scope.\nRelated works, such as [7] and [8], have demonstrated that some phases of the penetration testing process like the\nvulnerability Assessment and the Exploitation phase can be automated using techniques such as Artificial Intelligence.\nThis paper presents a new approach to carry out the automation of the pentests by developing an open-source and\nmodular tool called PTHelper. PTHelper does not try to take over the role of the pentesters as other tools, such as [9],\ndoes, but to give them support in automating the different phases of the process. It tries to fix the problems presented by\nthe previous approaches, by creating a tool that involves all the phases of the pentesting assessment, including reporting.\nThe paper is organised as follows. Section 2 offers an explanation of the context of penetration testing (pentesting)\nand performs an analysis to the state of the art techniques to the problem of automating the process. After that, the\napproach of PTHelper is presented. In Section 3, the tool\u2019s architecture and implementation is detailed and in Section\n4, experiments are performed in order to check that the objective has been accomplished and to look for points of\nimprovement. Finally, in Section 5, a conclusion and the future work in the development of PTHelper are detailed.\n2\nBackground\n2.1\nOffensive Security and Penetration Testing\nNowadays, taking defensive security measures is not enough to ensure the security of modern systems and networks.\nA supplementary proactive strategy, i.e. offensive security, is required where systems are constantly analyzed by\nprofessionals that try to imitate a malicious threat actor and detect vulnerabilities before a real threat does. Both\noffensive and defensive security complement each other to achieve security in an organization. Offensive Security is a\nbroad term that encompasses various techniques and practices, like vulnerability assessments, exploit development,\nsocial engineering, and penetration testing, among others.\nIn penetration testing, vulnerabilities are found and also exploited to compromise other hosts and detect additional\nvulnerabilities in the infrastructure of an organization. Penetration testers act as real adversaries of the organization, so\nthey need to be updated with the latest tools and methodologies in order to mimic the latest attacks.\nThey have a wealth of resources at their disposal. A primary resource is the National Vulnerability Database (NVD) [5]\nthat performs an in-depth analysis of software vulnerabilities published in the Common Vulnerabilities and Exposures\n(CVE) database. The CVE system, an industry standard, assigns a unique identifier to publicly disclosed cybersecurity\nvulnerabilities, thereby enabling a systematic approach to vulnerability management. The NVD further enriches the\nCVE data by assigning severity scores to known vulnerabilities using the Common Vulnerability Scoring System\n(CVSS).\nBeyond just identifying and scoring vulnerabilities, pentesters often need to leverage public exploits to validate these\nvulnerabilities. Resources like Exploit Database [10] and Metasploit Framework are commonly used for this purpose.\nThese CVE identifiers, CVSS scores, and public exploits play an instrumental role for pentesters. The ability to refer to\nstandardized databases and exploit resources simplifies the complex task of vulnerability management, enabling a more\nprecise and targeted approach to maintaining system security.\n2.2\nPenetration testing lifecycle\nPenetration testing is a structured process made up of various stages that typically need to be carried out within a limited\ntime (Figure 1). As mentioned in [11], a common methodology to divide the stages is the following:\n1. Scoping: The pentester works with the client to identify the assets and systems that will be tested and the\nrules of engagement. The purpose of the scope is to ensure that the pentester does not disrupt the expected\noperations of the client\u2019s business.\n2. Reconnaissance: The pentester gathers information about the target environment using specialized tools such\nas Nmap [3], Nessus [12] or by applying special techniques, e.g. Open-Source Intelligence (OSINT).\n2\narXiv Template\nA PREPRINT\nFigure 1: Graphical view of the penetration testing lifecycle.\n3. Vulnerability Analysis: Vulnerabilities of the network devices found in the last step are identifiedMost\nof the vulnerabilities are already disclosed publicly and are mapped to vulnerability repositories, like the\naforementioned NVD [5] vulnerability database.\n4. Exploitation: In this phase, detected vulnerabilities are exploited . Pentesters can obtain the exploits from\nseveral sources including public exploit databases, such as ExploitDB [10]. For zero-day vulnerabilities,\nprivate exploit databases or manually crafted exploits can be used.\n5. Reporting: This phase consists in the development of an executive report, a high-level overview explaining\nthe findings in detail (the vulnerabilities discovered and their severity), as well as the risks involved and the\nremediation to avoid them. Technical and non-technical sections are included to detail this information to\ndifferent stakeholders of the organization.\nThe pentesting lifecycle follows an iterative approach (Figure 1) as findings and insights from each test may serve as\ninput for subsequent tests, and, sometimes, exploiting a host can lead to space to perform reconnaissance on new hosts\nthat were not previously reachable.\n2.3\nPentest automation\nAutomating pentesting can significantly reduce the time and effort to test systems and applications for vulnerabilities. It\ncan also avoid the risk of vulnerabilities or attack vectors being overlooked which may happen in a manual scenario.\nAutomating the report phase provides more time to focus on other phases and helps in keeping track of the information\ngenerated throughout the process.\nThe automation of penetration testing has been a topic since the last decade. Several studies and approaches have been\ndeveloped over the course of the years, differing each other in scope and purpose. The application that first introduced\nthis automation process was made by Boddy et al [13]. In 2005, Mark Boddy demonstrated that it was possible to\nuse classical planning to generate hypothetical attack scenarios to exploit a specific system, with the downside of\nconsidering only insider attacks.\nThe approach in [8] took into account the presence of outsiders or hackers and used classical planning to automate the\npenetration testing process into a framework like Metasploit. One of the goals of this approach was to demonstrate\nthat scalability is not a problem for PDDL solving, as the approach worked great with medium to large networks.\nNevertheless, this approach bases its job into having a full overview of the target organization and is focused on the\nperspective of the defender (not the real-case scenario for a pentester).\nThe approach of [14] focuses on time efficient generation of a minimal attack graph, using a model-checker that\nremoves visualization problems and avoids state-space explosion. A similar project is [15], that tries to automatize\nthe Vulnerability Assessment phase. Both of these projects do not generate the PDDL language automatically and\nneither of them work with a framework like Metasploit. They present theoretical concepts with complex mathematical\ncalculations.\n3\narXiv Template\nA PREPRINT\nThe FIDIUS framework [7] is also one of the first attempts that uses artificial intelligence to automate the penetration\ntesting process. This framework implements DDL for the attack plan generation and also uses a Neural Network to\npredict the value of a host in terms of the importance for the attacker. The problem is that, as said in [7], \"When using\nthe classical planner the user has to specify all hosts, its connections, its subnets and its services in advance\", which,\nfor sure, does not represent a real pentesting scenario.\nUnlike traditional planning, [16] attempts to solve attack graphs with Markov Decision Processes (MDPs), which model\nthe world as states and actions as transitions between states, with a function that assigns a value to each state change.\nTheir work seeks to define an optimal pentesting policy \u2013 that is, what best action is \u2013 for each state prior to execution\nbased on using a fixed-lookahead horizon. By contrast, the approach in [17] features an adaptive attacker \u2013 i.e., using\nonline techniques alongside an MDP-solving system. Both of these MDP-based approaches assign probabilities to\nactions, moving uncertainty from the environment into uncertainty in the action\u2019s success. Again, this approach is\ntheoretical and is based on a white-box scenario, which is not the reality when performing pentesting assessments.\nThese works, despite having some differences in their approach, share several points in common that make them\nunknown for the pentesting community. The points are the following:\n1. The scenario in which these approaches work is a white-box scenario, where it is assumed that all the variables\nof the environment are known by the pentester at first. In real scenarios, the pentesters usually need to discover\nthe information by themselves along the assessment, like a real attacker would do.\n2. These studies focus on one specific phase of the pentest, isolating that part from the rest of the asessment. The\nfinal result is an automated phase of the pentest, but not a whole automated pentesting process.\n3. These studies develop a mathematical solution, but they do not provide a real and usable tool.\nCompared to those, Lore [9] tried to automate and emulate a red team by using a trained model. However, it has only\nlimited application to the scenarios used for testing as the authors stated: \"The systems and software used to train the\nmodels are not representative to systems and software in the real world\". Additionally, it does not provide support for\nthe reporting phase.\nIn contrast to these approaches, this work presents PTHelper, a modular tool designed for pentesters to work in a\nblack-box scenario providing help and tooling for each of the phases of the process. In the next section, the design and\narchitecture of the tool is explained.\n3\nArchitecture Overview\n3.1\nA different approach to automation\nPTHelper is crafted to provide supportive functionality to the pentester throughout the whole penetration testing\nassessment. It incorporates four modules, each of them specialized in a different phase of the pentesting process. The\nnovelty of PTHelper lies in the orchestrated interaction of these modules, automating the transition of information\nfrom one phase to the next up to the reporting one. It is important to note that PTHelper does not render the human\nexpert obsolete. It strikes a balance between facilitating a more efficient penetration testing process and maintaining the\nindispensable human oversight.\nFigure 2 describes the paradigm of the main approaches in the state of the art (note the number of interactions a pentester\nhas to perform) whereas Figure 3 describes the approach of PTHelper regarding the automation of the pentest. Note\nthat both approaches produce the same result, which is an executive report with all the findings obtained during the\nassessment.\nAs shown in Figure 3, PTHelper was designed with the objective of minimizing the pentester\u2019s interaction during the\nphases of the pentest. The only provided input during the assessment is the initial information, while the rest of inputs\nand interactions are substituted by PTHelper\u2019s native operations and communications between modules, reducing the\nrisk of losing information during the different phases.\nInitially designed with infrastructure penetration testing in mind, PTHelper possesses the inherent flexibility to\naccommodate diverse pentesting needs. The architectural design of the tool leverages modularization, which enables\nit to be responsive to future enhancements and adjustments. Each module can be modified or extended to adapt it to\ndifferent types of penetration testing, such as Web or Mobile application penetration testing. This adaptive design\nprovides potential to evolve in parallel with emerging pentesting methodologies and challenges in the dynamic field of\ncybersecurity.\n4\narXiv Template\nA PREPRINT\nFigure 2: Traditional pentesting methodology. Red lines indicate pentester interactions, black lines indicate the output\nof each process.\nFigure 3: Pentesting methodology proposed by using PTHelper. Red lines indicate pentester interactions, purple lines\nindicate tool operations.\nPTHelper leverages specific state of the art tools within each module to fulfill its tasks. For instance, the Scanner\nmodule currently utilizes nmap [3] by default. Yet, it allows the integration of other scanners, such as Shodan[18] or\nNessus[12], into the Scanner module to meet the unique requirements of different pentesters.\nThe forthcoming subsections will offer a detailed exploration of each module incorporated within PTHelper, and an\nexplanation of how these modules interact and communicate with each other.\n3.2\nScanner module\nThe Scanner module is responsible for executing the Reconnaissance and Vulnerability Analysis stages of the pentest.\nLike most scanning tools, its input is an IP address - the only piece of network infrastructure information required\nto employ the tool, and usually, the only piece of information available to the pentester. Figure 4 provides a visual\nrepresentation of the mentioned module\u2019s operations and interactions.\nThe primary duty of this module is to extract the maximum possible information about the specified host(s) and relay this\ninformation to other modules. The module funnels the information to the NLPAgent module. Herein lies a significant\ndifference of PTHelper: instead of the pentester handling the raw scan data, the information is processed and enriched\nby an AI source.\nThis module uses the network security scanner nmap [3] to extract comprehensive data about the specified host(s).\nStarting with nmap\u2019s Host Discovery scan output, PTHelper identifies open ports on the host and compiles them into a\nlist for further analysis. This list then undergoes into the Service and Version detection scan to obtain detailed insights\ninto the open ports.\nFor the Vulnerability Analysis phase, the tool utilizes one of nmap\u2019s renowned scripts called vulners, which is used\nto extract information about the Common Vulnerabilities and Exposures (CVEs) found in the open ports. Once the\ninformation has been enriched with the vulners repository, the module uses the nvdlib python NVD API wrapper to\nquery the National Vulnerability Database (NVD) [5] to add the CVE description and CVSS information. The Vulners\n5\narXiv Template\nA PREPRINT\nFigure 4: Scanner module operations and interactions\ndatabase serves as the primary source of CVE information in this script, meaning the most recent CVEs may not be\npresent if the database isn\u2019t up-to-date.\n3.3\nExploiter module\nThe Exploiter module executes the Exploitation phase of the pentest. The list of identified hosts, ports and CVEs,\nobtained by the Scanner module serves as the foundation for this module\u2019s operations. This module uses the given data\nto search for public exploits corresponding to the identified vulnerabilities of the hosts, subsequently downloading them\nand providing the pentester with an informative pool of the available exploits. This is the only module that reports the\noutput of its execution to the pentester via the command-line. The displayed output contains a list of the open ports, a\nbrief explanation of each of the CVEs obtained per port as well as the exploits obtained per CVE and the path to the\ndownloaded exploits. Figure 5 provides a visual representation of the mentioned module\u2019s operations and interactions.\nThis module interacts with ExploitDB [10] using its API to download the required exploits. Additionally, it presents the\npentester with essential information, such as the platform of the exploit (e.g., Python, Metasploit, bash) and whether the\nexploit has been validated by the ExploitDB community, amongst others. This information extends the one provided by\nthe Scanner, therefore obtaining an enhanced overview of the infrastructure.\nThe module also detects the language of the exploit amongst a wide variety of programming languages (whereas the\nlanguage is written in C, python, Java, Ruby...) by using regular expressions and also detects the compilation options of\nthe script (if they are specified in the exploit) and compiles the script to get a functional exploit that can be used by the\npentester.\nIt\u2019s essential to highlight that the Exploiter module doesn\u2019t automatically execute the exploits. Instead, this intentional\ndesign leaves the final exploit execution in the hands of the pentester. This approach accounts for situations where\nexecuting an exploit may inadvertently disrupt the availability of the vulnerable system or where certain modifications\nwithin the exploit are required (e.g., altering the IP and port of the target host). Therefore, the pentester retains\nfull control over the final exploit execution, while PTHelper efficiently handles the preparatory steps, significantly\nsimplifying and expediting the exploitation process.\n6\narXiv Template\nA PREPRINT\nFigure 5: Exploiter module operations and interactions\nThe output of this module includes the information received from the Scanner module with the addition of the exploit\ninformation. It acts as input for the NLPAgent module and provides an overview of the situation that includes exploit\ninformation given the present vulnerabilities.\n3.4\nNLPAgent module\nThis module integrates a NLP source to fulfill the assessment report generated by the tool with technical and executive\ninsights. The context of the assessment, supplied by the Exploiter module and a set of crafted conversational prompts\nform the basis for the extraction and generation of this supplemental information. Examples of the generated output\nvary from the executive report to a severity rationale for each found vulnerability.\nIn order to fulfill the several parts of the report, a set of prompts that interact with the underlying agent are designed as\nit will be explained below.\nRegarding the available agents, OpenAI API [19] is the base NLPAgent that was integrated at this time, due to is ease\nof use and popularity. Nevertheless, as happens with the rest of the modules, this can be upgradable to include another\nagents like Google Bard [20] or Llama 2 from Meta [21]. The designed prompts that come with PTHelper are reusable\nbetween these agents.\nIn the case of ChatGPT API, the tool is created to be able to change hyperparameters of this agent by modifying a\nconfiguration file. This allows the pentester to modify some of the settings of the agent, like the Temperature value,\nwhich indicates how creative/coherent are the agent\u2019s outputs between program executions. Also, the API version of the\nagent (like ChatGPT API version 3.5 or 4) can be modified in this configuration file. Lastly, some techniques that are\nparticular to OpenAI\u2019s API were performed in order to reduce token consumption and optimize the token usage without\nlosing information.\nFigure 6 shows an overview of the module functioning and interactions.\n7\narXiv Template\nA PREPRINT\nFigure 6: NLPAgent module operations and interactions\n3.4.1\nApplying prompt engineering to the agent\nEach of the parts of the executive report requires a different level of technical content and detail. In order to achieve this,\ngiven the same input, which is the one provided by the Exploiter module, adjustments must be made in this module.\nA technique called Prompt Engineering is applied. Tailored prompts are designed for each of the parts of the report that\nneed to be filled with different expertise levels. A new conversation with the underlying NLP agent is created for each\nof these report sections, and the tailored prompt is given to the agent as a context message. This means that the agent\nwill not interpret this message as a chat message, but as a message that serves as context and modules its behavior.\nPrompts were also used to avoid the generation of misleading content by the underlying agent (such as vulnerabilities\nthat do not exist), which would harm the results and the quality of the whole project.\nTo this day, several prompts were crafted in order to fulfill two important parts of the report. The first one is the\nExecutive Summary section, that contains information about the hosts and ports that were involved in the assessment, a\nbig overview of the vulnerabilities found in a non-technical language, and a list of mitigations to apply to the vulnerable\nhosts in order to reduce the risk of the organization. The rest of the prompts are used inside a main function which its\nmain purpose is to generate a Findings dictionary. For each of the detected vulnerabilities, additional information is\ncompleted using the agent, for example, steps on how to mitigate the vulnerability in the organization to avoid direct\nattacks, or attach a severity rationale to justify the severity of the given vulnerability. The result is a finding report with\nvaluable information for each of the vulnerabilities found, that completes the information given by the previous Scanner\nand Exploiter modules.\nThe outputs of this module are sent to the Reporter module.\n8\narXiv Template\nA PREPRINT\nFigure 7: Reporter module operations and interactions\n3.5\nReporter module\nThis module executes the Reporting phase of the pentest. It parses the information delivered by the other modules\nand displays it into a SAFR (Security Assessment Findings Report). The SAFR is a complete report that exposes the\nsecurity findings by the pentester during a certain assessment.\nThe module works by using a document template that is filled with the information received from the Reporter\nand NLPAgent modules. This information includes the executive summary, a table containing an overview of the\norganization with the scanned IPs, open ports, and found vulnerabilities in CVE format, and a fully-completed findings\nsection containing one finding per vulnerability found. The findings contain detailed information about the vulnerability,\nits severity and a rationale about the impact of the vulnerability in the organization, a list of the public exploits for the\ngiven vulnerability and also a remediation list of steps to help with the mitigation of the vulnerability.\nCurrently the tool includes a base report in Docx format. This report comes with all the template tags introduced, ready\nto be completed with the execution of the tool. The template framework used is the Jinja2 template framework for Docx\ndocuments [22]. This was made with the intention to work with a document that could be easy to edit and visualize.\nNevertheless, the tool is made to allow pentesters to develop a report in other formats, like Markdown or Latex, and\nalso add additional templating frameworks, to adapt the tool to their needs.\nThe template that comes with the tool includes all the sections that a professional report needs. Some of these sections\nare ready to be filled by the pentester with additional information to end up with a report that can be used and understood\nby the technical and non-technical parts of the target organization. Note that the report is not final and it is recommended\nto review it, and add all the information that is found by manual means.\nFigure 7 is a visual description of the communications between the Reporter and other modules as described.\n4\nImplementation and results\n4.1\nTool usage and information\nPTHelper is developed in Python3 programming language [23], due to its popularity amongst the pentesting commu-\nnityand it can be downloaded from the GitHub repository1. It requires nmap [3] binary to be installed in the system (the\n1https://github.com/jacobocasado/PTHelper/\n9\narXiv Template\nA PREPRINT\nFigure 8: Scenario 1. Black box infrastructure with pivot host.\nversion of nmap which was used during the development and testing process is version 7.94). In order to install all the\nPython packages that the tool needs to operate, a requirements.txt file is attached to be fed into the pip command.\nAfter the requirements are satisfied, PTHelper can be installed as a python package (called pthelper), as configured\nin the setup.py file. The NVD API key and the OpenAI API key have to be set up in the configuration file\n(config/pthelper_config.py) for the modules to work properly.\nPTHelper is usable via the CLI (Command Line Interface), and the following parameters need to be specified:\n\u2022 The IP address (or range of IPs) for the assessment.\n\u2022 The port (or range of ports) to scan of the given IPs.\n\u2022 Type of Scanner that will be used. At this time, only nmap Scanner is available.\n\u2022 Type of Exploiter that will be used. At this time, only exploitdb Exploiter is available.\n\u2022 Type of NLPAgent that will be used. At this time, only chatgpt NLPAgent is available.\n\u2022 Type of Reporter that will be used. At this time, only docxtpl (Docx Jinja3 framework) Reporter is available.\n\u2022 Project to store the results. Exploits found by the Exploiter module, the generated report and other results will\nbe placed in the specified project folder.\n4.2\nTesting PThelper functionality\nTwo simulated pentesting environments were deployed to validate the behaviour of the tool.\n4.2.1\nBlack box infrastructure\nThis is a local networking scenario that includes several Virtual Machines simulating a real pentesting environment.\nThree vulnerable Virtual Machines based on Metasploitable2 [24] and Metasploitable3 [25] were used. These machines\ncontain a wide list of vulnerabilities and are intentionally designed to be vulnerable to help the pentesters develop their\nskills.\nFigure 8 shows the topology of this environment. The pentester only has network visibility of the first host, a Windows\nMetasploitable3 machine (Host A). The other two hosts in the environment are Linux hosts, corresponding to a Linux\nMetasploitable2 (Host B) and a Linux Metasploitable3 (Host C) machine. The idea is to verify if PThelper can be used\nin a black-box environment, this is, using PTHelper to compromise a host, and use the tool with the compromised host\nas pivot with hosts that were not previously accessible. This is a real and typical pentesting scenario.\nPThelper was able to detect a RCE (Remote Code Execution) vulnerability on the first host, apart from a wide list of\nother vulnerabilities. After exploiting the RCE vulnerability (CVE-2014-3120) to compromise Host A, a port forwarding\ntechnique was used to forward all traffic from PTHelper to the hosts that are not in direct network range (Host B and\nHost C) to use the tool against these hosts. PTHelper managed to detect a wide list of vulnerabilities in these two hosts\nand offered a list of exploits, some of which were used to gain DoS (denial of service) and RCE to fully compromise\n10\narXiv Template\nA PREPRINT\nthe infrastructure. The output report generated with the tool after performing this experiment by using the tool against\nthe three hosts is also available2.\nNote that not all the vulnerabilities of these hosts were found in the process, as some of them are web vulnerabilities,\nthat need to be enumerated and exploited using manual means or a specialized web scanner. This was taken into account\nand it will be one of the main improvement points of the tool.\nTable 1 details the execution times in seconds of each of the modules of the tool, in order to detect which parts of the\ntool need more development and optimization for the next versions. The benchmark was executed in a Kali 2023.2\nVirtual Machine, with 4GB of RAM memory and 4 CPU cores, and, therefore, the tool could perform better in an\nenvironment with more resources.\nTable 1: Execution time of PTHelper for each of the hosts (seconds)\nTask\nHost A\nHost B\nHost C\nScanner-Port Discovery\n1.16\n3.10\n3.13\nScanner-Vulnerability Discovery\n147.15\n350.28\n284.39\nScanner - OS Discovery\n0.01\n0.34\n0.2\nExploiter\n56.04\n128.04\n89.04\nNLPAgent - Executive Summary\n158.84\n289.82\n233.34\nNLPAgent - Finding report\n1454.66\n2493.24\n2097.75\nReporter - Render report\n0.1362\n0.1418\n0.1591\nTotal time\n1720.98\n3365.83\n2708.75\nOverall, the most time-consuming part of the Scanner module is the Vulnerability Discovery part where queries to the\nNVD API are performed. For each of these queries, there is a delay when performing and receiving these requests,\nalthough the delay parameter was adjusted to the minimum possible allowed by the API. Due to the amount of\nvulnerabilities per host, this part was time consuming, reaching more than five (5) minutes for the Host B.\nThe Exploiter module had an execution time between one (1) and two (2) minutes. For the NLPAgent module, times are\nsignificantly higher compared to the rest of the modules. Most of the execution time of the tool resides in this module,\nand, specially, in the Finding Report section of the tool. The justification is simple: The tool performs one query to the\nOpenAI API per obtained finding. Taking into account that each of the hosts generated more than 20 findings, and\nthat each finding needs to be processed by the engine, the amount of time spent in this operations is high. Finally, the\nReporter module does not have a great implication in the execution time as the overall execution time is less than one\n(1) second.\nAs the operations of some of the modules depend directly on the found vulnerabilities, the execution time is directly\ncorrelated on how vulnerable the host is.\nA proper update to the NLPAgent module would be to parallelize the requests performed to the OpenAI API, in order to\ngenerate the findings list faster. Also note that the model used was gpt-3.5-turbo-16k. Using gpt-4 model will\nprobably provide better values.\n4.2.2\nHackTheBox machine\nIn this experiment, the tool is tested against a host in the Internet instead of the local network. The targeted host is\na machine from HackTheBox[26]. HackTheBox is a gamified cibersecurity training platform, containing vulnerable\nmachines that can be used to practise hacking skills. A machine of this platform called Blue was used in this experiment.\nThe tool was used against an instance of this machine, specifying some of the most popular ports as a parameter. The\ntool managed to discover the vulnerability of this machine, CVE-2017-0144. After discovering the vulnerability, the\nExploit module returned several exploits to leverage Remote Code Execution and compromise the host using this\nvulnerability. One of the obtained exploits was a Metasploit script, which is the one used in the video demonstration3 to\ncompromise the host and retrieve the flag, finishing the challenge.\nBy performing this experiment, it has been possible to demonstrate that the tool can be used by the pentesters in\nnon-local scenarios and that the exploits that the Exploiter module obtains are usable.\n2https://bit.ly/pthelper-report\n3https://www.youtube.com/watch?v=z7APguceuME\n11\narXiv Template\nA PREPRINT\n5\nConclusion and future work\nA tool to automate the pentesting process and support the pentested has been presented and tested in two different\nscenarios. It is reduces the number of the interactions that the pentester has to perform in the assessments in certain\ntypes of penetration tests, such as infrastructure penetration testing. The modular design of the tool lets functionality to\nbe expanded to cover other needs of the community. This tool is able to cover of the pentesting lifecycle and provide a\ndraft for the integrated report.\nFuture work includes fitting in another pentesting scenarios (such as Web or Mobile application pentesting). Another\ntool improvement, as seen in the experiments section, would be to parallelize some of the operations of the tool, such as\nthe Finding List generation by the NLPAgent. The tool has been developed with one option per module, this is, nmap\nfor the Scanner module, ExploitDB for the Exploiter module, OpenAI API for the NLPAgent module and a Jinja2\nframework with a Docx document for the Reporter module. Additional options will be integrated.\n6\nAcknowledgement\nA. S\u00e1nchez-Maci\u00e1n would like to acknowledge the support of the R&D project PID2022-136684OB-C21 (Fun4Date)\nfunded by the Spanish Ministry of Science and Innovation MCIN/AEI/ 10.13039/501100011033.\nReferences\n[1] D. Rogers and V. Kanth, \u201cWannacry data collection system design and tutorial,\u201d in MILCOM 2021 - 2021 IEEE\nMilitary Communications Conference (MILCOM), 2021, pp. 1\u20136.\n[2] J. Li, D. Sisodia, and S. Stafford, \u201cOn the detection of smart, self-propagating internet worms,\u201d IEEE Transactions\non Dependable and Secure Computing, vol. 20, no. 4, pp. 3051\u20133063, 2023.\n[3] \u201cNmap: the network mapper.\u201d [Online]. Available: https://nmap.org/\n[4] \u201cMetasploit, a penetration testing framework.\u201d [Online]. Available: https://www.metasploit.com/\n[5] \u201cNist - national vulnerability database (nvd).\u201d [Online]. Available: https://nvd.nist.gov/vuln\n[6] \u201cMitre - common vulnerabilities and exposures (cve).\u201d [Online]. Available: https://www.cve.org/Media/News/\nAllNews\n[7] D. Elsbroek, D. Kohlsdorf, and L. Meyer, \u201cFidius: Intelligent support for vulnerability testing,\u201d in 2011 IJCAI\nWorkshop on Intelligent Security (SecArt), 2011, pp. 58\u201365.\n[8] J. L. Obes, C. Sarraute, and G. Richarte, \u201cAttack planning in the real world,\u201d 2013.\n[9] H. Holm, \u201cLore a red team emulation tool,\u201d IEEE Transactions on Dependable and Secure Computing, vol. 20,\nno. 2, pp. 1596\u20131608, 2023.\n[10] \u201cExploit database - exploits for penetration testers.\u201d [Online]. Available: https://www.exploit-db.com/\n[11] \u201cUnderstanding\nthe\nfive\nphases\nof\nthe\npenetration\ntesting\nprocess.\u201d\n[Online].\nAvailable:\nhttps:\n//www.eccouncil.org/cybersecurity-exchange/penetration-testing/penetration-testing-phases/\n[12] \u201cTenable nessus vulnerability scanner.\u201d [Online]. Available: https://nmap.org/\n[13] M. Boddy, J. Gohde, T. Haigh, and S. Harp, \u201cCourse of action generation for cyber security using classical\nplanning.\u201d in ICAPS 2005 - Proceedings of the 15th International Conference on Automated Planning and\nScheduling, jan 2005, pp. 12\u201321.\n[14] N. Ghosh and S. Ghosh, \u201cA planner-based approach to generate and analyze minimal attack graph,\u201d Appl. Intell.,\nvol. 36, pp. 369\u2013390, mar 2012.\n[15] O. Khan, S. Khan, and S. Parkinson, \u201cTowards automated vulnerability assessment,\u201d jun 2017.\n[16] K. Durkota and V. Lisy, \u201cComputing optimal policies for attack graphs with action failures and costs,\u201d in STAIRS\n2014: Proceedings of the 7th European Starting AI Researcher Symposium, jan 2014, pp. 101\u2013110.\n[17] L. Krautsevich, F. Martinelli, and A. Yautsiukhin, \u201cTowards modelling adaptive attacker\u2019s behaviour,\u201d in Founda-\ntions and Practice of Security: 5th International Symposium, FPS 2012, oct 2012, pp. 357\u2013364.\n[18] \u201cSearch engine for the internet of everything.\u201d [Online]. Available: https://www.shodan.io//\n[19] \u201cOpenai - api reference.\u201d [Online]. Available: https://platform.openai.com/docs/guides/gpt\n12\narXiv Template\nA PREPRINT\n[20] \u201cGoogle bard - ai assisted tool based in google, with palm 2 help.\u201d [Online]. Available:\nhttps:\n//bard.google.com/?hl=es\n[21] \u201cLlama2 - meta ai.\u201d [Online]. Available: https://ai.meta.com/llama/\n[22] \u201cJinja2 for docx - python package.\u201d [Online]. Available: https://docxtpl.readthedocs.io/en/latest/\n[23] \u201cPython 3.11.4.\u201d [Online]. Available: https://www.python.org/ftp/python/3.11.4/\n[24] \u201cMetasploitable 2 | metasploit.\u201d [Online]. Available: https://docs.rapid7.com/metasploit/metasploitable-2/\n[25] \u201cMetasploitable 3 | metasploit.\u201d [Online]. Available: https://github.com/rapid7/metasploitable3\n[26] \u201cHackthebox - hacking training for the best.\u201d [Online]. Available: https://www.hackthebox.com/\n13\n", "metadata": {"Published": "2024-06-12", "Title": "PTHelper: An open source tool to support the Penetration Testing process", "Authors": "Jacobo Casado de Gracia, Alfonso S\u00e1nchez-Maci\u00e1n", "Summary": "Offensive security is one of the state of the art measures to protect\nenterprises and organizations. Penetration testing, broadly called pentesting,\nis a branch of offensive security designed to find, rate and exploit these\nvulnerabilities, in order to assess the security posture of an organization.\nThis process is often time-consuming and the quantity of information that\npentesters need to manage might also be difficult to handle. This project takes\na practical approach to solve the automation of pentesting and proposes a\nusable tool, called PTHelper. This open-source tool has been designed in a\nmodular way to be easily upgradable by the pentesting community, and uses state\nof the art tools and artificial intelligence to achieve its objective.", "entry_id": "http://arxiv.org/abs/2406.08242v1", "published_first_time": "2024-06-12", "comment": null, "journal_ref": null, "doi": null, "primary_category": "cs.CR", "categories": ["cs.CR"], "links": ["http://arxiv.org/abs/2406.08242v1", "http://arxiv.org/pdf/2406.08242v1"]}, "type": "Document"}
{"page_content": "Interactive Greybox Penetration Testing for Cloud Access Control using\nIAM Modeling and Deep Reinforcement Learning\nYANG HU\u2217, The University of Texas at Austin, USA\nWENXI WANG\u2217, The University of Texas at Austin, USA\nSARFRAZ KHURSHID, The University of Texas at Austin, USA\nMOHIT TIWARI, The University of Texas at Austin, USA\nIdentity and Access Management (IAM) is an access control service in cloud platforms. To securely manage\ncloud resources, customers need to configure IAM to specify the access control rules for their cloud organi-\nzations. However, incorrectly configured IAM can be exploited to cause a security attack such as privilege\nescalation (PE), leading to severe economic loss. To detect such PEs due to IAM misconfigurations, third-party\ncloud security services are commonly used. The state-of-the-art services apply whitebox penetration testing\ntechniques, which require access to complete IAM configurations. However, the configurations can contain\nsensitive information. To prevent the disclosure of such information, customers need to manually anonymize\nthe configuration.\nIn this paper, we propose a precise greybox penetration testing approach called TAC for third-party services\nto detect IAM PEs. To mitigate the dual challenges of labor-intensive anonymization and potentially sensitive\ninformation disclosures, TAC interacts with customers by selectively querying only the essential information\nneeded. Our key insight is that only a small fraction of information in the IAM configuration is relevant\nto the IAM PE detection. We first propose IAM modeling, enabling TAC to detect a broad class of IAM PEs\nbased on the partial information collected from queries. To improve the efficiency and applicability of TAC, we\naim to minimize interactions with customers by applying Reinforcement Learning (RL) with Graph Neural\nNetworks (GNNs), allowing TAC to learn to make as few queries as possible. Furthermore, to pretrain and\nevaluate TAC with enough diverse tasks, we propose an IAM PE task generator called IAMVulGen. Experimental\nresults on both synthetic and real-world tasks show that, compared to state-of-the-art whitebox approaches,\nTAC detects IAM PEs with competitively low false negative rates, employing a limited number of queries.\n1\nINTRODUCTION\nIAM [4] refers to an access control service in cloud platforms. It aims to securely manage the access\nto resources based on an IAM configuration specified by cloud customers with the access control\nrules in their cloud organizations. An IAM configuration consists of two components: entities (e.g.,\nusers and services such as Amazon EC2 instances) and permissions. Given a service request and an\nIAM configuration, IAM is able to check if the request obeys or violates the IAM configuration,\nand decide if the request should be allowed or denied.\nTherefore, the correctness of IAM configurations plays an essential role in the effectiveness\nof cloud access control. Incorrect IAM configurations, namely IAM misconfigurations, can cause\nadverse security consequences such as data breaches, denial of services and resource hijacking\n[16, 39, 40, 43, 44], which have led to significant economic loss in recent years [37]. IAM PE\n[20, 28, 30] is an attack towards cloud access control that exploits the flaws within IAM to obtain\nadditional permissions for performing sensitive operations or accessing sensitive data/resources.\nOne of the most common ways to realize IAM PEs is to exploit IAM misconfigurations: the\nmisconfigured IAM may allow the attacker to modify its configuration so that the attacker is\nallowed by the modified IAM configuration to obtain additional sensitive permissions.\n\u2217these authors contributed equally to this work.\nAuthors\u2019 addresses: Yang Hu, huyang@utexas.edu, The University of Texas at Austin, Austin, Texas, USA; Wenxi Wang,\nwenxiw@utexas.edu, The University of Texas at Austin, Austin, Texas, USA; Sarfraz Khurshid, khurshid@ece.utexas.edu,\nThe University of Texas at Austin, Austin, Texas, USA; Mohit Tiwari, tiwari@austin.utexas.edu, The University of Texas at\nAustin, Austin, Texas, USA.\narXiv:2304.14540v5  [cs.CR]  8 Jun 2024\n2\nYang Hu, Wenxi Wang, Sarfraz Khurshid, and Mohit Tiwari\nTo mitigate this issue, several cloud security services have been released to detect PEs due to\nIAM misconfigurations. There are two kinds of services: 1) native cloud security services [7\u201311]\nprovided by cloud providers, and 2) third-party cloud security services provided [24, 26, 27] by\ncloud security startups, labs, open-source projects, etc. Native services usually aim to provide basic\nsecurity guarantees for cloud customers, while third-party services aim to provide specialized\nsecurity guarantees for cloud customers with complex and specialized demands [25, 52].\nIn this paper, we focus on third-party cloud security services for detecting PEs due to IAM\nmisconfigurations. To our knowledge, all existing third-party services apply whitebox penetration\ntesting techniques [21, 23, 33, 34, 47, 53], which require the access to complete IAM configurations.\nHowever, sharing the entire IAM configurations to third-party cloud security services can raise a\npotential security risk in leaking sensitive information of their cloud organizations (e.g., the internal\norganization architecture). This level of transparency might not be acceptable for cloud customers in\nfields with elevated security requirements, such as healthcare, finance, and government [31, 41, 46].\nTo mitigate the security concerns, cloud customers have to anonymize the sensitive information in\ntheir IAM configurations before using third-party services, which could take a significant amount\nof manual efforts. Moreover, the labor-intensive anonymization leads to a significant shortage\nof publicly available real-world IAM configurations, which impedes academic and open research\ncommunities from engaging effectively in addressing the issue.\nTo avoid both laborious anonymizations and sensitive information disclosure, we propose a pre-\ncise greybox penetration testing approach called TAC to detect IAM PEs. The idea is to intelligently\ninteract with cloud customers by a sequence of queries, requesting only the essential information\nneeded for the detection. Specifically, each query seeks information about one permission assign-\nment (i.e., whether a particular permission is assigned to a specific entity). During each interaction,\ncustomers will be presented with one query and given the option to either accept or decline the\nquery based on their knowledge of whether the query might potentially result in the exposure of\nconfidential information. In addition, customers are allowed to set up a query budget, which is the\nmaximum number of queries they are willing to interact with. The primary goal of TAC is to detect\nthe IAM PE within the query budget. Furthermore, to make TAC practically applicable, the main\nchallenge lies in minimizing customer inputs, thereby reducing the total number of queries during\nthe detection process.\nTo achieve the goal and overcome the challenge, TAC faces two problems: 1) detecting PEs based\non partial information of IAM configurations collected by queries, and 2) learning to generate as\nfew queries as possible to perform the detection within the query budget. To solve the first problem,\nwe propose a comprehensive IAM modeling, for detecting a broader class of PEs than the existing\nwhitebox detectors. In particular, to detect PE only with partial information, we propose abstract\nmodeling for IAM configurations based on our Permission Flow Graph (PFG) with predefined abstract\nstates and rules for updating the configuration with partial information provided by the queries.\nFor the second problem, we formulate it into an RL problem, and apply GNN-based deep RL with\npretraining to solve the problem.\nPretraining and evaluating TAC require a large number of diverse tasks. To our knowledge, there\nis only one publicly available IAM PE task set called IAM Vulnerable [1] containing only 31 tasks.\nRegarding this, we propose an IAM PE task generator called IAMVulGen which randomly generates\nIAM PE tasks from a large entity and permission space with diverse types manually identified from\nAmazon Web Services (AWS) official documentation [4\u20136] and studies on IAM PEs [20, 28, 30, 60].\nTo evaluate TAC, we used 500 tasks generated by IAMVulGen, the 31 tasks from the only publicly\navailable IAM PE task set IAM Vulnerable, and two real-world IAM PE tasks collected from a\nU.S. based security startup as our evaluation benchmarks. For baselines, since there is no existing\ngreybox or blackbox penetration testing tool regarding IAM PEs, we take three state-of-the-art\nInteractive Greybox Penetration Testing for Cloud Access Control using IAM Modeling and Deep Reinforcement Learning\n3\nwhitebox penetration testing tools, namely Pacu [33], Cloudsplaining [47] and PMapper [21] as\nour baselines. In addition, to understand how our IAM modeling contributes to TAC, we build a\nwhitebox variant of TAC that solely applies our IAM modeling to detect PEs. To assess how our\nproposed GNN-based RL with pretraining enhances TAC, we build three greybox variants of TAC,\neach of which employs a different pretraining strategy or query model.\nAs a result, on the synthesized IAM PE task set by IAMVulGen, TAC\u2019s whitebox variant successfully\ndetected all PEs, and significantly outperforms all three state-of-the-art whitebox baselines, showing\nthe outstanding effectiveness of our IAM modeling. In addition, given a query budget of 100,\nTAC identifies 6% to 38% more PEs with 16% to 23% fewer queries on average than all its three\ngreybox variants, demonstrating the superiority of our pretraining based deep RL approach. On\nthe only publicly available task set IAM Vulnerable [1], TAC is able to detect 23 PEs under a query\nbudget of 10, and all 31 PEs with a query budget of 20, which substantially outperforms all three\nwhitebox baselines. Furthermore, TAC successfully detects two real-world PEs with a query budget\nof 60. The contributions of this paper are:\n\u2022 Modeling. A comprehensive modeling for IAM configurations is introduced, providing the\nfoundation of IAM PE detection.\n\u2022 Approach. TAC is the first interactive greybox penetration testing tool for third-party cloud\nsecurity services to detect PEs due to IAM misconfigurations.\n\u2022 Synthetic Data. An IAM PE task generator called IAMVulGen is proposed.\n2\nBACKGROUND\n2.1\nRL Basics\nRL refers to a set of algorithms that aim to learn to make decisions from interactions [57]. An RL\nproblem is usually formulated as a Markov Decision Process (MDP). In MDP, the learner or the\ndecision maker is called the RL agent. The RL agent interacts with the environment which maintains\nits internal state. In each interaction between the RL agent and the environment, the RL agent\nchooses an action to perform; the environment then updates its state based on the action, and\nreturns a reward quantifying the effectiveness of the action.\nIn this paper, we only consider a finite sequence of interactions between the RL agent and the\nenvironment, which are divided into several sub-sequences, namely episodes. Each episode starts\nfrom an initial state and ends with a terminal state. If an episode ends, the state of the environment\nwill be automatically reset to the initial state for the next episode to start. The return refers to the\ncumulative rewards for one episode. The goal of the RL agent is to learn an RL policy for choosing\nan action per interaction that maximizes the expected return.\n2.2\nIAM Basics\n2.2.1\nIAM Configurations. IAM configuration consists of two components: entities and permissions.\nAn entity represents either a subject or a role in an IAM configuration. Subjects (i.e., users, user\ngroups and services) can actively perform actions. Roles are created to represent job functions and\nresponsibilities within an organization. Permissions refer to privileges of performing operations. An\nentity in an IAM configuration can obtain permissions in both direct and indirect ways. Permissions\ncan be directly assigned to users, user groups and roles; permissions assigned to an entity can be\nindirectly assigned to another entity in many ways, depending on the relationship between the\ntwo entities. For example, all permissions assigned to a user group can be indirectly assigned to a\nuser in the user group; all permissions assigned to a role can be indirectly assigned to a user who\nassumes the role (i.e., become a member of the role).\n4\nYang Hu, Wenxi Wang, Sarfraz Khurshid, and Mohit Tiwari\nUser 1\nUser 2\nPerm 1\nPerm 2\nPerm 3\nPermissions\nService 1\nRole 1\nRole 2\nGroup 1\nEntities\n(a) Original configuration.\nUser 1\nUser 2\nPerm 1\nPerm 2\nPerm 3\nPermissions\nService 1\nRole 1\nRole 2\nGroup 1\nEntities\n(b) Modified configuration.\nFig. 1. An illustrative example of a PE due to IAM misconfiguration, derived from a notable real-world incident\nin 2019. Figure (a) shows the original IAM configuration, where the entity-entity and entity-permission\nconnections are highlighted in blue and orange, respectively. Figure (b) shows the modified IAM configuration\nin the PE, where the modification is highlighted in red.\nFigure 1a presents an IAM configuration example as a relational graph. In the example, there\nare six entities with four entity types: one user group Group 1, two users User 1 and User 2, one\nservice Service 1, and two roles Role 1 and Role 2. Besides, there are three permissions: Perm\n1, Perm 2 and Perm 3. Each entity-permission connection denotes that the permission is directly\nassigned to an entity. In the example, Perm 1 and Perm 2 are directly assigned to Role 1; Perm 2 is\ndirectly assigned to Group 1; Perm 3 is directly assigned to Role 2. Each entity-entity connection\ndenotes that one entity is currently related to another under the relation between their entity types.\nIn the example, there are five entity-entity connections under three relations: user-group relation\nrepresenting that a user is in a user group, user-role relation representing that a user assumes a\nrole, and service-role relation representing that a service assumes a role. Based on the semantics of\nthe user-group relation illustrated above, User 1 and User 2 in Group 1 can indirectly obtain the\npermission Perm 2 directly assigned to the group. Similarly, based on the semantics of user-role\nand service-role relations, both User 2 and Service 1 obtain Perm 3 indirectly by assuming Role\n2.\n2.2.2\nPEs due to Misconfigurations. The PE on IAM [20, 28, 30] is the act of exploiting the IAM\u2019s\nflaws to obtain additional permissions for performing the sensitive operation or accessing sensitive\ndata/resources. One of the most common causes of PEs is due to IAM misconfigurations, which is the\nmain focus in this paper. The misconfigured IAM may allow the attacker to change its configuration\nso that the attacker is allowed by the modified IAM configuration to obtain additional sensitive\npermission. We define the untrusted entity as the entity controlled by the attacker, and the target\npermission as the permission that the attacker targets to obtain illegally. The attacker realizes a\nPE by controlling the untrusted entity to modify the IAM misconfiguration such that the target\npermission is assigned to the untrusted entity.\nFor illustration purposes, we craft a simplified version of a notorious real-world IAM PE in\n2019 [29, 40],which gained access to 100 million credit card applications and accounts in Capital\nOne bank. Our illustrative example is shown in Figure 1. In the real-world PE example, the untrusted\nentity is an Amazon EC2 instance; the target permission is a permission allowing to access a sensitive\nS3 bucket, which contains customers\u2019 credit card application data. In our illustrative example,\nService 1 corresponds to the untrusted entity, Perm 1 corresponds to the target permission, and\nInteractive Greybox Penetration Testing for Cloud Access Control using IAM Modeling and Deep Reinforcement Learning\n5\nUser 1\nUser 2\nRole 1\nRole 2\nService 1\nPerm 2\nPerm 1\nPerm 2\nPerm 3\nGroup 1\n(a) The concrete PFG.\nGroup 1\nUser 1\nUser 2\nRole 1\nRole 2\nService 1\nPerm 1\nPerm 2\nPerm 3\nPerm 1\nPerm 2\nPerm 2\nPerm 3\nPerm 3\nPerm 2\n(b) The concrete IAM modeling.\nGroup1\nUser 2\nRole 2\nPerm 1\nPerm 2\nPerm 3\nPerm 1\nPerm 2\nPerm 2\nPerm 3\nPerm 3\nPerm 2\nRole 1\nService 1\nUser 1\n(c) The visible concrete PFG.\nFig. 2. PFGs of the illustrative example shown in Figure 1a. Permission flows with enabled states are annotated\nin green; with disabled states are annotated in red; with unknown states are annotated in black.\nPerm 3 allows the untrusted entity to assume Role 1. During the PE as shown in Figure 1, the\nattacker controls the untrusted entity to obtain the target permission in two steps: 1) the untrusted\nentity Service 1 indirectly obtains Perm 3 by assuming Role 2; 2) the untrusted entity Service\n1 applies Perm 3 to assume Role 1, and thus indirectly obtains the target permission Perm 1 from\nRole 1.\nThe example above illustrates a single-step PE, where the untrusted entity uses one permission\nto realize PE. However, a more complicated multi-step PE (or transitive PE) [23, 53] can occur,\ninvolving multiple permissions. This paper focuses on detecting both PE types.\n3\nIAM MODELING\nWe present our concrete IAM modeling using the proposed Permission Flow Graph. We further\npropose our abstract IAM modeling, which provides the foundation of our greybox penetration\ntesting approach.\n3.1\nConcrete IAM Modeling\n3.1.1\nThe Permission Flow. We first propose the permission flow to model an indirect permission\nassignment from one entity to another. Each permission flow has a flow state representing whether\nthe flow is currently enabled or disabled. If a permission flow from entity \ud835\udc521 to entity \ud835\udc522 is currently\nenabled, all permissions assigned to \ud835\udc521 can be automatically assigned to \ud835\udc522; otherwise (i.e., the\npermission flow is currently disabled), the permissions cannot be automatically assigned.\nWhether there is a permission flow between two entities depends on whether there exists a\nrelation between the two entity types whose semantics are associated with indirect permission\nassignments. For example, based on the semantics of the user-role relation stating that all permis-\nsions assigned to a role can be indirectly assigned to the user who assumes the role, there exists a\npermission flow from each role entity to each user entity. Accordingly, there exist four permission\nflows from Role 1 / Role 2 to User 1 / User 2 in the illustrative IAM configuration example\nshown in Figure 1a. The permission flows can be manually extracted based on the semantics of\nentity-entity relations from AWS documentation and relevant studies[5, 20, 28, 30, 60]. Details\nabout identifying permission flows is introduced in Section 6.\nThe state of each permission flow is determined by the relationship between the two entities\ninvolved in the flow. If they are currently related, the flow state is marked as enabled. Otherwise, it\nis marked as disabled. An illustration of this can be found in Figure 1a (showing the illustrative\n6\nYang Hu, Wenxi Wang, Sarfraz Khurshid, and Mohit Tiwari\nIAM configuration example) and Figure 2a (showing its corresponding permission flow states). In\nFigure 1a, User 1 is related to Role 1 but unrelated to Role 2; in alignment with this, in Figure 2a,\nthe flow from Role 1 to User 1 is enabled, whereas the flow from Role 2 to User 1 is disabled.\n3.1.2\nThe Permission Space. Next, we introduce the permission space considered in our concrete\nmodeling. We identify two types of permissions which can be utilized by the untrusted entity to\nobtain the target permission. We call them Type-I and Type-II permissions. A Type-I permission\nallows to enable a permission flow from one entity \ud835\udc521 to another entity \ud835\udc522 such that all permissions\nof \ud835\udc521 are automatically assigned to \ud835\udc522. A Type-II permission allows to directly assign a Type-I\nor target permission (denoted as \ud835\udc5d) to an entity \ud835\udc52. For example, the permission for adding a user\nto a user group is a Type-I permission. The permission for attaching an IAM policy to a user is a\nType-II permission, as it directly assigns each permission in the policy to the user.\nThe permission space in our modeling consists of all Type-I permissions (denoted as \ud835\udc43I), all\nType-II permissions (denoted as \ud835\udc43II) and the target permission (if the target permission is neither\nthe Type-I nor Type-II permission). Figure 1a shows three permissions in the permission space:\nPerm 1, Perm 2, and Perm 3. Perm 1 is the target permission. Perm 2 is the Type-II permission\nwhich allows its assigned entity to directly assign the target permission Perm 1 to Role 1. Perm\n3 is the Type-I permission which allows its assigned entity to assume Role 1, that is enabling a\npermission flow from the assigned entity to Role 1.\n3.1.3\nThe PFG. We propose the PFG to concretely model an IAM configuration. A PFG includes\nentities as its nodes and permission flows as its edges. Formally, a PFG is defined as a tuple\n\ud835\udc3a= (\ud835\udc38, \ud835\udc39, A, W), where \ud835\udc38denotes the entity space; \ud835\udc39\u2286\ud835\udc38\u00d7 \ud835\udc38denotes a set of permission flows;\nA : \ud835\udc38\u21a6\u21922\ud835\udc43denotes a permission assignment function which maps an entity to permissions in\nthe permission space \ud835\udc43; W : \ud835\udc39\u21a6\u2192{true, false} denotes a concrete flow state function which\noutputs whether a permission flow is currently enabled (denoted as true) or disabled (denoted as\nfalse). Figure 2a shows a PFG which straightforwardly models the IAM configuration example\nshown in Figure 1a. Three entities (i.e., Group 1, Role 1 and Role 2) are directly assigned with\npermissions. According to the semantics of user-role relation, service-role relation and user-group\nrelation which are all associated with indirect permission assignments, there are 12 identified\npermission flows between the entities with the corresponding entity types. As shown in Figure 1a,\nfive of the entity-entity pairs are currently related, thus resulting in five enabled permission flows.\nThe remaining seven flows are disabled.\n3.1.4\nConcrete Modeling of IAM Configurations. Given a PFG \ud835\udc3a= (\ud835\udc38, \ud835\udc39, A, W), we define the\npermission flow function returning a new PFG \ud835\udc3a\u2032 = (\ud835\udc38, \ud835\udc39, A\u2032, W) by performing one permission\nflow iteration. The permission flow function M is defined as \ud835\udc3a\u2032 = M(\ud835\udc3a) where\nA\u2032(\ud835\udc522) =\n\u00d8\n{(\ud835\udc521,\ud835\udc522)\u2208\ud835\udc39|W(\ud835\udc521,\ud835\udc522)=true}\nA(\ud835\udc521) \u222aA(\ud835\udc522)\nmeaning that, for each entity \ud835\udc522, all permissions of the entities which have enabled permission\nflows to \ud835\udc522 are assigned to \ud835\udc522.\nGiven a PFG \ud835\udc3a, we perform the fixed point iteration w.r.t. the permission flow function M on\n\ud835\udc3a. The resulting PFG denoted as \ud835\udc3a\u2032 is our concrete model of the IAM configuration. Formally,\n\ud835\udc3a\u2032 = M\u2217(\ud835\udc3a), where M\u2217refers to the fixed point iteration of M (i.e., M\u2217(\ud835\udc3a) = M\ud835\udc5b(\ud835\udc3a) s.t.\nM\ud835\udc5b(\ud835\udc3a) = M\ud835\udc5b\u22121(\ud835\udc3a)). Figure 2b shows a concrete modeling of the illustrative IAM configuration\nexample shown in Figure 1a, which is the fixed point of the PFG in Figure 2a. Based on five enabled\npermission flows, the PFG is updated with indirect permission assignments: User 1 and User 2\nindirectly obtain Perm 2 from Group 1; User 2 and Service 1 indirectly obtain Perm 3 from\nInteractive Greybox Penetration Testing for Cloud Access Control using IAM Modeling and Deep Reinforcement Learning\n7\nRole 2; User 1 indirectly obtains Perm 1 and Perm 2 from Role 1. The resulting PFG can no\nlonger be updated further by any indirect permission assignments, having reached a fixed point.\n3.1.5\nConcrete Modeling of IAM PEs. An IAM configuration has a PE iff the untrusted entity can\nobtain the target permission through the permissions assigned to the untrusted entity. Formally,\nlet \ud835\udc3a0 = (\ud835\udc380, \ud835\udc390, A0, W0) be an initial IAM configuration, \ud835\udc62be the untrusted entity, and \ud835\udc59\u2208\n\ud835\udc43\\ A0(\ud835\udc62) be a target permission; the concrete IAM configuration \ud835\udc3a0 has a PE iff there exists\na sequence of permissions \ud835\udc5d1, . . . , \ud835\udc5d\ud835\udc5b, where \ud835\udc5d\ud835\udc56\u2208A\ud835\udc56\u22121(\ud835\udc62), and a modified IAM configuration\n\ud835\udc3a\ud835\udc5b= (\ud835\udc38\ud835\udc5b, \ud835\udc39\ud835\udc5b, A\ud835\udc5b, W\n\ud835\udc5b) such that\n\ud835\udc3a0\n\ud835\udc5d1\n\u21a9\u2192\ud835\udc3a1 . . .\n\ud835\udc5d\ud835\udc5b\n\u21a9\u2192\ud835\udc3a\ud835\udc5b\u2227\ud835\udc59\u2208A\ud835\udc5b(\ud835\udc62),\nwhere \ud835\udc3a\ud835\udc56\u22121\n\ud835\udc5d\ud835\udc56\n\u21a9\u2192\ud835\udc3a\ud835\udc56annotates that the concrete IAM configuration \ud835\udc3a\ud835\udc56\u22121 is modified to \ud835\udc3a\ud835\udc56by the\nuntrusted entity \ud835\udc62through the permission \ud835\udc5d\ud835\udc56\u2208A\ud835\udc56\u22121(\ud835\udc62).\n3.2\nAbstract IAM Modeling\nThe above concrete IAM modeling requires full access to the IAM configuration. However, not all\npermission assignment information in the IAM configuration is necessary for detecting PEs. For\ninstance, the PE shown in Figure 1b can be detected using only the following partial permission\nassignment information: Service 1 owns Perm 3, and Role 1 owns Perm 1. Based on this insight,\nwe propose our abstract IAM modeling that can identify PEs using partial permission assignment\ninformation, forming the foundation of our greybox penetration testing technique.\n3.2.1\nAbstract PFG. The abstract PFG aims to model the IAM configurations with partially visible\nentities and the permission flows among them with unknown flow states (which are called visible\npermission flows). For the illustrative example, the visible entities User 1, Role 1 and Service 1;\nand the visible permission flows are shown in Figure 2c. With the visible entity space \ud835\udc38vis \u2286\ud835\udc38and\nthe visible permission flow space \ud835\udc39vis \u2286\ud835\udc39, we construct a visible permission space \ud835\udc43vis \u2286\ud835\udc43which\nonly includes Type-I and Type-II permissions that are related to \ud835\udc38vis or \ud835\udc39vis (i.e., permissions\nwhich can directly assign a permission to a visible entity or enable a visible permission flow), and\nthe target permission. Given the visible entities, visible permission flows and visible permissions,\nwe define our abstract PFG as a tuple \u02c6\n\ud835\udc3a= ( \u02c6\n\ud835\udc38, \u02c6\n\ud835\udc39, \u02c6\nA, \u02c6\nW), where \u02c6\n\ud835\udc38denotes the abstract entity space; \u02c6\n\ud835\udc39\ndenotes the abstract permission flow space; \u02c6\nA denotes the abstract entity-permission state function;\n\u02c6\nW denotes the abstract permission flow state function. In the following, we elaborate each of these\ncomponents in detail.\nIn the construction of our abstract entity space and permission flow space, the initial step involves\ntransforming each Type-II permission into a Type-I permission. This transformation step aims\nto simplify the formulation of state transitions which will be demonstrated later in this section.\nRecall that a Type-II permission \ud835\udc60, if being assigned to an entity, allows the entity to directly\nassign a target permission or a Type-I permission \ud835\udc61\ud835\udc60to an entity \ud835\udc52\ud835\udc60. For each Type-II permission\n\ud835\udc60, we 1) add a pseudo entity \ud835\udefd\ud835\udc60assigned with the corresponding target or Type-I permission \ud835\udc61\ud835\udc60, and\n2) add the pseudo permission flow from the pseudo entity \ud835\udefd\ud835\udc60to the corresponding entity \ud835\udc52\ud835\udc60. This\nway, each Type-II permission \ud835\udc60becomes a Type-I permission which allows the assigned entity\nto enable the pseudo permission flow from the pseudo entity \ud835\udefd\ud835\udc60to the corresponding entity \ud835\udc52\ud835\udc60.\nWith the transformations, we then define our abstract entity space \u02c6\n\ud835\udc38and abstract flow space \u02c6\n\ud835\udc39by\nextending the visible entity space \ud835\udc38vis and the visible flow space \ud835\udc39vis, with the pseudo entities and\npseudo permission flows, respectively. Formally, \u02c6\n\ud835\udc38= \ud835\udc38vis \u222a{\ud835\udefd\ud835\udc60|\ud835\udc60\u2208\ud835\udc43II \u2229\ud835\udc43vis \u2227\ud835\udc52\ud835\udc60\u2208\ud835\udc38vis}, and\n\u02c6\n\ud835\udc39= \ud835\udc39vis \u222a{(\ud835\udefd\ud835\udc60,\ud835\udc52\ud835\udc60)|\ud835\udc60\u2208\ud835\udc43II \u2229\ud835\udc43vis \u2227\ud835\udc52\ud835\udc60\u2208\ud835\udc38vis}.\n8\nYang Hu, Wenxi Wang, Sarfraz Khurshid, and Mohit Tiwari\nNext we define our abstract entity-permission state function \u02c6\nA : \u02c6\n\ud835\udc38\u00d7 \ud835\udc43vis \u21a6\u2192{?, +} maps each\nentity-permission pair to an abstract state.\n\u02c6\nA(\ud835\udc52, \ud835\udc5d) =? means that it is unknown whether the\npermission \ud835\udc5dcan be assigned to the entity \ud835\udc52or not;\n\u02c6\nA(\ud835\udc52, \ud835\udc5d) = + means that the permission \ud835\udc5d\ncan be assigned to the entity \ud835\udc52, either directly or indirectly. Initially, the entity-permission state\nfunction assigns ? to all entity-permission pairs except for the pairs of each pseudo entity and the\ncorresponding Type-I or target permission (involved in the Type-II permission). Formally, the\ninitial abstract entity-permission state function \u02c6\nA\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61(\ud835\udc52, \ud835\udc5d) is defined as\n\u02c6\nA\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61(\ud835\udc52, \ud835\udc5d) =\n(\n+,\n\u2203\ud835\udc60\u2208\ud835\udc43II \u2229\ud835\udc43vis.\ud835\udc52= \ud835\udefd\ud835\udc60\u2227\ud835\udc5d= \ud835\udc61\ud835\udc60,\n?,\n\ud835\udc5c\ud835\udc61\u210e\ud835\udc52\ud835\udc5f\ud835\udc64\ud835\udc56\ud835\udc60\ud835\udc52.\n*\n*\n*\nEntity \u03b2perm2\nPerm3\nPerm2\nPerm1\n?\n?\n+\nEntity 4 (Role 1)\nPerm3\nPerm2\nPerm1\n?\n?\n?\nEntity 2 (User 1)\nPerm3\nPerm2\nPerm1\n?\n?\n?\nEntity 6 (Service 1)\nPerm3\nPerm2\nPerm1\n?\n?\n?\n*\n(a) The initial abstract IAM configuration representing the\nvisible concrete PFG in Figure 2c.\n*\n*\n*\nEntity \u03b2perm2\nPerm3\nPerm2\nPerm1\n?\n?\n+\nEntity 4 (Role 1)\nPerm3\nPerm2\nPerm1\n?\n?\n?\nEntity 2 (User 1)\nPerm3\nPerm2\nPerm1\n?\n?\n?\nEntity 6 (Service 1)\nPerm3\nPerm2\nPerm1\n+\n?\n?\n(b) The intermediate abstract configuration updated with\nthe response O(Entity 6, Perm 3).\n*\n*\nEntity \u03b2perm2\nPerm3\nPerm2\nPerm1\n?\n?\n+\nEntity 4 (Role 1)\nPerm3\nPerm2\nPerm1\n?\n?\n+\nEntity 2 (User 1)\nPerm3\nPerm2\nPerm1\n?\n?\n?\nEntity 6 (Service 1)\nPerm3\nPerm2\nPerm1\n+\n?\n+\n*\n(c) The terminal abstract IAM configuration updated with\nthe response O(Entity 4, Perm 1).\nFig. 3. An illustrative example introducing our interactive greybox\npenetration testing approach for IAM PEs; for demonstration\npurposes, we only show three visible permissions.\nThe abstract permission flow state\nfunction\n\u02c6\nW : \u02c6\n\ud835\udc39\u21a6\u2192{\u2217, \u2295} maps each\npermission flow to an abstract state.\n\u02c6\nW(\ud835\udc53) = \u2217means that it is unknown\nwhether the permission flow \ud835\udc53can be\nenabled or not; 2)\n\u02c6\nW(\ud835\udc53) = \u2295means\nthat the permission flow can be en-\nabled. Initially, the states of all per-\nmission flows are mapped to \u2217, which\nis defined as \u2200\ud835\udc53\u2208\u02c6\n\ud835\udc39.\n\u02c6\nW\n\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61(\ud835\udc53) = \u2217.\nFigure 3a shows an example of\nan initial abstract PFG\n\u02c6\n\ud835\udc3a\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61\n=\n( \u02c6\n\ud835\udc38, \u02c6\n\ud835\udc39, \u02c6\nA\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61, \u02c6\nW\n\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61), which is the ab-\nstract modeling of the visible con-\ncrete PFG example shown in Fig-\nure 2c. Recall that Perm\n2 is the\nType-II permission which allows its\nassigned entity to directly assign the\ntarget permission Perm 1 to Role 1.\nPerm 2 is converted into a Type-I\npermission with the added pseudo\npermission flow from the pseudo en-\ntity Entity \ud835\udefd\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc5a2 to Role 1. The\nabstract entity space is expanded\nwith the added pseudo entity Entity\n\ud835\udefd\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc5a2. The abstract permission flow\nspace is also expanded with the added\npseudo permission flows. The entity-\npermission states are initialized to\n?, except for the state of the pseudo\nentity Entity \ud835\udefd\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc5a2 and the target\npermission Perm 1 (involved in the\nType-II permission Perm 2) being\ninitialized to +. All permission flow\nstates are initialized to \u2217.\nInteractive Greybox Penetration Testing for Cloud Access Control using IAM Modeling and Deep Reinforcement Learning\n9\n3.2.2\nAbstract Permission Flow Func-\ntion. Given an abstract PFG \u02c6\n\ud835\udc3a\n=\n( \u02c6\n\ud835\udc38, \u02c6\n\ud835\udc39, \u02c6\nA, \u02c6\nW), the abstract permission\nflow function \u02c6\nM outputs a new PFG \u02c6\n\ud835\udc3a\u2032 = ( \u02c6\n\ud835\udc38, \u02c6\n\ud835\udc39, \u02c6\nA\u2032, \u02c6\nW\u2032) by performing one permission flow itera-\ntion. Formally, the function is defined as \u02c6\n\ud835\udc3a\u2032 =\n\u02c6\nM( \u02c6\n\ud835\udc3a), where\n\u02c6\nA\u2032(\ud835\udc52, \ud835\udc5d) =\n(\n+,\nC1: \u2203\ud835\udc52\u2032 \u2208\ud835\udc41(\ud835\udc52)\n\u2295. \u02c6\nA(\ud835\udc52\u2032, \ud835\udc5d) = +,\n\u02c6\nA(\ud835\udc52),\n\ud835\udc5c\ud835\udc61\u210e\ud835\udc52\ud835\udc5f\ud835\udc64\ud835\udc56\ud835\udc60\ud835\udc52.\n\u02c6\nW\u2032(\ud835\udc53) =\n\u001a\n\u2295,\nC2: \u2203\ud835\udc5d\u2208\ud835\udc43I \u2229\ud835\udc43vis.J\ud835\udc5dK = \ud835\udc53\u2227\u02c6\nA(\ud835\udc62, \ud835\udc5d) = +,\n\u02c6\nW(\ud835\udc53),\n\ud835\udc5c\ud835\udc61\u210e\ud835\udc52\ud835\udc5f\ud835\udc64\ud835\udc56\ud835\udc60\ud835\udc52.\nHere, \ud835\udc41(\ud835\udc52)\n\u2295\n= {\ud835\udc52\u2032|(\ud835\udc52\u2032,\ud835\udc52) \u2208\u02c6\n\ud835\udc39\u2227\n\u02c6\nW(\ud835\udc52\u2032,\ud835\udc52) = \u2295}; J\ud835\udc5dK refers to the permission flow that can be enabled\nwith the Type-I permission \ud835\udc5d.\nEntity e\u2019\n\u2295\n\u2026\np\n\u2026\n\u2026\n+\n\u2026\n\u2026\np\n\u2026\n\u2026\n?\n\u2026\nEntity e\n\u2026\np\n\u2026\n\u2026\n+\n\u2026\n\u2026\np\n\u2026\n\u2026\n?\n\u2026\nEntity e\u2019\n\u2295\n\u2026\np\n\u2026\n\u2026\n+\n\u2026\n\u2026\np\n\u2026\n\u2026\n?\n\u2026\nEntity e\n\u2295\n\u2026\np\n\u2026\n\u2026\n+\n\u2026\n\u2026\np\n\u2026\n\u2026\n+\n\u2026\n(a) Update under C1.\nEntity e\u2019\nEntity u\n\u2026\np\n\u2026\n\u2026\n+\n\u2026\n\u2026\np\n\u2026\n\u2026\n+\n\u2026\n\u2026\n\u2026\n*\nEntity e\n\u2026\n\u2026\nEntity e\u2019\nEntity u\n\u2026\np\n\u2026\n\u2026\n+\n\u2026\n\u2026\np\n\u2026\n\u2026\n+\n\u2026\n\u2026\n\u2026\nEntity e\n\u2026\n\u2026\n\u2295\n(b) Update under C2.\nFig. 4. Abstract state updates.\nThe condition C1 is used\nto update the abstract state\nof an entity-permission pair.\nIf there exists an entity \ud835\udc52\u2032\nhaving the permission \ud835\udc5d\n(i.e., the abstract state is +)\nand an enabled permission\nflow (i.e., the permission\nflow state is \u2295) from the en-\ntity \ud835\udc52\u2032 to an entity \ud835\udc52, then\n\ud835\udc52can have the permission\n\ud835\udc5d(i.e., the abstract state of\nthe pair (\ud835\udc52, \ud835\udc5d) is updated\nto +). Figure 4a illustrates\nhow the abstract state of an\nentity-permission pair gets\nupdated under the condi-\ntion C1.\nThe condition C2 is used to update the abstract state of a permission flow. If there exists a\npermission \ud835\udc5dassigned to the compromised entity \ud835\udc62(i.e., the abstract state of the pair (\ud835\udc62, \ud835\udc5d) is +)\nand the permission \ud835\udc5dis a Type-I permission which allows to enable a permission flow \ud835\udc53, then the\npermission flow \ud835\udc53can be enabled (i.e., the abstract state of \ud835\udc53is updated to \u2295). Figure 4b illustrates\nhow the abstract state of a permission flow gets updated under condition C2.\n3.2.3\nAbstract IAM Configuration Modeling. Similar with the concrete IAM configuration modeling,\ngiven an abstract PFG \u02c6\n\ud835\udc3a, we perform the fixed point iteration w.r.t. the abstract permission flow\nfunction\n\u02c6\nM on \u02c6\n\ud835\udc3a. The resulting \u02c6\n\ud835\udc3a\u2032 is our abstract model of the IAM configuration. Formally,\n\u02c6\n\ud835\udc3a\u2032 =\n\u02c6\nM\u2217( \u02c6\n\ud835\udc3a) where \u02c6\nM\u2217refers to the fixed point iteration of \u02c6\nM (i.e., \u02c6\nM\u2217(\ud835\udc3a) =\n\u02c6\nM\ud835\udc5b(\ud835\udc3a) such that\n\u02c6\nM\ud835\udc5b(\ud835\udc3a) =\n\u02c6\nM\ud835\udc5b\u22121(\ud835\udc3a)).\nIn particular, the initial abstract PFG \u02c6\n\ud835\udc3a\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61= ( \u02c6\n\ud835\udc38, \u02c6\n\ud835\udc39, \u02c6\nA\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61, \u02c6\nW\n\ud835\udc56\ud835\udc5b\ud835\udc56\ud835\udc61) (introduced in Section 3.2.1)\nis the initial abstract IAM configuration. In addition, \u02c6\n\ud835\udc3a\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc5a= ( \u02c6\n\ud835\udc38, \u02c6\n\ud835\udc39, \u02c6\nA\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc5a, \u02c6\nW\n\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc5a) denotes the\nterminal abstract IAM configuration, where \u02c6\nA\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc5a(\ud835\udc62,\ud835\udc59) = +. The rest configurations are referred\nto as intermediate abstract IAM configurations. Figure 3 shows three abstract IAM configurations\nabstracting the partially visible PFG shown in Figure 2c, including an initial abstract configuration\n10\nYang Hu, Wenxi Wang, Sarfraz Khurshid, and Mohit Tiwari\n(Figure 3a), an intermediate abstract configuration (Figure 3b) and a terminal abstract configuration\n(Figure 3c).\n4\nTAC\n4.1\nOverview\nBased on abstract IAM modeling, we propose a greybox penetration testing approach called TAC for\ndetecting IAM PEs, without requiring a complete IAM configuration. Unlike existing whitebox\npenetration testing approaches which force their customers to pay lots of manual efforts to blindly\neliminate all sensitive information of their IAM configurations, TAC actively interacts with cloud\ncustomers to query only the essential information related to PE detection.\nTAC only requires cloud customers to provide two simple initial inputs beforehand: 1) the type of\nthe untrusted entity and the target permission; 2) the types of visible entities that they are inclined\nto be queried with. TAC renames each visible entity (including the untrusted entity) with a randomly\ngenerated entity ID; constructs the visible permissions with the renamed visible entities; and creates\nvisible permission flows (with unknown flow states) among visible entities based on their types.\nThese visible entities, visible permissions, and visible permission flows are used to create the initial\nabstract IAM configuration. For the illustrative example, suppose the customer chooses User 1,\nRole 1 and Service 1 as the visible entities, they are randomly renamed by TAC as Entity 2,\nEntity 4, and Entity 6, respectively. The converted initial abstract IAM configuration is shown\nin Figure 3a.\nTAC delivers one query to the cloud customer at a time, inquiring whether a visible permission is\nassigned to a visible entity. The cloud customer can choose to either respond to or decline the query,\nbased on their knowledge of whether the inquired permission assignment information is confidential.\nFormally, let \ud835\udc44= \ud835\udc38vis\u00d7\ud835\udc43vis be the query space. The response of the cloud customer w.r.t. a concrete\nIAM configuration \ud835\udc3a= (\ud835\udc38, \ud835\udc39, A, W) is defined as a function O : \ud835\udc44\u21a6\u2192{true, false, unknown}\nsatisfying\nO(\ud835\udc52, \ud835\udc5d) =\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3\ntrue,\n\ud835\udc4e\ud835\udc50\ud835\udc50\ud835\udc52\ud835\udc5d\ud835\udc61\u2227\ud835\udc5d\u2208A(\ud835\udc52),\nfalse,\n\ud835\udc4e\ud835\udc50\ud835\udc50\ud835\udc52\ud835\udc5d\ud835\udc61\u2227\ud835\udc5d\u2209A(\ud835\udc52),\nunknown,\n\u00ac\ud835\udc4e\ud835\udc50\ud835\udc50\ud835\udc52\ud835\udc5d\ud835\udc61\nwhere the boolean variable \ud835\udc4e\ud835\udc50\ud835\udc50\ud835\udc52\ud835\udc5d\ud835\udc61denotes whether the customer accepts to answer the query.\nAdditionally, TAC allows cloud customers to specify the number of queries they accept to response,\nwhich is called the query budget. TAC outputs if a PE is detected within the query budget. In TAC,\nan IAM configuration has a PE iff its initial abstract configuration can be updated to a terminal\nabstract configuration, based on the customer query responses. Formally, let \u02c6\n\ud835\udc3a0 = ( \u02c6\n\ud835\udc380, \u02c6\n\ud835\udc390, \u02c6\nA0, \u02c6\nW0)\nbe an initial abstract IAM configuration, \ud835\udc62be the untrusted entity, and \ud835\udc59be the target permission.\nThe initial abstract IAM configuration \u02c6\n\ud835\udc3a0 has an abstract PE iff there exists a sequence of queries\n(\ud835\udc521, \ud835\udc5d1), . . . , (\ud835\udc52\ud835\udc5b, \ud835\udc5d\ud835\udc5b) \u2208\ud835\udc44, and a terminal abstract IAM configuration \u02c6\n\ud835\udc3a\ud835\udc5b= ( \u02c6\n\ud835\udc38\ud835\udc5b, \u02c6\n\ud835\udc39\ud835\udc5b, \u02c6\nA\ud835\udc5b, \u02c6\nW\n\ud835\udc5b) such\nthat\n\u02c6\n\ud835\udc3a0\n(\ud835\udc521,\ud835\udc5d1)\n\u21a9\u2192\n\u02c6\n\ud835\udc3a1 . . .\n(\ud835\udc52\ud835\udc5b,\ud835\udc5d\ud835\udc5b)\n\u21a9\u2192\n\u02c6\n\ud835\udc3a\ud835\udc5b\u2227\u02c6\nA\ud835\udc5b(\ud835\udc62,\ud835\udc59) = +,\nwhere \u02c6\n\ud835\udc3a\ud835\udc56\u22121\n(\ud835\udc52\ud835\udc56,\ud835\udc5d\ud835\udc56)\n\u21a9\u2192\n\u02c6\n\ud835\udc3a\ud835\udc56annotates that the abstract IAM configuration \u02c6\n\ud835\udc3a\ud835\udc56\u22121 is updated to \u02c6\n\ud835\udc3a\ud835\udc56based on\nthe customer response of the query (\ud835\udc52\ud835\udc56, \ud835\udc5d\ud835\udc56):\n\u02c6\n\ud835\udc3a\ud835\udc56=\n( \u02c6\nM\u2217( \u02c6\n\ud835\udc3a\ud835\udc56\u22121[ \u02c6\nA\ud835\udc56\u22121[\ud835\udc52\ud835\udc56, \ud835\udc5d\ud835\udc56] \u21a6\u2192+]),\nO(\ud835\udc52\ud835\udc56, \ud835\udc5d\ud835\udc56) = true,\n\u02c6\n\ud835\udc3a\ud835\udc56\u22121,\n\ud835\udc5c\ud835\udc61\u210e\ud835\udc52\ud835\udc5f\ud835\udc64\ud835\udc56\ud835\udc60\ud835\udc52.\nInteractive Greybox Penetration Testing for Cloud Access Control using IAM Modeling and Deep Reinforcement Learning\n11\nNote that our abstract IAM modeling and state updating rules guarantee the precision of IAM PE\ndetection, meaning that the PE identified by TAC must be a true PE.\nWe use the illustrative example (shown in Figure 3) to briefly introduce how TAC interacts with its\ncustomer through queries to detect IAM PEs. Given the initial abstract IAM configuration in Figure\n3a, TAC may query the customer whether Entity 6 initially has the permission Perm 3 (i.e., the query\n(Entity 6, Perm 3)). The customer answers yes to the query (i.e., O(Entity 6, Perm 3) = true).\nThus, the abstract state of the entity-permission pair (Entity 6, Perm 3) is updated to +. In addition,\nPerm 3 is the Type-I permission which allows its assigned entity (i.e., Entity 6) to enable the\npermission flow from Entity 4 to Entity 6. Thus, the abstract state of the permission flow from\nEntity 4 to Entity 6 is updated to \u2295. The resulting intermediate abstract IAM configuration is\nshown in Figure 3b. Next, TAC may send another query to see whether Entity 4 has the target\npermission Perm 1 (i.e., the query (Entity 4, Perm 1)). As a result, the customer answers yes to\nthe query (i.e., O(Entity 4, Perm 1) = true). Thus, the abstract state of the entity-permission\npair (Entity 4, Perm 1) is updated to +. Based on the condition C1 of the abstract permission\nflow function \u02c6\nM, the abstract state of the entity-permission pair (Entity 6, Perm 1) is updated to\n+. Since the initial IAM configuration can be updated to the terminal abstract IAM configuration\nshown in Figure 3c, the initial configuration has a PE.\n4.2\nGeneral Framework\nTo be practically applicable, TAC aims to minimize the customer responses. To achieve this, the goal\nis to detect the IAM PE with as few queries as possible within the query budget. The problem is a se-\nquential decision making problem, where each query is selected based on the customer\u2019s responses of\nprevious queries. To solve the problem, we apply RL to learn to use as few queries as possible to iden-\ntify the IAM PEs. The general framework of TAC is designed based on our RL formulation of the prob-\nlem,\nas\nshown\nin\nFigure\n5.\nReward\nFeedback\nQuery \nModel\nAbstract IAM \nModeling\nAbstract \nIAM Config.\nQuery\nReward\nEnvironment\nRL Agent\nVisibility\nLearning \nAlgorithm\nQuery \nBudget\nInitial Input\nResponse\nCustomer\nPE\nFig. 5. The general framework of TAC.\nIn each episode, the RL agent begins with its\nvisibility, an initial abstract IAM configuration,\nand a query budget. The agent iteratively sends\nqueries to update the abstract IAM configura-\ntion until either a PE is identified or the query\nbudget is exhausted. In each iteration, an RL\nagent uses a query model (i.e., the RL policy) for\nselecting one query (i.e., the action) based on\nthe current abstract IAM configuration (i.e., the\nstate). In the environment of our RL formula-\ntion, the abstract IAM configuration is updated\nbased on the customer response of the query; a\nreward, which is \u22121 for each query, is output by\na reward feedback module. The RL agent then\nuses the classic Actor-Critic Method [57] as the\nlearning algorithm to update the query model\nbased on the reward. Note that the current re-\nwards and future rewards are treated equally\nimportant (i.e., the reward discount factor is set to 1). The goal of the RL agent is to learn a good\nquery model to maximize the return, which is equivalent to minimizing the number of queries.\n12\nYang Hu, Wenxi Wang, Sarfraz Khurshid, and Mohit Tiwari\nPseudo\n(\u03b2perm2 )\nOther\n(entity 4)\nCompromised\n(entity 6)\nTarget\n(perm 1)\nType-I\n(perm 2)\n\u2026\n\u2026\n\u2295\n\u2217\n\u2217\n+\n?\n?\n?\n?\n?\nFig. 6. The graph representation of the abstract IAM configuration in Figure 3b for GNN (Entity 2 and\nPerm 3 are omitted). Each entity node is represented with a circle; each permission node is represented\nwith a triangle; each entity-entity edge representing a permission flow is annotated in a blue line and each\nentity-permission edge is annotated in an orange line (an edge representing a permission assignment is\nrepresented in a solid line; an edge from a source/sink entity of the permission flow in a Type-I permission\nto the corresponding Type-I permission is represented in a dotted/dashed line, respectively).\nNote that the formulated RL problem requires the RL agent to detect the PE within only one\nepisode. However, classic deep RL approaches [57] usually train an RL policy from scratch (i.e.,\nweights in the policy model are randomly initialized), which requires lots of episodes to maximize\nthe return. Inspired by recent advances in zero/few-shot learning for language models [13, 42], we\npretrain our query model on a diverse set of PE tasks via multi-task RL across multiple episodes.\nThe goal is to enhance the model\u2019s query efficiency on a new PE task within a single episode.\nExisting multi-task RL techniques [15, 17, 56] face two limitations in our problem. First, they\nrequire a shared action space for all tasks, while our PE tasks have specific action/query spaces.\nSecond, they may experience the negative transfer issue, where training on some tasks negatively\nimpacts others [45, 55]. To address the first limitation, we implement our query model as a Graph\nNeural Network (GNN), which can be generalized across diverse PE tasks with different query\nspaces. To mitigate the negative transfer issue, we first use domain knowledge to divide the PE task\nspace into subspaces, each containing non-interfering tasks, and then pretrain a specialized query\nmodel for each subspace. Further details on the query model and its negative transfer mitigation\nare discussed in the following section.\n4.3\nQuery Model\nOur idea is to generate a query embedding (vector representation) for each query within the query\nspace of the current abstract IAM configuration. This embedding is used to infer a probability\ndistribution over the query space for query sampling/selection. To achieve this, we encode the\ncurrent abstract IAM configuration into a graph where queries are represented as edges, and utilizes\nGNN to generate these edge embeddings. Note that the GNN\u2019s capability to effectively process and\ngeneralize across various graph structures allows our query model to generate query embeddings\nfor any arbitrary abstract IAM configurations. This enables us to pretrain our query model across\ndiverse PE tasks. The following subsection details the graph representations, model architecture,\nand pretraining process.\n4.3.1\nThe Graph Representation. In this section, we explain how we transform an abstract IAM\nconfiguration into a directed graph representation, which serves as the input for our GNN-based\nInteractive Greybox Penetration Testing for Cloud Access Control using IAM Modeling and Deep Reinforcement Learning\n13\nQuery\n(Entity 4, Perm 1)\nGNN Layers\n\u03b2perm2 \nEntity 4\nEntity 6\nPerm 1 \nPerm 2\n+\n?\n?\n?\n?\n?\n\u03b2perm2 \nEntity 4\nEntity 6\nPerm 2\nPerm 1\n\u03b2perm2 \n0.1\n0.7\n0.05\n0.01\n0.1\nEntity 4\nEntity 6\nPerm 2\nPerm 1\n(A)\n(B)\n(C)\nMLP Layer\nGNN Layers\nGNN Layers\nFig. 7. The design and workflow of the query model.\nquery model. The nodes in the converted graph representation are generally classified into two\ntypes: entity nodes and permission nodes. Entity nodes are further classified into three sub-types:\nthe pseudo entity type, untrusted entity type, and other entity type; permission nodes can be\nfurther classified into two sub-types: target permission type and Type-I permission type (there is\nno Type-II permission type, since all Type-II permissions are converted into Type-I permissions\nas introduced in Section 3.2.1). The directed edges in the graph are generally classified into two\ntypes, entity-entity type representing permission flows, and entity-permission type including three\nsub-types: (1) edges representing the permission assignments from an entity to one of its assigned\npermissions; (2) edges from a source entity of the permission flow in a Type-I permission to the\ncorresponding Type-I permission; (3) edges from a sink entity of the permission flow in a Type-I\npermission to the corresponding Type-I permission. Note that each permission assignment edge\nin sub-type (1) with unknown abstract state ? also represents one query. The features of the nodes\nand edges include their corresponding types. In addition, the features of edges representing the\npermission flows and assignments also include their corresponding abstract values\n\u02c6\nW and\n\u02c6\nA,\nrespectively. Figure 6 shows the input graph representation of the abstract IAM configurations\nshown in Figure 3b.\n4.3.2\nGNN-based Model Design. Given the graph representation of the abstract IAM configuration\nas the input, GNN-based query model first samples an entity-permission edge representing a\npermission assignment with ? abstract state in the input graph, based on the inferred probability\ndistribution. Then, it outputs the corresponding query of the sampled permission assignment edge.\nThe idea is to let the query model predict which permission assignment with the unknown state is\ncritical for the PE detection.\nFigure 7 illustrates the design and workflow of our GNN-based query model. Given a graph\nrepresentation of an abstract IAM configuration, shown as the graph (A), five stacked Graph\nAttention Network named GATv2 layers [12] are first applied to generate the embedding of the\npermission assignment edges, shown as the graph (B). A Multi-Layer Perceptron (MLP) layer is\nthen applied to predict the probability distribution over the query edges (permission assignment\nedges with ? abstract state), shown as the graph (C). Last, a query edge is sampled from the\npredicted probability distribution, which is converted into a query with the same corresponding\nentity and permission, as the output of the query model. For example, as shown in Figure 7, the edge\nfrom Entity 4 to Perm 1 is sampled since it has the highest probability. Thus, the corresponding\nquery (Entity 4, Perm 1) is selected as the output of the query model.\n4.3.3\nModel Pretraining. To address the negative transfer issue mentioned in Section 4.2, our\nintuition is that PE tasks involving the same untrusted entity type are likely to share similar optimal\nquery policies for detecting PEs. Therefore, they are unlikely to interfere with each other during\nmodel pretraining. Based on this intuition, we pretrain a query model on PE tasks with the same\nuntrusted entity type. Specifically, given a set of pretraining tasks, we first divide them into groups\n14\nYang Hu, Wenxi Wang, Sarfraz Khurshid, and Mohit Tiwari\naccording to their untrusted entity types. For each group, we pretrain a distinct query model\nspecialized for handling PE tasks with that specific untrusted entity type. This is achieved using RL\nwith a sequential task scheduling strategy, where PE tasks in the group are randomly shuffled and\nsequentially used to optimize the query model over multiple episodes per task.\n5\nIAMVULGEN\nBoth our pretraining and evaluation require a large, diverse and challenging IAM PE task set. To our\nknowledge, the only publicly available IAM PE task set is IAM Vulnerable [1], which only includes\n31 simple tasks. To remedy the lack of PE tasks, we introduce IAMVulGen, aiming to synthesize\nIAM PE tasks that are diverse and can mimic PEs in real-world scenarios.\nBased on AWS\u2019s official documentation [4\u20136] and recent studies on IAM PEs [20, 28, 30, 60], we\nidentified 72 common entity types and 219 permission flow templates, giving rise to thousands of\npotential entities and millions of possible permissions. Consequently, IAMVulGen is able to generate\nIAM misconfigurations with any size up to the identified entity and permission space. In particular,\nIAMVulGen constructs each IAM PE task in two steps: 1) generate a concrete IAM misconfiguration;\n2) generate the corresponding initial abstract IAM misconfiguration.\n5.1\nConcrete Misconfiguration Generation\nTo generate a concrete IAM misconfiguration with PE, IAMVulGen first randomly generates a\nconcrete IAM configuration by creating the four components of a PFG \ud835\udc3a= (\ud835\udc38, \ud835\udc39, A, W):\n\u2022 The entity space \ud835\udc38is constructed based on 72 common entity types manually identified from\nAWS official service documentation [4\u20136], including user, user group, role, and 69 service types.\nIAMVulGen uniformly samples \ud835\udc5b(\ud835\udc5b\u2208[1, 5] by default) entity types from the identified types. For\neach selected type, it generates \ud835\udc5a(\ud835\udc5a\u2208[1, 20] by default) entities.\n\u2022 The permission flow space \ud835\udc39is created based on 219 permission flow templates manually extracted\nfrom AWS service authorization reference documentation [5] and studies on IAM PEs [20, 28, 30,\n60]. The template identifies the type of each entity pair that has a permission flow. Given the\ngenerated entity space \ud835\udc38, IAMVulGen adds a permission flow between each entity pair that has\nthe identified type in a template.\n\u2022 To build the permission assignment A, the first step is to generate a permission space \ud835\udc43including\nType-I, Type-II, and target permissions. A Type-I permission is created for each generated\npermission flow to enable the flow. For the Type-II permission, three entity types (i.e., user, user\ngroup and role) are manually identified which can be directly assigned with a Type-I/target per-\nmission; for each entity with one of these types and each Type-I/target permission, IAMVulGen\ngenerates a Type-II permission for assigning the Type-I/target permission to the entity. For\nthe target permission, based on AWS IAM security best practice documentation [6] and studies\n[20, 28, 30, 60], permissions which attackers usually target to obtain (e.g., the permission to access\na sensitive S3 bucket) are manually identified. With the generated permission space, IAMVulGen\ncreates the permission assignment component A, by assigning each entity with \ud835\udefe\ud835\udc5d(\ud835\udefe\ud835\udc5d= 20% by\ndefault) of the permissions uniformly sampled from the permission space.\n\u2022 For the flow state function W, IAMVulGen sets the state of each permission flow to true with\nthe probability of \ud835\udefe\ud835\udc64(\ud835\udefe\ud835\udc64= 0.2 by default) and to false with the probability of 1 \u2212\ud835\udefe\ud835\udc64. With the\ngenerated PFG, the fixed point iteration is performed to produce a concrete IAM configuration\n(as introduced in Section 3.1.3).\nWith the generated IAM configuration, an entity and a permission are uniformly selected\nfrom the configuration\u2019s entity and permission spaces to be the untrusted entity and the target\npermission, respectively. Next, IAMVulGen utilizes four precise whitebox PE detectors to check if\nthere exists a PE in the generated concrete IAM configuration. If at least one detector reports a PE,\nInteractive Greybox Penetration Testing for Cloud Access Control using IAM Modeling and Deep Reinforcement Learning\n15\nthe concrete misconfiguration is thus generated; otherwise, the process iterates by generating a\nnew configuration. The applied four whitebox PE detectors include three state-of-the-art IAM PE\ndetectors, namely Pacu [33], Cloudsplaining [47] and PMapper [21], and a whitebox variant of\nTAC which only applies the concrete IAM modeling to detect PEs, namely TAC-WB.\n5.2\nInitial Abstract Misconfiguration Generation\nAs introduced in Section 3.2.1, the initial abstract IAM configuration is generated with the pre-\ndefined visible entities. Based on the created concrete misconfiguration, IAMVulGen creates the\ncorresponding initial abstract IAM misconfiguration by uniformly sampling\ud835\udefe\ud835\udc63(\ud835\udefe\ud835\udc63= 20% by default)\nof entities in the concrete IAM misconfiguration as the visible entities.\n6\nIAMVULGEN\nBoth our pretraining and evaluation require a large, diverse and challenging IAM PE task set. To our\nknowledge, the only publicly available IAM PE task set is IAM Vulnerable [1], which only includes\n31 simple tasks. To remedy the lack of PE tasks, we introduce IAMVulGen, aiming to synthesize\nIAM PE tasks that are diverse and can mimic PEs in real-world scenarios.\nBased on AWS\u2019s official documentation [4\u20136] and recent studies on IAM PEs [20, 28, 30, 60], we\nidentified 72 common entity types and 219 permission flow templates, giving rise to thousands of\npotential entities and millions of possible permissions. Consequently, IAMVulGen is able to generate\nIAM misconfigurations with any size up to the identified entity and permission space. In particular,\nIAMVulGen constructs each IAM PE task in two steps: 1) generate a concrete IAM misconfiguration;\n2) generate the corresponding initial abstract IAM misconfiguration.\n6.1\nConcrete Misconfiguration Generation\nTo generate a concrete IAM misconfiguration with PE, IAMVulGen first randomly generates a\nconcrete IAM configuration by creating the four components of a PFG \ud835\udc3a= (\ud835\udc38, \ud835\udc39, A, W):\n\u2022 The entity space \ud835\udc38is constructed based on 72 common entity types manually identified from\nAWS official service documentation [4\u20136], including user, user group, role, and 69 service types.\nIAMVulGen uniformly samples \ud835\udc5b(\ud835\udc5b\u2208[1, 5] by default) entity types from the identified types. For\neach selected type, it generates \ud835\udc5a(\ud835\udc5a\u2208[1, 20] by default) entities.\n\u2022 The permission flow space \ud835\udc39is created based on 219 permission flow templates manually extracted\nfrom AWS service authorization reference documentation [5] and studies on IAM PEs [20, 28, 30,\n60]. The template identifies the type of each entity pair that has a permission flow. Given the\ngenerated entity space \ud835\udc38, IAMVulGen adds a permission flow between each entity pair that has\nthe identified type in a template.\n\u2022 To build the permission assignment A, the first step is to generate a permission space \ud835\udc43including\nType-I, Type-II, and target permissions. A Type-I permission is created for each generated\npermission flow to enable the flow. For the Type-II permission, three entity types (i.e., user, user\ngroup and role) are manually identified which can be directly assigned with a Type-I/target per-\nmission; for each entity with one of these types and each Type-I/target permission, IAMVulGen\ngenerates a Type-II permission for assigning the Type-I/target permission to the entity. For\nthe target permission, based on AWS IAM security best practice documentation [6] and studies\n[20, 28, 30, 60], permissions which attackers usually target to obtain (e.g., the permission to access\na sensitive S3 bucket) are manually identified. With the generated permission space, IAMVulGen\ncreates the permission assignment component A, by assigning each entity with \ud835\udefe\ud835\udc5d(\ud835\udefe\ud835\udc5d= 20% by\ndefault) of the permissions uniformly sampled from the permission space.\n\u2022 For the flow state function W, IAMVulGen sets the state of each permission flow to true with\nthe probability of \ud835\udefe\ud835\udc64(\ud835\udefe\ud835\udc64= 0.2 by default) and to false with the probability of 1 \u2212\ud835\udefe\ud835\udc64. With the\n16\nYang Hu, Wenxi Wang, Sarfraz Khurshid, and Mohit Tiwari\nTask Set\nSource\n# Task\n# Untrusted\n# Visible Entity\n# Visible Perm Flow\n# Permission\nEntity Type\nmin\nmax\navg\nmin\nmax\navg\nmin\nmax\navg\nPretrain\nIAMVulGen\n2,000\n51\n2\n34\n15\n2\n274\n48\n6\n313\n67\nTest-A\nIAMVulGen\n500\n51\n3\n27\n14\n2\n300\n70\n12\n322\n72\nTest-B\nIAM Vulnerable\n31\n2\n1\n3\n2\n0\n6\n2\n3\n12\n7\nTest-C\nSecurity Startup\n2\n2\n15\n25\n20\n84\n261\n172\n88\n252\n170\nTable 1. Statistics of three PE task sets.\ngenerated PFG, the fixed point iteration is performed to produce a concrete IAM configuration\n(as introduced in Section 3.1.3).\nWith the generated IAM configuration, an entity and a permission are uniformly selected\nfrom the configuration\u2019s entity and permission spaces to be the untrusted entity and the target\npermission, respectively. Next, IAMVulGen utilizes four precise whitebox PE detectors to check if\nthere exists a PE in the generated concrete IAM configuration. If at least one detector reports a PE,\nthe concrete misconfiguration is thus generated; otherwise, the process iterates by generating a\nnew configuration. The applied four whitebox PE detectors include three state-of-the-art IAM PE\ndetectors, namely Pacu [33], Cloudsplaining [47] and PMapper [21], and a whitebox variant of\nTAC which only applies the concrete IAM modeling to detect PEs, namely TAC-WB.\n6.2\nInitial Abstract Misconfiguration Generation\nAs introduced in Section 3.2.1, the initial abstract IAM configuration is generated with the pre-\ndefined visible entities. Based on the created concrete misconfiguration, IAMVulGen creates the\ncorresponding initial abstract IAM misconfiguration by uniformly sampling\ud835\udefe\ud835\udc63(\ud835\udefe\ud835\udc63= 20% by default)\nof entities in the concrete IAM misconfiguration as the visible entities.\n7\nEVALUATION\n7.1\nExperimental Setup\n7.1.1\nPretraining and Testing Task Sets. To pretrain TAC, we create an IAM PE task set called\nPretrain, containing 2,000 tasks randomly generated by our task generator IAMVulGen under its\ndefault setting. To evaluate TAC, we create three testing task sets: 1) Test-A set consisting of 500\nnew tasks randomly generated by IAMVulGen under its default setting, and 2) Test-B set consisting\nof 31 tasks collected from public IAM PE benchmark set called IAM Vulnerable [1], and Test-C set\nconsisting of two real-world misconfigurations with PEs collected from a US-based cloud security\nstartup. Note that none of the three testing task sets overlap with the Pretrain set.\nTable 1 shows the statistics of the generated task sets. The Pretrain task set includes diverse PE\ntasks with 51 untrusted entity types, having 2\u201334 visible entities, 2\u2013274 visible permission flows,\nand 6\u2013313 permissions. The Test-A task set has similar statistics. In contrast, Task-B set includes\nmuch smaller and less diverse tasks with only 2 untrusted entity types, 1\u20133 visible entities, 0\u20136\npermission flows, and 3\u201312 permissions.\nThe Test-C task set includes two real-world misconfigurations, namely Real-1 and Real-2.\nReal-1 has 15 visible entities, 84 permission flows, and 88 permissions. Real-2 has 25 visible\nentities, 261 permission flows, and 252 permissions. Due to a data security protocol with the startup\nand its clients, we cannot disclose specific details. However, both misconfigurations involve at least\none transitive PE with paths of at least five steps, presenting significant detection challenges within\na limited query budget.\n7.1.2\nCustomer Query Response Simulation. As introduced, TAC interacts with cloud customers in\ndetecting IAM PEs. To evaluate TAC with hundreds of PE tasks, we build a customer query response\nsimulator. Given an IAM PE task, the query response simulator randomly samples a set of queries\nInteractive Greybox Penetration Testing for Cloud Access Control using IAM Modeling and Deep Reinforcement Learning\n17\nfrom the query space to serve as the ones that cloud customers accept to answer. Given a concrete\nIAM configuration and a query selected by TAC, the simulator automatically decides whether to\naccept the query based on the sampled query set, and gives the answer to the accepted query based\non the concrete IAM configuration.\n7.1.3\nBaselines. Given the absence of publicly available greybox or blackbox IAM PE detectors,\nwe take three state-of-the-art open-source whitebox PE detectors as our baselines, including Pacu\n[33], Cloudsplaining [47] and PMapper [21]. Besides, to understand the effectiveness of TAC\u2019s\nIAM modeling, we also include the whitebox variant of TAC , namely TAC-WB, which only applies\nour concrete IAM modeling to detect PEs. In addition, to understand how the GNN-based RL helps\nto improve the performance of the query model, we build two greybox variants of TAC: one with a\nquery model which randomly selects queries, namely TAC-RD; the other one with a query model\ntrained by the state-of-the-art evolutionary algorithm called CMA-ES [22], namely TAC-EA. To\nunderstand how pretraining helps to improve the query model performance, we build another\ngreybox variant of TAC, where the query model learns from scratch without pretraining (i.e., having\nthe query model initialized with default model parameters by pytorch), namely TAC-NoPT.\n7.1.4\nEvaluation Metrics. To evaluate the effectiveness of TAC, we use the false negative rate (FNR)\nas the evaluation metric, which is defined as FNR = |\ud835\udc47|\u2212|\ud835\udc37|\n|\ud835\udc47|\nin our setting, where |\ud835\udc47| refers to the\nsize of the whole task set \ud835\udc47, and |\ud835\udc37| be the size of the task set \ud835\udc37\u2286\ud835\udc47where PEs are successfully\nidentified by the detector. Note that we do not measure false positive rates, as all detectors in our\nexperiments are precise. To evaluate the efficiency of TAC, we use the query count as our evaluation\nmetric, which is the number of queries used to interact with the customer during the detection.\n7.1.5\nQuery Budgets. In real-world scenarios, customers set the query budget based on their will-\ningness to answer queries. The larger this budget is, the more information TAC obtains, increasing\nits chances of detecting PEs. For our experiments, we deliberately chose smaller query budgets to\nchallenge TAC and assess its performance. In detail, for Test-A and Test-C task sets, we have 10\nquery budgets, which are set to 10, 20, 30, . . ., 100, respectively. Note that these query budgets are\nset much smaller than the maximum size of the query space (which is 8, 448). For Test-B task set\n(the maximum size of the query space is 27), we have two query budgets which are set to 10 and 20,\nrespectively.\n7.1.6\nHyper-Parameter Settings. In the pretraining, each task is used to pretrain a query model in\n20 episodes. In addition, the AdamW optimizer [36] with a learning rate of 10\u22124 is applied in both\nthe pretraining and testing. To obtain reliable results, each experiment including the pretraining\nand testing is repeated 11 times.\n7.2\nResearch Questions\nWe try to answer the following three research questions:\nRQ1: How effective is our concrete IAM modeling?\nRQ2: How effective is TAC in terms of false negative rate?\nRQ3: How efficient is TAC in terms of query count?\n7.3\nExperimental Results\n7.3.1\nRQ1: Effectiveness of Concrete IAM Modeling. To empirically evaluate our concrete IAM\nmodeling, we run all three whitebox baselines and TAC-WB on the task set Test-A, Test-B and\nTest-C. TAC-WB detects all PEs of the three task sets, achieving zero false negative rate. In contrast,\non Test-A set, the false negative rates of PMapper, Pacu and Cloudsplaining are 12%, 20% and\n18\nYang Hu, Wenxi Wang, Sarfraz Khurshid, and Mohit Tiwari\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\nQuery Budget\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nFalse Negative Rate\nCloudsplaining\nPacu\nPMapper\nTAC-WB\nTAC\nTAC-NoPT\nTAC-EA\nTAC-RD\nWhitebox\n(a) False negative rates of TAC and its three variants\non Test-A across 10 different query budgets. For fur-\nther comparisons, the false negative rates of the four\nwhitebox baselines are also added, represented in four\nblue dashed lines.\n0\n50\n100\n150\n200\n250\n300\n350\nDetected Privilege Escalation\n0\n20\n40\n60\n80\n100\nQuery Count\nTAC\nTAC-NoPT\nTAC-EA\nTAC-RD\n(b) The query efficiency of TAC and its three greybox\nvariants in detecting PE tasks in Test-A under the\nquery budget of 100. Under the same query count,\nTAC consistently identifies more PEs than the three\ngreybox variants.\nFig. 8. Evaluation results. Solid lines and their corresponding shadow regions refer to the mean and standard\ndeviation of false negative rates or query counts over 11 repeated experiments, respectively.\n26%, respectively; on Test-B set, the false negative rates of PMapper, Pacu and Cloudsplaining\nare 29%, 32% and 39%, respectively; On the Test-C set, PMapper, Pacu, and Cloudsplaining fail to\ndetect both PEs, resulting in a 100% false negative rate. Upon manual inspection, we found that the\nfalse negative cases of pattern-based detectors, Pacu and Cloudsplaining, arose from the absence\nof relevant PE patterns; the false negative instances of the graph-based detector, PMapper, resulted\nfrom the limited expressiveness of their graph representations. Overall, the impressively low false\nnegative rates of TAC-WB underscore the significant benefits of our specific modeling approach.\n7.3.2\nRQ2: Effectiveness of TAC. On Test-A set, Figure 8a illustrates the false negative rates of\nTAC compared to four whitebox baselines and its three greybox variants, across 10 different query\nbudgets. We can observe that, as the query budget increases from 10 to 100, TAC\u2019s false negative\nrate keeps decreasing significantly from 57% to 27%, and is always significantly lower than the\nfalse negative rates of its three greybox variants. Moreover, the standard deviation of TAC\u2019s false\nnegative rate is close to zero, indicating that TAC\u2019s performance is apparently more stable than its\nthree greybox variants. These results demonstrate that both GNN-based RL and the pretraining can\nsignificantly help improve the effectiveness of TAC. In comparison to the whitebox baselines, TAC\u2019s\nfalse negative rate under a query budget of 100 is close to Cloudsplaining (which is 26%), and is\nonly 6% and 14% higher than the false negatives than Pacu and PMapper, respectively. This already\nshows the significant effectiveness of TAC as a greybox detector, with limited access to partially\nqueried information. Inspired by this promising result, we further increase the query budget of\nTAC to study the effectiveness of TAC under larger query budgets. As a result, TAC performs better\nthan all three whitebox baselines when the query budget is increased to 258. This result shows the\nsubstantial superiority of our IAM modeling approach which considers a broader class of PEs than\nthe three state-of-the-art whitebox baselines. In general, results show that TAC exhibits competitive\neffectiveness on Test-A set, comparing to its greybox variants and state-of-the-art whitebox baselines.\nOn Test-B set, TAC successfully detects 23 PEs within a query budget of 10, with a false negative\nrate of just 3%. Furthermore, TAC identifies all 31 PEs within a query budget of 20, which not only\nInteractive Greybox Penetration Testing for Cloud Access Control using IAM Modeling and Deep Reinforcement Learning\n19\noutperforms the three state-of-the-art whitebox baselines, but also achieves the performance of\nTAC-WB. In comparison, the greybox variants of TAC detect between 17 and 22 PEs within a query\nbudget of 10, resulting in a false negative rate ranging from 29% to 45%; they detect between 23\nand 30 PEs within a query budget of 20, yielding a false negative rate ranging from 3% to 26%. On\nTest-C set, TAC successfully detects both PEs when the query budget is set to 60 or above. On the\ncontrary, the greybox variants of TAC fail to detect both PEs across all query budgets. In summary,\nTAC achieves the lowest false negative rate on both Test-B and Test-C sets.\n7.3.3\nRQ3: Efficiency of TAC. To investigate how our proposed GNN-based RL with pretraining\nhelps to improve the query efficiency, we compare TAC with its greybox variants in terms of query\ncount. Figure 8b shows the query count of TAC and its greybox variants under the query budget of\n100 on Test-A set. For a clear demonstration, we sort the detected PEs for each detector, based on\nthe average query count derived from 11 repeated experiments in its ascending order.\nWe can observe that, for the same number of detected PEs, TAC consistently operates with a\nsignificantly smaller query count compared to its greybox variants; given the same query count,\nTAC consistently identifies many more PEs. Specifically, in comparison to TAC, TAC-NoPT only\ndetects 175 PEs at an average query count that is 4.5 to 22.4 times greater than that of TAC, and\nTAC-NoPT exhibits substantially higher standard deviations. We can learn from the results that the\npretraining is crucial for improving and stabilizing the query efficiency. In addition, TAC-EA detects\nmerely 34 PEs at an average query between 8.2 to 61.1 times that of TAC. TAC-RD performs even\nworse than TAC-EA. The results show that our GNN-based RL approach substantially lowers the\nquery count of TAC. In sum, we can say that the GNN-based RL with pretraining plays an essential\nrole in improving and stabilizing the query efficiency of TAC.\n8\nRELATED WORK\nIAM PE Detection and Modeling. For IAM PE detection, existing cloud security teams only focus\non building whitebox cloud penetration testing tools. These tools can be classified into three kinds:\npattern-based approach, graph-based approach and reasoning-based approach. For the pattern-based\napproach, Gietzen was the first to identify 21 typical IAM PE patterns[20]. Two whitebox detectors\nPacu [33] and Cloudsplaining [47] select relevant PE patterns identified by Gietzen to discover\nIAM PEs. However, these tools do not support detecting transitive PEs (i.e., attackers gain sensitive\npermissions indirectly through intermediate entities) [2].\nGraph-based approaches are proposed to mitigate this limitation. PMapper [21] models the\nauthentication relation between users/roles (i.e., whether a user/role can be authenticated as\nanother user/role through permissions) in an IAM configuration as a directed graph. With the\ngraph modeling, PMapper detects a certain kind of transitive PEs by checking if a non-admin\nuser/role can be authenticated as an admin user. AWSPX [34] applies similar graph modeling, and\nfurther visualizes the detected PEs. These approaches have two limitations: 1) the graph modeling\nconsiders only authentications between users/roles, ignoring possible PEs among other entity types\n(e.g., services) or caused by non-authentication strategies (e.g., changing the default version of an\nIAM policy [3]); 2) they ignore the fact that PEs can be realized by obtaining sensitive permissions\nfrom non-admin entities. TAC models the IAM configuration based on our defined permission flow\ngraph which is more comprehensive for detecting PEs w.r.t. both admin and non-admin entities\nwith broader entity types.\nFor reasoning-based approach, Ilia and Oded [53] recently employs SMT-based bounded model\nchecking to formally verify if IAM configurations have PEs. While this approach represents IAM\nconfigurations with SMT formulas for whitebox detection, TAC represents IAM configurations as\n20\nYang Hu, Wenxi Wang, Sarfraz Khurshid, and Mohit Tiwari\nabstract PFGs for greybox penetration testing. Unfortunately, by the time of the paper submission,\nthis reasoning-based detector has not been made publicly available.\nThe modeling used in IAM PE detection can also be adapted for IAM PE repair. IAM-Deescalate[14]\nis the first approach for IAM PE repair, utilizing IAM modeling from PMapper[21]. Recently,\nIAMPERE [23], built on the IAM modeling of TAC, has shown significant improvements over\nIAM-Deescalate in both effectiveness and efficiency, highlighting the superiority of TAC\u2019s IAM\nmodeling.\nFormal Methods for IAM. Besides IAM PE detection tools, there are IAM security tools using\nformal methods to address broader security issues. The AWS team has developed several formal ver-\nification tools for IAM, including ZELKOVA [10], Block Public Access [11], and Amazon Verified\nPermission [9]. These tools utilize SMT solvers to verify non-PE security and availability properties\nof IAM configurations, such as determining whether a user can access a resource. Eiers et al.[18, 19]\nintroduced a quantitative IAM policy analysis framework based on model counting to identify and\nmitigate security risks associated with overly permissive IAM policies. Unlike these tools that rely\non automated logical reasoning techniques, TAC models IAM configurations as permission flow\ngraphs, enabling PE detection through a lightweight fixed-point iteration process without complex\nreasoning.\nRL for Greybox Penetration Testing. RL has been extensively utilized to enhance greybox\npenetration testing. Existing tools [48\u201351, 54, 58] use the Partially Observable Markov Decision\nProcess (POMDP) [38] to select attack operations based on partial network/system configurations.\nOur abstract IAM modeling enables TAC to frame the query decision problem as a classic Markov\nDecision Process, which can be optimized effectively and efficiently using advanced RL approaches.\nIn contrast, optimizing POMDPs faces severe computational and statistical challenges [32, 35, 59],\npotentially affecting the performance of these testing techniques.\n9\nDISCUSSION\nApplicability. Customers have a variety of options to simplify their query response procedures.\nThey can utilize tools or services of the cloud provider to improve the efficiency of reviewing or\nassessing configurations. For instance, the official IAM Policy Simulator [7] is an excellent tool\nfor shaping query responses. More specifically, to address a query about a permission assignment,\ncustomers can leverage the tool to simulate the entity applying the permission, avoiding the hassle\nof manual configuration analysis. Moreover, in the future, we plan to develop a light-weight open-\nsource tool to provide a user-friendly GUI in aiding customers with their query response. This not\nonly improves TAC\u2019s applicability, but also allows customers to examine the source code of the tool\nto enhance the trustworthiness.\nAlthough TAC is initially designed for AWS, it can be adapted to detect privilege escalations\nin other cloud platforms such as Google Cloud. This can be simply achieved by adding new\npermission flow templates based on other cloud\u2019s official documentation. Moreover, the GNN\nand RL approach that TAC leverages to interact with humans in a semi-automated fashion can\nfind broader applicability in security research, such as fuzzing, vulnerability repair, and privacy-\ncentric machine learning, etc. For example, GNN-based RL can be employed in fuzzing to enhance\nseed scheduling and mutation operator selection, thereby boosting fuzzer\u2019s capability of finding\nbugs. Furthermore, the interactive concept can be applied in efficient human-assisted fuzzing for\nenhancing the overall code coverage: GNN-based RL can be applied to intelligently identify critical\nand challenging constraints, and deliver to human experts who can then use their domain-specific\nknowledge to design high-quality test cases for these constraints.\nLimitations. We identify three limitations of our approach. First, TAC requires customers to respond\nto queries manually. We have mitigated this by refining our query model with RL, reducing the\nInteractive Greybox Penetration Testing for Cloud Access Control using IAM Modeling and Deep Reinforcement Learning\n21\nnumber of queries. Further, auxiliary tools can facilitate semi/fully automated responses. Second,\nwithout PEs present, TAC consumes its entire query budget before confirming their absence. An\nearly-stopping mechanism, halting queries when PEs seem unlikely to appear, can address this.\nThird, the scarcity of real-world IAM misconfigurations makes it hard to assess how accurately\nIAMVulGen reflects actual scenarios. However, our permission flow templates are sourced from\nofficial documentation and manually verified, ensuring the validness and representativeness of the\nsynthesized misconfigurations.\n10\nCONCLUSION\nIn this paper, we introduced the first greybox penetration testing approach, called TAC, designed for\nthird-party cloud security services to detect IAM PEs due to misconfigurations. Unlike whitebox\napproaches that necessitate customers to anonymize their entire IAM configurations, TAC intelli-\ngently interacts with customers by selectively querying only the essential information required for\ndetection. TAC relies on our comprehensive IAM modeling to identify a broad range of IAM PEs\nwithin partially visible IAM configurations and employs a GNN-based RL approach with pretraining\nto learn to detect PEs using as few queries as possible. To pretrain and assess TAC, we also proposed\nan IAM PE task generator named IAMVulGen. Experimental results illustrate that TAC is a promising\napproach, detecting IAM PEs with high query efficiency, and notably low false negative rates as\ncompetitive as those whitebox approaches.\nREFERENCES\n[1] Seth Art. 2021. IAM Vulnerable - An AWS IAM Privilege Escalation Playground. https://bishopfox.com/blog/aws-iam-\nprivilege-escalation-playground.\n[2] Seth Art. 2021. IAM Vulnerable - Assessing the AWS Assessment Tools. https://bishopfox.com/blog/assessing-the-\naws-assessment-tools.\n[3] AWS. 2023. AWS IAM API Reference: SetDefaultPolicyVersion. https://docs.aws.amazon.com/IAM/latest/APIReference/\nAPI_SetDefaultPolicyVersion.html.\n[4] AWS. 2023. AWS Identity and Access Management (IAM). https://aws.amazon.com/iam/.\n[5] AWS. 2023.\nAWS Service Authorization Reference: Actions, resources, and condition keys for AWS ser-\nvices. https://docs.aws.amazon.com/pdfs/service-authorization/latest/reference/service-authorization.pdf#reference_\npolicies_actions-resources-contextkeys.\n[6] AWS. 2023. Security best practices in IAM. https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html.\n[7] AWS. 2023. Testing IAM policies with the IAM policy simulator. https://docs.aws.amazon.com/IAM/latest/UserGuide/\naccess_policies_testing-policies.html.\n[8] AWS. 2023. Using AWS IAM Access Analyzer. https://docs.aws.amazon.com/IAM/latest/UserGuide/what-is-access-\nanalyzer.html.\n[9] AWS. 2023. What is Amazon Verified Permissions? https://docs.aws.amazon.com/verifiedpermissions/latest/userguide/\nwhat-is-avp.html.\n[10] John Backes, Pauline Bolignano, Byron Cook, Catherine Dodge, Andrew Gacek, Kasper Luckow, Neha Rungta, Oksana\nTkachuk, and Carsten Varming. 2018. Semantic-based automated reasoning for AWS access policies using SMT. In\n2018 Formal Methods in Computer Aided Design (FMCAD). IEEE, 1\u20139.\n[11] Malik Bouchet, Byron Cook, Bryant Cutler, Anna Druzkina, Andrew Gacek, Liana Hadarean, Ranjit Jhala, Brad\nMarshall, Dan Peebles, Neha Rungta, et al. 2020. Block public access: trust safety verification of access control policies.\nIn Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the\nFoundations of Software Engineering. 281\u2013291.\n[12] Shaked Brody, Uri Alon, and Eran Yahav. 2021.\nHow attentive are graph attention networks?\narXiv preprint\narXiv:2105.14491 (2021).\n[13] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan,\nPranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural\ninformation processing systems 33 (2020), 1877\u20131901.\n[14] Jay Chen. 2022. IAM-Deescalate: An Open Source Tool to Help Users Reduce the Risk of Privilege Escalation.\nhttps://unit42.paloaltonetworks.com/iam-deescalate/.\n22\nYang Hu, Wenxi Wang, Sarfraz Khurshid, and Mohit Tiwari\n[15] Myungsik Cho, Whiyoung Jung, and Youngchul Sung. 2022. Multi-task reinforcement learning with task representation\nmethod. In ICLR 2022 Workshop on Generalizable Policy Learning in Physical World.\n[16] Cybersecurity Insiders. 2021. Cloud Security Report. https://www.isc2.org/Landing/cloud-security-report.\n[17] Carlo D\u2019Eramo, Davide Tateo, Andrea Bonarini, Marcello Restelli, and Jan Peters. 2024. Sharing knowledge in multi-task\ndeep reinforcement learning. arXiv preprint arXiv:2401.09561 (2024).\n[18] William Eiers, Ganesh Sankaran, and Tevfik Bultan. 2023. Quantitative Policy Repair for Access Control on the Cloud.\n(2023).\n[19] William Eiers, Ganesh Sankaran, Albert Li, Emily O\u2019Mahony, Benjamin Prince, and Tevfik Bultan. 2022. Quantifying\npermissiveness of access control policies. In Proceedings of the 44th International Conference on Software Engineering.\n1805\u20131817.\n[20] Spencer Gietzen. 2018. AWS IAM Privilege Escalation \u2013 Methods and Mitigation. https://rhinosecuritylabs.com/aws/\naws-privilege-escalation-methods-mitigation/.\n[21] NCC Group. 2023. Principal Mapper. https://github.com/nccgroup/PMapper.\n[22] Nikolaus Hansen. 2006. The CMA evolution strategy: a comparing review. Towards a new evolutionary computation\n(2006), 75\u2013102.\n[23] Yang Hu, Wenxi Wang, Sarfraz Khurshid, Kenneth L McMillan, and Mohit Tiwari. 2023. Fixing Privilege Escalations\nin Cloud Access Control with MaxSAT and Graph Neural Networks. , 104\u2013115 pages.\n[24] Orca Security Inc. 2024. Thrive Security in the Cloud. https://orca.security/.\n[25] Sysdig Inc. 2024. Cloud-Native vs. Third-Party Cloud Security Tools. https://sysdig.com/learn-cloud-native/cloud-\nsecurity/cloud-native-vs-third-party-cloud-security-tools/.\n[26] Symmetry Systems Inc. 2024. Data Security Posture Management. https://www.symmetry-systems.com/.\n[27] Wiz Inc. 2024. Secure Everything You Build And Run in the Cloud. https://go.wiz.io/.\n[28] Eric Kedrosky. 2022. Achieving AWS Least Privilege: Understanding Privilege Escalation. https://sonraisecurity.com/\nblog/common-methods-aws-privilege-escalation/.\n[29] Shaharyar Khan, Ilya Kabanov, Yunke Hua, and Stuart Madnick. 2022. A systematic analysis of the capital one data\nbreach: Critical lessons learned. ACM Transactions on Privacy and Security 26, 1 (2022), 1\u201329.\n[30] Gerben Kleijn. 2022. Well, That Escalated Quickly: Privilege Escalation in AWS. https://bishopfox.com/blog/privilege-\nescalation-in-aws.\n[31] Manjur Kolhar, Mosleh M Abu-Alhaj, and Saied M Abd El-atty. 2017. Cloud data auditing techniques with a focus on\nprivacy and security. IEEE Security & Privacy 15, 1 (2017), 42\u201351.\n[32] Akshay Krishnamurthy, Alekh Agarwal, and John Langford. 2016. PAC reinforcement learning with rich observations.\nAdvances in Neural Information Processing Systems 29 (2016).\n[33] Rhino Security Lab. 2022. Pacu: The Open Source AWS Exploitation Framework. https://rhinosecuritylabs.com/aws/\npacu-open-source-aws-exploitation-framework/.\n[34] WithSecure Labs. 2022. A graph-based tool for visualizing effective access and resource relationships in AWS\nenvironments. https://github.com/WithSecureLabs/awspx.\n[35] Qinghua Liu, Praneeth Netrapalli, Csaba Szepesvari, and Chi Jin. 2023. Optimistic mle: A generic model-based\nalgorithm for partially observable sequential decision making. In Proceedings of the 55th Annual ACM Symposium on\nTheory of Computing. 363\u2013376.\n[36] Ilya Loshchilov and Frank Hutter. 2017. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101\n(2017).\n[37] Trend Micro. 2021.\nThe Most Common Cloud Misconfigurations That Could Lead to Security Breaches.\nhttps://www.trendmicro.com/vinfo/us/security/news/virtualization-and-cloud/the-most-common-cloud-\nmisconfigurations-that-could-lead-to-security-breaches.\n[38] George E Monahan. 1982. State of the art\u2014a survey of partially observable Markov decision processes: theory, models,\nand algorithms. Management science 28, 1 (1982), 1\u201316.\n[39] Assaf Morag. 2021. Cloud Misconfigurations: The Hidden but Preventable Threat to Cloud Data. https://www.\ninfosecurity-magazine.com/opinions/cloud-misconfigurations-threat/.\n[40] Capital One. 2022. Information on the Capital One Cyber Incident. https://www.capitalone.com/digital/facts2019/.\n[41] Momen Oqaily, Yosr Jarraya, Meisam Mohammady, Suryadipta Majumdar, Makan Pourzandi, Lingyu Wang, and\nMourad Debbabi. 2019. SegGuard: segmentation-based anonymization of network data in clouds for privacy-preserving\nsecurity auditing. IEEE Transactions on Dependable and Secure Computing 18, 5 (2019), 2486\u20132505.\n[42] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini\nAgarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback.\nAdvances in Neural Information Processing Systems 35 (2022), 27730\u201327744.\n[43] Cedric Pernetf. 2021. Research reveals that IAM is too often permissive and misconfigured. https://www.techrepublic.\ncom/article/research-iam-permissive-misconfigured/.\nInteractive Greybox Penetration Testing for Cloud Access Control using IAM Modeling and Deep Reinforcement Learning\n23\n[44] Nathaniel Quist. 2021. Unit 42 Cloud Threat Report Update: Cloud Security Weakens as More Organizations Fail to\nSecure IAM. https://unit42.paloaltonetworks.com/iam-misconfigurations/.\n[45] Michael T Rosenstein, Zvika Marx, Leslie Pack Kaelbling, and Thomas G Dietterich. 2005. To transfer or not to transfer.\nIn NIPS 2005 workshop on transfer learning, Vol. 898.\n[46] Jungwoo Ryoo, Syed Rizvi, William Aiken, and John Kissell. 2013. Cloud security auditing: challenges and emerging\napproaches. IEEE Security & Privacy 12, 6 (2013), 68\u201374.\n[47] Salesforce. 2022. Cloudsplaining. https://cloudsplaining.readthedocs.io/en/latest/.\n[48] Carlos Sarraute, Olivier Buffet, and J\u00f6rg Hoffmann. 2012. POMDPs make better hackers: Accounting for uncertainty\nin penetration testing. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 26. 1816\u20131824.\n[49] Carlos Sarraute, Olivier Buffet, and J\u00f6rg Hoffmann. 2013. Penetration testing== POMDP solving? arXiv preprint\narXiv:1306.4714 (2013).\n[50] Jonathon Schwartz and Hanna Kurniawati. 2019. Autonomous penetration testing using reinforcement learning. arXiv\npreprint arXiv:1905.05965 (2019).\n[51] Jonathon Schwartz, Hanna Kurniawati, and Edwin El-Mahassni. 2020. Pomdp+ information-decay: Incorporating\ndefender\u2019s behaviour in autonomous penetration testing. In Proceedings of the International Conference on Automated\nPlanning and Scheduling, Vol. 30. 235\u2013243.\n[52] Hemani Sehgal. 2021. Cloud Security Conundrum Debunked: Native Vs. Third-Party Tools. https://www.horangi.\ncom/blog/cloud-security-native-third-party-tools.\n[53] Ilia Shevrin and Oded Margalit. 2023. Detecting {Multi-Step}{IAM} Attacks in {AWS} Environments via Model\nChecking. In 32nd USENIX Security Symposium (USENIX Security 23). 6025\u20136042.\n[54] Dorin Shmaryahu, Guy Shani, Joerg Hoffmann, and Marcel Steinmetz. 2018. Simulated penetration testing as contingent\nplanning. In Proceedings of the International Conference on Automated Planning and Scheduling, Vol. 28. 241\u2013249.\n[55] Trevor Standley, Amir Zamir, Dawn Chen, Leonidas Guibas, Jitendra Malik, and Silvio Savarese. 2020. Which tasks\nshould be learned together in multi-task learning?. In International conference on machine learning. PMLR, 9120\u20139132.\n[56] Lingfeng Sun, Haichao Zhang, Wei Xu, and Masayoshi Tomizuka. 2022. Paco: Parameter-compositional multi-task\nreinforcement learning. Advances in Neural Information Processing Systems 35 (2022), 21495\u201321507.\n[57] Richard S Sutton and Andrew G Barto. 2020. Reinforcement learning: An introduction. MIT press.\n[58] Khuong Tran, Ashlesha Akella, Maxwell Standen, Junae Kim, David Bowman, Toby Richer, and Chin-Teng Lin. 2021.\nDeep hierarchical reinforcement agents for automated penetration testing. arXiv preprint arXiv:2109.06449 (2021).\n[59] Nikos Vlassis, Michael L Littman, and David Barber. 2012. On the computational complexity of stochastic controller\noptimization in POMDPs. ACM Transactions on Computation Theory (TOCT) 4, 4 (2012), 1\u20138.\n[60] Xscaler. 2021. Anatomy of a Cloud Breach: How 100 Million Credit Card Numbers Were Exposed. https://www.zscaler.\ncom/resources/white-papers/capital-one-data-breach.pdf.\n", "metadata": {"Published": "2024-06-08", "Title": "Interactive Greybox Penetration Testing for Cloud Access Control using IAM Modeling and Deep Reinforcement Learning", "Authors": "Yang Hu, Wenxi Wang, Sarfraz Khurshid, Mohit Tiwari", "Summary": "Identity and Access Management (IAM) is an access control service in cloud\nplatforms. To securely manage cloud resources, customers need to configure IAM\nto specify the access control rules for their cloud organizations. However,\nincorrectly configured IAM can be exploited to cause a security attack such as\nprivilege escalation (PE), leading to severe economic loss. To detect such PEs\ndue to IAM misconfigurations, third-party cloud security services are commonly\nused. The state-of-the-art services apply whitebox penetration testing\ntechniques, which require access to complete IAM configurations. However, the\nconfigurations can contain sensitive information. To prevent the disclosure of\nsuch information, customers need to manually anonymize the configuration.\n  In this paper, we propose a precise greybox penetration testing approach\ncalled TAC for third-party services to detect IAM PEs. To mitigate the dual\nchallenges of labor-intensive anonymization and potentially sensitive\ninformation disclosures, TAC interacts with customers by selectively querying\nonly the essential information needed. Our key insight is that only a small\nfraction of information in the IAM configuration is relevant to the IAM PE\ndetection. We first propose IAM modeling, enabling TAC to detect a broad class\nof IAM PEs based on the partial information collected from queries. To improve\nthe efficiency and applicability of TAC, we aim to minimize interactions with\ncustomers by applying Reinforcement Learning (RL) with Graph Neural Networks\n(GNNs), allowing TAC to learn to make as few queries as possible. Experimental\nresults on both synthetic and real-world tasks show that, compared to\nstate-of-the-art whitebox approaches, TAC detects IAM PEs with competitively\nlow false negative rates, employing a limited number of queries.", "entry_id": "http://arxiv.org/abs/2304.14540v5", "published_first_time": "2023-04-27", "comment": null, "journal_ref": null, "doi": null, "primary_category": "cs.CR", "categories": ["cs.CR", "cs.SE"], "links": ["http://arxiv.org/abs/2304.14540v5", "http://arxiv.org/pdf/2304.14540v5"]}, "type": "Document"}
{"page_content": "Knowledge-Informed Auto-Penetration Testing Based on\nReinforcement Learning with Reward Machine \u2217\nYuanliang Li\nConcordia University\nMontr\u00b4\neal, Canada\nyuanliang.li@concordia.ca\nHanzheng Dai\nConcordia University\nMontr\u00b4\neal, Canada\nhanzheng.dai@mail.concordia.ca\nJun Yan\nConcordia University\nMontr\u00b4\neal, Canada\njun.yan@concordia.ca\nABSTRACT\nAutomated penetration testing (AutoPT) based on reinforcement learning (RL) has proven its ability\nto improve the efficiency of vulnerability identification in information systems. However, RL-based\nPT encounters several challenges, including poor sampling efficiency, intricate reward specification,\nand limited interpretability. To address these issues, we propose a knowledge-informed AutoPT\nframework called DRLRM-PT, which leverages reward machines (RMs) to encode domain knowl-\nedge as guidelines for training a PT policy. In our study, we specifically focus on lateral movement\nas a PT case study and formulate it as a partially observable Markov decision process (POMDP)\nguided by RMs. We design two RMs based on the MITRE ATT&CK knowledge base for lateral\nmovement. To solve the POMDP and optimize the PT policy, we employ the deep Q-learning al-\ngorithm with RM (DQRM). The experimental results demonstrate that the DQRM agent exhibits\nhigher training efficiency in PT compared to agents without knowledge embedding. Moreover, RMs\nencoding more detailed domain knowledge demonstrated better PT performance compared to RMs\nwith simpler knowledge.\nKeywords Penetration testing \u00b7 Reinforcement learning \u00b7 Human knowledge integration \u00b7 Reward machine\n1\nIntroduction\n1.1\nBackground of AI-Powered AutoPT\nIn the rapidly advancing digital epoch, ensuring the security of information systems has emerged as a paramount\nconcern. One of the effective methods used to evaluate the security of a computer system is Penetration Testing\n(PT) [1], which is important in probing for and identifying potential vulnerabilities that could be exploited by malicious\nentities. However, traditional PT requires highly specialized skills and domain expertise and can only be performed\nby trained professionals. Moreover, manual PT on a medium-sized LAN can be time-consuming and labor-intensive,\nsometimes lasting for several days or weeks [2]. Furthermore, PT can also cause substantial system downtime [3]. As\na result, the security industry requires the development of automated PT techniques (AutoPT).\nSo far, many advanced AutoPT tools and frameworks have been created in the industry to increase PT efficiency.\nMetasploit [4], for example, helps collect information and exploit vulnerabilities. However, the current automation\nlevel of these tools is relatively contextually limited (restricted to specific tasks) and unoptimized, preventing them\nfrom autonomously conducting comprehensive tests and evaluations on extensive assets, compared to the proficiency\nof human experts [5].\nOne promising solution to advance PT performance is the application of reinforcement learning (RL) or deep RL\n(DRL). RL/DRL is a branch of artificial intelligence (AI) used to tackle sequential decision-making tasks. This in-\n\u2217This work is supported in part by the Natural Sciences and Engineering Research Council of Canada under grants RGPIN-\n2018-06724 and DGECR-00022-2018 and by the Concordia University Research Chair in Artificial Intelligence in Cyber Security\nand Resilience. This work has been submitted to the IEEE World Congress on Computational Intelligence 2024. Copyright may be\ntransferred without notice, after which this version may no longer be accessible.\narXiv:2405.15908v1  [cs.AI]  24 May 2024\nvolves an intelligent agent that takes actions within a specific environment, aiming to maximize its cumulative rewards\nover time through a process of trial and error [6]. RL/DRL has already shown impressive accomplishments in a range\nof artificial intelligence (AI) applications, such as autonomous driving, robotics, DeepMind AlphaGo, and OpenAI\nChatGPT, among others [7, 8]. PT powered by RL/DRL can automate the process, improve PT efficiency, and have\nthe potential to identify complex or hidden vulnerabilities (or critical attack paths) that a human tester might not\nconsider [9].\nIn recent years, there has been a rise in research on RL/DRL-powered PT on information systems. Schwartz et al. [10]\nformulated the PT process as a Markov decision process (MDP) where the network configuration serves as the states\nand the available scans and exploits serve as the actions. The optimal PT policy with respect to the designed MDP is\nsolved by using the deep Q-Network (DQN) algorithm. Similarly, Ryusei et al. [11] proposed a method to automate\npost-exploitation by combining DRL and the PowerShell Empire [12]. The results of the experiment show that the\ntrained agent using the A2C algorithm could obtain administrative privileges from the domain controller. To further\nminimize manual labor costs in PT, Ghanem et al. introduced the Intelligent Automated Penetration Testing System\n(IAPTS) developed based on the partially observable MDP (POMDP) formulation of PT [3,13]. This system combines\nan RL module with existing industrial PT frameworks. Hu et al. [14] introduced a two-stage PT method based on DRL\nin communication networks. The first stage involves the use of scanning tools to collect network data and create\nan attack tree. In the second stage, the DQN algorithm is employed to determine the most efficient and impactful\nattack path from the attack tree. Tran et al. [15] introduced a hierarchical DRL method for PT to address its large\ndiscrete action space, where a decomposition strategy for the action space is utilized. Qianyu et al. [9] proposed the\nINNES model for DRL-based PT to characterize its observation space and action space of PT, which makes the MDP\nformulation of PT more accurate. For PT in industrial control systems (ICSs), such as the power grid, [16] proposed\nto apply the DQN algorithm to identify the optimal ordering and timing of replay attacks on PMU packets that can\ntrigger grid voltage violations.\n1.2\nChallenges of AI-Powered AutoPT\nHowever, existing RL/DRL-based PT approaches still face the sampling efficiency issue in the training process, during\nwhich the agent needs a large number of agent-environment interactions to obtain the optimal policy. One reason is\nbecause of the large action space, where the pen-tester has various attack actions to choose from. According to\nMITRE ATT&CK, a knowledge base of adversary tactics and techniques [17], there are 14 attacking tactics (e.g.,\nprivilege escalation) for the Enterprise category. Each tactic has a set of techniques (e.g., access token manipulation),\nand each technique may have a set of sub-techniques. Additionally, each technique or subtechnique may also have a\nset of parameters to choose to form an atomic action for RL/DRL agents.\nThe difficulty of reward specification in RL/DRL-based PT is another challenge to consider. Previous studies assign\n1) positive rewards to the agent when it successfully obtains network resources or takes impactful actions; and 2)\nnegative rewards as penalties when the agent takes invalid actions or violates certain constraints. However, expressing\nthese specification rules in a single reward function could increase its complexity, making it difficult for the agent to\ndifferentiate which aspects of contributions or losses result from its actions. Therefore, the agent may need many more\ninteractions to figure it out.\nMoreover, interpretability is often lacking in RL/DRL-based PT. The trained PT policy cannot explicitly identify the\ncurrent phase or situation of the PT agent and the subsequent direction it shall be heading. This type of perception\nor awareness could be encoded into the agent\u2019s neural networks representing the DRL policy through training, but it\nremains challenging to extract such information by decoding the neural networks.\n1.3\nContributions of This Work\nIn response to the aforementioned challenges with respect to sampling efficiency, reward specification, and inter-\npretability for RL/DRL-based PT, we propose to embed knowledge from the cybersecurity domain as guidelines into\nthe agent\u2019s learning process in an explainable way. This approach can automatically break down the complex PT task\ninto multiple subtasks, thereby enabling the agent to learn more efficiently.\nMore specifically, we propose a knowledge-informed AutoPT framework called DRLRM-PT, which utilizes a reward\nmachine (RM) to encode domain knowledge based on cybersecurity knowledge bases, such as MITRE ATT&CK [17]\nand Cyber Kill Chain [18], etc. The RM specifies a set of events that occurred in PT and decomposes PT into\nmultiple subtasks based on existing PT practices. Moreover, RM can specify different reward functions for PT in\ndifferent phases, expanding the flexibility of traditional reward functions in RL/DRL-based PT. Under the DRLRM-\nPT framework, PT is formulated as a POMDP guided by RMs. We focus specifically on lateral movement as a case\nstudy, which assumes the pen-tester has gained the initial access to the network and will move deeper into the network\nfor owning high-value assets. We investigate two different RMs as two guidelines. Finally, we employ the deep\nQ-learning algorithm with RM (DQRM) to solve the POMDP and optimize the PT policy.\nTo the best of our knowledge, this work is the first attempt to integrate the domain-specific knowledge and expertise\nof humans into DRL to automate and enhance PT in complex network systems. In brief, the contributions of this work\ncan be summarized as follows:\n\u2022 We proposed a knowledge-informed AutoPT framework (DRLRM-PT), which utilizes RMs to encode do-\nmain knowledge as guidelines to train PT policies.\n\u2022 We applied RMs to specify and arrange subtasks of PT based on existing PT practices. We also designed a\ndedicated event set for AutoPT , where events represent successful executions of adversary tactics defined in\ncybersecurity knowledge bases, which are used by RMs to assign subtasks to agents during PT.\n\u2022 We took the lateral movement of PT as a case study and formulated PT as a POMDP guided by RMs, where\ntwo RMs were designed based on MITRE ATT&CK knowledge base; DQRM algorithm was applied to\noptimize the PT policy. This case study proves the effectiveness of our proposed approach and provides an\nillustrative example of embedding existing cybersecurity knowledge bases into RL/DRL-based PT.\nThis paper is organized as follows: Section 2 presents the proposed DRLRM-PT framework. Section 3 introduces the\nPOMDP formulation with RM specifically for the lateral movement of PT. Section 4 describes the simulation platform\nand testing environments. Comparative studies are performed to validate the PT performance of DQRM agents In\nSection 5. The conclusions and future works are discussed in Section 6.\n2\nKnowledge-Informed AutoPT Framework\n2.1\nDRLRM-PT Framework\nIn this study, we investigate an AutoPT method, which employs a computer program acting as an agent to launch a\nseries of cyberattacks on network systems. The objective is to discover possible attack paths to take ownership of\ncritical resources, similar to the capture-the-flag game. Thus, PT is a sequential decision-making problem, which can\nbe formulated as a partially observable Markov decision process (POMDP) [3], and the optimal PT policy with respect\nto the POMDP can be obtained by applying RL/DRL algorithms.\nTo address the challenges of sampling efficiency, reward specification, and interpretability in RL/DRL-based PT, we\npropose a knowledge-informed AutoPT framework based on RL with reward machine (DRLRM-PT), as depicted in\nObservation Space:\n\"newly discovered nodes count\",\n\"leaked credentials\",\n\"discovered node count\",\n\"nodes privilege level\"\n...\nAction Space:\n\"exploit local vulnerability\"\n\"exploit remote vulnerability\"\n\"connect\"\n...\nEvent Detector\nstart\nu0\nu1\nu2\n<!b, 0>\n<b, 0>\n<c, 0>\nu3\n<True, 0>\n<h&d&f, 10>\n<h&!d&!f&!g, 0>\n<h&!d&!f&g, 0>\n<!h, 0>\n<!c&!g, 0> <!c&g, 0>\n<h&d&!f&!g, 1>\n<h&d&!f&g, 1>\n(Labeling Function)\nEvent Set : \n'a': 'discovered new nodes', \n'b': 'discovered new credentials', \n'c': 'lateral moved/connected to a new node', \n'd': 'privilege elevated', \n'e': 'new flags captured', \n...\nEvents \n(e.g., {'h','d', 'f'})\nSubpolicy\nfor subtask:\nReward Machine\nPT Agent\nTarget Network System\nAction\nObservation\nSubpolicy for u0 :\nSubpolicy for u1 :\nSubpolicy for u2 :\nCybersecurity Domain\nKnowledge Encoding\n(e.g., MITRE ATT&CK, Cyber Kill\nChain, etc.)\nCybersecurity\nKnowledge Base\nReward\nSubtask \n(e.g., u = u2),\nFigure 1: The proposed knowledge-informed AutoPT framework (DRLRM-PT).\nFigure 1, which uses a reward machine (RM) to encode domain knowledge of PT based on existing cybersecurity\nknowledge bases.\nThis framework involves an agent that acts as a pen-tester and interacts with the target network system that makes up\nthe environment. This environment typically consists of hosts, firewalls, routers, and communication channels, among\nother components. The agent\u2019s action is selected from a range of PT activities (action space), such as network scanning,\nexploiting vulnerabilities, lateral movement, and privilege escalation. Additionally, the agent can gather observations\nfrom the environment through the information from scanning operations, defined by an observation space containing\nnewly discovered vulnerabilities, leaked credentials, etc. The immediate reward reflects the evaluation of the agent\u2019s\naction. The aim of PT typically involves taking ownership of critical resources within the networks, such as customer\ndata. Thus, the agent can assign a positive reward to itself when the action is beneficial for accomplishing this goal or a\nnegative reward when it is not. The agent wants to find an optimal PT policy to maximize accumulated rewards through\nlearning experiences from agent-environment interactions [19]. To tackle the challenge of high dimensionality of the\ntarget system arising from the large observation or action spaces [20], the PT policy is represented by deep neural\nnetworks to determine the best action based on input observation. During the training phase, after each step, the agent\nwill use the experience (observation, action, reward, next observation) to update the weights of the neural networks\n(iteratively improving the PT policy).\nIn this framework, the agent is informed and guided by a cybersecurity domain knowledge encoding module, which\nuses an RM to encode the domain knowledge of PT based on the cybersecurity knowledge bases, such as MITRE\nATT&CK, Cyber Kill Chain, etc.\nThe RM is a state machine with two essential functions: 1) decomposing the PT task into a series of subtasks, such as\n\u201cdiscover credentials\u201d and \u201cprivilege escalation\u201d, and organizing them using a state machine structure; 2) specifying a\nreward function for each state transition within the RM.\nThe RM receives a set of events detected during PT as input, leading to a transition of its internal state from one state\nto another according to its transition rules (logic formula over the event set). The output of the RM includes the RM\nstate and a reward function. The RM state indicates the completion of the previous subtask and the initiation of a new\nsubtask; thus, it can be used to denote the subtask ID.\nThe event detector (also called the labeling function under the RM theory [21]) can identify occurring events, denoted\nby symbols, e.g., \u2018a\u2019 for \u201cdiscovered new nodes\u201d and \u2018b\u2019 for \u201cdiscovered new credentials\u201d, from the environment by\nanalyzing the latest agent-environment interaction. These events are designed to represent successful executions of\nadversary tactics as defined by cybersecurity knowledge bases. Because these tactics serve as the adversary\u2019s tactical\ngoals, providing the motivation behind their actions [17]. For instance, privilege escalation is one tactic for attacking\nenterprise networks defined by ATT&CK. Therefore, the corresponding event can be defined as its successful outcome,\ni.e., \u201cprivilege escalated\u201d. All events are predefined in an event set and can be detected using the event detector. Table 1\nshows an example of an event set designed for PT based on ATT&CK tactics.\nTable 1: Event Set of PT (P)\nEvent Symbol\nEvent Description\n\u2018a\u2019\nDiscovered new nodes\n\u2018b\u2019\nDiscovered new credentials\n\u2018c\u2019\nLateral moved (connected to a new node)\n\u2018d\u2019\nPrivilege elevated\n\u2018e\u2019\nNew flags captured (new target nodes owned)\n\u2018f\u2019\nAchieved the PT goal\n\u2018g\u2019\nHas unused credentials\n\u2018h\u2019\nTaken action to elevate the privilege\nAs an example shown in Figure 1, when events \u2018h\u2019, \u2018d\u2019, and \u2018f\u2019 are detected, the RM will transit its state from u2 to\nu3 and output u3 (subtask ID) and a constant reward function (reward = 10) according to its defined transition rule\n< h&d&f, 10 >.\nIn addition, RM outputs a reward function instead of a reward value. Thus, RM allows the agent to specify task-specific\nreward functions to enhance the flexibility of the single reward function used in traditional RL algorithms.\nFurthermore, DRLRM-PT utilizes deep Q-learning with RM algorithm (DQRM) to train a PT policy, which decom-\nposes the policy into a set of sub-policies for every subtask and can train all sub-policies simultaneously. Therefore,\nthe final PT policy actually selects the sub-policy to determine the PT action.\n2.2\nPOMDP with Reward Machine Formulation for PT\nThe proposed PT under the DRLRM-PT framework is formulated as a POMDP with RM, which is characterized by a\ntuple consisting of seven components \u27e8S, A, O, T(st+1|st, at), O(ot|st), R, \u03b3\u27e9[22].\nS represents the set of environment states, where st \u2208S denotes the state at time t. O represents the set of observa-\ntions, and ot \u2208O denotes the observation at time t. A represents the set of actions, and at \u2208A denotes the action\ntaken by the agent at time t. T(st+1|st, at) is the probability of transition from the current state st to the next state st+1\nwhen the agent performs an action at. O(ot|st) is the emission function that maps the current state to the observation\nreceived by the agent.\nR is the RM, which is a tuple with six components R = \u27e8P, L, U, u0, \u03b4u, \u03b4r\u27e9. P is an event set of PT. L is the labeling\nfunction (event detector), L : O \u00d7 A \u00d7 O \u21922P, which assigns truth values to events (True: event occurred, False:\nevent not occurred), by analyzing the input experience (ot, at, ot+1). U is a finite set of RM states. u0 \u2208U is an\ninitial state. \u03b4u is the state-transition function, \u03b4u : U \u00d7 2|P | \u2192U, which determines the next RM state based on\nits current state and the captured events (i.e., ut+1 \u2190\u03b4u(ut, L(ot, at, ot+1))). \u03b4r is the reward-transition function,\n\u03b4r : U \u00d72|P | \u2192[O \u00d7A\u00d7O \u2192R], which outputs a reward function based on its current state and the captured events\n(i.e., R(ot, at, ot+1) \u2190\u03b4r(ut, L(ot, at, ot+1))). The agent can use the output reward function to obtain the reward.\n\u03b3 \u2208[0, 1) is the discount factor that determines the trade-off between immediate and long-term rewards that the agent\nprefers to achieve.\nDue to the complex nature of the target network system, the determination of T(st+1|st, at) and O(ot|st) poses\nchallenges for PT. However, the agent can take the environment as a black box and learn the policy through pure trial\nand error.\nFor a specific scope of PT, the action space, observation space, and RM can be customized accordingly.\n3\nPOMDP with RM Design for Lateral Movement\nIn this work, the lateral movement on enterprise networks is considered as the study case of PT, which is under the\nassumption that the agent has already entered the target network (post-exploitation assumption). The POMDP with\nRM formulation and two RMs are designed in the following subsections.\n3.1\nAction Space\nWe consider three types of actions that the agent can execute during lateral movement. The first is scanning, which\ninvolves collecting network information by discovering new machines (nodes), determining the connections between\nthese nodes, acquiring machine configuration data, and gathering vulnerability information for discovered nodes.\nThe second type of action is vulnerability exploitation, which can be classified into local vulnerability exploitation and\nremote vulnerability exploitation. Local vulnerability exploitation can only be performed on a connected node (the\nnode where the agent is operating), and the agent seeks to steal local information, increase host privileges, or discover\ncredentials for connecting to other nodes. Remote vulnerabilities come from nodes that are currently discovered but\nare not owned by the agent. By exploiting remote vulnerabilities, the agent can gather more information about the\nremote nodes.\nThe third type of action is connection, which enables the agent to connect a node using specific credentials and ports.\nDue to the agent\u2019s lack of direct access to action outcomes, scanning is considered a mandatory action that must be\nperformed after each action rather than being optional in action space. Additionally, the scanning operation can also\ncontribute to forming an observation.\nThe action space is listed in Table 2, which includes three subspaces for local vulnerability exploitation, remote\nvulnerability exploitation, and connection, respectively. i, j, l, r, p, and c denote the ID of the source node, the target\nnode, the local vulnerability, the remote vulnerability, the port, and the credentials, respectively. \u02c6\nn, \u02c6\nnl, \u02c6\nnr, \u02c6\nnp, and\n\u02c6\nnc are agent\u2019s estimations of the maximum number of nodes, local vulnerabilities, remote vulnerabilities, ports, and\ncredentials, respectively. Table 2 implies that for local vulnerability exploitation, the agent should choose the node ID\nand local vulnerability ID. For remote vulnerability exploitation, the agent should choose the source node ID, target\nTable 2: Action space of PT\nAction\nNotation\nSubspace Size\nLocal vulnerability exploit\n[i, l]\n\u02c6\nn \u00d7 \u02c6\nnl\nRemote vulnerability exploit\n[i, j, r]\n\u02c6\nn \u00d7 (\u02c6\nn \u22121) \u00d7 \u02c6\nnr\nConnection\n[i, j, p, c]\n\u02c6\nn \u00d7 (\u02c6\nn \u22121) \u00d7 \u02c6\nnp \u00d7 \u02c6\nnc\nnode ID, and remote vulnerability ID. The source node ID, target node ID, port ID, and credential ID should be set for\nthe connection. The PT action is a vector selected from one of the subspaces.\nWe consider each action will last a constant unit period, after which it will be considered completed and terminated.\n3.2\nObservation Space\nThe observation of the agent in PT is obtained by scanning operation after each action taken using scanning tools, such\nas Nmap [23]. The observation space is designed and shown in Table 3, which consists of many subspaces, including\nthe discovered nodes count, nodes privilege level, discovered nodes properties, leaked credentials, and lateral move.\nTable 3: Observation space of PT\nObservation\nNotation\nSubspace Size\nDiscovered nodes count\nnd\n\u02c6\nn\nNodes privilege level\n[ai]\u02c6\nn\n2\u02c6\nn\nDiscovered nodes properties\n[ai,p]\u02c6\nn\u00d7\u02c6\nnpr\n3\u02c6\nn\u00d7\u02c6\nnpr\nLeaked credentials\n[ai,p,c]\u02c6\nn\u00d7\u02c6\nnp\u00d7\u02c6\nnc\n3\u02c6\nn\u00d7\u02c6\nnp\u00d7\u02c6\nnc\nLateral move\nbl\n2\nAmong them, nodes privilege level is a vector describing the privilege level of every node, where two values can be\nassigned to each entry: 0 = \u201cnot owned\u201d, 1 = \u201cAdmin\u201d.\nDiscovered nodes properties tells what properties each node has. Properties include different types of operating\nsystems (e.g., Windows, Linux), different types of databases (e.g., SQLServer, MySQL), etc. It is represented by\na \u02c6\nn \u00d7 \u02c6\nnpr matrix, where \u02c6\nnpr is the estimated maximum number of properties. Each entry has three values: 0 = \u201cNo\u201d,\n1 = \u201cYes\u201d, 2 = \u201cUnknown\u201d.\nLeaked credentials is a \u02c6\nn \u00d7 \u02c6\nnp \u00d7 \u02c6\nnc tensor with the first dimension indicating the target node ID, the second dimen-\nsion indicating the port ID, the third dimension indicating the credential ID. Each entry has three values: 0 = \u201cNot\ndiscovered\u201d, 1 = \u201cUsed\u201d, 2 = \u201cUnused\u201d.\nLateral move indicates whether the agent successfully moves from one node to another in a new interaction with two\nvalues: 0 = \u201cNo\u201d, 1 = \u201cYes\u201d.\nBy flattening and concatenating all vectors from these five subspaces, we can get an observation vector.\n3.3\nReward Machine I (R1)\nIn this work, the PT agent is guided by the domain knowledge of PT encoded in an RM. In the field of PT, one useful\nguideline is that the pen-tester attempts to discover as many login credentials as possible to gain access and control\nover as many nodes as possible. Therefore, the PT can be divided into three subtasks: 1) discover new credentials, 2)\ngain access (connect) to a new node by using the discovered credentials, and 3) elevate the privilege of the connected\nnode to own its properties. This process will be repeated to own more and more nodes until the PT goal is met, such\nas discovering critical data or owning a specific number of nodes.\nAccording to this guideline, our first designed RM (R1) is shown in Figure 2, which has four states (U1 =\n{u0, u1, u2, u3}) starting from u0 and terminates at u3. Its event set P1 = {\u2018b\u2019, \u2018c\u2019, \u2018d\u2019, \u2018f\u2019, \u2018g\u2019, \u2018h\u2019} is a subset\nof the set defined in Table 1.\nR1 tells that the agent will stay on u0 until new credentials are found (\u2018b\u2019), then transition to u1. The agent will remain\nin u1 if no successful connection is made (\u2018c\u2019) and the previously discovered credentials do not run out (\u2018g\u2019). If all\ncredentials are used (\u2018!g\u2019), but still cannot connect to a new node (\u2018!c\u2019), it will go back to u0 to find new credentials.\nstart\nu0\nu1\nu2\n<!b, 0>\n<b, 0>\n<c, 0>\nu3\n<True, 0>\n<h&d&f, 10>\n<h&!d&!f&!g, 0>\n<h&!d&!f&g, 0>\n<!h, 0>\n<!c&!g, 0> <!c&g, 0>\n<h&d&!f&!g, 1>\n<h&d&!f&g, 1>\nEvent Set:       = {'b', 'c', 'd', 'f', 'g', 'h'}\nFigure 2: The diagram of Reward Machine I (R1).\nIf the agent can connect to a new node from u1 (\u2018c\u2019), it will move to u2. Then, the agent tries to take actions to elevate\nthe privilege level of the connected node (\u2018h\u2019). If the privilege level is elevated (\u2018d\u2019) and the final goal is reached (\u2018f\u2019),\nR1 ends in u3. If the final goal is not reached (\u2018!f\u2019), the agent checks for unused credentials. If it is (\u2018g\u2019), the agent\nreturns to u1 to try other credentials. If not, the agent returns to u0 to find new credentials.\nEach transition in R1 also outputs a reward value. According to Figure 2, when the privilege level of a connected node\nis elevated (\u2018d\u2019), the agent gets a reward = 1. When the final goal is reached (\u2018f\u2019), the agent gets a reward = 10.\n3.4\nReward Machine II (R2)\nWe also investigate a more detailed RM R2 where the knowledge guides the agent to discover new nodes first, then\ndiscover new credentials. Next, connect to a new node, and finally, elevate the privilege of the connected node.\nTherefore, its event set is P2 = {\u2018a\u2019, \u2018b\u2019, \u2018c\u2019, \u2018d\u2019, \u2018f\u2019, \u2018g\u2019, \u2018h\u2019}, where \u2018a\u2019 is added. The diagram of R2 is shown in\nFigure 3. R2 has five states since it has one more task compared to R1.\nu0\nstart\nu1\nu2\n<a&!b, 0>\nu4\nu3\n<!a, 0>\n<!b, 0>\n<b, 0>\n<c, 0>\n<h&d&f, 10>\n<a&b, 0>\n<!c&g, 0>\n<!c&!g, 0>\n<h&d&!f&g, 1>\n<h&d&!f&!g, 1>\n<!h, 0>\n<True, 0>\n<h&!d&!f&g, 0>\n<h&!d&!f&!g, 0>\nEvent Set:       = {'a', 'b', 'c', 'd', 'f', 'g', 'h'}\nFigure 3: The diagram of Reward Machine II (R2).\nAccording to Figure 3, the agent will stay on u0 until new nodes are discovered (\u2018a\u2019), then transition to u1. Sometimes,\nthe agent also finds credentials simultaneously (\u2018a&b\u2019) because discovering a new credential usually comes with a new\ntarget node; thus, it can directly transition to u2. The transitions in R2 from u1 are similar to those in R2 from u0.\nOne difference is that after a successful connection (\u2018c\u2019) if all discovered credentials are run out (\u2018!g\u2019) but still cannot\nachieve the PT goal (\u2018!f\u2019), it will transition to u0 to find new nodes instead of to find new credentials.\nThe reward transition function of R2 is similar to that of R1. When the connected node\u2019s privilege level is elevated\n(\u2018d\u2019), the agent receives a reward of 1. When the agent reaches the final goal (\u2018f\u2019), the reward is 10.\n3.5\nPT Objective\nThe goal of lateral movement is to take ownership (elevate privilege) of as many nodes as possible to own their\nproperties. Therefore, discounted accumulated rewards with respect to R (denoted by GR) during PT can be used as\nthe objective function for the agent to maximize, as expressed in Eq. 1.\nGR =\nNit\nX\nt=1\n\u03b3t\u22121rt,\n(1)\nwhere Nit is the total number of actions taken in the PT. rt is the immediate reward obtained by R.\n\u03b3 is the\ndiscount factor. By optimizing Eq. 1, we hope to find out an optimal PT policy with respect to R, denoted as\n\u03c0\u2217\nR = arg max\u03c0 GR.\n3.6\nPT policy optimization based on DQRM\nThe deep Q-learning with RM algorithm (DQRM) is used to train the agent and obtain the optimal PT policy \u03c0\u2217\nR. It is\nan updated version based on the Q-learning with RM (QRM).\nGive an RM R, QRM decomposes the training process by learning one Q-function (Q(o, a), a function used to\nevaluate future rewards for a certain observation and action) per state in R [24]. These Q-functions can be considered\nas subpolicies and represented by Q-tables. We denote Qu as the Q-function for state u of R. Since the terminal state\nwill bring no future rewards, the corresponding Q-function will always output 0. For example, in Figure 2, R1 has\nfour states and will have four Q-functions.\nAs the complexity of the environment increases, the observation space of PT defined in Table 2 will grow exponentially,\nbringing a curse of dimensionality challenging to the QRM. Therefore, we adopt DQRM, which utilizes deep neural\nnetworks (called Q-networks and are parameterized by \u03b8u) instead of Q-tables to approximate Q-functions. It also\nadopts target Q-networks (parameterized by \u03b8\u2212\nu ) and the experience replay mechanism to stabilize the training process.\nThe update rule for Q-networks is as follows:\nQu(o, a; \u03b8u)\n\u03b1\n\u2190\n\u2212r(o, a, o\u2032) + \u03b3 max\na\u2032 Q\u2212\nu\u2032(o\u2032, a\u2032; \u03b8\u2212\nu\u2032),\n(2)\nwhere Qu is the Q-network of state u; Q\u2212\nu\u2032 is the target Q-network of the next state u\u2032.\nThese Q-networks will be iteratively updated through the agent\u2019s interactions with the environment until the end of\ntraining. Finally, the optimal action a\u2217\nt given ot can be obtained by:\na\u2217\nt = arg max\na\u2208A Qu(ot, a; \u03b8u).\n(3)\nThe pseudo-code of the PT optimization using DQRM is shown in Algorithm 1.\n4\nSimulation Platform and Testing Environments\nIn this study, we use CyberBattleSim as our experimental platform [25]. This platform, developed by Microsoft, is\nan open-source network simulator designed for lateral movement research. It enables users to examine PT strategies\nthey establish on simulated enterprise networks. Simulation networks are modeled by an abstract graph with nodes\n(machines) parameterized by a set of pre-planted vulnerabilities. In addition, the OpenAI Gym interface allows for the\ntraining of automated agents by utilizing RL/DRL algorithms.\nIn CyberBattleSim, two typical networks are set as selectable environments to test PT strategies, called CyberBat-\ntleChain (denoted as env-1) and CyberBattleToyCtf (denoted as env-2), as shown in Figure 4 and 5, respectively. Each\nnode in both environments possesses a set of properties and is pre-planted with a set of local and remote vulnerabilities.\nThese vulnerabilities may reveal the credentials of adjacent nodes or lead to the privilege escalation of target nodes.\nMoreover, both environments are pre-configured with \u2018flag\u2019 nodes, which contain important or sensitive resources,\nsuch as customer data. The agent\u2019s goal is to capture as many flags as possible during the PT while minimizing the\nnumber of actions.\nAlgorithm 1 PT policy optimization using DQRM\nInput: A, O, \u03b3, \u03b1, R = \u27e8P, L, U, u0, \u03b4u, \u03b4r\u27e9, C\n1: For every u \u2208U \u2212{uT }, initialize Qu(\u00b7) and Q\u2212\nu (\u00b7) with parameters \u03b8u and \u03b8\u2212\nu , respectively;\n2: Initialize an experience replay buffer D;\n3: for episode = 1 to Nep do\n4:\nAgent takes scanning operation to get the initial observation o0 from the target network system, ot \u2190o0;\n5:\nut \u2190u0;\n6:\nfor t = 1 to Nit do\n7:\nAgent selects an action at under ot from A based on \u03f5-greedy strategy;\n8:\nAgent executes at and takes scanning operation to get the observation ot+1 from the target network system;\n9:\nut+1 \u2190\u03b4u(ut, L(ot, at, ot+1));\n10:\nR(\u00b7) \u2190\u03b4r(ut, L(ot, at, ot+1));\n11:\nrt+1 = R(ot, at, ot+1);\n12:\nSave the experience (ot, at, ot+1, ut, ut+1, rt+1) into D;\n13:\nSample random mini-batch of experiences (o, a, o\u2032, u, u\u2032, r) from D, and update \u03b8u for Qu(\u00b7) based on Eq. 2;\n14:\nif t mode C = 0 ? then\n15:\nFor every u \u2208U \u2212{uT }, \u03b8\u2212\nu \u2190\u03b8u;\n16:\nend if\n17:\not \u2190ot+1\n18:\nut \u2190ut+1\n19:\nend for\n20: end for\nenv-1 has a sequential network structure with the flag located at the end node, as shown in Figure 4. N means the\nnumber of \u201cLinux-Windows\u201d link. In this case, we set N to 8. Therefore, to capture the flag, the agent needs to elevate\nthe privileges of all nodes sequentially.\nWindows (start)\nLocal vulnerability: \nScan Explorer Recent Files\nLinux\nLocal vulnerability: \n(Scan Bash History,\nCrack Keep Pass X)\nRemote vulnerability: \nProbe Linux\nWindows\nLocal vulnerability:     \n(Scan Explorer Recent Files,\nCrack Keep Pass)\nRemote vulnerability:  \nProbe Windows\nLinux (Flag)\nLocal vulnerability:\nNone\nRemote vulnerability:\nNone\n. . .\nx N\nStatic Communication Edge\nAttack Path\ninitial infect\n. . .\nFigure 4: CyberBattleChain environment (env-1).\nClient\nLocal vulnerability:\nSearch edge history\nRemote vulnerability:\nNone\nWbesite\nLocal vulnerability: \nScan bash history\nRemote vulnerability: \n(Scan page content,\n Scan page source)\nGitHub Project\nLocal vulnerability: None\nRemote vulnerability: Scan git history\nWebsite Directory\n(FLAG: Discover secret data) Unownable\nLocal vulnerability: None\nRemote vulnerability (Navigate web directory\nfurther, Navigate web directory)\nWebsite Monitor\nLocal vulnerability: Scan home directory\nRemote vulnerability: None\nShare Point\nLocal vulnerability: None\nRemote vulnerability: Scan\nShare point parent directory\nAzure Resource Manager monitor\nLocal vulnerability: None\nRemote vulnerability: None\nAzure Storage (FLAG: Leaked customer data)\nLocal vulnerability: None\nRemote vulnerability: Access data with SAS token\nAzure Resource Manager\n(FLAG: Leaked Customer Data)\nLocal vulnerability: None\nRemote vulnerability: \nList Azure Resources\nAzure VM\n(FLAG: VM Private Info) Unownable\nLocal vulnerability: None\nRemote vulnerability: None\nStatic Environment Edge\nAttack Path\nInitial Infect\nFigure 5: CyberBattleToyCtf environment (env-2).\nCompared to env-1, env-2 is more complex. env-2 is made up of a mesh network architecture, as shown in Figure 5.\nenv-2 contains four flags, of which two are unattainable since they did not leak credentials and the attacker cannot gain\nhigher privileges, but the attacker can discover other nodes from it by performing remote attacks, such as navigating\nthe web directory. The agent\u2019s goal is to capture two attainable flags.\n5\nExperimental Validation\nWe design the experiments to validate our proposed method and attempt to answer two research questions below:\n\u2022 RQ1: Can the agent guided by RM improve the learning efficiency of PT compared to the agent without RM?\n\u2022 RQ2: How will different RM designs affect the PT performance.\n5.1\nAgent Configurations\nTable 4 lists four different agents, where DQRM-RM1 and DQRM-RM2 are agents that use the DQRM algorithm with\nR1 and R2, respectively. DQN-RM1 and DQN-RM2 are agents that use the DQN algorithm where only the reward is\nobtained by R1 and R2, respectively.\nTable 4: Learning Agents\nAgent Name\nDescription\nDQRM-RM1\nDQRM guided and rewarded by R1\nDQN-RM1\nDQN rewarded by R1\nDQRM-RM2\nDQRM guided and rewarded by R2\nDQN-RM2\nDQN rewarded by R2\nThe agents\u2019 training parameters are empirically determined, as listed in Table 5. We run 100 episodes to train each\nagent and 50 episodes to evaluate their trained policies. Each episode is an execution of one PT, which is terminated\nupon the achievement of the predefined PT goal (capture all flags) or the maximum number of actions performed.\nThe Q-functions are fully connected neural networks with two hidden layers, and each hidden layer has 150 neurons.\nAfter each step, the agents will randomly sample 100 experiences (batch size) to update their policies. For every 10\nsteps, the target neural networks will copy the weights from the training neural networks. The learning rate of neural\nnetworks is set to 0.001. \u03b3 is set to 0.9. \u03f5 is set to 0.3.\nTable 5: Training Parameters For DQRM and DQN\nParameter\nDescription\nValue\nNit\nMaximum number of actions per episode\n1500\nNep\nNumber of episodes (train)\n100\nNevl\nNumber of episodes (evaluation)\n50\n\u03b3\nDiscount factor\n0.9\n\u03b1\nLearning rate\n0.001\nC\nTarget networks update frequency\n10\nNbch\nBatch size\n100\nNhl\nNumber of hidden layers\n2\nNhs\nHidden size\n150\n\u03f5\n\u03f5-greedy parameter\n0.3\nThese four agents in Table 4 are comparable in the same environment since agents always receive the same reward\ngiven the same agent-environment interaction. The performance indicators of agent include training efficiency and PT\nefficiency, which will be compared in the training phase and in the evaluation phase, respectively. Training efficiency\nindicates how quickly an agent learns to achieve a high accumulated reward within a certain number of training\nepisodes, which will be visualized by the accumulated reward with respect to the number of steps (actions) taken. PT\nefficiency indicates how quickly an agent achieves its goal during PT, which will be evaluated by the distribution of\nthe total number of steps per episode among a certain number of evolution episodes.\n5.2\nComparative Studies\nWe train these four agents based on the configurations in env-1 and env-2 and plot results in Figure 6, 7, 8, and 9.\nFigure 6 and 7 show the accumulated rewards with respect to the number of steps in env-1 under the training phase and\nthe evaluation phase, respectively. Figure 8 shows the distributions of the total number of steps taken per episode in\nenv-1 for different agents, where the left side shows the training phase and the right side shows the evaluation phase.\nSimilarly, Figure 9 presents the distributions of the total number of steps taken per episode in env-2 for different agents\nin the training phase and evaluation phase.\nFigure 6: The training performance of four agents in env-1.\n5.2.1\nComparison between DQRM agents and DQN agents\nTo answer RQ1, we compare the PT performance between the DQRM agents and the DQN agents in env-1 and env-2,\nguided by R1 and R2, respectively.\nFrom Figure 6, we can see that both DQRM-RM1 and DQRM-RM2 outperform DQN-RM1 and DQN-RM2 in terms\nof the training efficiency in env-1, respectively. This is because by using the same number of actions, DQRM agents can\nobtain higher average accumulated rewards than DQN agents. As a result, the curve that exhibits superior performance\nwill tend to approach the top left corner more closely. For instance, by 200 steps, the average accumulated rewards\nof DQRM-RM1 and DQRM-RM2 are about 15 and 16, respectively, whereas the average accumulated rewards of\nDQN-RM1 and DQN-RM2 are about 10 and 13, respectively.\nFigure 7: The evaluation performance of four agents in env-1.\nTraining phase\nEvaluation phase\nFigure 8: The attack steps of four agents in env-1.\nThe training efficiency in env-1 can also be observed on the left side of Figure 8, where the two DQRM agents can\ncapture the flag through fewer steps in most episodes compared to the DQN agents. Specifically, the average number\nof steps taken during the training phase for DQRM-RM1 and DQRM-RM2 is 186.13 and 104.48, respectively, which\nis approximately half the number of steps taken by the two DQN agents (374.71 and 218.39, respectively).\nIn Figure 7, the x-axis is the logarithmic scale of the step. The trained PT policies of DQRM-RM1, DQRM-RM2, and\nDQN-RM1 in env-1 can achieve higher accumulative rewards in around 50 steps compared to DQN-RM2. DQRM-\nRM1 and DQRM-RM2 exhibit similar levels of performance, both of which outperform DQN-RM1. On the right\nside of Figure 8, it can also be observed that DQRM-RM1, DQRM-RM2, and DQN-RM1 can capture the flag using\na limited number of steps, which means that their policies are well trained. However, the number of steps in DQN-\nRM2 has a great variance. Finally, the average number of steps for DQRM-RM1, DQRM-RM2, and DQN-RM1 is\n23.48, 21.32, and 29.76, respectively. The average number of steps for DQN-RM2 is 767.46, which reflects poor PT\nperformance.\nIn env-2, DQRM agents also show improved training efficiency and evaluation performance according to Figure 9.\nOn the left side of Figure 9, the median values of the steps of DQRM-RM1 (225) and DQRM-RM2 (235) outperform\nDQN-RM1 (310) and DQN-RM2 (276), respectively. On the right side of Figure 9, the median value of the steps of\nDQRM-RM2 (211) is shorter than DQN-RM2 (305), which means it has better evaluation performance. Similarly,\nDQRM-RM1 (206) also has better evaluation performance than DQN-RM1 (336).\nFrom the previous analysis, we can answer RQ1 that RMs can help the agent learn PT policies faster in different\nenvironments.\n5.2.2\nComparison between different RMs\nTo answer RQ2, we compare the PT performance between DQRM-RM1 and DQRM-RM2 in env-1 and env-2, respec-\ntively.\nFrom Figure 6, DQRM-RM2 demonstrates better training efficiency compared to DQRM-RM1 in env-1. We can see\nthat after approximately 80 steps, DQRM-RM2 achieves an average accumulated reward of approximately 15, whereas\nDQRM-RM1 achieves around 10.\nFrom the left side of Figure 8, the DQRM-RM2 agent requires fewer steps to capture two flags in most episodes\ncompared to the DQRM-RM1 agent in env-1. Specifically, the average number of steps taken during the training\nphase for DQRM-RM1 is 186.13, which is 78% higher than DQRM-RM2.\nFrom the right side of Figure 8, the average number of attack steps used by DQRM-RM1 and DQRM-RM2 are 23.48\nand 21.32, respectively, indicating that DQRM-RM2\u2019s PT performance is better than DQRM-RM1 in env-1.\nTraining phase\nEvaluation phase\nFigure 9: The attack steps of four agents in env-2.\nFrom the left side of Figure 9, DQRM-RM2 shows fewer average steps (290.85) compared to DQRM-RM1 (302.01)\nin env-2, which means DQRM-RM2 has better training efficiency than DQRM-RM1. On the right side of Figure 9,\nDQRM-RM2 has better evaluation performance since DQRM-RM2 takes an average of 295.48 steps, which is fewer\nthan DQRM-RM1 (329.34).\nBased on the previous analysis, we can conclude that the PT performance of agents guided by R2 is more effective\nthan R1 in different environments since it involves an additional subtask, i.e., discovering new nodes, which is more\ndetailed than R1.\n6\nConclusion and Future Works\nIn this work, we proposed a knowledge-informed AutoPT framework called DRLRM-PT. This framework utilizes\nRMs to embed domain knowledge from the field of cybersecurity, which serves as guidelines for training PT policies.\nWe took lateral movement as a case study of PT, and we formulated it as a POMDP guided by RMs. We also designed\ntwo RMs based on the MITRE ATT&CK knowledge base. To train the agent and derive the PT policy, we adopted the\nDQRM algorithm. The effectiveness of our solution was evaluated using the CyberBattleSim platform, from which the\nexperimental results demonstrate that the DQRM agent exhibits a higher training efficiency in PT compared to agents\nwithout knowledge embedding. Furthermore, RMs that incorporate more detailed domain knowledge exhibit superior\nPT performance compared to RMs with simpler knowledge.\nIn the future, we will continue investigating MITRE ATT&CK and Cyber Kill Chain knowledge base to design more\nsophisticated RMs for PT. The objective is to improve the quality and adaptability of embedded knowledge in various\nPT scenarios. Additionally, we have plans to expand the scope of PT from lateral movement to more PT applications.\nReferences\n[1] Patrick Engebretson. The basics of hacking and penetration testing: ethical hacking and penetration testing\nmade easy. Elsevier, 2013.\n[2] Matthew Denis, Carlos Zena, and Thaier Hayajneh. Penetration testing: Concepts, attack methods, and defense\nstrategies. In 2016 IEEE Long Island Systems, Applications and Technology Conference (LISAT), pages 1\u20136.\nIEEE, 2016.\n[3] Mohamed C Ghanem and Thomas M Chen. Reinforcement learning for efficient network penetration testing.\nInformation, 11(1):6, 2019.\n[4] David Maynor. Metasploit toolkit for penetration testing, exploit development, and vulnerability research. Else-\nvier, 2011.\n[5] Verina Saber, Dina ElSayad, Ayman M. Bahaa-Eldin, and Zt Fayed. Automated penetration testing, a systematic\nreview. In 2023 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC), pages 373\u2013\n380, 2023.\n[6] Annie Wong, Thomas B\u00a8\nack, Anna V Kononova, and Aske Plaat.\nDeep multiagent reinforcement learning:\nChallenges and directions. Artificial Intelligence Review, 56(6):5023\u20135056, 2023.\n[7] Kun Shao, Zhentao Tang, Yuanheng Zhu, Nannan Li, and Dongbin Zhao. A survey of deep reinforcement\nlearning in video games. arXiv preprint arXiv:1912.10944, 2019.\n[8] B Ravi Kiran, Ibrahim Sobh, Victor Talpaert, Patrick Mannion, Ahmad A Al Sallab, Senthil Yogamani, and\nPatrick P\u00b4\nerez. Deep reinforcement learning for autonomous driving: A survey. IEEE Transactions on Intelligent\nTransportation Systems, 23(6):4909\u20134926, 2021.\n[9] Qianyu Li, Miao Hu, Hao Hao, Min Zhang, and Yang Li. Innes: An intelligent network penetration testing model\nbased on deep reinforcement learning. Applied Intelligence, 53(22):27110\u201327127, 2023.\n[10] Jonathon Schwartz and Hanna Kurniawati. Autonomous penetration testing using reinforcement learning. arXiv\npreprint arXiv:1905.05965, 2019.\n[11] Ryusei Maeda and Mamoru Mimura. Automating post-exploitation with deep reinforcement learning. Computers\n& Security, 100:102108, 2021.\n[12] Powershell-empire.\n[13] Mohamed C Ghanem and Thomas M Chen. Reinforcement learning for intelligent penetration testing. In 2018\nSecond World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4), pages 185\u2013192.\nIEEE, 2018.\n[14] Zhenguo Hu, Razvan Beuran, and Yasuo Tan. Automated penetration testing using deep reinforcement learning.\nIn 2020 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW), pages 2\u201310. IEEE, 2020.\n[15] Khuong Tran, Ashlesha Akella, Maxwell Standen, Junae Kim, David Bowman, Toby Richer, and Chin-Teng\nLin. Deep hierarchical reinforcement agents for automated penetration testing. arXiv preprint arXiv:2109.06449,\n2021.\n[16] Yuanliang Li, Jun Yan, and Mohamed Naili.\nDeep reinforcement learning for penetration testing of cyber-\nphysical attacks in the smart grid. In 2022 International Joint Conference on Neural Networks (IJCNN), pages\n01\u201309. IEEE, 2022.\n[17] Mitre att&ck.\n[18] Cyber kill chain.\n[19] Richard S Sutton and Andrew G Barto. Reinforcement learning: An introduction. MIT press, 2018.\n[20] Thanh Thi Nguyen and Vijay Janapa Reddi. Deep reinforcement learning for cyber security. arXiv preprint\narXiv:1906.05799, 2019.\n[21] Rodrigo Toro Icarte, Toryn Klassen, Richard Valenzano, and Sheila McIlraith. Using reward machines for high-\nlevel task specification and decomposition in reinforcement learning. In International Conference on Machine\nLearning, pages 2107\u20132116. PMLR, 2018.\n[22] Rodrigo Toro Icarte, Ethan Waldie, Toryn Q Klassen, Richard Valenzano, Margarita P Castro, and Sheila A\nMcIlraith. Learning reward machines: A study in partially observable reinforcement learning. arXiv e-prints,\npages arXiv\u20132112, 2021.\n[23] Angela Orebaugh and Becky Pinkard. Nmap in the enterprise: your guide to network scanning. Elsevier, 2011.\n[24] Rodrigo Toro Icarte, Toryn Q Klassen, Richard Valenzano, and Sheila A McIlraith. Reward machines: Exploiting\nreward function structure in reinforcement learning. Journal of Artificial Intelligence Research, 73:173\u2013208,\n2022.\n[25] Microsoft Defender Research Team. Cyberbattlesim, 2021.\n", "metadata": {"Published": "2024-05-24", "Title": "Knowledge-Informed Auto-Penetration Testing Based on Reinforcement Learning with Reward Machine", "Authors": "Yuanliang Li, Hanzheng Dai, Jun Yan", "Summary": "Automated penetration testing (AutoPT) based on reinforcement learning (RL)\nhas proven its ability to improve the efficiency of vulnerability\nidentification in information systems. However, RL-based PT encounters several\nchallenges, including poor sampling efficiency, intricate reward specification,\nand limited interpretability. To address these issues, we propose a\nknowledge-informed AutoPT framework called DRLRM-PT, which leverages reward\nmachines (RMs) to encode domain knowledge as guidelines for training a PT\npolicy. In our study, we specifically focus on lateral movement as a PT case\nstudy and formulate it as a partially observable Markov decision process\n(POMDP) guided by RMs. We design two RMs based on the MITRE ATT\\&CK knowledge\nbase for lateral movement. To solve the POMDP and optimize the PT policy, we\nemploy the deep Q-learning algorithm with RM (DQRM). The experimental results\ndemonstrate that the DQRM agent exhibits higher training efficiency in PT\ncompared to agents without knowledge embedding. Moreover, RMs encoding more\ndetailed domain knowledge demonstrated better PT performance compared to RMs\nwith simpler knowledge.", "entry_id": "http://arxiv.org/abs/2405.15908v1", "published_first_time": "2024-05-24", "comment": null, "journal_ref": null, "doi": null, "primary_category": "cs.AI", "categories": ["cs.AI", "cs.CR", "cs.LG"], "links": ["http://arxiv.org/abs/2405.15908v1", "http://arxiv.org/pdf/2405.15908v1"]}, "type": "Document"}
{"page_content": "1\nMake Safe Decisions in Power System: Safe\nReinforcement Learning Based Pre-decision Making\nfor Voltage Stability Emergency Control\nCongbo Bi, Student Member, IEEE, Lipeng Zhu, Di Liu, Member, IEEE, and Chao Lu, Senior Member, IEEE\nAbstract\u2014The high penetration of renewable energy and\npower electronic equipment bring significant challenges to the\nefficient construction of adaptive emergency control strate-\ngies against various presumed contingencies in today\u2019s power\nsystems. Traditional model-based emergency control methods\nhave difficulty in adapt well to various complicated operating\nconditions in practice. Fr emerging artificial intelligence-based\napproaches, i.e., reinforcement learning-enabled solutions, they\nare yet to provide solid safety assurances under strict constraints\nin practical power systems. To address these research gaps, this\npaper develops a safe reinforcement learning (SRL)-based pre-\ndecision making framework against short-term voltage collapse.\nOur proposed framework employs neural networks for pre-\ndecision formulation, security margin estimation, and correc-\ntive action implementation, without reliance on precise system\nparameters. Leveraging the gradient projection, we propose a\nsecurity projecting correction algorithm that offers theoretical\nsecurity assurances to amend risky actions. The applicability of\nthe algorithm is further enhanced through the incorporation\nof active learning, which expedites the training process and\nimproves security estimation accuracy. Extensive numerical tests\non the New England 39-bus system and the realistic Guangdong\nProvincal Power Grid demonstrate the effectiveness of the\nproposed framework.\nIndex Terms\u2014pre-decision making, safe reinforcement learn-\ning, security margin, power system, short-term stability\nI. INTRODUCTION\nW\nITH the increasing penetration of renewable energy\nsources and electronic equipment into modern power\nsystems, the operating conditions of the power systems are\nmore and more complex and variable, bringing unprecedented\nchallenges to the efficient construction of adaptive emergency\ncontrol strategies against various presumed contingencies [1].\nConventionally, the widely-used approach to emergency con-\ntrol in practical power systems is implemented in the form of\nformulating formulating a set of control strategies in advance,\nThis work was supported in part by the China Southern Power Grid\nResearch Project ZBKJXM20232029 and the National Natural Science Foun-\ndation of China under Grant 52207094.\nThis work has been submitted to the IEEE for possible publication.\nCopyright may be transferred without notice, after which this version may\nno longer be accessible.\nCongbo Bi is with the Department of Electrical Engineeering, Tsinghua\nUniversity, Beijing, 100084 China (e-mail: thueea bcb@outlook.com).\nLipeng Zhu is with the College of Electrical and Information Engineering,\nHunan University, Hunan, 410082 China (e-mail:zhulpwhu@126.com).\nDi Liu is with the Department of Electrical Engineeering, Tsinghua\nUniversity, Beijing, 100084 China (e-mail: kfliudi@163.com).\nChao Lu is with the Department of Electrical Engineeering, Tsinghua\nUniversity, Beijing, 100084 China (e-mail: luchao@tsinghua.edu.cn).\nand matching them with practical operational scenarios in real-\ntime. This procedure involves the construction of a \u2018presumed\nfault set\u2019, necessitating numerous time-consuming simulations\nto derive a suitable table of emergency control strategies [2].\nConsidering the complexity, it is a common practice to focus\non a small number of representative scenarios for strategy\nformulation. As the structural and operational complexity\nof power systems increases, the above-mentioned traditional\napproaches is confronted with challenges of how to effectively\nmanage the remendous presumed operational scenarios within\na limited period of time [3]. Moreover, the intricate dynamic\ncharacteristics of renewable energy sources and power elec-\ntronic devices make it quite difficult to accurately model\nsystem dynamics, thereby undermining the reliability of the\ntraditional approach to emergency control [4]. In this respect,\nit is imperative to swiftly identify high-risk operating statuses\nand formulate suitable emergency control measures.\nDifferent from traditional approaches severely relying on\ndetailed system modeling and simulations, deep reinforcement\nlearning (DRL) methods provide a promising data-driven\nalternative to solve these issues. Specifically, DRL agent can\nlearn from interactions with the environment of the system\nand update its policy without reliance on the knowledge about\ndetailed system models and parameters [5]. There have been\nextensive studies on the formulation of DRL-based emergency\ncontrol strategies [6]\u2013[8], where emergency control is modeled\nas a Markov decision process (MDP) and a DRL agent learns\noptimal policy in a trial-and-error fashion [9]. Nonetheless,\nmost DRL methods lack explicit safety guarantees of the\ncontrol strategies, which may limit their application in actual\npower systems [10]. Moreover, the prevalent offline training\nprocedure of RL agents requires the preparation of substan-\ntial learning samples, raising challenges in offline-learning\nefficiency and thus limiting its availability. Consequently, to\nenhance the applicability of DRL-based emergency control, it\nis imperative to introduce security constraints into DRL-based\nemergency control strategy formulation.\nFor security constraints, most existing RL methods use a\npenalty term to discourage violations of the security con-\nstraints [7], [8], but this does not guarantee satisfying hard\nconstraints. Additionally, some studies simplified the optimiza-\ntion problem by transforming constraints, e.g., constructing\nLyapunov function [11] or using Lagrangian methods [12].\nHowever, building a suitable Lyapunov function or solving the\ndual optimization problem is challenging in complex systems.\nTo address this issue, safe reinforcement learning (SRL), in-\narXiv:2405.16485v1  [eess.SY]  26 May 2024\n2\ncorporating security constraints into the RL framework, is pro-\nposed [13]. SRL has been applied to tackle some power system\ncontrol and decision-making issues [14]\u2013[16]. However, exist-\ning studies still have some limitations. Firstly, their learning\nschemes are mainly designed for strategy formulation about\nsteady-state scenarios like power system dispatch, which have\ndifficulties in emergency control scenarios with much more\ncomplex dynamics. Secondly, these existing algorithms can\u2019t\nadequately address the nonlinear characteristics of transient\nconstraints and feasible action space boundaries of emergency\ncontrol. Therefore, adapting these methods to develop effective\nemergency control strategies would be challenging.\nSRL addresses the feasibility of solutions; however, man-\naging large datasets remains a pragmatic challenge in realistic\napplications. Active learning (AL) techniques mitigate this\nissue by efficiently leveraging extensive samples [17]. In\ncontemporary data-driven power system emergency control,\nthe critical samples not only refer to high-risk operating\nconditions with potentially hazardous control actions but also\nrefer to conditions at the edge of the operating space. We pre-\ndominantly address the former in this work. While numerous\nstudies have explored the application of AL methodologies\nwithin the power system stability assessment [18]\u2013[20], there\nexists a discernible void in the quantitative estimation of the\nsecurity margin within emergency control decision-making\nprocesses. Integrating AL learning can enhance thesecurity\nmargin estimators\u2019 learning efficiency and practical implemen-\ntation in actual systems.\nTo address these challenges, a novel SRL-based emergency\ncontrol strategy pre-formulation via security margin estimation\nand gradient projection is developed in this paper, where\nboth the nonlinear transient stability constraints and strategies\nare approximated by neural networks (NNs). Considering\nthat short-term voltage stability emergency control is one\nof the most challenging tasks in power systems, successful\nperformance by the proposed method in this context provides\ncompelling evidence for its effectiveness in other related tasks.\nTherefore, we choose short-term voltage stability emergency\ncontrol as an illustrative example. This study conceptualizes\nshort-term voltage stability emergency control as a state-\nconstrained Markov decision process (SCMDP). The post-fault\nsecurity margin of the pre-decision action is adjudicated via\na NN-based estimator. For insecure actions, security margin\ngradient-based corrective measures are implemented until safe.\nMoreover, we augment the algorithm\u2019s efficacy on both theo-\nretical and practical fronts: theoretically, by furnishing proof of\nthe algorithm\u2019s security, and practically, by integrating AL to\nbolster the training efficiency of the security margin estimator\namidst a voluminous dataset. The main contributions of our\nwork are as follows:\n1. We present an emergency control framework predicated\non SRL, utilizing gradient projection to ensure short-term\nvoltage stability in power systems. A theoretical performance\nproof accompanies this framework. Compared with its coun-\nterparts, our method has a more solid theoretical foundation\nand performs well in power systems with various scales.\n2. We propose a security margin estimation scheme integrat-\ning state and action information in emergency decision-making\nscenarios for the first time. Compared to the fully connected\nnet structure, the proposed structure can effectively capture the\ncharacteristics of risky operation points and has more robust\nadaptive capability against various operating scenarios.\n3. The proposed AL algorithm enhances the security margin\nestimator\u2019s training process by swiftly identifying critical oper-\nating points within complex power systems. This enhancement\nsignificantly boosts the security margin estimator\u2019s training\nefficiency. Moreover, its high practical value is underscored\nby its applicability to large-scale power systems for effectively\ncapturing critical operating conditions.\nThe remainder of the paper is structured as follows. Section\nII briefly introduces the basic knowledge of pre-decision\nmaking, SRL algorithm, and AL. Section III elaborates the\nproposed framework, including the AL-based security margin\nestimator and the gradient projection-based short-term voltage\nstability emergency control pre-decision making module. The\nNew England 39-bus system and the Guangdong Provincal\nPower Grid (GPG) are utilized to test the performance of our\nframework in Section IV. Section V concludes the paper.\nII. PRELIMINARIES\nA. Safe Reinforcement Learning (SRL)\nReinforcement learning involves continuous interaction with\nthe environment to ascertain the most effective strategy via\ntrial and error. However, in some practical applications, includ-\ning autonomous driving and power system operations, faulty\npolicies can result in substantial economic repercussions or\ncompromise safety [13]. Hence, the imperative to integrate\nsafety considerations during the training or operational phases\nin such contexts has precipitated the emergence of SRL algo-\nrithms. Depending on the form of constraints, safe reinforce-\nment learning can be categorized into two types: process-wise\nsafe reinforcement learning and state-wise safe reinforcement\nlearning. Initial endeavors of process-wise safe reinforcement\nlearning were grounded on the constrained Markov decision\nprocesses (CMDP) framework, wherein constraints are articu-\nlated as either cumulative or episodic. However, real-world\nscenarios often involve transient and deterministic critical\nconstraints, which, if violated, can lead to catastrophic task\nfailure [21]. Therefore, it is necessary to introduce more\nrobust constraints in reinforcement learning. Unlike process-\nwise safe reinforcement learning, state-wise SRL is based on\nthe SCMDP, where the safety specification is to satisfy a\nhard cost constraint at every step persistently. Similarly, the\ncost functions are denoted with C1, C2, ..., and the feasible\nstationary policy set \u00af\n\u03a0C for SCMDP is defined as:\n\u00af\n\u03a0C = {\u03c0 \u2208\u03a0|\u2200(st, at, st+1) \u223c\u03c4,\n\u2200i, Ci(st, at, st+1) \u2264\u03c9i}\n(1)\nwhere \u03c4 \u223c\u03c0, \u03c9i \u2208R, and \u03c0 is the agent\u2019s policy. Compared\nto process-wise SRL, state-wise SRL has stronger constraint\neffects and is more suitable for scenarios with stricter state\nsecurity demand.\nThe purpose of state-wise SRL is to find a policy that max-\nimizes the cumulative gain G = P\u221e\nt=0 \u03b3trt while satisfying\nthe security constraints, which is mathematically expressed as\nmax\n\u03b8\nG(\u03c0\u03b8),\ns.t. \u03c0\u03b8 \u2208\u00af\n\u03a0C\n(2)\n3\nwhere rt denotes the reward at t, \u03b3 denotes the discount factor,\nand \u03c0\u03b8 is the agent\u2019s parameterized policy.\nB. Pre-decision making and its SCMDP Modeling\nPre-decision making plays a crucial role in preventing\nfault propagation and safeguarding power system security and\nstability. In this approach, emergency control strategies are\npre-generated based on the system\u2019s operating state and a\npredefined set of potential faults. When a fault occurs, the\nstability control apparatus consults these pre-established rules\naccording to the fault type and the existing operating condition\nand then executes the necessary emergency control actions\naccording to pre-determined criteria. Emergency control mea-\nsures in power systems, such as load shedding, generator\ntripping, and modulating DC transmission line power, are es-\nsential for preventing system collapse and enhancing stability.\nIn this context, we focus on load shedding as a representative\nexample. Our proposed pre-decision making scheme aims to\naddress short-term voltage instability, minimizing the impact\nof faults while keeping costs as low as possible. Specifically,\nwe seek to reduce the amount of load shedding required to\nstabilize the system\u2019s voltage after a fault. The mathematical\nformulation of the power system\u2019s short-term voltage stability\ncontrol pre-decision making process is delineated as follows:\narg min\nat\u2208A\nC(st, at)\ns.t.\nf(st+T ) \u22640\n(3)\nwhere st represents the extant operating status of the system at\ntime t and at signifies the emergency control action, e.g., load\nshedding amount at time t. The cumulative expense associated\nwith at is denoted as C(st, at). The function f(\u00b7) encapsulates\nthe transient stability constraints during the post-fault recovery\nphase. f(st+T ) \u22640 indicates the system remains stable\nfollowing the fault and the emergency control actions.\nThe short-term voltage stability emergency control strategy\npre-formulation can be modeled as a SCMDP. Critical ele-\nments in the SCMDP are defined as follows.\n1) State and Action: In practical power systems, the in-\njected power space [P, Q]1\u00d72n is commonly utilized as the\ninput information for emergency control pre-decision making\n[22]. Furthermore, the bus voltage V , the active power PG, and\nreactive power generation QG of generators are also incorpo-\nrated as a critical piece of input information. Consequently,\nthe state variables can be succinctly represented as O(t):\nO(t) = [P, Q, V, PG, QG]1\u00d7(3nb+2ng)\n(4)\nwhere nb and ng denote the amount of buses and generators\nin the system, respectively. The state information s aligns with\na specific point within the power system operating space. As\nper the principles of dynamic security region theory [23], the\noperating point is associated with a sequence of emergency\ncontrol actions that fulfill the established constraints. Conse-\nquently, it is practical to devise an emergency control strategy\nthat takes the power system\u2019s operating point as the primary\ninput information and implements it via a real-time matching\napproach in realistic power systems.\nThe action space A in emergency control pre-decision\nmaking refers to the load-shedding, adjusting the power on DC\ntransmission lines, or generator-tripping. Since under-voltage\nload-shedding (UVLS) is a common control strategy to prevent\nvoltage collapse, UVLS is considered as the emergency control\nmeasure taken in our proposed scheme:\na(t) = [\u2206L1(t), ..., \u2206Lnd(t)]1\u00d7nd\n(5)\nwhere \u2206Li(t) denotes the proportion of load-shedding at the\nith load shedding control device, and nd denotes the device\namount. Without loss of generality, this study\u2019s methodology\nand conclusions can be generalized to situations with more\ndiverse control measures.\n2) Reward: The reward function of the short-term voltage\nstability emergency control is designed as follows:\nr =\n\uf8f1\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f3\n\u2212\u03be, min vj(t + 10) \u22640.8\n\u2212\u03b1\nnd\nX\ni=1\n\u2206Li(t) \u2212\u03b2\nnb\nX\nj=1\n\u2206v2\nj ,\notherwise\n(6)\nwhere \u2212\u03be is a large negative number and \u03b1,\u03b2 are the weight\nfactors respectively. P \u2206Li(t) denotes the amount of load\nshedding, and P \u2206v2\nj denotes the voltage deviation.\n3) State Constraint:\nThe state constraint in short-term\nvoltage stability control ensures the system is stable after a\ndisturbance. Specifically, the post-fault state must be stable,\nas expressed in (3).\nAlthough the actual UVLS involves multiple rounds of\nload shedding, removing a sufficient number of loads si-\nmultaneously earlier can prevent the spread of faults more\neffectively [24]. Consequently, our analysis focuses on single-\nround resection.\nC. Active Learning (AL)\nAL is a semi-supervised technique that identifies and queries\nthe most informative examples, e.g., those with the highest\nuncertainty in classification tasks, during model training. AL\noperates on the premise that a model learns more effectively\nwhen it concentrates on ambiguous instances. Metrics such\nas entropy or probability distributions are employed to gauge\nand articulate the level of uncertainty. By emphasizing these\nuncertain points, AL enhances model accuracy using fewer\nlabeled examples, thus optimizing labeling efforts and reduc-\ning costs. AL strategies can significantly reduce the amount\nof data needed for training by intelligently selecting the most\ninformative samples, which saves resources and leads to more\naccurate and robust models.\nIII. PROPOSED METHODOLOGY\nA. Overall Framework\nThe overall framework of our proposed emergency control\npre-decision making scheme via SRL is shown in Fig. 1, which\nincludes two parts: the AL-based security margin estimator\nwith a state-action joint network structure, and the projection-\nbased pre-decision making module. In the proposed frame-\nwork, the initial control actions generated by the DRL agent\ndo not directly take effect. Instead, they pass through a security\nmargin estimator constructed by a NN. Subsequently, these\nactions are adjusted based on the gradient of the estimated\nmargin before being implemented.\n4\nSimulated System\nSimulated System\nOperating Status \ns1, s2, ...\nAL-based Security Margin Estimation\nPre-emptive Control Module with Gradient-based SRL\nSelect (s, a) via Uncertainty\nOperating Dataset \nwith Fault fn\nOperating Dataset \nwith Fault fn\nPre-emptive \nAction Making \nBlock\n (via SAC)\nSampled \nOperation \nStatus st\nat,0\na\uf0a2t\nOutput\nCalculating \nSecurity Margin\nTraining\nSecurity Margin Estimator\nDataset Dn with action\nc1(s, f )\nsi\nai\nAction \nset A\nAction \nset A\nControl Action \na1, a2, ...\nOperating statuses with \nmaximum uncertainty\nState-action pairs with \nmaximum uncertainty\nLabeling\nGenerating\nc(s,a)\nSafety \nCorrection \nLayer\n(via Gradient)\nApplying gradient\n\uf0d1ac(s,a, f ) \nRisk \nFig. 1. Framework for proposed SRL-based pre-decision making scheme to\nagainst short-term voltage instability.\nB. Active Learning-based Security Margin Estimation\nIt is widely considered that short-term voltage instability\noften stems from inadequate local reactive power support\n[25]. In a receiving-end system, the post-fault stability is\nintricately linked to the pre-fault operating status. Additionally,\nthe efficacy of emergency control measures implemented to\nmitigate fault progression is contingent upon the initial status.\nConsequently, estimating the system\u2019s post-fault stability and\nthe \u2018margin\u2019 is achievable by checking the operational points\nand the corresponding emergency control measures [26].\nThis subsection will detail the architecture of the envisioned\nsecurity margin estimation module, encompassing the basic\ntheory, the network structure, the pivotal samples selecting\nmethodology, and the training methodology.\n1) Security Margin Estimation via DSR: The theory of se-\ncurity regions [23] maintains that the power system\u2019s security\nregion ADSR is well-defined within the context of injected\npower space for a given network topology, system component\nparameters, and the location of pre-determined faults. Without\nemergency control measures, the operating point\u2019s dynamic\nsecurity margin (DSM) is quantified as the distance from\nthe operating point to the dynamic security region boundary.\nSince the security region is delineated by hyperplanes, the\ncomputation of the DSM bifurcates into two processes: firstly,\nthe delineation of the security region\u2019s boundary \u2202ADSR,\nand secondly, solving for the minimum distance from the\noperational point to points on the designated boundary, which\nis shown in Fig. 2(a). The definition of DSM is as follows:\nDSM = min dis(P, PC),\ns.t. PC \u2208\u2202ADSR\n(7)\nwhere P is the operating point in injected power space and PC\nis a point on the boundary. The term \u2018dis\u2019 refers to Euclidean\ndistance. This representation transforms the solution of the\n(c)\n*\n*\n*\n*\n\u00d7\n\u00d7\nP1\nP2\nNon-Linear PDSR \nBoundary\nDSMPos\nDSMNeg\n\u00d7\n\u00d7\n\u00d7\nPL1\nPL2\nFeasible Action \nBoundary\nBefore \nUVLS\nAfter \nfeasible \nUVLS\n(a)\n(b)\nUVLS  \nAction\nSecure\nInsecure\nStable Region\nUnstable \nRegion\nt0\nt0\nt1\nt1\nt2\nt2\ntn\ntn\nFault \nOccur\nFault \nClear\nShedding\nQuasi-steady \nStatus\nU\nt\nFeasible Shedding\nNo Shedding\nor Failed Shedding\nCritically \nStable\nAfter \nfailed \nUVLS\n\u00d7\n\u00d7\nSecure \nPoint\nInsecure \nPoint\nPositive \nMargin\nNegative \nMargin\n\u00d7\n*\nOperating \nPoint \nMapping\nOP0\nOP1\nOP2\n0\n0\n0\nFig. 2.\nPower system security margin incorporating both system state\ninformation and emergency control actions.\ns\ns0\ns2\nA\nPre-Fault\nDuring Fault\nA\uf0a2 \nC\uf0a2 \nB\uf0a2 \nD\uf0a2 \nC\nB\nD\ns1\ns3\nTm\nTe\nFig. 3. Changes in slip during the fault process.\ndistance from the point to \u2202ADSR into the solution of the\nminimum distance from the point to a point on \u2202ADSR. The\ndetailed computational procedures of DSM are thoroughly\noutlined in [26].\nTo enhance reader comprehension, we illustrate the concept\nusing a system equipped with induction motors as an example.\nSpecifically, we apply a similar mathematical formulation to\naddress short-term DSM when considering emergency control\nactions. In this system, voltage instability is closely linked to\nthe risk of motor stalling [27]. Throughout the fault recovery\nstage, the system\u2019s slip rate and the absorbed reactive power\nare approximately adhered to the subsequent equations:\n2Hi\nds\ndt = Tmi \u2212\nrR1v2\ni /s\nrs + (rR1/s)2 + (xs + xR1)2\nqi = v2\ni\nxm\n+ v2\ni\nxs + xR1\nrs + (rR1/s)2 + (xs + xR1)2\n(8)\nwhere rR1, rs, xR1, xs and xm are the induction motor\nparameters. Tmi is the torque. vi is the voltage amplitude of\nbus i, and qi is the reactive power absorbed by the motor.\nFrom the given formula, the relationship between motor slip\nand electromagnetic torque Te can be determined. During the\nentire fault process, the slip of the motor changes as shown\n5\nPower system \nInput \noperating \nstates \nFeature \nextraction\nFeature \nextraction\nC2(s, a)\nC1(s)\nC(s, a)\nRegularization\nEvaluated \naction\nEmergency \ndecision system\nFig. 4. Proposed state-action-joint security margin estimation network.\nin Fig. 3, where the slip ratio at the moment of the fault\noccurrence is s0, and the slip ratio of the extreme point is\ns2. When a fault occurs, the slip ratio will remain s0, and\nthe status point moves from A to A\u2032. Because Te is smaller\nthan Tmi at the moment, s will increase. The slip ratio will\nremain unchanged when the fault is cleared, while the voltage\nwill try to increase and revert to its value before the fault,\naltering the status point. During the recovery process, if the\nload shedding is not applied or the load shedding amount is\ninsufficient, the slip ratio s will continue to escalate, surpassing\ns2; this leads to motor stalling and a failed UVLS scenario,\ndepicted as \u2018failed UVLS\u2019 in Fig. 2 (b) (corresponding to\npoint OP1 in Fig. 2 (a)). Conversely, if the load shedding\nis sufficient, the motor slip will consistently remain below s2\nthroughout the recovery, ensuring stability. This scenario is\nillustrated as \u2018feasible UVLS\u2019 in Fig. 2 (b) (corresponding to\npoint OP2 in Fig. 2 (a)). In the analysis outlined above, a\ncritical load shedding threshold exists, which is the minimum\namount of load that must be shed to ensure the system\u2019s\nstability. This pivotal value is demonstrated as the \u2018Feasible\nAction Boundary\u2019 in Fig. 2 (c). The dynamic action-jointed\nsecurity margin (DASM) is defined as follows:\nDASM = dis(P, \u2202ADSR) + dis(PLS, \u2202ALS,P )\n(9)\nwhere \u2202ALS,P is the \u2018Feasible Action Boundary\u2019 of emer-\ngency control action at operating point P, and PLS is the\nload shedding amount. The latter term shows the impact of\nload shedding on the security margin, and the subscript P\ndenotes that the calculation of the threshold above depends on\nthe specific operating point. Within the injected power space\nand the UVLS space, we can further simplify the solution to\nthe formula as follows:\nDASM = min dis([P, PLS], [PC, PLS,P ]),\ns.t. PC \u2208\u2202ADSR and PLS,P \u2208\u2202ALS,P\n(10)\nSimilarly, we can address the problem via gradient opti-\nmization. Consequently, this approach leads to an integrated\nrepresentation of the power system\u2019s security margin, which\nencompasses both the system\u2019s state information and the\nemergency control measures.\n2) State-action-joint Structure for Margin Estimation:\nDespite introducing the security margin representation incor-\nporating action and operating points, resolving the DASM with\nnonlinear attributes remains challenging. The employment of\nNNs, with their robust nonlinear feature extraction capabilities,\npresents a viable solution. However, the precise estimation\nof the DASM necessitates effectively extracting the power\nsystem\u2019s operating point characteristics and their integration\nwith emergency control actions. Drawing inspiration from\nthe dueling DQN [28], our study reevaluates the challenges\nassociated with short-term voltage security margin estimation\nin power systems. We focus on the discrepant impacts of\nthe power system\u2019s static operating point and the emergency\ncontrol actions on post-fault stability. Specifically, we propose\na joint state-action security margin estimation network, as\nshown in Fig. 4. The proposed innovative dueling framework\ndelineates the state-wise security value function C1(s) and the\nadvantage function C2(s, a) from the predicted overarching\nsecurity margin C. The state-wise security value function\nC1(s) is exclusively tasked with forecasting the security\nmargin at the present operating point, while the advantage\nfunction C2(s, a) is dedicated to evaluating the influence\nof each emergency control action on the security margin\noutcomes at that operating point:\nC(s, a) = C1(s) \u2212C2(s, a)\n(11)\nGiven the absence of constraints on the state-wise security\nvalue function and the advantage function, (11) is unidentifi-\nable in the sense that C1 and C2 cannot be recovered via given\nC. Hence, the learned features may diverge from anticipated\noutcomes. To address this, (11) is reformulated as follows:\nC(s, a) =\n(C1(s) \u2212(C2(s, a) \u2212min\nai\u2208A C2(s, ai)), discrete\nC1(s) \u2212(C2(s, a) \u2212C2(s, azero)), continuous\n(12)\nwhere the terms \u2018discrete\u2019 and \u2018continuous\u2019 refer to whether\nthe action space is discrete or continuous. A is the action\nspace and minai\u2208A C2(s, ai) denotes the minimal advantage\nvalue in C2(s, \u00b7) with discrete action space. Similarly, azero\nepitomizes the advantage function under unregulated situations\nwith continuous action space. The procedures above serve not\nonly to regularize the feature extraction but also to fortify the\ntraining process.\nEmploying the decomposition mentioned above enables a\nmore effective capture of the distinctive features of risky\noperating points within the power system, surpassing the\nconventional network architecture and refining estimation ac-\ncuracy. Moreover, the proposed architecture\u2019s capacity to\nindependently investigate the attributes of operating states\nand actions ensures that the computation of the state-wise\nmargin function and the advantage function remains robust\nagainst interference upon changes in the operating scenarios.\nThis attribute endows the proposed method with superior\ngeneralization capabilities across complex scenarios.\n3) Critical Operating Samples Searching and Training via\nUncertainty: Given the vast array of potential operating points\nin intricate power systems, one crux of enhancing training effi-\nciency lies in selecting samples pivotal for training. In training\nthe security margin estimator for obtaining the DSR boundary,\nnot every sample contributes equally. Samples proximate to\nthe classification boundary are instrumental in developing\nprecise security boundaries and margins. Consequently, this\nresearch proposes a search scheme for pivotal operational\nsamples grounded in AL methodology. The quintessence\n6\nof AL involves commencing with a limited set of initial\ncalibration samples to derive a preliminary evaluation model.\nSubsequently, employing a defined sample search strategy,\na cohort of the most informative samples is selected for\ncalibration. Specifically, a sample\u2019s proximity to the DSR\nboundary directly correlates to its utility in obtaining an\naccurate boundary. The closer the operating point outcome of\nan evaluated sample is to the boundary, the more significant\nit is deemed for acquiring a precise estimator. Taking the\nthreshold value \u03f5 for illustrative purposes, suppose the DASM\nof a single sample (s, a) is denoted by d(s, a). In this context,\nthe uncertainty Ur of the sample is defined as follows:\nUr(s, a) = \u2225d(s, a)\u2225\u22121\n(13)\nBased on the state-action joint network structure and the\ndefinition of sample uncertainty, we introduce a robust training\nframework tailored for the proposed action-jointed security\nmargin estimator leveraging AL to enhance its efficacy. The\nprocedural steps are as follows:\n1. Initial Sample Selection: Randomly select N samples to\nform the initial calibration data set for training the estimator.\n2. Initial Labeling: Employ a simulation program to label\nthe initial dataset with \u2018stable\u2019 and \u2018unstable\u2019 for training.\n3. Model Training: Utilize the latest training sample set to\ntrain the DSR boundary and security margin estimator.\n4. Uncertainty Measurement: Determine the uncertainty of\nunlabeled samples via the updated security margin estimator\naccording to (13). Identify and select the top M unlabeled\nsamples with the highest uncertainty for further processing.\n5. Simulation and Labeling: Send the selected samples with\nthe highest uncertainty to the simulator for labeling.\n6. Iterative Process: Repeat steps 3 through 5, refining the\ncalibration, training, and sample selecting procedures until the\nclassification accuracy attains the preset threshold.\nThe proposed methodology leverages an AL paradigm to\nexpedite the learning process of the parameterized DASM\nestimator. Through iterative refinement and continual model\nupdates, it demonstrates the capability to assimilate the in-\ntricacies of security assessment with a limited dataset. This\napproach not only streamlines the sample calibration process\nand improves the efficiency of constructing the security as-\nsessment model but also enhances the overall model training\nand updating speed, thereby contributing to the applicability\nof the proposed security margin estimator. Concurrently, the\nselection and utilization of critical samples enhance the mod-\nule\u2019s robustness amidst intricate scenarios.\nC. Gradient Projection-based Decision Making Module\nThe quandary of fulfilling nonlinear safety constraints while\nconcurrently ensuring performance parity remains a critical\nissue in SRL. A novel algorithm called unrolling safety layer\n(USL) is raised in [29], proffering a methodical enforcement\nof stringent constraints via the deep unrolling architecture and\ngradient projection. Inspired by USL, a two-stage short-term\nvoltage stability emergency control policy pre-formulation and\ncorrection scheme is developed. The details of this scheme are\nshown in Fig. 6 and Fig. 7.\nOperating Status \ns1, s2, ...\nSecurity Margin \nEstimator\nSecurity Margin \nEstimator\nDataset of\nMassive Scenarios\nDataset of\nMassive Scenarios\nDataset\nDn with \naction\nInitial \nSelection\nEmergency Comtrol \na1, a2, ...\nEstimating\nSelecting \nSamples \n*\n*\n*\n*\n*\n*\n\u00d7\n\u00d7\n\u00d7\n\u00d7\n\u00d7\n\u00d7\nP1\nP2\n*\n*\n*\n*\n*\n*\n\u00d7\n\u00d7\n\u00d7\n\u00d7\n\u00d7\n\u00d7\nP1\nP2\n*\n*\n*\n*\n*\n*\n\u00d7\n\u00d7\n\u00d7\n\u00d7\n\u00d7\n\u00d7\nP1\nP2\n*\n*\n*\n*\n*\n*\n\u00d7\n\u00d7\n\u00d7\n\u00d7\n\u00d7\n\u00d7\nP1\nP2\nDSR boundary\n\u00d7 * Risky and safe \nsamples \n\u00d7 *\nSelected risky \nand safe samples \nFig. 5. Active learning-based security margin estimator training process.\nOperating Status \nO=[P,Q,V,PG,QG]\na0\nFinal \nEmergency \nControl  \nAction a*\nak+1=ak-\n\u03b7\uf0d1aC(st,ak) \nTraining via back propagation\nPreliminary Policy \nFormulation via SAC\nProjection via Gradient \nof DASM\nOperating Status \nO=[P,Q,V,PG,QG]\na0\nFinal \nEmergency \nControl  \nAction a*\nak+1=ak-\n\u03b7\uf0d1aC(st,ak) \nTraining via back propagation\nPreliminary Policy \nFormulation via SAC\nProjection via Gradient \nof DASM\n\u03c0\u03b8(O) \nFig. 6. Proposed gradient projection-based action correction.\n1) Initial Emergency Control Policy Formulation: Con-\nsidering the multitude of operating points typically present\nin real-world power systems, it is imperative to to distill\npivotal initial strategies from extensive operational datasets\nexpediently. To this end, the formulation of the initial policy\nis predicated on the Soft Actor-Critic (SAC) algorithm, which\nis renowned for its efficacy in balancing exploration and\nexploitation in complex, high-dimensional spaces. The input\nof the proposed emergency control policy formulation network\nis the operating status O(t) = [P, Q, V, PG, QG], and the\noutput of the policy network is the uncorrected emergency\ncontrol action a0, i.e., the output action a0(t) is specified by a\nparameterized NN \u03c0\u03b8(Ot). The details of SAC can be found\nin [30].\nThe reward mechanisms outlined in II-B are instrumental\nin guiding the decision-making agent away from hazardous\nstrategies throughout this stage. Despite these measures, there\nremains a possibility of constraint violations occurring, which\nis attributed to the inherent challenges of RL agents when deal-\ning with intricate nonlinear constraints, distributional shifts,\netc. To tackle these challenges, we improve the existing\nframework. The preliminary decision network does not directly\nfurnish the optimal action that meets all constraints. Instead, it\nEmergency control action space\nFeasible region of pre-decision \naction space\nC\nA\n\uf0d1\uf0b6\nC\nA\n\uf0b6\nC\nA\nFig. 7. Action correction via gradient.\n7\nprovides an initial action for the subsequent correction stage,\nwhich may be sub-optimal but serves as a foundation for\nfurther refinement.\n2) Policy correction via Gradient Projection: Built on the\npremise that the security margin estimator acquires a relatively\nprecise understanding of assessment knowledge, the action a0\nis adopted as the initial solution for the ensuing constrained\noptimization problem:\narg max\nat\u2208A\nr(Ot, at)\ns.t.\nD\u03b8(Ot, at) \u2265\u03f5\n(14)\nwhere r is the reward, \u03f5 is a positive margin value indicating\nsecure status and D\u03b8(Ot, at) is the estimated security margin\n(distance) at operating status Ot with emergency control action\nat. The optimization problem in (14) has nonlinear constraints\nand objective function. Considering the nonlinear characteris-\ntics of the problem, a direct linearization and projection could\nresult in significant errors. We employ gradient descent to\nderive emergency control actions with an improved security\nmargin to mitigate this. Specifically, the gradient of the pa-\nrameterized security margin function, \u2207aD\u03b8(st, at), indicates\nthe different impact of these control action components on the\nparameterized security margin, as follows:\n\u2207aD\u03b8(st, at) = {\u2202D\u03b8\na(1) , \u2202D\u03b8\na(2) , ..., \u2202D\u03b8\na(n)}|a=at\n(15)\nwhere a(i) denotes the ith component of a. The above\ngradient information provides a reference for action correction.\nSubsequently, utilizing the gradient, we project the preliminary\naction into the feasible action space\u2019s interior until the eval-\nuated security margin D\u03b8(st, ak) is no lower than a preset\nthreshold \u03f5:\nak+1 = ak + \u03bb\u2207aD\u03b8(st, ak)\n(16)\nwhere \u03bb is the step size. Corrective action aims to enhance\nthe DASM, ensuring that the pre-decision action remains\ninherently more secure. The above gradient-based projections\nultimately project the initial action into the feasible action\nspace, as Fig. 7 shows. These operations transform risky\nactions into safer alternatives, and, finally, into a feasible\nemergency control action space.\nFurthermore, in this study, we propose a feasible update\nstep size with no performance degradation via the Lipschitz\ncontinuous theory:\n\u03bb = D\u03b8(s, a) \u2212\u03f5\n2naL2\n(17)\nwhere L is the Lipschitz constant of the network and n is the\ndimension of pre-decision action. This result provides a solid\ntheoretical foundation for our approach.\nIV. CASE STUDY\nThe proposed scheme is tested on the IEEE 39-bus system\nand the GPG system in China Southern Power Grid (CSG)\nto illustrate the validity of the proposed methodology. All the\nsimulations and tests are performed in a workstation equipped\nwith an AMD Ryzen 9 5900X 12-Core Processor, 64GB RAM\nand an NVIDIA RTX 3090 GPU. The simulated system is built\non Dynamic Simulation Program (DSP), an AC-DC hybrid\npower system calculation and analysis software developed by\n30\n39\n1\n2\n25\n37\n29\n17\n26\n9\n3\n38\n16\n5\n4\n18\n27 28\n36\n24\n35\n22\n21\n20\n34\n23\n19\n33\n10\n11\n13\n14\n15\n8\n31\n12\n6\n32\n7\nZone A\nZone B\nZone C\nG\nG\nG\nG\nG\nG\nG\nG\nG\nG\nFig. 8. Single line diagram of IEEE 39-bus system.\nReward\nReward\n0\n500\n1000\n1500\n2000\nTrain epoch\n(a)\n-20\n-15\n-10\n-5\n0\n-20\n-15\n-10\n-5\n0\n0\n500\n1000\n1500\n2000\nTrain epoch\n(a)\n-20\n-15\n-10\n-5\n0\n0\n500\n1000\n1500\n2000\nTrain epoch\n(b)\n-20\n-15\n-10\n-5\n0\n-20\n-15\n-10\n-5\n0\n0\n500\n1000\n1500\n2000\nTrain epoch\n(b)\n-20\n-15\n-10\n-5\n0\nRtrain\nAvg(Rtest)\nRtest\nRtrain\nAvg(Rtest)\nRtest\nRtrain\nAvg(Rtest)\nRtest\nRtrain\nAvg(Rtest)\nRtest\nFig. 9. Reward during the training process. (a) Reward with safety correction\nmodule. (b) Reward without safety correction module.\nCSG Electric Power Research Institute (CSG EPRI), while the\nproposed SRL-based scheme is built on PyTorch 1.12.0.\nA. IEEE 39-bus System Case\nWe first verified the performance of the proposed scheme\nvia the IEEE 39-bus system, a simple approximation of the\nNew-England Power System. The main structure of the IEEE\n39-bus system is illustrated in Fig. 8.\n1) Simulation Setup and Case Generation: Considering the\noperating point from [31] as the baseline condition, a variety\nof operating conditions and contingencies were generated.\nSpecifically, the operating levels of the three zones varied from\n60% to 100%, and a typical dynamic load proportion varied\nfrom 50% to 60%. In this study, we focus on faults occurring\non lines across zones [F5, F19, F21] and faults in heavy-load\nareas [F7-18], and the fault clearing time was set to 0.18s. The\nproposed emergency control agents are specifically designed\nfor each fault in the predefined fault set.\n2) Validation of the SRL-based Decision Making Frame-\nwork: Taking Fault F5 as an example, we tested the per-\nformance of the proposed scheme together with the one\nwithout correction. Fig. 9(a) shows the reward in the training\nof the SRL-based emergency control pre-decision making\nmodule with \u03f5 = 0.1. Fig. 9(b) shows the same training\nresult without security correction. In the initial training phase,\nthe proposed scheme outperforms the agent without safety\ncorrection because the proposed scheme integrates knowledge\n8\nabout feasible action space via DSM estimation, enabling effi-\ncient correction of risky actions. Despite initial transgressions\nof constraints in certain scenarios, the agent with security\nestimating faculties swiftly integrated knowledge about these\nincidents. This culminates in an enhanced proficiency of the\nproposed emergency control pre-decision making agent in\nnavigating such predicaments. In the subsequent stage, the\nproposed scheme, bolstered by gradient projection, circum-\nvented further violations and garnered a superior test reward\nrelative to its counterpart devoid of action correction. The\nsafety correction helps the agent stay within the safe range\nof actions, making the decision not only safer but also more\nstable and robust.\nTo validate the security of our proposed scheme, we com-\npared its performance with that of the trained agent without\naction correction. This evaluation encompassed 100 scenar-\nios unseen in training, including a random selection from\na broader operating space and boundaries. These scenarios\nencompassed load deviations and dynamic load fluctuations\nto rigorously test the method\u2019s dependability. The results,\ndelineated in Table I, demonstrate that our proposed scheme\nhad significantly fewer violations. In contrast, strategies em-\nployed by the agent without security correction failed to\nsatisfy security constraints in a considerable proportion of\nscenarios, resulting catastrophic voltage collapse within the\nsystem. Moreover, adopting safe projection constraints guar-\nantees that our strategy secures the system while necessitating\nonly a minimal amount of additional load shedding, further\nsubstantiating the validity of our proposed scheme. Note that\nlimited occurrences of violations occurred due to the security\nestimator\u2019s failure to capture some extremely infrequent cases,\nwhere our ongoing research will address this issue.\nTABLE I\nPERFORMANCE VALIDATION IN EXTREME SCENARIOS\nMethod\nAvg(R) Time/ms Violation Avg(\u2206v2) Avg(PLS)\nProposed\n-12.83\n1.33\n6\n0.0025\n0.4349\nSAC\n-30.61\n1.24\n26\n0.1152\n0.3731\nIn addition, we compare our proposed safe decision-making\nmethod with other typical approaches, including the typical de-\ncentralized multi-round approach in [24], the traversal method,\nthe Lyapunov-based safe policy optimization method [32] and\nConservative Safety Critics (CSC) [33]. The typical multi-\nround LS approach adheres to the following guidelines: If\nthe voltage falls below a specified threshold within a certain\nduration, a predetermined amount of load is shed. The traversal\nmethod computes load shedding amounts at each bus using a\nfixed 20% step. We maintain consistent hyperparameters for\nthe latter two methods based on our proposed scheme. Table II\nsummarizes their pre-decision making performances, where\nPLS denotes load shedding amount. Due to time constraints,\nwe did not evaluate the traversal method on all available data.\nOur results demonstrate that our proposed method outperforms\nthe other two approaches. This superiority can be attributed\nto the proposed method\u2019s integration of nonlinear constraints\nand policy functions, which ensures flexibility and adaptability\nto complex fault scenarios. In contrast, the typical multi-\nround LS approach neglects the impact of system dynamic\ncharacteristics on voltage recovery during subsequent periods.\nIn certain instances, untimely load shedding led to voltage\ncollapse after a duration. The CSC suffered from random\nstrategy selection limiting its effectiveness in utilizing power\nsystem safety constraints and control actions, while Lyapunov\nlinearization lacked suitability for nonlinear scenarios with\nhigh load over-shedding.\nTABLE II\nPERFORMANCE OF DIFFERENT UVLS APPROACHES\nMethod\nAvg(R)\nTime/s\nViolation Avg(PLS)\nProposed\n-4.671\n0.00133\n0\n0.2009\nTypical LS\n-20.04\n-\n38\n0.3120\nTraversal\n\u2212\n>1e2\n0\n\u2212\nLyapunov PG\n-6.154\n0.00139\n0\n0.3231\nCSC\n-10.32\n0.00329\n0\n0.8794\n3) Validation of the Proposed Security Margin Estimator:\nWe evaluate the effectiveness of our proposed security classi-\nfier and margin estimator structure by comparing it with tradi-\ntional alternatives, including fully connected network (FCN),\nand Long Short-Term Memory (LSTM). Our testing dataset\ncomprises 3500 samples, representing random operating points\nand emergency control actions. For all networks, we set the\nlearning rate to 1e-4, use 3 layers, and allocate 256 neurons\nper layer unless specific considerations dictate otherwise.\nThe performance for different network structures is sum-\nmarized in Table III, covering learning efficiency, accuracy,\nand specificity. Notably, the proposed network structure out-\nperforms FCN across all evaluated metrics. While the pro-\nposed network may not match the performance of LSTM\nin certain respects, it\u2019s essential to recognize that LSTM\ndemands significantly more training time due to its complex\narchitecture. Additionally, the risk categorization employed by\nthe LSTM model tends to be overly binary, leading to potential\nmisclassification of pivotal states. This issue becomes partic-\nularly pronounced under extreme operational conditions. In\nsummary, our proposed security classifier effectively identifies\nrisky operating points and control actions, aiding early warning\nand subsequent corrective measures.\nTABLE III\nPERFORMANCE COMPARISON OF DIFFERENT NETWORK STRUCTURES\nFOR SECURITY ASSESSMENT AND MARGIN ESTIMATION\nMethod\nAcc.\nSpe.\nTrain Time/s\nProposed 0.988 0.978\n27.48\nFCN\n0.963 0.986\n20.73\nLSTM\n0.978 0.908\n91.53\n4) Validation of the Proposed Active Learning Scheme: In\nthis subsection, we validate the proposed AL-based training\nefficiency enhancement scheme. Following the earlier settings,\nwe generated 3500 simulation cases using time-domain nu-\nmerical simulation. With a threshold of \u03f5 = 0.5 to distinguish\nbetween stable and unstable states, and 50 iterations for each\nselected set with 128 samples, we trained the proposed security\nmargin estimator using 5-fold cross-validation (as depicted in\nFig.10 and Fig.11). During training, both the training error\nand testing error decreased gradually, leading to an accuracy\nexceeding 95% on the test set.\n9\n0\n100\n200\n300\n400\n500\nEpoch\n0\n0.2\n0.4\n0.6\n0.8\n1\nRate\n(b)\n0\n100\n200\n300\n400\n500\nEpoch\n0\n0.5\n1\n1.5\nMSE Loss\n(a)\nAcc\nSpe\nAcc\nSpe\nAcc\nSpe\nLtrain\nLtest\nLtrain\nLtest\nLtrain\nLtest\nFig. 10.\nLearning curves of security via active learning. (a) Train and test\nlosses (MSE). (b)Test accuracy.\n-0.5\n-0.3\n-0.1\n0.1\n0.3\n0.5\nMargin Threshold \u03f5 \nSpecificity (or Acc)\n0\n0.2\n0.4\n0.6\n0.8\n1\n0\n0.2\n0.4\n0.6\n0.8\n1\nSpecificity\nAccuracy\nSpecificity\nAccuracy\n0\n0.2\n0.4\n-0.2\n-0.4\nFig. 11. Change in specificity and accuracy as \u03f5 changes.\nFurthermore, we compared the proposed scheme with an\nalternative approach trained using all cases. The results,\nsummarized in Table III, highlight the learning performance\nachieved by our method within 300 training epochs (equivalent\nto 384 cases, considering a batch size of 128). In contrast,\nthe alternative approach necessitated over 5,000 seconds for\ndataset preparation and exhibited much longer training time\n(7.142s vs 50.76s). These findings underscore the effectiveness\nof our proposed method, which can effectively adapt to\nchanging operating scenarios and topologies.\nTABLE IV\nEFFICIENCY VERIFICATION OF PROPOSED ACTIVE LEARNING-BASED\nSECURITY ASSESSMENT AND MARGIN ESTIMATION APPROACH\nMethod\nAcc.\nSpe.\nttotal/s ttotal/s\nProposed 0.9602 0.8505\n974\n7.142\nNormal\n0.9786 0.9112\n5850\n50.76\nB. GPG System Case\nTo further validate the scalability and applicability of the\nproposed method in real power grids with complex structures\nand operating conditions, extended study in the GPG system\nis considered in this subsection. The GPG system case is\nsimplified from one realistic provincial power grid of CSG,\nwhich is relatively susceptible to short-term voltage stabiliza-\ntion problems due to the concentration of numerous industrial\nareas with high electrical loads. Consequently, we selected the\nGPG system to investigate the proposed pre-decision making\nscheme. The structure of the GPG system is depicted in\nFig. 12, including all 500-kV buses and large power plants.\n500-kV Substation \nHVDC Converter Station\nRegular Power Plant\nNuclear Power Plant\nPumped-Storage Power Plant \nFig. 12. Single line diagram of GPG system from realistic CSG.\nReward\n0\n500\n1000\n1500\n2000\nTrain epoch\n(a)\n-20\n-15\n-10\n-5\n0\n-20\n-15\n-10\n-5\n0\n0\n500\n1000\n1500\n2000\nTrain epoch\n(a)\n-20\n-15\n-10\n-5\n0\nRtrain\nMov(Rtest)\nRtest\nRtrain\nMov(Rtest)\nRtest\nFig. 13. Training process for GPG system.\n1) Simulation Setup and Case Generation: The overall load\nlevel of the GPG was set between [0.6, 1, 1]. Additionally,\nto account for potential load level fluctuations, we introduce\nsupplementary disturbances at buses in heavy load areas to\nsimulate the complex operating scenarios encountered in the\nrealistic power systems. Furthermore, we intentionally set\nfaults in the heavy load area to emphasize the voltage stability\nchallenges faced by the system. Other settings are similar to\nthe IEEE 39-bus system. Under these settings, we generate\n5,000 samples, with 4,000 samples allocated for training and\n1,000 samples reserved for testing.\n2) Overall Performance Validation and Comparison: The\ntraining and test results are depicted in Fig. 13 and Table\nV. Considering the practical applicability of the proposed\nemergency control pre-decision-making scheme in complex\nrealistic power systems, we conducted specific verification\nof its computational efficiency within the GPG system. Ta-\nble V also illustrates that the proposed method maintains\nrobust performance in complex systems with zero violations.\nSimultaneously, it demonstrates greater efficiency compared\nto algorithms that seek the optimal reduction amount via\nexhaustive search. Despite the limited selection of test samples\ndue to time constraints, these results corroborate its efficacy.\nTABLE V\nPERFORMANCE VALIDATION IN EXTREME SCENARIOS FOR GPG SYSTEM\nMethod\nAvg(R) Time/ms Violation\nProposed\n-6.567\n1.33\n0\nNo Correction\n-9.325\n1.24\n12\n3) Computational Efficiency Analysis: We further verified\nthe impact of the proposed AL scheme on training, with\nthe results presented in Table VI. As indicated by the table,\nthe proposed scheme achieves efficient training for complex\nsystem security margin estimation in significantly less time\ncompared to traditional methods. Moreover, it ensures the\nperformance of the proposed security margin estimator, reaf-\n10\nfirming the applicability of the proposed AL framework in\ncomplex real power systems.\nTABLE VI\nEFFICIENCY VERIFICATION OF PROPOSED AL-BASED SECURITY\nASSESSMENT AND MARGIN ESTIMATION\nTrain Method\nAcc.\nSpe.\nttotal/s ttrain/s\nProposed\n0.9365 0.9336\n2931\n3.232\nNormal\n0.9531 0.9090\n8524\n23.93\nV. CONCLUSION\nMotivated by the growing need for efficient and safe\nemergency control strategy formulation in complex power\nsystems, this paper presents an innovative pre-formulation\napproach for short-term voltage stability control based on\nSRL. The proposed scheme comprises two key components: a\nsecurity margin estimation module using NNs and a decision-\nmaking module based on SRL with gradient projection. The\nsecurity margin estimator accurately characterizes the nonlin-\near boundary of feasible actions in power system emergency\ncontrol scenarios, enhancing interpretability and providing a\nsolid theoretical foundation for gradient-based corrections.\nLeveraging a dueling network architecture alongside active\nlearning (AL) techniques significantly improves the scheme\u2019s\nperformance and practicality in complex systems. The gradient\nprojection-based method cleverly integrates hard constraints\nassociated with power system stability and data-driven re-\ninforcement learning techniques, enhancing method security\nwhile ensuring efficiency. Empirical testing on the IEEE 39-\nbus system and GPG validates the excellent performance of the\nproposed approach. Future research will focus on the outlier\nevents with low frequency and high risk in strategies training,\nand simplify the decision model to enhance the applicability\nof the proposed scheme in realistic power systems.\nREFERENCES\n[1] W. Yi, D. J. Hill, and Y. Song, \u201cImpact of High Penetration of Renewable\nResources on Power System Transient Stability,\u201d in 2019 IEEE Power\n& Energy Society General Meeting (PESGM), pp. 1\u20135, Aug. 2019.\n[2] L. Zhang, Y. Yin, Y. Ma, and J. Ma, \u201cSecurity and stability control\nsystem for Huanggang and Huangshi network of Hubei Province,\u201d Power\nSystem Protection and Control, vol. 38, no. 1, pp. 79\u201382 (in Chinese),\n2010.\n[3] Y. Zhao, W. C. Zhang, Y. Li, X. Gao, and X. Gu, \u201cResearch on the\ngeneral control strategy of power system tuning method,\u201d Power System\nProtection and Control, vol. 43, no. 4, pp. 102\u2013107 (in Chinese), 2015.\n[4] J. Shair, H. Li, J. Hu, and X. Xie, \u201cPower system stability issues,\nclassifications and research prospects in the context of high-penetration\nof renewables and power electronics,\u201d Renewable and Sustainable\nEnergy Reviews, vol. 145, p. 111111, July 2021.\n[5] R. S. Sutton and A. G. Barto, Reinforcement Learning: An Introduction.\nMIT press, 2018.\n[6] W. Liu, D. Zhang, X. Wang, J. Hou, and L. Liu, \u201cA Decision Making\nStrategy for Generating Unit Tripping Under Emergency Circumstances\nBased on Deep Reinforcement Learning,\u201d Proceedings of the CSEE,\nvol. 38, no. 01, pp. 109\u2013119+347, 2018.\n[7] J. Zhang, Y. Luo, B. Wang, C. Lu, J. Si, and J. Song, \u201cDeep\nReinforcement Learning for Load Shedding Against Short-Term Voltage\nInstability in Large Power Systems,\u201d IEEE Transactions on Neural\nNetworks and Learning Systems, pp. 1\u201312, 2021.\n[8] R. R. Hossain, Q. Huang, and R. Huang, \u201cGraph Convolutional Network-\nBased Topology Embedded Deep Reinforcement Learning for Voltage\nStability Control,\u201d IEEE Transactions on Power Systems, vol. 36,\npp. 4848\u20134851, Sept. 2021.\n[9] X. Chen, G. Qu, Y. Tang, S. Low, and N. Li, \u201cReinforcement Learning\nfor Selective Key Applications in Power Systems: Recent Advances and\nFuture Challenges,\u201d IEEE Transactions on Smart Grid, pp. 1\u20131, 2022.\n[10] G. Dulac-Arnold, N. Levine, D. J. Mankowitz, J. Li, C. Paduraru,\nS. Gowal, and T. Hester, \u201cChallenges of real-world reinforcement\nlearning: Definitions, benchmarks and analysis,\u201d Machine Learning,\nvol. 110, pp. 2419\u20132468, Sept. 2021.\n[11] Y. Shi, G. Qu, S. Low, A. Anandkumar, and A. Wierman, \u201cStability\nConstrained Reinforcement Learning for Real-Time Voltage Control,\u201d in\n2022 American Control Conference (ACC), pp. 2715\u20132721, June 2022.\n[12] T. L. Vu, S. Mukherjee, T. Yin, R. Huang, J. Tan, and Q. Huang,\n\u201cSafe Reinforcement Learning for Emergency Load Shedding of Power\nSystems,\u201d in 2021 IEEE Power & Energy Society General Meeting\n(PESGM), pp. 1\u20135, July 2021.\n[13] L. Brunke, M. Greeff, A. W. Hall, Z. Yuan, S. Zhou, J. Panerati, and A. P.\nSchoellig, \u201cSafe Learning in Robotics: From Learning-Based Control to\nSafe Reinforcement Learning,\u201d Annual Review of Control, Robotics, and\nAutonomous Systems, vol. 5, no. 1, pp. 411\u2013444, 2022.\n[14] J. Li, X. Wang, S. Chen, and D. Yan, \u201cResearch and Application of Safe\nReinforcement Learning in Power System,\u201d in 2023 8th Asia Conference\non Power and Electrical Engineering, pp. 1977\u20131982, Apr. 2023.\n[15] W. Wang, N. Yu, Y. Gao, and J. Shi, \u201cSafe Off-Policy Deep Reinforce-\nment Learning Algorithm for Volt-VAR Control in Power Distribution\nSystems,\u201d IEEE Transactions on Smart Grid, vol. 11, pp. 3008\u20133018,\nJuly 2020.\n[16] Y. Gao and N. Yu, \u201cModel-augmented safe reinforcement learning\nfor Volt-VAR control in power distribution networks,\u201d Applied Energy,\nvol. 313, p. 118762, May 2022.\n[17] P. Ren, Y. Xiao, X. Chang, P.-Y. Huang, Z. Li, B. B. Gupta, X. Chen,\nand X. Wang, \u201cA Survey of Deep Active Learning,\u201d ACM Computing\nSurveys, vol. 54, pp. 180:1\u2013180:40, Oct. 2021.\n[18] V. Malbasa, C. Zheng, P.-C. Chen, T. Popovic, and M. Kezunovic,\n\u201cVoltage Stability Prediction Using Active Machine Learning,\u201d IEEE\nTransactions on Smart Grid, vol. 8, pp. 3117\u20133124, Nov. 2017.\n[19] Y. Zhang, Q. Zhao, B. Tan, and J. Yang, \u201cA power system transient\nstability assessment method based on active learning,\u201d The Journal of\nEngineering, vol. 2021, no. 11, pp. 715\u2013723, 2021.\n[20] K. Wang, Z. Chen, W. Wei, X. Sun, S. Mei, Y. Xu, T. Zhu, and J. Liu,\n\u201cPower System Transient Stability Assessment Based on Deep Bayesian\nActive Learning,\u201d in 2022 IEEE/IAS Industrial and Commercial Power\nSystem Asia (I&CPS Asia), pp. 1692\u20131696, July 2022.\n[21] W. Zhao, T. He, R. Chen, T. Wei, and C. Liu, \u201cState-wise Safe\nReinforcement Learning: A Survey,\u201d May 2023.\n[22] Z. Shi, Y. Xu, X. Wu, J. He, R. Yang, and M. Yang, \u201cAssessment of\nsystem protection strategy and aided decision scheme for AC/DC hybrid\npower systems,\u201d Electric Power Automation Equipment, vol. 40, no. 4,\npp. 25\u201331 (in Chinese), 2020.\n[23] Y. Yu, Y. Liu, C. Qin, and T. Yang, \u201cTheory and Method of Power\nSystem Integrated Security Region Irrelevant to Operation States: An\nIntroduction,\u201d Engineering, vol. 6, pp. 754\u2013777, July 2020.\n[24] R. M. Larik, M. W. Mustafa, and M. N. Aman, \u201cA critical review of\nthe state-of-art schemes for under voltage load shedding,\u201d International\nTransactions on Electrical Energy Systems, vol. 29, no. 5, p. e2828,\n2019.\n[25] C. Dwivedi, \u201cLiterature Survey on Short-Term Voltage Stability Effect,\nCause and Control,\u201d in 2018 IEEE Green Technologies Conference\n(GreenTech), pp. 15\u201320, Apr. 2018.\n[26] Y. Chen, Y. Luo, and C. Lu, \u201cPower System Transient Voltage Stability\nRegion Boundary Approximation and Stability Margin Estimation Based\non Residual Neural Network,\u201d in 2023 IEEE Belgrade PowerTech, pp. 1\u2013\n10, June 2023.\n[27] X. Zhang and D. J. Hill, \u201cLoad Stability Index for Short-term Voltage\nStability Assessment,\u201d in 2019 IEEE Power & Energy Society General\nMeeting (PESGM), pp. 1\u20135, Aug. 2019.\n[28] Z. Wang, T. Schaul, M. Hessel, H. van Hasselt, M. Lanctot, and\nN. de Freitas, \u201cDueling Network Architectures for Deep Reinforcement\nLearning,\u201d arXiv:1511.06581 [cs], Apr. 2016.\n[29] L. Zhang, Q. Zhang, L. Shen, B. Yuan, X. Wang, and D. Tao,\n\u201cEvaluating Model-Free Reinforcement Learning toward Safety-Critical\nTasks,\u201d Proceedings of the AAAI Conference on Artificial Intelligence,\nvol. 37, pp. 15313\u201315321, June 2023.\n[30] T. Haarnoja, A. Zhou, P. Abbeel, and S. Levine, \u201cSoft Actor-Critic:\nOff-Policy Maximum Entropy Deep Reinforcement Learning with a\nStochastic Actor,\u201d arXiv:1801.01290 [cs, stat], Aug. 2018.\n[31] T. Athay, R. Podmore, and S. Virmani, \u201cA Practical Method for the\nDirect Analysis of Transient Stability,\u201d IEEE Transactions on Power\nApparatus and Systems, vol. PAS-98, pp. 573\u2013584, Mar. 1979.\n11\n[32] Y. Chow, O. Nachum, A. Faust, M. Ghavamzadeh, and E. A. Du\u00b4\ne\u02dc\nnez-\nGuzm\u00b4\nan, \u201cLyapunov-based safe policy optimization for continuous\ncontrol,\u201d in The 36th International Conference on Machine Learning\n(ICML 2019), vol. abs/1901.10031, 2019.\n[33] H. Bharadhwaj, A. Kumar, N. Rhinehart, S. Levine, F. Shkurti, and\nA. Garg, \u201cConservative Safety Critics for Exploration,\u201d in International\nConference on Learning Representations, Oct. 2020.\n", "metadata": {"Published": "2024-05-26", "Title": "Make Safe Decisions in Power System: Safe Reinforcement Learning Based Pre-decision Making for Voltage Stability Emergency Control", "Authors": "Congbo Bi, Lipeng Zhu, Di Liu, Chao Lu", "Summary": "The high penetration of renewable energy and power electronic equipment bring\nsignificant challenges to the efficient construction of adaptive emergency\ncontrol strategies against various presumed contingencies in today's power\nsystems. Traditional model-based emergency control methods have difficulty in\nadapt well to various complicated operating conditions in practice. Fr emerging\nartificial intelligence-based approaches, i.e., reinforcement learning-enabled\nsolutions, they are yet to provide solid safety assurances under strict\nconstraints in practical power systems. To address these research gaps, this\npaper develops a safe reinforcement learning (SRL)-based pre-decision making\nframework against short-term voltage collapse. Our proposed framework employs\nneural networks for pre-decision formulation, security margin estimation, and\ncorrective action implementation, without reliance on precise system\nparameters. Leveraging the gradient projection, we propose a security\nprojecting correction algorithm that offers theoretical security assurances to\namend risky actions. The applicability of the algorithm is further enhanced\nthrough the incorporation of active learning, which expedites the training\nprocess and improves security estimation accuracy. Extensive numerical tests on\nthe New England 39-bus system and the realistic Guangdong Provincal Power Grid\ndemonstrate the effectiveness of the proposed framework.", "entry_id": "http://arxiv.org/abs/2405.16485v1", "published_first_time": "2024-05-26", "comment": "11 pages", "journal_ref": null, "doi": null, "primary_category": "eess.SY", "categories": ["eess.SY", "cs.SY"], "links": ["http://arxiv.org/abs/2405.16485v1", "http://arxiv.org/pdf/2405.16485v1"]}, "type": "Document"}
{"page_content": "ARTIFICIAL INTELLIGENCE AS THE NEW HACKER:\nDEVELOPING AGENTS FOR OFFENSIVE SECURITY\nby\nLeroy Jacob Valencia\nSubmitted in Partial Fulfillment\nof the Requirements for the Degree of\nMasters of Science in Transdiciplinary Cybersecurity\nNew Mexico Institute of Mining and Technology\nSocorro, New Mexico\nMay, 2024\narXiv:2406.07561v1  [cs.CR]  9 May 2024\nThis work is dedicated to my wife, whose unwavering support and belief in my\npotential have been my constant source of strength and inspiration.\nLeroy Jacob Valencia\nNew Mexico Institute of Mining and Technology\nMay, 2024\nACKNOWLEDGMENTS\nI wish to extend my sincerest gratitude to Danny Quist PhD., whose insights\nand guidance were invaluable throughout this research. We also appreciate the\nsupport provided by New Mexico Cybersecurity Center of Excellence. Lastly, I\nwant to thank my peers and family members for their encouragement.\nThis report was typeset with L\nAT\nEX1 by the author.\n1The L\nAT\nEX document preparation system was developed by Leslie Lamport as a special ver-\nsion of Donald Knuth\u2019s T\nEX program for computer typesetting. T\nEX is a trademark of the Ameri-\ncan Mathematical Society. The L\nA\nT\nEX macro package for the New Mexico Institute of Mining and\nTechnology report format was written by John W. Shipman.\niii\nABSTRACT\nIn the vast domain of cybersecurity, the transition from reactive defense to\noffensive has become critical in protecting digital infrastructures. This paper ex-\nplores the integration of Artificial Intelligence (AI) into offensive cybersecurity,\nparticularly through the development of an autonomous AI agent, ReaperAI, de-\nsigned to simulate and execute cyberattacks. Leveraging the capabilities of Large\nLanguage Models (LLMs) such as GPT-4, ReaperAI demonstrates the potential to\nidentify, exploit, and analyze security vulnerabilities autonomously.\nThis research outlines the core methodologies that can be utilized to increase\nconsistency and performance, including task-driven penetration testing frame-\nworks, AI-driven command generation, and advanced prompting techniques.\nThe AI agent operates within a structured environment using Python, enhanced\nby Retrieval Augmented Generation (RAG) for contextual understanding and\nmemory retention. ReaperAI was tested on platforms including, Hack The Box,\nwhere it successfully exploited known vulnerabilities, demonstrating its poten-\ntial power.\nHowever, the deployment of AI in offensive security presents significant eth-\nical and operational challenges. The agent\u2019s development process revealed com-\nplexities in command execution, error handling, and maintaining ethical con-\nstraints, highlighting areas for future enhancement.\nThis study contributes to the discussion on AI\u2019s role in cybersecurity by\nshowcasing how AI can augment offensive security strategies. It also proposes\nfuture research directions, including the refinement of AI interactions with cy-\nbersecurity tools, enhancement of learning mechanisms, and the discussion of\nethical guidelines for AI in offensive roles. The findings advocate for a unique\napproach to AI implementation in cybersecurity, emphasizing innovation.\nKeywords: Artificial Intelligence, Offensive Cybersecurity, Large Language Mod-\nels, Penetration Testing\nCONTENTS\nPage\nLIST OF TABLES\nviii\nLIST OF FIGURES\nix\nCHAPTER 1.\nINTRODUCTION\n1\n1.1\nProblem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.2\nImpact\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2\nCHAPTER 2.\nBACKGROUND AND LITERATURE REVIEW\n3\n2.1\nEvolution of Offensive Security . . . . . . . . . . . . . . . . . . . . .\n3\n2.2\nEvolution of Large Language Models . . . . . . . . . . . . . . . . . .\n3\n2.3\nAI in Cybersecurity: A Historical Perspective . . . . . . . . . . . . .\n4\n2.4\nReview of Current AI in Offensive Security . . . . . . . . . . . . . .\n4\n2.4.1\nPentestGPT . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n2.4.2\nHackingbuddyGPT . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.5\nLLM Limitations\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.5.1\nPrompt Engineering . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.5.2\nContext & Long Term Memory . . . . . . . . . . . . . . . . .\n7\n2.5.3\nLLM Learning & Reasoning . . . . . . . . . . . . . . . . . . .\n7\n2.5.4\nCommand Parsing . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2.5.5\nTraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2.5.6\nRisk/Fear . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n2.5.7\nCreativity\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n2.5.8\nDiligence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n2.5.9\nSituational Awareness . . . . . . . . . . . . . . . . . . . . . .\n10\n2.6\nAgents\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\nv\nCHAPTER 3.\nCORE TECHNOLOGIES AND METHODOLOGIES\n12\n3.1\nPentesting Methodology . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n3.1.1\nATT&CK Life Cycle\n. . . . . . . . . . . . . . . . . . . . . . .\n12\n3.1.2\nHack The Box . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n3.2\nMethodology\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.2.1\nIntegration with LLM\n. . . . . . . . . . . . . . . . . . . . . .\n14\n3.2.2\nAutonomous Agents . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.2.3\nObjectives and Tasks . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.2.4\nDecision-Making in Tasks . . . . . . . . . . . . . . . . . . . .\n15\n3.2.5\nAnalyzation . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.2.6\nEvaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\nCHAPTER 4.\nBUILDING THE AI OFFENSIVE AGENT\n17\n4.1\nAgents\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n4.2\nPrompting, Decision Making, and Natural Language Understanding 19\n4.2.1\nTemplating\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n4.2.2\nEnhanced Decision-Making Through Natural Language Prompt-\ning\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n4.2.3\nAdaptive Decision-Making . . . . . . . . . . . . . . . . . . .\n19\n4.2.4\nMinimizing Unwanted Behaviors Through Precise Prompt\nEngineering . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n4.3\nRAG for Enhanced Memory and Contextual Understanding . . . .\n21\n4.3.1\nPostgreSQL + Python Classes . . . . . . . . . . . . . . . . . .\n21\n4.4\nTask-Driven Methodology . . . . . . . . . . . . . . . . . . . . . . . .\n22\n4.4.1\nTask Tree Management . . . . . . . . . . . . . . . . . . . . . .\n22\n4.4.2\nDynamic Task Updates\n. . . . . . . . . . . . . . . . . . . . .\n22\n4.5\nAI-Driven Command Generation and Processing . . . . . . . . . . .\n23\n4.5.1\nWorkflow\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n4.5.2\nIntegration with LLM\n. . . . . . . . . . . . . . . . . . . . . .\n24\n4.5.3\nStateful Interaction . . . . . . . . . . . . . . . . . . . . . . . .\n25\n4.6\nCommand Execution . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n4.6.1\nNon-Interactive Execution . . . . . . . . . . . . . . . . . . . .\n26\n4.6.2\nInteractive Execution . . . . . . . . . . . . . . . . . . . . . . .\n27\n4.7\nProgress and State Management: . . . . . . . . . . . . . . . . . . . .\n28\n4.7.1\nContinuous Evaluation\n. . . . . . . . . . . . . . . . . . . . .\n28\nvi\n4.7.2\nState Updates and Logging . . . . . . . . . . . . . . . . . . .\n29\n4.8\nError Handling and Adaptability . . . . . . . . . . . . . . . . . . . .\n29\n4.8.1\nError Handling . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n4.9\nSecurity and Scope Consideration . . . . . . . . . . . . . . . . . . . .\n29\n4.9.1\nConstraint Awareness . . . . . . . . . . . . . . . . . . . . . .\n29\nCHAPTER 5.\nRESULTS & DISCUSSION\n31\n5.1\nAutomated Penetration Testing . . . . . . . . . . . . . . . . . . . . .\n31\n5.2\nUnsuccessful Attempts . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\nCHAPTER 6.\nIMPLEMENTATION CHALLENGES, ETHICAL CONSID-\nERATIONS, FUTURE DIRECTION\n34\n6.1\nChallenges in Implementing AI Offensive Agents\n. . . . . . . . . .\n34\n6.2\nEthical Considerations in Offensive Cybersecurity . . . . . . . . . .\n34\n6.3\nFuture Directions in AI-Driven Offensive Security . . . . . . . . . .\n35\nCHAPTER 7.\nCONCLUSION\n37\nREFERENCES\n38\nAPPENDIX A. PROMPTS\n41\nA.1 query next command.txt . . . . . . . . . . . . . . . . . . . . . . . . .\n41\nA.2 analyze cmd.txt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n42\nA.3 evaluate progress.txt . . . . . . . . . . . . . . . . . . . . . . . . . . .\n42\nA.4 get objectives\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n43\nvii\nLIST OF TABLES\nTable\nPage\n4.1\nTable of Intent for Prompting Techniques\n. . . . . . . . . . . . . . .\n20\n4.2\nPrompts that aided in Cleaning Response . . . . . . . . . . . . . . .\n20\nviii\nLIST OF FIGURES\nFigure\nPage\nFigure 3.1\nhttps://www.mandiant.com/resources/insights/targeted-\nattack-lifecycle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\nFigure 3.2\nMain Logic Flow\n. . . . . . . . . . . . . . . . . . . . . . . . .\n14\nFigure 4.1\nAgent Hierarchy\n. . . . . . . . . . . . . . . . . . . . . . . . .\n18\nFigure 4.2\nExample Task Tree\n. . . . . . . . . . . . . . . . . . . . . . . .\n22\nFigure 4.3\nDecision Making on Tasks . . . . . . . . . . . . . . . . . . . .\n23\nFigure 4.4\nGet Next Command Workflow . . . . . . . . . . . . . . . . .\n24\nFigure 4.5\nLLM Object\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\nFigure 4.6\nA Sample of State at a Given Time . . . . . . . . . . . . . . .\n26\nFigure 4.7\nState Workflow . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\nFigure 4.8\nSample Analyzation at a Given Time . . . . . . . . . . . . . .\n26\nFigure 4.9\nInteractive Command Workflow . . . . . . . . . . . . . . . .\n28\nix\nThis report is accepted on behalf of the faculty of the Institute by the following\ncommittee:\nLorie Liebrock\nAcademic Advisor\nDanny Quist\nResearch Advisor\nJun Zheng\nI release this document to the New Mexico Institute of Mining and Technology.\nLeroy Jacob Valencia\nMay 3, 2024\nCHAPTER 1\nINTRODUCTION\nIn the rapidly changing domain of cybersecurity, defensive strategies have\nlong been the focal point, emphasizing the protection of digital assets from ma-\nlicious entities. However, with the increasing complexity and sophistication of\ncyber threats, the significance of offensive cybersecurity has grown, serving as\nan essential complement to traditional defensive tactics. Offensive cybersecurity\nemploys the tactics, techniques, and mindset of adversaries to properly identify,\nexploit, and neutralize vulnerabilities before they can be exploited by attackers.\nThis paper examines the transformative role of Artificial Intelligence in ad-\nvancing offensive security measures. AI\u2019s exceptional capabilities in processing\nextensive datasets, recognizing patterns, and automating intricate tasks make it\na vital component in developing sophisticated offensive security strategies. This\nresearch provides an in-depth analysis of current technologies, methodologies,\nand the ethical concerns associated with AI in cybersecurity, highlighting AI\u2019s\npotential.\nAdditionally, this paper discusses a GitHub project known as ReaperAI Leroy\nJacob Valencia [2023], which exemplifies the practical application of the concepts\nexplored. ReaperAI serves as a proof of concept, demonstrating how AI can in-\ntegrate into offensive cybersecurity to effectively simulate an adversary.\nThe\naim of this research is to build upon existing AI studies, exploring new direc-\ntions and the potential to harness existing AI capabilities to develop a functional\nproduct tailored for advanced cybersecurity solutions. This exploration not only\ncontributes to the academic field but also to practical applications, pushing the\nboundaries of how AI can be leveraged in the context of offensive cybersecurity.\n1.1\nProblem Statement\nThis research seeks to answer the question \u201dHow can existing research on\nlarge language models be leveraged to develop a fully autonomous offensive se-\ncurity agent?\u201d. The objective is to develop a comprehensive compilation of re-\nsearch and ideas, drawing from future directions suggested in other scholarly\narticles and presentations. The effectiveness of the proposed methodologies and\ntechnologies will be evaluated based on the performance and behaviors exhibited\nby the agent\u2019s ability to produce a desired pentesting-like behavior.\n1\n1.2\nImpact\nThe potential impact of this research on the industry could be significant.\nWhile there is ongoing speculation about the feasibility of such studies, there has\nyet to be a demonstration through a proof of concept or a minimum viable prod-\nuct executed in this manner. Successful implementation could set a precedent\nand inspire further innovation within the field.\n2\nCHAPTER 2\nBACKGROUND AND LITERATURE REVIEW\n2.1\nEvolution of Offensive Security\nThe world of offensive security has evolved quite a bit. It used to be mainly\nabout simple vulnerability scanning, but now it involves advanced techniques\nthat simulate actual cyberattacks. This shift brings to light the increasing com-\nplexity of cyber threats and how attackers are becoming more sophisticated by\nusing more advanced techniques and tactics. In the past, security efforts were\nmostly about responding to incidents after they had happened. But now, with\napproaches like red teaming and ethical hacking, there\u2019s a focus on getting ahead\nof these issues by thinking like an attacker. This stance helps strengthen our de-\nfenses against cyber threats.\nThe early history of penetration testing dates back to the 1960s, when con-\ncerns about the security of computer communications were first raised. Govern-\nment and businesses began forming teams to test and find vulnerabilities within\ntheir networks, to serve as a defense against any actual attacks. Notable contribu-\ntions to this field were made by pioneers like James P. Anderson, who developed\nmethodologies still in use today, like the Anderson Report Institute [2019].\nFurthermore, the integration of continuous penetration testing with systems\nlike a SIEM, security incident event management, are revolutionizing how vul-\nnerabilities are identified and addressed, offering a more streamlined approach\nto cybersecurity. This integration helps in automating the response and remedi-\nation processes, thus enhancing the efficiency of security teams and reducing the\ntime needed to address vulnerabilities Security [2022].\n2.2\nEvolution of Large Language Models\nThe evolution of Large Language Models over the past decade illustrates a\nleap in artificial intelligence, transforming from basic natural language process-\ning tools to highly sophisticated systems capable of generating human-like text\nand responses to human input. Initially, LLMs were limited in scope and capa-\nbility in the early stages around 2018, focusing on specific tasks such as language\n3\ntranslation and getting a response from a basic query. The significant publica-\ntion of models like BERT (Bidirectional Encoder Representations from Transform-\ners) in 2018 marked an advancement, introducing techniques that allowed for a\ndeeper understanding of context within text generation Devlin et al. [2018]. Sub-\nsequently, the release of GPT (Generative Pre-trained Transformer) by OpenAI\nfurther expanded the possibilities, employing unsupervised learning to generate\ncoherent and contextually relevant text across a wide range of topics and formats\nRadford et al. [2019]. This progression from specialized applications to gener-\nalized capabilities reflects a broader trend in AI towards models that not only\nunderstand and generate text but also can be successful at conducting human\nlike actions and exhibit nuanced understanding of complex subjects. This idea\nof understanding has begun a wave of advancement into the capabilities that are\npossible due to the sheer knowledge and data. The continuous growth in model\nsize and sophistication, exemplified by the launch of GPT-3 OpenAI [2023] and\nits successors, really highlights an ongoing shift toward systems that can seam-\nlessly integrate with human tasks and communication, prompting both ethical\nconsiderations and unique applications in technology and communication.\n2.3\nAI in Cybersecurity: A Historical Perspective\nHistorically, AI\u2019s involvement in cybersecurity has evolved from simple rule-\nbased detection systems to more advanced machine learning algorithms that rec-\nognize complex patterns associated with cyber threats. \u201dThe evolving GenAI\ntools have been a double-edge sword in cybersecurity, benefiting both the de-\nfenders and the attackers.\u201d Gupta et al. [2023] AI\u2019s role has since broadened to\nencompass predictive analytics, automated response systems, and sophisticated\nthreat intelligence that has mainly supported Blue Teams and Defense Teams.\nIn the realm of offensive security, the use of AI has provided potential for\nchanging traditional practices, in the simulation of realistic cyberattacks, automat-\ning the discovery of vulnerabilities and proof of exploitation, and examples of\ngenerating realistic phishing attacks. This integration of AI with offensive secu-\nrity tactics represents a strategy in cybersecurity, utilizing AI\u2019s analytical capabil-\nities to stay ahead of cybercriminals. Zennaro and Erd\u02dd\nodi [2023]\n2.4\nReview of Current AI in Offensive Security\nRecent research in the field of cybersecurity has highlighted the significant\nrole that artificial intelligence plays in enhancing offensive security measures.\nAdvanced AI models, particularly those based on deep learning, are now re-\nlied on, in automating the detection of vulnerabilities, which was once manual\nand very labor-intensive. For example, the AutoPentest-DRL framework employs\n4\ndeep reinforcement learning to automate and optimize penetration testing, al-\nlowing dynamic and efficient vulnerability exploitation within network systems\nOrganization et al. [2020]. Moreover, AI\u2019s job of simulating complex cyberat-\ntack strategies through reinforcement learning models has expanded the scope of\noffensive security. Such models not only mimic attacker behaviors, but also inno-\nvate attack strategies, providing cybersecurity professionals with a tool set to an-\nticipate potential breaches Yang and Liu [2022]. The integration of AI in penetra-\ntion testing is also highlighted by its effectiveness in crafting sophisticated phish-\ning emails that can evade standard detection systems, showcasing the ability of\nAI to adopt an attacker\u2019s mindset, which is truly alarmingERMProtect [2020].\nThe adoption of large language models through natural language processing rep-\nresents a particularly compelling advancement in artificial intelligence and ma-\nchine learning due to the sheer level of intelligence, capable of understanding,\nreasoning, and offering suggestions and summarizations. This is made possible\nby their training on extensive internet datasets, making them highly valuable for\ncomplex tasks such as offensive security. In this paper, we will explore examples\nof these tools, as our discussion is primarily centered on the application of LLMs.\n2.4.1\nPentestGPT\nPentestGPT Deng et al. [2023] is a sophisticated penetration testing tool that\nleverages the power of OpenAI\u2019s GPT-4 to automate and streamline the penetra-\ntion testing process. Designed to function interactively, PentestGPT assists testers\nby guiding them through both the general progression of their penetration test\nand the execution of specific tasks. This tool is particularly adept at handling\nmedium complexity Hack the Box machines and various Capture The Flag (CTF)\nchallenges, enhancing the efficiency and precision of penetration tests.\nThe architecture of PentestGPT includes several modules that handle dif-\nferent aspects of the penetration testing workflow. It features a test generation\nmodule that generates the necessary commands for the testers to execute, a test\nreasoning module that aids in decision-making during the test, and a parsing\nmodule that interprets the outputs from the penetration tools and web interfaces.\nThese components work together to provide a comprehensive and automated\npenetration testing solution.\nPentestGPT has been shown to significantly outperform earlier models like\nGPT-3.5 in penetration testing tasks, achieving higher rates of task completion\nand demonstrating substantial improvements in operational efficiency. The de-\nvelopment of PentestGPT reflects a notable advance in the use of LLMs for prac-\ntical cybersecurity applications, offering a powerful tool that mimics the collabo-\nrative dynamics between experienced and novice testers in real-world settings.\n5\n2.4.2\nHackingbuddyGPT\nHackingbuddyGPT Happe and Cito [2023] is a cutting-edge tool designed\nto explore the potential of large language models in penetration testing, partic-\nularly focusing on Linux privilege escalation scenarios. Developed by the IPA\nLab, hackingbuddyGPT integrates with OpenAI\u2019s GPT models to automate com-\nmand generation for security testing. The tool operates by connecting via SSH to\nLinux targets (or SMB/PS Exec for Windows targets) and utilizes OpenAI\u2019s REST\nAPI-compatible models like GPT-3.5 Turbo and GPT-4 to suggest commands that\ncould potentially expose vulnerabilities or escalate privileges. Happe et al. [2023]\nThe system logs all run data, either into a file or in-memory, and features\nautomatic root detection and a beautifully designed console output for better user\ninteraction. One of the key functionalities of hackingbuddyGPT is its ability to\nlimit rounds of interaction, which dictates how often the LLM will be queried for\nnew commands, allowing for controlled testing scenarios. Happe and Cito [2023]\n2.5\nLLM Limitations\nLarge Language Models, such as GPT from OpenAI OpenAI [2023], possess\nsome serious capabilities in human natural language understanding and genera-\ntion, but, they also encounter several limitations that can affect their functionality\nand integration into practical applications. Often, these limitations are miscon-\nstrued as signs of greater intelligence. In the following sections, we outline these\nlimitations and explore their relevance to the field of penetration testing to ensure\nthat we try and overcome them to produce an efficient workable proof of concept\nthat isn\u2019t crippled by these limitations.\n2.5.1\nPrompt Engineering\nPrompt engineering is a fairly new but critical aspect of using large-language\nmodels, that plays a significant role in specializing crafted inputs to steer the\nmodel toward improved quality generated outputs. This process is especially\nsensitive, as minor modifications in the prompt\u2019s structure or phrasing of the\nprompt can lead to vastly different outcomes Radford et al. [2019].\nEffective\nprompt engineering requires a deep understanding of the model\u2019s training data\nand embedded biases, which can be both labor-intensive and technically complex\nBender et al. [2021]. This challenge typically involves considerable iterative ad-\njustment and experimentation to refine interactions with the model and achieve\noptimal results Liu et al. [2021].\nIn the context of offensive cybersecurity, prompt engineering can signifi-\ncantly enhance the capabilities of an offensive agent. By precisely tailoring prompts,\ndevelopers can direct the LLM to generate outputs that are more aligned with\n6\nspecific cybersecurity tasks, such as identifying vulnerabilities or providing com-\nmands to run on the terminal. This tailored approach allows for a more targeted\nand effective use of LLM in complex security environments, where generic re-\nsponses may not suffice due to the sheer state size of one given problem in offen-\nsive security. Moreover, skilled prompt engineering can help mitigate the impact\nof biases in the model\u2019s responses, reducing the risk of generating inaccurate or\nharmful actions in sensitive security contexts as well as reduce any hallucinations\nthe model might add that are not in factual data.\n2.5.2\nContext & Long Term Memory\nContext and memory present significant challenges in the effective deploy-\nment of large language models. Although LLMs handle brief segments of infor-\nmation effectively, their ability to retain or incorporate long-term context through-\nout a conversation or document is limited Kagaya et al. [2024]. This limitation can\nlead to a deterioration of coherence in prolonged interactions, with the model\npossibly \u201dforgetting\u201d earlier segments of a conversation or struggling to sustain\ncontext across interactions Wang et al. [2024]. Commonly, remedies include inte-\ngrating external systems to maintain the state or context, which can complicate\nthe architecture of such systems and may adversely affect the accuracy and rele-\nvance of responses Kagaya et al. [2024].\nFor instance, an offensive agent equipped with a supplementary memory\nsystem could better conduct and execute on prolonged penetration testing tasks,\nthat require maintaining awareness of previous actions and their outcomes to\nbecome more effective. This integration introduces a more coherent and strategic\napproach to simulating or conducting cyberattacks to mimic a human actor who\nwould adapt to dynamic targets or environments. While this complicates the\narchitecture of LLM-based systems, the trade-off can lead to more robust and\ncapable offensive tools in cybersecurity, where adaptability and persistence are\ncrucial as the complexity grows.\n2.5.3\nLLM Learning & Reasoning\nLarge language models, while proficient in language understanding due to\ntheir extensive pre-training on diverse datasets, do not adapt or learn dynami-\ncally post-deployment. Unlike some machine learning models that can continu-\nously learn from new data, LLMs remain static unless they are retrained or fine-\ntuned with updated datasets. This characteristic restricts their utility in rapidly\nevolving fields without regular updates to their training material, which can be a\nresource-intensive process Horowitz [2023].\nThe challenge with LLMs is that they are not inherently equipped to inte-\ngrate new information during operational use. Techniques such as prompt en-\ngineering are employed to mitigate this by carefully crafting inputs to guide the\n7\nmodel\u2019s responses, yet this does not equate to learning from those interactions.\nTo maintain relevance, particularly in dynamic fields, LLMs require periodic re-\ntraining or fine-tuning with new data, a process that demands both computa-\ntional resources and expert oversight AI [2023].\nHowever, this limitation can be mitigated by implementing periodic updates\nand fine-tuning sessions using the latest threat data, like CVEs, ensuring that the\noffensive agent remains updated with new tactics and vulnerabilities. Addition-\nally, employing techniques like prompt engineering can help tailor the LLM\u2019s\noutput to simulate evolving attack scenarios more accurately, even within the\nconstraints of its static knowledge base. This approach allows the offensive agent\nto remain a powerful tool in penetration testing, capable of adapting to new se-\ncurity landscapes through controlled updates rather than real-time learning, thus\nmaintaining operational relevance and effectiveness.\n2.5.4\nCommand Parsing\nCommand parsing with LLMs involves translating natural language com-\nmands into executable actions, which can be challenging due to the ambiguity\nand variability of human language. LLMs may misinterpret commands, espe-\ncially those that are complex or have vague documentation, leading to incorrect\nor unsafe actions being conducted. Moreover, the ability of LLMs to understand\ncontext-dependent commands or those that require integration of multiple data\nsources is constrained by their training and the specific architectures used. This\nnecessitates additional layers of validation and error handling in systems that\nrely on LLMs for command execution to ensure accuracy and safety in opera-\ntions.\nA method for transferring data not only between agents but also between\ncode and large language models involves using JSON or a similar JSON-based\nstandard. This approach facilitates the exchange of various types of information,\nincluding descriptions, outputs, and responses, ensuring a standardized commu-\nnication format across different platforms and systems.\n2.5.5\nTraining Data\nThe limitations associated with training data significantly influence the de-\nvelopment and effectiveness of large language models. The quality, diversity, and\nvolume of the data used during training not only affect the model\u2019s performance\nbut also its ability to function appropriately across various contexts. LLMs have\nthe propensity to adopt and amplify biases from their training datasets, which\ncan result in biased or detrimental output. Additionally, the reliance on vast\ndatasets demands considerable computational resources, which can pose both\nenvironmental and economic challenges. Therefore, it is essential to ensure that\n8\nthe training data is both representative and ethically sourced to alleviate these\nissues.\nWhen tailoring these models for specific domains, such as cybersecurity, in-\ntroducing domain-specific knowledge is a complex endeavor. Experience with\nother tools has shown that, while more fine-tuned models can exhibit high de-\ngrees of specialization, they may also lack versatility if significant compromises\nare made during the fine-tuning process. Furthermore, as models increase in pro-\nficiency, their size tends to expand, often reaching hundreds of gigabytes. This\nincrease in size can complicate deployment and operational efficiency. These con-\nsiderations are particularly critical when developing an offensive agent, where\nthe balance between model specificity, size, and adaptability must be carefully\nmanaged to ensure the production of a robust, production-grade agent.\n2.5.6\nRisk/Fear\nAnother limitation of Large Language Models is their lack of inherent emo-\ntional capabilities, such as fear, which in humans plays a crucial role in risk as-\nsessment and decision-making. Humans often use fear as a heuristic for danger;\nit helps them avoid risks that could lead to harm. LLMs, in contrast, process deci-\nsions based on patterns and data without any emotional weighting. This can lead\nto challenges in situations where risk assessment is crucial, as models might not\nprioritize or evaluate threats effectively as a human would. This topic of study is\nfairly new as well and has not attracted much research in the context of advanc-\ning LLMs let alone using LLMs to expedite the field of risk analysis. Esposito and\nPalagiano [2024]\nHowever, this limitation can also be viewed as an advantage, especially in\nthe context of deploying LLMs as offensive agents in cybersecurity. The absence\nof fear allows LLMs to methodically execute tasks that would be considered high-\nrisk or stressful for human operators. For instance, an LLM can engage in sim-\nulated cyber-attacks or test network vulnerabilities without hesitation or moral\nreservations, providing a thorough and relentless testing capability that might be\ncompromised by human emotions.\n2.5.7\nCreativity\nLack of creativity is a major limitation of Large Language Models like GPT.\nWhile LLMs excel at generating content by recombining existing patterns and\ninformation from their vast training data, they do not truly \u201dcreate\u201d in the hu-\nman sense of generating novel ideas from scratch. This limitation stems from the\nmodels\u2019 reliance on patterns and correlations within their training data, which\nconfines their outputs to combinations of what has already been seen. Creativity,\nin contrast, often involves breaking away from established patterns to produce\n9\nsomething genuinely new and original. There has been a framework developed\nrecently that is used to benchmark this creativity to showcase limitations and\nprovide potential for overcomings called: CreativeEval. DeLorenzo et al. [2024]\nCreativity is a critical asset in cybersecurity, particularly for human penetra-\ntion testers. These professionals thrive on their ability to think outside the box\nand devise innovative approaches to security testing, often breaking away from\nestablished patterns to uncover vulnerabilities that automated systems might\noverlook.\n2.5.8\nDiligence\nDiligence in humans refers to their ability to consistently perform tasks ac-\ncurately over time and to their fullest extent of knowledge and skills. Although\nLLMs can process and analyze large datasets with remarkable speed and ac-\ncuracy, they lack the continuous attention to detail necessary for diligence. Jin\net al. [2024] They do not have the capability to self-assess their performance crit-\nically or improve independently without further training or updates, which can\nlimit their application in environments requiring ongoing, meticulous attention\nto complex or changing data.\nIn the field of offensive security, the challenge of penetration testing is in-\nherently complex, often demanding significant human investment in terms of\ntime and expertise. While we can expect an LLM to deploy its full capabilities, it\nfalls short in actively pursuing all possible avenues and may need to revisit in-\nformation and tasks to improve outcomes, similar to what is required of human\noperators. LLMs have to be instructed and don\u2019t have natural knowledge of how\nthe world works and especially how computers work.\n2.5.9\nSituational Awareness\nLLMs typically lack situational awareness, which is critical in dynamic and\ncontext-dependent settings. They do not possess an understanding of the world\nin the same way humans do, nor can they interpret context beyond the scope of\ntheir training data. This limitation is particularly evident in scenarios requiring\nreal-time decision-making or adaptation to new and unforeseen circumstances,\nwhich can impede their effectiveness in roles that require a high level of contex-\ntual adaptability. There have been systems that try to overcome this, like dynamic\nretrieval augmented generation where \u201dOur framework is specifically designed\nto make decisions on when and what to retrieve based on the LLM\u2019s real-time\ninformation needs during the text generation process.\u201d Su et al. [2024]\nThis limitation is a very steep hurdle for using LLMs to conduct offensive\nsecurity due to the real time nature of the problem set that makes up penetration\ntesting. Analyzing what is happening in real time is even a matter of exploitation\n10\nor not with some time based attacks. Developing a way to properly integrate\nreal time data into an LLMs prompts would be invaluable to not only offensive\nsecurity but solving complex tasks all together.\n2.6\nAgents\nGPT agents OpenAI [2023], or Generative Pre-trained Transformer agents,\nare also a very significant advancement in artificial intelligence and especially in\nLLMs. GPT models can be subsequently fine-tuned to perform specific tasks and\nare labeled as \u201dagents\u201d. These agents are built on the existing models that are\ninitially pre-trained on a broad spectrum of internet-based text. This approach\ngives them the skills to grasp subtle context, generate text that\u2019s relevant and\ncoherent, and handle language-based and domain specific tasks with impressive\nexpertise.\nThe adaptability of GPT agents makes them applicable across a variety of\nfields, including customer service, content creation, summarization, program-\nming, task automation, insight generation, and enhancing user interaction. Their\ncapacity to continually learn from user engagements and adapt to novel infor-\nmation renders them invaluable for businesses aiming to harness AI to boost ef-\nficiency and engagementfr0gger [2023].\nFurther developments in GPT technology have introduced new methodolo-\ngies where individual agents, each trained with a specific prompt, sequentially\nprocess and hand off their outcomes to subsequent agents. This model facilitates\na more customized approach to problem-solving or response generation. During\nthe period of this research, innovations like \u201dCrew AI\u201d Crew AI [2023] and \u201dAu-\ntoGenStudio\u201d Autogen Studio [2023] emerged as leading platforms for creating\nsuch agent-based systems. This concept is particularly promising for develop-\ning autonomous systems like penetration testers, where the complexity of tasks\nnecessitates decomposition into manageable, discrete segments that can be effec-\ntively handled by LLMs.\n11\nCHAPTER 3\nCORE TECHNOLOGIES AND METHODOLOGIES\nThe core technologies and methodologies employed in this project form the\nbackbone of the research, emphasizing the integration of sophisticated AI tools\nwith advanced cybersecurity practices. At the heart of the technology stack is gpt-\n4-turbo-preview from OpenAI OpenAI [2024], a state-of-the-art Large Language\nModel utilized for its expansive context understanding and dynamic response\ngeneration capabilities. This LLM serves as a central processing unit, driving the\nautonomous agents in decision-making and analytical tasks. Complementing the\nLLM, the Python wrapper plays a crucial role as the operational framework, man-\naging interactions and ensuring seamless communication among various compo-\nnents of the system. Methodologically, the project adopts a hybrid approach that\nmerges structured task trees with dynamic reprioritization capabilities, mirror-\ning real-world penetration testing frameworks while incorporating the flexibility\nof AI-driven decision processes. This blend of cutting-edge AI technology and\nmethodical security testing techniques ensures a comprehensive and adaptive\nsystem capable of addressing complex cybersecurity challenges in real-time.\n3.1\nPentesting Methodology\n3.1.1\nATT&CK Life Cycle\nThe MITRE ATT&CK framework delineates a comprehensive catalog of tac-\ntics and techniques employed by cyber adversaries throughout the stages of a\ncyberattack MITRE [2024]. The initial phase, Reconnaissance, involves the sys-\ntematic collection of data on potential targets. During this stage, attackers gather\ninformation to ascertain vulnerabilities and formulate an effective attack strat-\negy. Methods employed include social engineering, network scanning, and the\nacquisition of publicly available data, which provide a broad understanding of\nthe target\u2019s defenses, technological infrastructure, and operational routines.\nFollowing the reconnaissance stage is Vulnerability Analysis. In this phase,\nattackers analyze the accumulated information to pinpoint weaknesses within\nthe target\u2019s systems. The analysis typically involves the identification of secu-\nrity gaps such as outdated software components, system misconfigurations, and\n12\nFigure 3.1:\nhttps://www.mandiant.com/resources/insights/targeted-attack-\nlifecycle\ninadequate security policies. Advanced automated scanning tools may be de-\nployed to detect these vulnerabilities, providing attackers with a clearer path for\nsubsequent exploitation.\nThe final stage in the initial attack cycle is Exploitation. With vulnerabilities\nidentified and strategies formulated, attackers exploit these weaknesses using\nvarious offensive measures. This stage involves the deployment of malware, use\nof exploit kits, and other intrusion techniques aimed at breaching security mea-\nsures. The primary objective is to establish a secure foothold within the network,\nenabling further malicious activities such as data exfiltration, system compro-\nmise, or the dissemination of additional malicious payloads.\nA deep understanding of these stages is imperative for cybersecurity profes-\nsionals. It aids in the formulation of robust defensive mechanisms designed to\npreemptively detect, thwart, and mitigate the actions of cyber adversaries before\nsubstantial damage is inflicted. The complete life cycle and be seen in Figure 3.1\n3.1.2\nHack The Box\nHack The Box is an innovative online platform that provides a hands-on\ncybersecurity training environment for individuals and companies alike Hack\nThe Box [2024]. It offers a variety of real-world scenarios through virtual labs,\nwhere users can practice hacking and test their penetration testing skills in a safe\nand legal setting. The platform features a range of challenges and machines that\n13\nFigure 3.2: Main Logic Flow\nmimic different environments and security vulnerabilities, allowing users to en-\ngage in tasks ranging from simple puzzles to complex system exploits. Hack The\nBox also facilitates community interaction and learning, with forums and leader-\nboards that encourage competition and collaboration among users. This practical\napproach to learning cybersecurity is designed to sharpen problem-solving skills\nand provide real-time feedback, making it an invaluable resource for both aspir-\ning and experienced cybersecurity professionals looking to enhance their offen-\nsive security capabilities.\nHack The Box is a common test bed for implementing and refining penetra-\ntion testing methodologies. ReaperAI orchestrates tasks that mimic real penetra-\ntion test scenarios, including reconnaissance, vulnerability assessment, exploita-\ntion, and post-exploitation, all crucial elements in HTB machines. HTB provides\na structured yet adaptable platform that allows the research to be applied and\ntested, proving more advantageous than self-hosted VM setups due to ease of\nuse and setup efficiency.\n3.2\nMethodology\n3.2.1\nIntegration with LLM\nFor this research, the decision was made to employ gpt-turbo-4-preview with\na substantial context size of 128k tokens, reflecting the most sophisticated tech-\nnology available at the time of testing. The primary aim of this choice was not\nto compare various Large Language Models, but rather to explore and demon-\nstrate the advanced capabilities highlighted in existing foundational research. As\nof April 22, 2024, the rate per one million tokens worth of input is $10 and $30 per\none million output. This study in total cost about $40 dollars in research, devel-\nopment, and testing. This approach ensures that the study focuses on leveraging,\nat the time, cutting-edge AI capabilities to assess their practical applications and\neffectiveness in complex computational tasks.\n14\n3.2.2\nAutonomous Agents\nThis project aimed to develop a fully autonomous agent that could operate\nindependently without human intervention. This objective brings forth its own\nset of challenges and complexities, particularly in ensuring robust and reliable\noperations while balancing cutting edge technology. The Python wrapper used\nin this configuration serves as the central nervous system, orchestrating inter-\nactions and maintaining seamless communication between agent loops, LLMs,\nterminals, and python code. These LLM agents are tasked with autonomous rea-\nsoning and decision-making that simulate a high level of cognitive processing\nakin to human-like thinking and problem-solving skills to ensure that the agent\ncan act as if is a human operator.\n3.2.3\nObjectives and Tasks\nUnlike the approach taken in hackingbuddyGPT, which follows the BabyAGI\nNakajima [2024] model of executing an action within a task, enriching it with con-\ntext, and then reassessing priorities, this project introduces a structured task tree\nmethodology. While penetration testing typically follows a systematic approach\nsimilar to a task tree, it is crucial to incorporate the dynamic element of BabyAGI,\nwhere new and critical information can prompt immediate reprioritization and\nstrategic shifts. This dual approach ensures that the agents not only adhere to a\nstructured methodology but also remains flexible and responsive to new insights\nand challenges.\n3.2.4\nDecision-Making in Tasks\nThe autonomous decision-making process in these agents was crafted around\nthe completion of specific tasks. It was crucial to design a system that was not\nlimited to pre-defined, hard-coded strategies, but instead could adapt based on\nsituational demands. To achieve this flexibility, the developed evaluation method\nincorporates concepts of diminishing returns and strict time constraints\u2014both re-\nflective of the nature required in penetration testing. This system evaluates task\ncompletion through dynamically generated prompts, which assess whether the\ntasks have been accomplished based on historical data and prior analyses.\n3.2.5\nAnalyzation\nBuilding upon the initial concepts of analyzation introduced by hackingbud-\ndyGPT, the methodology was enhanced to provide a more sophisticated analysis\nof actions and outcomes. This upgraded approach not only assesses what has\n15\ntranspired, but also generates recommendations for subsequent steps. Such on-\ngoing analyzation is crucial for the continuous improvement and adaptation of\nthe agents, ensuring they remain effective and relevant as they interact with com-\nplex environments.\n3.2.6\nEvaluation\nThis phase of the project introduces a new task evaluation concept that was\nnot covered by hackingbuddyGPT, inspired by traditional human-led decision-\nmaking processes. In this program, an agent performs an action, then evaluates\nthe results to determine if they suffice for the task at hand\u2014or if only progress to-\nwards the task has been made. This evaluative process is critical and mirrors the\nfeedback mechanism in reinforcement learning models, where the agent learns\nand adapts based on success feedback.\n16\nCHAPTER 4\nBUILDING THE AI OFFENSIVE AGENT\nThe design of the AI offensive agent is rooted in the principle of leveraging\nthe LLM technology described previously as well as the methodology described\npreviously to simulate and understand offensive cybersecurity tasks. The heart\nof this system is the LLM, accessible through Python classes and APIs, while a\nPython wrapper serves as the core logic driver to process functions and essen-\ntially be the body of the LLM. This architecture allows for innovated integration\nof advanced AI capabilities with current cybersecurity tools and frameworks,\nproviding a unique concept for simulating cyber-attacks, analyzing potential vul-\nnerabilities, and automating the decision-making process. The Python wrapper\nfacilitates easy access to the LLM\u2019s functionalities, enabling the dynamic con-\nstruction of queries and the interpretation of responses for further processing.\nThe core for this development was based on the foundation of hackingbuddyGPT\nwhich was enhanced to become ReaperAI, a proof of concept fully autonomous\noffensive agent. Happe and Cito [2023]\n4.1\nAgents\nThe design approach for this agent involves using a subset of specialized\nsub-agents, each tasked with executing more narrowly defined functions to en-\nhance result quality while ensuring communication upstream to the parent agent.\nMerely giving the LLM the task to \u201dcomplete a pentest\u201d is too vast and too vague.\nThe only predefined hard coded workflow was the pentesting methodology to\nprevent the AI from deviating and ensure it remains focused on its intended pur-\npose, rather than determining its own fundamental objectives of a penetration\ntest. Previous experimentation showed that the LLMs knowledge set did contain\n\u201dsteps to complete a black box penetration test\u201d but did not produce consistent and\naccurate fundamental objectives to be allowed to generate them autonomously.\nThe high-level agent tree can be seen in 4.1\n17\nFigure 4.1: Agent Hierarchy\n18\n4.2\nPrompting, Decision Making, and Natural Language Understanding\n4.2.1\nTemplating\nIn Happe\u2019s project, implementation of the Mako templating library, was a\ngood foundation but was ultimately needed to be expanded to achieve the level\nof quality required for this study Bayer [2006]. Each prompt functions as a sub-\nagent within a \u201dprompt chaining\u201d approach DAIR.AI [2024]. The prompts them-\nselves are stored in .txt files, which contain templating text. This setup allows the\ntext files to act as variables where various inputs can be introduced. For instance,\nstate history, commands, and other contextual data can be inserted to enhance\nthe quality of the interactions. This approach integrates several prompting tech-\nniques, including few-shot learning and chains of prompting, among others, to\nensure effective and efficient performance.\n4.2.2\nEnhanced Decision-Making Through Natural Language Prompting\nAt the heart of the agent\u2019s functionality is its sophisticated use of natural\nlanguage prompting to guide decision-making and reasoning processes. This\nmethod involves framing cybersecurity tasks within natural language prompts\nthat the Large Language Model processes. By utilizing the LLM\u2019s advanced lan-\nguage comprehension abilities, the system can generate insights, strategies, and\nresponses that closely resemble the thought processes of experienced human se-\ncurity experts. This strategic use of language-based prompts enhances the agent\u2019s\nability to reason and decide on the most effective course of action in complex\nsecurity situations. Through this, ReaperAI has a combined way of prompting\ntechniques that at the time of research are fairly new. This integrates concepts\nlike Role Prompting, Chain-of-Prompting, Chain-of-Thought, Real-Time prompt\noptimization. These are all fairly new techniques that were described earlier and\nall combined to create the prompts in ReaperAI as seen in Table 4.1\n4.2.3\nAdaptive Decision-Making\nAdaptive decision-making is a core feature of ReaperAI, allowing it to dy-\nnamically adjust its strategies based on the analysis of command outputs and the\ncurrent state of the system. This flexibility is crucial for navigating the complex\nlandscape of penetration testing, where conditions can change unpredictably.\nBy evaluating the effectiveness of each command and its impact on the system,\nReaperAI can decide whether to alter command sequences, repeat commands,\nor adjust arguments according to the recommendations provided by the other\nLLM agents who analyze output. This adaptive approach ensures that the test-\ning strategy remains aligned with the evolving security environment, maximiz-\ning the effectiveness of the test and ensuring that all security vulnerabilities are\n19\nTechnique\nIntent\nRole Prompting\nBypass filters that would be used in the generic\nrole\nChain-of-\nPrompting\nChain prompts together to allow a bigger task to\nbe fullfilled\nChain-of-Thought\nChain the thoughts together on a pentest to\nmake a decision\nReal-Time\nprompt\noptimization\nProvide real-time information to the LLM\nTable 4.1: Table of Intent for Prompting Techniques\nthoroughly explored and addressed. The ability to integrate new insights helps\nmaintain the relevance and efficacy of the penetration testing process, ensuring\nthat each action taken is informed by the most current data and expert system\nanalysis via the prompt injection.\n4.2.4\nMinimizing Unwanted Behaviors Through Precise Prompt Engineer-\ning\nTo prevent unwanted behaviors such as irrelevant command outputs or overly\ndetailed explanations, the system employs the Mako templating engine described\nabove. This engine integrates data from the ReaperAI\u2019s Python logic into the\nprompts, which are then passed to a prompt creation function. This approach\nminimizes the need for extensive prompt engineering by streamlining the inter-\naction with the LLM, focusing mainly on crafting basic, targeted inquiries that\nenhance the quality of the generated responses. By manipulating prompts to ex-\nclude undesired outputs, as seen in Table 4.2, the system maintains preciseness\nin its operations, which result in a more effective and efficient problem-solving\ncapabilities within the scope.\nPrompt Cleaning\n\u201dexplain step by step\u201d\n\u201dProvide a recommendation.\u201d\n\u201dOutput the list in a json array.\u201d\n\u201dDo NOT give any explanations or descriptions.\u201d\n\u201dDo not include any explanations or any prefixes. Only provide the command to run..\u201d\n\u201dAs well as serve for in context memory.\u201d\nTable 4.2: Prompts that aided in Cleaning Response\n20\n4.3\nRAG for Enhanced Memory and Contextual Understanding\n4.3.1\nPostgreSQL + Python Classes\nTo tackle the challenges of memory retention and contextual awareness in\nAI-driven cybersecurity tasks, the system employs a Retrieval Augmented Gen-\neration (RAG) component.\nThis innovative approach leverages the extensive\nknowledge base of pre-trained models, enhancing it with the capability to re-\ntrieve relevant information and generate responses that are contextually aware.\nThe integration of RAG significantly boosts the agent\u2019s ability to remember prior\ninteractions, comprehend complex command sequences, and make decisions in-\nformed by historical data and recognized patterns. This enhancement is pivotal\nfor maintaining a continuous state across individual and subsequent sessions,\nensuring that the agent can seamlessly resume its tasks without losing context.\nReaperAI utilizes this RAG capability by interacting with a database to ac-\ncess necessary information according to the agent\u2019s operational functions. For in-\nstance, when generating the next command, the system retrieves the current state\nand analyses of the previous command from the database to improve the quality\nand relevance of the forthcoming command outputs. This cycle of retrieval and\ngeneration ensures that each decision is as informed as possible.\nHowever, the application of RAG in ReaperAI deviates from traditional uses,\nparticularly due to the unique domain of offensive security. The cybersecurity\ndomain lacks the vector text and object embeddings required for conventional\nvector databases, which poses a significant challenge. This specific issue and\npotential solutions will be further discussed in the \u201dFuture Directions\u201d section\nof this paper, highlighting the ongoing adaptation of RAG technology to meet\nspecialized cybersecurity needs.\nTo assist the agent in managing tasks and tracking hosts, Python classes were\nimplemented. These classes are standard Python constructs that were designed\nto process information generated by the Large Language Model and to feed this\ninformation back into the LLM as needed. This cyclical interaction helps to struc-\nture the tasks efficiently, allowing the agent to maintain a clear and organized\nworkflow. In this approach, Python classes are utilized as intermediaries to en-\ncapsulate task and host details, which simplifies the management of complex\ndata and interactions. This structured framework not only enhances code clarity\nand maintainability but also empowers the Large Language Model to effectively\nmanage and update task-specific and host-specific information. Consequently,\nthis ensures all operations are coherent and well-aligned.\n21\n4.4\nTask-Driven Methodology\n4.4.1\nTask Tree Management\nIn the realm of penetration testing, the ReaperAI introduces a methodical\nstructure through the implementation of a task tree, which separates the entire\nprocess into distinct stages: reconnaissance, vulnerability analysis, exploitation.\nThis organizational strategy is vital for systematically managing the complex pro-\ncedures involved in penetration testing. The LLM will be tasked to breaking\ndown the process into manageable sections and loading those results into the\ntask tree to ensure that each phase is executed and is in alignment with the over-\nall testing strategy. It facilitates easier monitoring and progression through tasks,\nallowing focus on one segment at a time while maintaining an overview of the\nentire testing landscape. This structured approach not only streamlines the test-\ning process but also enhances the effectiveness of the tests by ensuring thorough\ncoverage of all necessary aspects of the system\u2019s security. It is worth mention-\ning that in Figure 4.2 there are only 3 sub-tasks under \u201dActive Reconnaissance\u201d\nthis is specifically due to the fact that when generating more than 3 sub-tasks the\nLLM would start to assume information about the system that was not actually\ntrue. For example, one task would be to \u201dUse gobuster to enumerate web direc-\ntories\u201d but the LLM hasn\u2019t actually conducted any scans to know that is a valid\ntask. To patch the solution of task validation, reducing the number of tasks pro-\nvided better results in staying consistent without demonstrating tasks that had\ninformation that was assumed.\nFigure 4.2: Example Task Tree\n4.4.2\nDynamic Task Updates\nThe dynamic nature of security environments requires an equally agile re-\nsponse during penetration testing, which the ReaperAI addresses through real-\ntime updates to tasks based on outcomes and feedback from the Large Language\nModel. As the penetration testing progresses, each action\u2019s result is analyzed\nand the subsequent tasks are generated based on the previous collection of in-\nformation. This adaptive method allows the testing process to remain flexible\n22\nand responsive, accommodating changes and unexpected results as they occur.\nFor instance, if an expected vulnerability is not found, the task tree won\u2019t in-\nclude any of the vulnerabilities-centric paths in order to prevent tangential rabbit\nholes. Similarly, successful exploitation might lead to additional tasks focusing\non deeper system analysis or cleanup. This real-time feedback loop ensures that\nthe penetration testing is not only thorough but also maximally efficient, adapt-\ning on-the-fly to findings and shifting priorities without losing momentum. The\nactual workflow is represented in Figure4.3.\nFigure 4.3: Decision Making on Tasks\n4.5\nAI-Driven Command Generation and Processing\n4.5.1\nWorkflow\nIn Figure 4.4 which shows the workflow for the main command generation\nprocess of the agent. The process begins with initializing the program by con-\nnecting to and retrieving it from the LLM. Next, the size determinations are made\nby fetching the current state size using get state size and determining the tem-\nplate size with num tokens from string, based on a source template to ensure\ntoken requirements aren\u2019t being exceeded. Following size determinations, the\ncommand history is retrieved through the get cmd history v3 function, which\ncombines the state size, template size, and other relevant parameters from the\n23\ndatabase and memory of the wrapper. A text prompt for the LLM is then gener-\nated using create and ask prompt text, incorporating all necessary parameters\nsuch as history, state, target, constraints, current task, current role, task tree, and\ndetails of the analysis.\nOnce the LLM has processed the prompt, the output\nis cleaned using command output cleaner to ensure the response doesn\u2019t have\nresidual artifacts included by the LLM like $ or bash. Finally, the process con-\ncludes with returning the cleaned response, completing the interaction cycle with\nthe LLM.\nFigure 4.4: Get Next Command Workflow\n4.5.2\nIntegration with LLM\nThe program capitalizes on the advanced capabilities of LLMs by establish-\ning a connection to an LLM server, using an API key. There are financial costs\nto using OpenAI\u2019s API, which are priced by the million tokens due to its closed\nsource subscription model. These costs are not too expensive, but are important\nfactors to consider when discussing the capabilities of an offensive agent. This\nintegration is crucial, however, as it harnesses the AI\u2019s ability to generate and\nprocess commands based on vast datasets it was trained on. By utilizing AI to\ngenerate actionable commands and interpret outputs through the use of com-\nmon communication protocol, REST API, the program reduces the manual effort\nrequired in formulating commands and speeds up the testing process. This au-\ntomation not only increases the autonomous nature of the tests but also enhances\ntheir accuracy by leveraging the LLM\u2019s easily available communication interface.\nThe AI\u2019s input helps ensure that the commands are both contextually relevant\nand highly optimized for the tasks at hand, thereby streamlining the workflow\nduring penetration testing.\nIn ReaperAI, the idea from Happe\u2019s project was to create a class for the LLM\nto ensure that the state and other functions and constants would stay contained\n24\nFigure 4.5: LLM Object\nin it shown in Figure4.5 This implementation of standard class/object behavior,\ncommon in most programming languages, was chosen as the most suitable for\nthe desired functionality of the LLM.\n4.5.3\nStateful Interaction\nTo ensure the continuity and relevance of interactions within the dynamic\nenvironment of penetration testing, the script maintains a stateful interaction\nwith the LLM. This approach helps preserve the context of the penetration test\nacross different interactions with the system, a critical aspect for maintaining the\naccuracy and relevance of AI-generated suggestions. By keeping track of previ-\nous commands and responses, the stateful system can provide contextually ap-\npropriate suggestions that build on earlier actions, thereby avoiding redundant\nor irrelevant commands.\nAnalysis is crucial both for the large language model and the human over-\nseeing it. By providing a summary at each main step of the workflow, as seen in\nFigure4.6, the LLM is equipped to reflect on its recent actions and respond appro-\npriately. This level of analysis is also beneficial for the human observer, enabling\nthem to monitor the LLM\u2019s performance and ensure that it is operating correctly.\nThis dual focus on analysis helps maintain the integrity and effectiveness of the\nprocess.\nThis method, seen in Figure 4.7, is essential for conducting comprehensive\nand effective penetration tests, as it allows the AI to adapt its recommendations\nbased on real-time data and the evolving state of the system being tested. This\nongoing contextual awareness, seen in Figure 4.8, ensures that AI\u2019s contributions\nare not only technically appropriate but also strategically astute, thereby enhanc-\ning the overall effectiveness of the penetration testing process by also giving a\nperspective view on what was just conducted on the terminal.\n25\nFigure 4.6: A Sample of State at a Given Time\nFigure 4.7: State Workflow\nFigure 4.8: Sample Analyzation at a Given Time\n4.6\nCommand Execution\n4.6.1\nNon-Interactive Execution\nArguably, one of the most complex aspects of this project involved devising\na unique method for the large language model to interact with a program. This\npaper previously outlined the significant challenge of lacking a standardized ap-\nproach for establishing bidirectional communication between a Python program\nand the LLM. In the ReaperAI system, JSON and structured prompts serve as the\nmain channels for this interaction, ensuring that outputs from the LLM are con-\nsistent, and well-formatted to allow parsing from within Python. Although the\nLLM can process a broad spectrum of information, the primary difficulty resides\n26\nin parsing, extracting, and applying the right information from the LLM and us-\ning that in a way that is effective.\nThis execution strategy draws inspiration from the concepts presented by\nHappe and hackingbuddyGPT Happe and Cito [2023] in 2023, yet deviates from\ntheir model by not using SSH to execute commands remotely. Instead, commands\nare run locally on a Kali machine using Python\u2019s subprocess piping mechanism.\nDepending on the objectives and current tasks, ReaperAI formats this informa-\ntion into a prompt to solicit a command from the LLM. The command received\nfrom the LLM, structured as a JSON output, is then converted into an actual com-\nmand string that the subprocess can execute. This method ensures a seamless\ntranslation of LLM outputs into executable actions, optimizing the interaction\nbetween the LLM and the Python environment.\n4.6.2\nInteractive Execution\nInteractive execution is also a crucial feature of the script, facilitated by a tool\ncalled \u2019pexpect\u2019 Spurrier [2013]. This tool allows the agent to interact dynamically\nwith the command-line interface, handling commands generated by the LLM.\nThe reason for the attention to this is that traditional one time run programs sig-\nnal an end to the terminal with an EOF, so the operator knows when to read the\nstdout. When commands prompt for user input, the EOF has not been reached\nyet, so we have to resort to another library for this concept. \u201dPexpect is a pure\nPython module for spawning child applications; controlling them; and responding to ex-\npected patterns in their output. Pexpect works like Don Libes\u2019 Expect. Pexpect allows\nyour script to spawn a child application and control it as if a human were typing com-\nmands\u201d Spurrier [2013]. This simulates a human-like interaction with the system.\nThis process is managed by a separate command agent, which determines the\nappropriate times to send new inputs or read outputs from the command line,\nenhancing the program\u2019s ability to handle complex sequences of commands that\nrequire interactive responses. This functionality is still not fully supported in\nReaperAI, but can be seen in Figure 4.9. The proof of concept demoed in ReaperAI,\nis based around metasploit, but the workflow was designed to be universal to-\nwards other interactive programs like smbclient, netcat, etc.\nReading of Interactive Output\nTo mimic human interaction patterns, ReaperAI\nutilizes a non-blocking read operation in a separate thread, allowing it to con-\ntinuously monitor the output as it becomes available for interactive programs.\nThis method involves periodically reading every line of output within a speci-\nfied time frame, much like a human will wait for, and read command outputs\nintermittently. The collected data is then updated and fed back to the LLM for\nfurther analysis, ensuring that the AI has the most current information to base its\nnext set of commands on. This approach not only enhances the responsiveness\nof ReaperAI, but also ensures that the AI\u2019s suggestions are grounded in the most\nrecent system responses.\n27\nFigure 4.9: Interactive Command Workflow\n4.7\nProgress and State Management:\n4.7.1\nContinuous Evaluation\nReaperAI implements a robust system of continuous evaluation to monitor\nthe progress of tasks against predefined criteria such as time spent, information\ngained, and task completion status. Evaluation occurs through a prompting tech-\nnique by providing both older information and new information, as well as start\ntimes and time limits, ReaperAI prompts the LLM to make decisions based on\nthis compiled data. The system uses the concept of diminishing returns to ensure\nthat new information results from recent actions taken by the LLM and to break\nwhen that level of new information is not fruitful. This fruitfulness is decided by\nthe LLM by processing the prompt and generating some output. This ongoing\nassessment is crucial, as it allows for real-time decision-making about whether\nto proceed with new tasks or refine existing ones. By evaluating each step of the\nprocess, ReaperAI ensures that objectives are met efficiently and effectively. This\nmethodology not only maximizes productivity but also enhances the quality of\nthe penetration testing by ensuring that all actions are aligned with the set goals\nand contribute effectively toward the overarching security objectives.\n28\n4.7.2\nState Updates and Logging\nTo maintain a high level of operational integrity, every action taken by the\nReaperAI and its outcomes are logged, and the system state is updated accord-\ningly. This comprehensive logging mechanism serves multiple purposes: it en-\nsures traceability of actions, which is essential for debugging and auditing pur-\nposes; it enhances accountability by providing a detailed record of operations;\nand it supports informed decision-making by preserving a historical context of\nthe target system\u2019s state. These updates and logs are instrumental in creating a\ntransparent and effective workflow, where past actions inform future decisions,\nthereby optimizing the overall penetration testing process. This approach not\nonly improves security assessments but also builds a foundation for more ad-\nvanced analytics and learning from the accumulated data for the LLM.\n4.8\nError Handling and Adaptability\n4.8.1\nError Handling\nActual error handling is not fully implemented in the ReaperAI proof of con-\ncept. For now, the critical error handling in ReaperAI involves capturing errors\nthat are piped to stderr. These errors occur when commands are executed through\nthe subprocess module in Python and are essential for informing the LLM about\nwhat transpired during the execution of the commands. This process grants the\nLLM complete transparency regarding command execution, which is crucial for\nresponse adaptation. To transition ReaperAI from a proof of concept to a fully\nfunctional system, comprehensive error handling will be vital, ensuring robust-\nness and reliability in real-world applications.\n4.9\nSecurity and Scope Consideration\n4.9.1\nConstraint Awareness\nReaperAI is engineered with specific constraints to ensure that the penetra-\ntion testing process remains ethical and minimally disruptive, focusing solely\non designated machines. These constraints are pivotal in mitigating potential\nadverse side effects, such as service disruptions or compromised data integrity\non non-target systems. Traditionally, adherence to these constraints is the re-\nsponsibility of the penetration tester, but integrating these directly into the pro-\ngram has proven effective. By incorporating explicit constraint statements into\nthe prompts, ReaperAI\u2019s behavior is modified to consistently adhere to these lim-\nits. This approach was particularly verified during initial tests where the gener-\nated objectives, such as scanning non-target devices or conducting unauthorized\n29\nport scans, initially fell outside the intended scope. While these constraints in\nReaperAI are currently limited, they demonstrate a viable proof of concept for\nhow to develop and enforce limitations to keep AI operations within predeter-\nmined boundaries.\nMoreover, these constraints systematically guide the behavior of the testing\nagents, preventing them from making inappropriate assumptions or executing\nactions that could potentially damage the network or systems. This structured\napproach not only enhances the precision and effectiveness of the penetration\ntesting process but also supports the ethical standards of cybersecurity practices.\nBy adhering to these established parameters, ReaperAI fosters trust and account-\nability in automated security assessments, ensuring that all activities are ethically\nsound and justifiable within the research framework.\n30\nCHAPTER 5\nRESULTS & DISCUSSION\nThe innovative design of an AI offensive agent, particularly one that inte-\ngrates a Large Language Model with advanced retrieval and command execu-\ntion capabilities, can significantly enhance defensive cybersecurity strategies. By\nsimulating offensive tactics, this agent can uncover vulnerabilities, refine defen-\nsive mechanisms, and improve overall security posture. Below are details on the\napplication and use cases of this AI offensive agent in cybersecurity efforts.\n5.1\nAutomated Penetration Testing\nReaperAI represents a foundational effort in applying AI to cybersecurity,\nserving as an initial proof of concept based on preliminary research. While its\nmethodologies and intentions are still in the nascent stages, the project has been\nintentionally simplified to demonstrate minimal viable functionality.\nDespite\nits early developmental stage, ReaperAI has achieved notable successes. For in-\nstance, it autonomously and successfully exploited the \u201dEternal Blue\u201d vulnera-\nbility on the \u201dBlue\u201d machine on Hack The Box using a metasploit module. This\nwas accomplished using a straightforward one-liner bash command, following\nthe penetration testing methodology outlined previously. The runs are logged in\nthe GitHub project under src/bashlogs/ due to the verbosity of runs.\nThe program is able to successfully run full recon workflows using tools like\nping, nmap, dns, and nikto to produce very realistic and usable recon information.\nThe other success is the analyzation and summaries that are accurate and can\nbe used by penetration testers to focus on more important concepts that require\nmore skills.\nFurthermore, ReaperAI demonstrated its potential by correctly identifying\nthe exploit for the \u201dLame\u201d machine on Hack The Box. However, it failed to fully\ncapitalize on this exploit due to an incorrect Metasploit command as well as not\nhaving the capability to start multiple threads to 1) start a listener session and\n2) execute the exploit found on Exploit-db. This highlights both the capabilities\nand current limitations of ReaperAI and showcases the limitation on operating\nthe bash terminal like a human would. These instances illustrate the practical\napplication of the AI in real-world scenarios, providing valuable insights into the\n31\neffectiveness of its current algorithms and indicating areas for further refinement\nand development.\nIn this research, the development of a benchmarking framework was not\npursued; instead, the focus was placed on analyzing existing behaviors, which\nprovided more substantive support for the research objectives at hand.\nThis\nanalysis was crucial for understanding the capabilities and limitations of cur-\nrent methodologies, thereby setting a solid foundation for future enhancements.\nThe decision to forego the immediate development of a benchmark framework\nwas based on the need to prioritize in-depth behavioral analysis over establishing\nperformance metrics at this stage.\nHowever, recognizing the importance of benchmarking in assessing the per-\nformance and efficiency of offensive security agents, this element is earmarked\nfor future exploration. The inclusion of a benchmarking framework in subse-\nquent research will be critical as AI-driven offensive agents become more sophis-\nticated and widely implemented. This future direction will aim to develop a com-\nprehensive set of standards and metrics that can rigorously evaluate the perfor-\nmance of these agents, ensuring they meet the necessary criteria for effectiveness\nand efficiency in real-world scenarios. This strategic approach aligns with the\noverarching goal of advancing the field while ensuring that future developments\nare measurable and aligned with industry standards.\n5.2\nUnsuccessful Attempts\nReaperAI experienced multiple instances of interruptions due to various fac-\ntors. There are numerous points within the agent chain where misconceptions or\nredundant task progressions can occur. These areas require further refinement\nto enhance the program\u2019s effectiveness and consistency. Some instances where\ninterruptions occurred include:\n\u2022 sudo permissions\n\u2013 Asking for sudo permissions to conduct elevated scans, but sudo is\ninteractive prompting for a user password\n\u2022 nc commands\n\u2013 Netcat is a network tool to communicate to services through ports, but\nis vague and interactive\n\u2022 smbclient commands because pexepects were not properly done\n\u2013 SMBClient is a smb shares tool used to connect to smb servers, but\ninteractive command execution wasn\u2019t generating the proper expect\nregex to match the user input prompt\n\u2022 Out of scope on different machines\n32\n\u2013 The agent started to do host discovery with nmap and started to scan\nother machines on the same vlan\n\u2022 curl commands\n\u2013 Conducting curl commands that were out of scope and assumed the\nserver had a web server\n\u2022 Tried to install applications but got stuck on sudo privileges\n\u2013 The agent tried to sudo apt install nikto but didn\u2019t have sudo privileges\n\u2022 Running tcpdump which was out of for the context of the test\n\u2013 The agent ran a tcpdump command that was out of scope of the test\nand not within its capabilities.\n\u2022 Assuming information based on \u201dpentesting methodology\u201d\n\u2013 It would assume information when creating objectives and tasks\n\u2013 e.g., \u201dIdentify SQL injections\u201d when it\u2019s unknown if a web server is\npresent\nDuring the development of the model, significant challenges were encoun-\ntered, particularly in the initial stages of transitioning from concept to imple-\nmentation. Prior to conducting thorough research and following a preliminary\nliterature review, there was an attempt to simply expand the capabilities of an ex-\nisting program, dubbed hackingbuddyGPT, from focusing solely on privilege esca-\nlation to encompassing comprehensive penetration testing tasks. This expansion\nproved problematic, as the program frequently struggled with the assigned tasks,\nveering into irrelevant tangents and rabbit holes. This lack of focus and direction\nnot only hindered progress but also highlighted the need for a more structured\nand research-driven approach.\nConsequently, these initial setbacks served as a catalyst for more extensive\nresearch. The difficulties faced underscored the complexities of adapting AI mod-\nels to the nuanced and dynamic field of cybersecurity, particularly in the realm of\npenetration testing. This led to a deeper exploration of the underlying principles\nand methodologies that could better support such a transition. The subsequent\nresearch aimed to refine the model\u2019s approach, enhance its task-specific perfor-\nmance, and ensure that its outputs were relevant and practical for real-world\ncybersecurity challenges. This phase of development was crucial in establishing\nwhat is needed to move towards a more robust and effective AI-driven cyberse-\ncurity solution.\n33\nCHAPTER 6\nIMPLEMENTATION CHALLENGES, ETHICAL\nCONSIDERATIONS, FUTURE DIRECTION\nExploring the implementation challenges, ethical considerations, and future\ndirections of deploying AI offensive agents in cybersecurity offers a nuanced un-\nderstanding of the potential impacts and responsibilities associated with this in-\nnovative approach. These crucial aspects mentioned above are detailed below.\n6.1\nChallenges in Implementing AI Offensive Agents\nThe implementation of AI offensive agents in cybersecurity faces several\ntechnical and operational challenges. One primary concern is the accuracy and\nreliability of the agents\u2019 actions, especially in complex and dynamic digital envi-\nronments. Unfruitful runs, can lead to unnecessary disruptions and resource allo-\ncation issues. Additionally, the scalability of AI systems to handle large-scale net-\nworks and rapidly evolving threats without compromising performance remains\na technical hurdle as well as relying on a closed source LLMs like GPT. There\u2019s\nalso the challenge of integrating these advanced AI capabilities with existing cy-\nbersecurity infrastructure, requiring significant customization and adaptation to\nensure compatibility and effectiveness, as well as adaptiveness for unique tools\nand unique vulnerabilities. The challenges that an AI offensive agent will face to\nactually see a significant impact on the domain of penetration testing is great, but\nfor now they are just challenges.\n6.2\nEthical Considerations in Offensive Cybersecurity\nThe use of AI for offensive purposes in cybersecurity introduces a range of\nethical considerations that must be meticulously addressed. Key among these is\nthe potential for misuse, where powerful AI capabilities could be leveraged by\nmalicious actors if not properly secured. The development and deployment of\nAI offensive agents must be guided by strict ethical standards to prevent unin-\ntended consequences, such as privacy violations or collateral damage to unin-\ntended targets. Moreover, the transparency of AI decisions and actions is crucial\n34\nto maintain trust and accountability, especially when those decisions may have\nsignificant repercussions. In addition to keeping the data secured for each run,\nthe operator would have to have their own collection of capable models to ensure\nconfidentiality, integrity and availability of the data.\n6.3\nFuture Directions in AI-Driven Offensive Security\nLooking ahead, the domain of AI-driven offensive security is set to undergo\nsignificant advancements, driven by continual improvements in AI technologies\nand methodologies. This study represents an important step towards shaping the\nfuture of this field by highlighting specific areas that require substantial develop-\nment to yield impactful results:\n1. Enhanced Command-Line Interaction: One of the primary areas for devel-\nopment is improving the way programming languages, such as Python,\ninteract with command-line interfaces to execute interactive commands.\nWhile the use of tools like Pexpect is a promising development, further re-\nsearch is needed to enable large language models to effectively run oper-\nating systems and utilize various tools. Additionally, the creation of tool-\nspecific models could enhance the functionality and task fulfillment capa-\nbilities of these systems.\n2. Expansion of Greater Context Windows: To tackle the broad and complex\nproblems inherent in penetration testing, LLMs require larger context win-\ndows. This expansion would allow the models to retain and process more\nextensive data from previous interactions, enhancing their ability to under-\nstand and solve complex security challenges.\n3. Standardization of LLM Outputs: Establishing a standard for processing\nand utilizing outputs from LLMs is critical. This could involve developing\ndata extraction agents or integrating storage functionalities within LLMs\nthemselves, facilitating easier parsing and application of model outputs\nwithin software environments like Python.\n4. Cybersecurity-Specific Embeddings: Introducing domain-specific embed-\ndings for the cybersecurity field could significantly enhance the effective-\nness of retrieval-augmented generation (RAG) systems and vector database\nfunctionalities. This would allow LLMs to better understand and respond\nto cybersecurity-specific queries and challenges.\n5. Simulation of Human-Like Abilities: Further research could also focus on\nsimulating more human-like cognitive abilities within LLMs, such as risk\nanalysis and the understanding of fear, pushing the ethical boundaries of\nAI capabilities. This could enhance the decision-making processes of AI\nsystems in complex and uncertain environments.\n35\n6. Advancement of Task Management: Advancing the development of task\ngeneration and completion that mimics human decision-making is another\ncrucial area. This involves creating models that can not only generate and\nmanage tasks but also dynamically adjust their strategies based on chang-\ning conditions and priorities, much like a human operator.\n7. Development of Pentesting Benchmarks: Establishing benchmarks for pen-\netration testing will provide a standardized framework to evaluate the ef-\nficacy of penetration tests, setting the bar for what constitutes a successful\nand thorough penetration test.\n8. Integration of Reinforcement Learning: Introducing reinforcement learning\ntools to better plan an attack can be beneficial to future directions, such\nideas include attack graphs or attack maps.\nBy addressing these areas, future research can significantly advance the capabil-\nities of AI in offensive security, leading to more sophisticated, autonomous, and\neffective security solutions.\n36\nCHAPTER 7\nCONCLUSION\nThe integration of Artificial Intelligence into offensive cybersecurity repre-\nsents a transformative shift towards more dynamic, intelligent, and offensive\nand defense mechanisms. This paper discusses the development of an AI-driven\noffensive agent, encapsulated within a Python wrapper around a Large Lan-\nguage Model, and enhanced with features such as Retrieval Augmented Gen-\neration (RAG), contextual memory, and advanced prompting capabilities. The\nagent, equipped to simulate cyber-attacks and thereby identify vulnerabilities,\nalso serves to enhance defensive strategies by learning from each interaction.\nThis exploration delves into the foundational technologies and methodolo-\ngies that drive the agent\u2019s functionality.\nThese include enhanced prompting,\ndecision-making processes, natural language processing, retrieval augmented gen-\neration, task-driven methodologies, AI-driven command generation, command\nexecution, progress and state management, error handling, and security enhance-\nments through constraint awareness. Collectively, these elements enable the AI\nagent to identify patterns, make informed decisions, and execute complex cy-\nbersecurity tasks, culminating in the development of a fully autonomous proof\nof concept. ReaperAI, demonstrates the potential for very effective and danger-\nous programs to be developed with little effort and understanding of LLMs. The\nmethodologies and techniques provided in this paper also were fully discovered\nand researched in the lens of offensive security, which at the time of this paper is\nan untouched topic.\nNonetheless, realizing the full potential of AI in offensive cybersecurity presents\nsubstantial challenges and ethical considerations. Technical obstacles such as\nimproving command-line interactions, expanding context windows, standard-\nizing LLM outputs, developing cybersecurity-specific embedding, incorporating\nreinforcement learning, simulating human-like abilities, enhancing task manage-\nment, and establishing penetration testing benchmarks must be addressed. Eth-\nically, the development and deployment of such agents must be managed with\ngreat care to avoid misuse and ensure transparency and accountability.\nIn conclusion, leveraging AI within offensive cybersecurity showcases a sig-\nnificant advancement in technology and the domain of cybersecurity. By con-\ntinuing to innovate and address challenges with cutting edge technology, cyber\ndefense teams can stay on top of upcoming threats and foster a more secure and\nresilient digital environment.\n37\nREFERENCES\nArize AI. Best practices for large language model (llm) deployment, 2023. URL\narize.com/blog-course/large-language-model-llm-deployment/.\nAc-\ncessed: 2024-04-15.\nAutogen Studio. Homepage - autogen studio, 2023. URL autogen-studio.com/.\nAccessed: April 15, 2024.\nMike Bayer. Mako templates \u2013 a fast and lightweight templating for python, 2006.\nURL www.makotemplates.org/. Accessed: April 16, 2024.\nEmily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret\nShmitchell. On the dangers of stochastic parrots: Can language models be\ntoo big? In Proceedings of the 2021 Conference on Fairness, Accountability, and\nTransparency. ACM, 2021.\nCrew AI. Homepage - crew ai, 2023. URL www.crewai.com/. Accessed: April 15,\n2024.\nDAIR.AI.\nPrompt chaining \u2014 prompt engineering guide, 2024.\nURL www.\npromptingguide.ai/techniques/prompt_chaining.\nMatthew DeLorenzo, Vasudev Gohil, and Jeyavijayan Rajendran. Creativeval:\nEvaluating creativity of llm-based hardware code generation. arXiv preprint\narXiv:2404.08806, 2024.\nGelei Deng, Yi Liu, V\u00b4\n\u0131ctor Mayoral-Vilches, Peng Liu, Yuekang Li, Yuan Xu,\nTianwei Zhang, Yang Liu, Martin Pinzger, and Stefan Rass.\nPentest-\ngpt: An llm-empowered automatic penetration testing tool. arXiv preprint\narXiv:2308.06782, 2023.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.\nBert:\nPre-training of deep bidirectional transformers for language understanding.\narXiv preprint arXiv:1810.04805, 2018.\nERMProtect.\nHow artificial intelligence will drive the future of pene-\ntration testing in it security, 2020.\nURL ermprotect.com/insights/\nhow-artificial-intelligence-will-drive-the-future-of-penetration-testing-in-\nAccessed: 2024-04-15.\nMatteo Esposito and Francesco Palagiano. Leveraging large language models\nfor preliminary security risk analysis: A mission-critical case study. arXiv\npreprint arXiv:2403.15756, 2024.\n38\nfr0gger.\nAwesome gpt agents.\nGitHub repository, 2023.\nURL github.com/\nfr0gger/Awesome-GPT-Agents. Accessed: April 15, 2024.\nMaanak Gupta, CharanKumar Akiri, Kshitiz Aryal, Eli Parker, and Lopamudra\nPraharaj. From chatgpt to threatgpt: Impact of generative ai in cybersecurity\nand privacy. arXiv preprint arXiv:2307.00691, 2023.\nHack The Box. Hack the box. Hack The Box Website, 2024. URL www.hackthebox.\ncom.\nAndreas Happe and J\u00a8\nurgen Cito. Getting pwn\u2019d by ai: Penetration testing with\nlarge language models. In Proceedings of the 31st ACM Joint European Software\nEngineering Conference and Symposium on the Foundations of Software Engineer-\ning, ESEC/FSE \u201923. ACM, November 2023. doi: 10.1145/3611643.3613083.\nURL http://dx.doi.org/10.1145/3611643.3613083.\nAndreas Happe, Aaron Kaplan, and J\u00a8\nurgen Cito. Evaluating llms for privilege-\nescalation scenarios. arXiv preprint arXiv:2310.11409, 2023.\nAndreessen Horowitz. Emerging architectures for llm applications, 2023. URL\na16z.com/emerging-architectures-for-llm-applications/.\nAccessed:\n2024-04-15.\nInfosec\nInstitute.\nThe\nhistory\nof\npenetration\ntesting.\nwww.\ninfosecinstitute.com/resources/penetration-testing/\nthe-history-of-penetration-testing/#:~:text=For%20more%20than%\n2050%20years,or%20even%20destroy%20information%20networks.,\n2019.\nAccessed: 2024-03-15.\nTian Jin, Wanzin Yazar, Zifei Xu, Sayeh Sharify, and Xin Wang. Self-selected at-\ntention span for accelerating large language model inference. arXiv preprint\narXiv:2404.09336, 2024.\nTomoyuki Kagaya, Thong Jing Yuan, Yuxuan Lou, Jayashree Karlekar, Sugiri\nPranata, Akira Kinose, Koki Oguri, Felix Wick, and Yang You. Rap: Retrieval-\naugmented planning with contextual memory for multimodal llm agents.\narXiv preprint arXiv:2402.03610, 2024.\nLeroy Jacob Valencia.\nReaperai.\nGitHub repository, 2023.\nURL github.com/\ntac01337/ReaperAI. Accessed: April 22, 2024.\nYang Liu, Mofan Zhou, Xipeng Qiu, and Zhiyuan Yan. Pre-train, prompt, and\npredict: A systematic survey of prompting methods in natural language pro-\ncessing. arXiv preprint arXiv:2107.13586, 2021.\nMITRE. Mitre att&ck. MITRE ATT&CK Database, 2024. URL attack.mitre.org.\nYohei Nakajima.\nbabyagi.\nGitHub repository, 2024.\nURL github.com/\nyoheinakajima/babyagi. Accessed: April 15, 2024.\nOpenAI. Introducing gpts. openai.com/blog/introducing-gpts, Nov 2023. Ac-\ncessed: 01-23-24.\n39\nOpenAI. Introducing chatgpt - openai. OpenAI Blog, May 2023. URL openai.\ncom/blog/introducing-the-chatgpt-app-for-ios.\nOpenAI. Gpt-4 turbo and gpt-4. OpenAI Platform Documentation, 2024. URL\nplatform.openai.com/docs/models/gpt-4-turbo-and-gpt-4.\nCyber Range Organization, Design (CROND) at the Japan Advanced Institute of\nScience, and Technology (JAIST).\nAutopentest-drl: Automated penetra-\ntion testing using deep reinforcement learning, 2020.\nURL github.com/\ncrond-jaist/AutoPentest-DRL. Accessed: 2024-04-15.\nAlec\nRadford,\nJeffrey\nWu,\nRewon\nChild,\nDavid\nLuan,\nDario\nAmodei,\nand\nIlya\nSutskever.\nLanguage\nmodels\nare\nunsupervised\nmulti-\ntask\nlearners.\nOpenAI\nBlog,\n2019.\nURL\nopenai.com/research/\nlanguage-models-are-unsupervised-multitask-learners/.\nGuidePoint Security. Guidepoint security 2022 predictions: The future of penetra-\ntion testing in 2022 and beyond. www.guidepointsecurity.com/newsroom/\nthe-future-of-penetration-testing-in-2022-and-beyond/, 2022.\nAc-\ncessed: 2024-03-18.\nNoah Spurrier. Pexpect, 2013. URL github.com/pexpect/pexpect. Accessed:\nApril 15, 2024.\nWeihang Su, Yichen Tang, Qingyao Ai, Zhijing Wu, and Yiqun Liu. Dragin: Dy-\nnamic retrieval augmented generation based on the real-time information\nneeds of large language models, 2024.\nYu Wang, Xiusi Chen, Jingbo Shang, and Julian McAuley. Memoryllm: Towards\nself-updatable large language models. arXiv preprint arXiv:2402.04624, 2024.\nYizhou Yang and Xin Liu.\nBehaviour-diverse automatic penetration testing:\nA curiosity-driven multi-objective deep reinforcement learning approach.\narXiv preprint arXiv:2202.10630, 2022.\nF.M. Zennaro and L. Erd\u02dd\nodi. Modelling penetration testing with reinforcement\nlearning using capture-the-flag challenges: trade-offs between model-free\nlearning and a priori knowledge. 10.1049/ise2.12107, 17(3):441\u2013457, 2023.\n40\nAPPENDIX A\nPROMPTS\nA.1\nquery next command.txt\nYour current role:\n\"${current_role}\"\nYou can only:\n- give a command to be executed on the shell that is NOT\ninteractive.\nYou don\u2019t have that integration yet and I will respond with the\nterminal output when running this c\nommand on the linux server. Only state the\ncommand to be executed.\n- give commands that do not contain \u2018nc\u2018\nYour current task is:\n\"${current_task}\"\nYour current constraints are:\n\"${constraints}\"\nYour current target is:\n\"${target.ip}\"\n% if len(history) != 0:\nYou already tried the following commands and their arguments:\n\u2019\u2019\u2019bash\n${history}\n\u2019\u2019\u2019\nDo not repeat already tried attacks.\n%endif\nYou currently know the following about the target system:\n\"${state}\"\nBased on this you have thought about it and the analyzation you have\nconcluded on from the previous step is: \"${analyzation}\"\n41\n% if task_tree:\nYour task tree to keep track of this pentest:\n${task_tree.generate_task_summary()}\n%endif\nGiven the current role, objective, constraints, history, and state, and\nanalysis of Give your command that will best accomplish the task.\nDo not add any explanation or add an initial \u2018$\u2018\nA.2\nanalyze cmd.txt\nAs a penetration tester analyzing the outputs of a command,\nI\u2019ve executed\u2019${cmd}\u2019 against the system\u2019s defenses.\nI\u2019ll share the stdout, stderr, and exit code with you.\nYour task is to distill this data into a concise summary,\ncapped at ${summary_max_chars} characters. Focus your\nanalysis uncovering insights related to security\nvulnerabilities, performance bottlenecks, or any signs\nof instability or unreliability in the system or its\nservices. Highlight critical findings that could indicate\npotential risks or weaknesses in the system\u2019s architecture\nor configurations and explain step by step\nCommand: ${cmd}\nStderr: ${stderr}\nStdout: ${resp}\nSummary (in ${summary_max_chars} or fewer characters):\nA.3\nevaluate progress.txt\nYou are an advanced LLM designed to assist in\ncybersecurity operations, specifically in evaluating\nthe progress of \"${stage}\" tasks during penetration\ntesting phases. Based on the given inputs, your goal\nis to determine the appropriate next steps in the\n\"${stage}\" process by considering time limits,\ncoverage thresholds, and diminishing returns.\nInputs:\nList of \"${stage}\" Tasks: ${task}\nConstraints:\n42\nTime Limits: Each \"${stage}\" task has a maximum\nallotted time of ${max_time_per_task} seconds. If\nthe cumulative time which is ${cur_time} reaches this\nlimit from the start time which is ${start_time},\nrecommend moving to the next phase.\nDiminishing Returns: \"${stage}\" is limited to a maximum of\n${max_recon_iterations} iterations. If additional iterations\nyield less than ${min_new_information} new information,\nindicate that diminishing returns have been reached and recommend\nstopping \"${stage}\" to proceed further.\nDecision Points:\nEvaluate if the time limit for a \"${stage}\" task has\nbeen exceeded. If so, advise moving to the next phase.\nDetermine if the \"${stage}\" efforts are experiencing\ndiminishing returns based on the number of iterations\nand the percentage of new information gained from the new:\n${new_information} compared to the old: ${old_information}.\nIf diminishing returns are detected, recommend\nstopping \"${stage}\" and proceeding to the next step.\nOutput:\nProvide a recommendation. The recommendation should\nindicate whether to continue \"${stage}\", move to the\nthe next phase, or conclude the \"${stage}\" phase due\nto coverage thresholds being met or diminishing returns.\nA.4\nget objectives\nYou are a cybersecurity pentester and not a redteamer\nconducting a BLACK BOX pentest on one single machine\nwhich means we know nothing prior about this machine.\nGiven the current stage in your penetration testing\ncycle named \"${stage}\", produce a realistic and tangible\nordered list of 3 most important tasks of the given stage\nthat can be completed to finish the ${stage} that does\nNOT assume anything about the machine, its ports or\nservices and should be solely based on the context\nI give you here: \u2018\u2018\u2018 ${background} \u2018\u2018\u2018 This list\nshould encompass tasks that are specific to the stage,\nand can be properly executed and fulfilled to ultimately\nproceed to the next stage. Do NOT give any explanations\nor descriptions. Again, ensure the tasks do NOT assume any\ninformation about the target. Objectives need to be brief\nand very specific.\nOutput the list in an json array.\n43\nARTIFICIAL INTELLIGENCE AS THE NEW HACKER: DEVELOPING\nAGENTS FOR OFFENSIVE SECURITY\nby\nLeroy Jacob Valencia\nPermission to make digital or hard copies of all or part of this work\nfor personal or classroom use is granted without fee provided that\ncopies are not made or distributed for profit or commercial advantage\nand that copies bear this notice and the full citation on the last page.\nTo copy otherwise, to republish, to post on servers or to redistribute\nto lists, requires prior specific permission and may require a fee.\n44\n", "metadata": {"Published": "2024-05-09", "Title": "Artificial Intelligence as the New Hacker: Developing Agents for Offensive Security", "Authors": "Leroy Jacob Valencia", "Summary": "In the vast domain of cybersecurity, the transition from reactive defense to\noffensive has become critical in protecting digital infrastructures. This paper\nexplores the integration of Artificial Intelligence (AI) into offensive\ncybersecurity, particularly through the development of an autonomous AI agent,\nReaperAI, designed to simulate and execute cyberattacks. Leveraging the\ncapabilities of Large Language Models (LLMs) such as GPT-4, ReaperAI\ndemonstrates the potential to identify, exploit, and analyze security\nvulnerabilities autonomously.\n  This research outlines the core methodologies that can be utilized to\nincrease consistency and performance, including task-driven penetration testing\nframeworks, AI-driven command generation, and advanced prompting techniques.\nThe AI agent operates within a structured environment using Python, enhanced by\nRetrieval Augmented Generation (RAG) for contextual understanding and memory\nretention. ReaperAI was tested on platforms including, Hack The Box, where it\nsuccessfully exploited known vulnerabilities, demonstrating its potential\npower.\n  However, the deployment of AI in offensive security presents significant\nethical and operational challenges. The agent's development process revealed\ncomplexities in command execution, error handling, and maintaining ethical\nconstraints, highlighting areas for future enhancement.\n  This study contributes to the discussion on AI's role in cybersecurity by\nshowcasing how AI can augment offensive security strategies. It also proposes\nfuture research directions, including the refinement of AI interactions with\ncybersecurity tools, enhancement of learning mechanisms, and the discussion of\nethical guidelines for AI in offensive roles. The findings advocate for a\nunique approach to AI implementation in cybersecurity, emphasizing innovation.", "entry_id": "http://arxiv.org/abs/2406.07561v1", "published_first_time": "2024-05-09", "comment": null, "journal_ref": null, "doi": null, "primary_category": "cs.CR", "categories": ["cs.CR", "cs.AI"], "links": ["http://arxiv.org/abs/2406.07561v1", "http://arxiv.org/pdf/2406.07561v1"]}, "type": "Document"}
{"page_content": "Bridging the Gap: A Survey and Classification of\nResearch-informed Ethical Hacking Tools\nPaolo Modesti, Lewis Golightly, Louis Holmes, Chidimma Opara, Marco Moscini\nTeesside University, Middlesbrough, United Kingdom\nAbstract\nThe majority of Ethical Hacking (EH) tools utilised in penetration testing are developed by practitioners\nwithin the industry or underground communities. Similarly, academic researchers have also contributed to\ndeveloping security tools. However, there appears to be limited awareness among practitioners of academic\ncontributions in this domain, creating a significant gap between industry and academia\u2019s contributions to\nEH tools. This research paper aims to survey the current state of EH academic research, primarily focusing\non research-informed security tools. We categorise these tools into process-based frameworks (such as PTES\nand Mitre ATT&CK) and knowledge-based frameworks (such as CyBOK and ACM CCS). This classification\nprovides a comprehensive overview of novel, research-informed tools, considering their functionality and\napplication areas. The analysis covers licensing, release dates, source code availability, development activity,\nand peer review status, providing valuable insights into the current state of research in this field.\nKeywords:\nEthical Hacking; Tools and Techniques; Research-informed, Classification; PTES; Mitre\nATT&CK; CyBOK; ACM CCS\n1. Introduction\nIn the domain of Ethical Hacking (EH), developing innovative tools is essential to tackle emerging threats\nand vulnerabilities. Ethical Hacking tools are designed mainly by industry practitioners, occasionally by\nunderground communities [2], and sometimes even by state actors [3]. However, even experienced security\ndevelopers may overlook critical requirements for such applications.\nAn intriguing example is provided\nby Valenza et al. [4], challenging the conventional belief that remote scanning carries negligible risk. Their\nmethodology, which transformed the scanning system into a target for counterattacks, revealed vulnerabilities\nin widely deployed tools, including Metasploit Pro. Overall, the researchers identified weaknesses in 36 out\nof 78 scanning applications.\nThe existing divide between industry and academia in developing EH tools reflects differing goals and\napproaches, highlighting a significant awareness gap. Industry practitioners are often insufficiently informed\nabout the outcomes and insights generated by academic research in this field. Driven by immediate op-\nerational requirements, the industry tends to favour established tools and practices that promptly address\nreal-time threats. However, this emphasis on practical application can result in a lack of awareness regarding\nsignificant academic contributions, such as novel methodologies and solutions for emerging threats or ad-\nvancements in theoretical frameworks. Consequently, research findings may remain underutilised by industry\npractitioners.\nOne way to bridge the gap between industry and academia in developing EH tools is by producing in-depth\nsurvey papers that detail the tools created by both communities. However, existing surveys primarily assess\nEmail addresses: p.modesti@tees.ac.uk (Paolo Modesti), l.golightly@tees.ac.uk (Lewis Golightly),\nb1445121@tees.ac.uk (Louis Holmes), c.opara@tees.ac.uk (Chidimma Opara), m.moscini@tees.ac.uk (Marco Moscini)\nThis is the extended version of the published paper [1] is available at https://doi.org/10.3390/jcp4030021.\narXiv:2407.14255v1  [cs.CR]  19 Jul 2024\nand compare tools used by industry practitioners, with only occasional consideration of research-informed\ntools [5, 6, 7]. This focus overlooks the innovative contributions from the research community.\nAdditionally, the quantity and breadth of tools reviewed by state-of-the-art surveys in EH tools are\nlimited. For instance, the work by Altulaihan et al. [8] covered 15 papers for web application penetration\ntesting, while Yaacoub et al. [6] reviewed 13 tools specifically applied to IoT. This limited scope restricts\nthe comprehensive evaluation of EH tools. Moreover, existing surveys that classify EH methodologies or\nframeworks compare existing frameworks such as PTES or other industry methodologies like the Information\nSystems Security Assessment Framework (ISAF) [9]. However, they do not discuss the specific tools that\nfall under each category. This narrow focus fails to provide a holistic view of the EH tools landscape.\nResearch Contributions\nIn light of these limitations, this paper makes two significant contributions:\n1. Survey of Research-Informed EH Tools: this study surveys 100 research-informed EH tools developed\nin the last decade. It highlights key areas such as licensing, release dates, source code availability,\ndevelopment activity level, and peer review status. This analysis aims to provide insights into the\nstate-of-the-art EH tools developed by the research community.\n2. Alignment with Recognised Frameworks: this study categorises the tools into process-based frameworks,\nsuch as the Penetration Testing Execution Standard (PTES) [10], and the Mitre ATT&CK framework\n[11] and knowledge-based frameworks like the National Cyber Security Centre\u2019s Cyber Security Body\nOf Knowledge (CyBOK) [12] and the Association for Computing Machinery\u2019s Computing Classifica-\ntion System (ACM CCS) [13]. Combining these four classifications offers an informative view of the\nlandscape of novel and research-informed ethical tools, their functionality, and application domain for\nthe benefit of scholars, researchers, and practitioners.\nThis comprehensive approach not only bridges the gap between industry and academia but also ensures that\nEthical Hacking tools evolve in tandem with the ever-changing cyber threat landscape.\nOutline of the Paper\nSection 2 introduces the background of EH and the methodologies used by\npractitioners, Section 3 presents our research methodology, and Section 4 discusses the classification criteria\napplied to the EH tools. Section 5 discusses the tool categorisation into process-based and knowledge-based\nframeworks. Section 6 presents the systematic evaluation of research-informed EH tools, while Section 7\nconcludes the paper.\n2. Background\nIn this section, we discuss the background and fundamentals of Ethical Hacking, including the motivations\nbehind hacking systems and the different motivations of hackers categorised and represented using hats.\nAdditionally, we introduce methodologies used in EH.\n2.1. (Unethical) Hacking Landscape and Motivations\nCyberattacks, intrusion techniques, social engineering, and information manipulation are increasingly be-\ncoming more sophisticated, targeting individuals and organisations. The objective of each attack, regardless\nof its nature, is to circumvent the three primary principles of security: Confidentiality, Integrity, and Avail-\nability [14]. There is a wide range of motivations for cyberattacks, and many factors interplay. According to\n[15, 16, 17, 18], the motivations for these attacks can be grouped into:\n\u2022 Economic Gain: cybercriminals often target individuals, businesses, or organisations to extort money\nthrough ransomware [19] or financial fraud. Financial institutions such as banks and related services\ncan be a target, as in the case of the attack on the Swift international transaction system [20].\n2\n\u2022 Competitive Advantage and Sabotage: competing companies, state-sponsored actors, and individuals\ncan steal and reveal industrial secrets and intellectual properties to gain a competitive edge and com-\npromise the data integrity and accessibility in businesses. While the WannaCry ransomware was used\nprimarily to extort money from the victims, the attack on the UK National Health Service (NHS)\ncould have also been done to demonstrate the business complacency and lack of digital transformation\n[19].\n\u2022 Personal Revenge: cyberattacks driven by personal revenge are often perpetrated by disgruntled in-\nsiders or individuals with a vendetta against specific targets. These attacks leverage insider knowledge\nor access to inflict damage, disrupt operations, or steal sensitive data.\n\u2022 Political: the attack is carried out as groups of hackers engaged in politics, sponsored-stated hacking\nteams aiming at damaging specific targets. This includes governmental institutions, political parties,\nsocial society organisations and other public subjects. Examples are the alleged interference in the US\npresidential elections by Russian state-sponsored cyber actors in 2016 [21], and the Operation Socialist\nin 2010\u20132013 against Belgacom attributed to the UK\u2019s GCHQ [22], a case of an attack perpetrated by\na NATO member state against another one.\nThe activities described above broadly fall into the category of cybercrime and involve hacking, data\ntheft, identity theft, financial fraud, and malware distribution. However, when cyberattacks are carried\nout by state-sponsored actors against other nations or entities, they are often called cyber warfare. The\ndistinction can be blurred in some cases, as the direct involvement of government organisations can have\nsurprising ramifications and side effects.\nThe EternalBlue exploit [23] was developed by the United States National Security Agency (NSA) tar-\ngeting a vulnerability in Microsoft\u2019s Windows operating system, specifically in the Server Message Block\n(SMB) protocol. The NSA utilised the exploit for years without reporting the vulnerability to Microsoft.\nHowever, it became widely known when a hacking group called the Shadow Brokers leaked the exploit in\nApril 2017. The most notorious incident involving EternalBlue was the aforementioned WannaCry attack in\nMay 2017. The exploit allowed the rapid spread of malware across networks, affecting hundreds of thousands\nof computers in over 150 countries and causing hundreds of millions of USD of damage worldwide.\nThis demonstrates the potential for unintended consequences and collateral damage as malicious actors\ncan weaponise an offensive security tool developed by a government agency for large-scale cybercrime. This\ncase also highlights the importance of responsible handling and disclosure of vulnerabilities by any entity,\nincluding government intelligence agencies.\n2.2. Ethical Hacking\nEthical Hacking, also known as penetration testing, aims to identify vulnerabilities in computer systems,\nnetworks, and software applications before real-world attackers can exploit them. By uncovering weaknesses\nand providing recommendations for mitigation, EH helps organisations enhance their defences, protect sens-\nitive data, and prevent unauthorised access. Ethical hackers utilise their skills to simulate potential cyber-\nattacks and assess the security of a system. In fact, such specialists essentially utilise the same techniques as\ncyber attackers, with the important difference being that the system\u2019s owner authorises them and agrees on\nthe scope of the penetration testing exercise. As individuals capable of compromising systems, any misuse\nof their skills is criminally punishable according to the laws of various countries. The Budapest Convention\non Cybercrime of 2001 (Article 6) [24], the EU Directive 2013/40 (Article 7) [25], and the UK Computer\nMisuse Act of 1990 (Section 3A) [26] are some of the legislations that regulate cybersecurity activities in\nterms of the improper use of personal capabilities, software, and hardware dedicated to unauthorised access\nto third-party information.\nThe key issue in determining the legality of hacking activities is avoiding actions that contravene the law.\nHacking professionals must prioritise legal compliance to avoid prosecution. While the term Legal Hacking\nmay more accurately describe this focus on legality, it is essential to recognise that legality does not always\nequate to ethical behaviour. Nevertheless, the term Ethical Hacking remains widely used, emphasising the\nimportance of both legal compliance and ethical conduct in the profession.\n3\n2.3. Ethical Hackers\nTraditional media often portrays hackers as mysterious figures, typically depicted wearing hoodies in\ndimly lit rooms, perpetuating a stereotype prevalent in pop culture. Hackers are commonly seen as computer\npirates who infiltrate systems for personal or financial gain.\nHowever, historical context reveals a more\nnuanced understanding.\nAccording to the classic definition reported by Gehring [27], hackers enjoy the\nintellectual challenge of overcoming programming limitations and seeking to extend their capabilities. This\ndefinition, prevalent until the 1980s and intertwined with notions of democracy and freedom, has evolved,\nas discussed by Jaquet-Chiffelle and Loi [28].\nHats of different colours are broadly used as a symbolic\nrepresentation of individuals based on their intentions and actions related to hacking [16]:\n\u2022 White Hat (ethical): Embodies the principles of hacker culture by employing technical skills to pro-\nactively enhance system security measures. These individuals focus on identifying vulnerabilities and\ndeveloping defensive strategies to mitigate potential risks.\n\u2022 Black Hat (malicious): Represents individuals who maliciously exploit vulnerabilities within systems\nfor personal gain or disruptive purposes. Their actions typically involve unauthorised access, data\ntheft, and system manipulation, often resulting in financial losses or reputational damage for targeted\nentities.\n\u2022 Grey Hat (undecided): Occupies an intermediary role, engaging in activities that blur the line between\nethical and malicious hacking. These individuals engage in operations as both Black Hat and White\nHat, depending on the circumstances [28].\nAccording to [29, 17], further categories have been identified based on distinctive motivations and com-\npetencies from the original definition of hacker:\n\u2022 Red Hat: Individuals dedicated to countering black hat hackers using offensive techniques rather than\ndefensive ones [30].\n\u2022 Blue Hat: People employed in companies that test software before release to find bugs [31].\n\u2022 Green Hat: A category composed of people new to the hacking world [29].\n\u2022 Script Kiddie: People with few hacking skills who use software already created by real hackers.\n\u2022 Hacktivist: People who use hacking to promote political, social, or ideological manifestos [32].\n\u2022 Professional Criminals: People with professional skills in security who use hacking to steal financial\ninformation.\n\u2022 Internals or Insiders: People who usually attack their workplace for revenge or financial gain.\nIn recent years, cybersecurity and privacy protection have emerged as central themes for all organisations,\nand professional roles have arisen to address these needs. Penetration testing and malware analysis are among\nthe sought-after roles in the cybersecurity job market, falling under the main category of EH.\n2.4. Ethical Hacking Methodologies\nPenetration Testing takes different forms and can cover various areas. Yaacoub et al. [15] describe the\nprocess of conducting an attack in five main phases:\n\u2022 Reconnaissance: The hacker gathers information on systems and users through passive or active tech-\nniques. This includes physical methods like social engineering and analysing network packets to identify\ndetails such as network configuration, hardware, and security measures.\n4\n\u2022 Scanning: The hacker searches for vulnerabilities in systems through simulated tests, including identi-\nfying open ports, active hosts, and weak firewall configurations. Enumeration is then carried out to\ngather further information while maintaining an active connection.\n\u2022 Gaining Access: The hacker attempts to access the system using penetration testing tools and tech-\nniques, aiming to bypass security measures.\n\u2022 Maintaining Access: The hacker establishes backdoors or rootkits to maintain remote access with\nelevated privileges.\n\u2022 Covering Tracks: The hacker eliminates evidence that could reveal their identity or traces of the attack.\nEach phase is complex and crucial for the success of a cyber attack. Due to the unique nature of each\nsystem, there are no strict rules for systematically executing an attack or penetration test. However, various\nframeworks and methodologies have been developed to guide the penetration testing process in planning and\nexecuting cyber attack simulations.\nThese frameworks can be categorized into three main areas: open source, maintained by non-profit\norganisations or security institutes; industrial/governmental, maintained by government entities such as the\nNational Institute of Standards and Technology (NIST); and proprietary, maintained by private companies\nand accessible through payment of a usage license.\n2.4.1. PTES\nThe Penetration Testing Execution Standard [10] was created in 2009 by a group of practitioners who\ndeveloped this framework to provide both businesses and security service providers with a common language\nfor conducting penetration tests. It comprises 7 phases: Pre-engagement Interactions, Intelligence Gathering,\nThreat Modelling, Vulnerability Analysis, Exploitation, Post Exploitation, and Reporting. The methodology\nis presented in detail in Section 4.1.\n2.4.2. Mitre ATT&CK\nMitre Adversarial Tactics, Techniques, and Common Knowledge [11] is a matrix that describes the be-\nhaviour of attackers throughout the life cycle of an operation. It covers tactics, techniques, and procedures\n(TTP) used by threat actors to achieve their objectives. Mitre is a non-profit American company involved in\nnumerous cybersecurity standards and frameworks, such as CVE (Common Vulnerabilities and Exposures)\n[33] to identify and classify disclosed security vulnerabilities. CWE (Common Weakness Enumeration) [34]\nis used as a common language for weakness identification, prevention and mitigation. See Section 4.2 for the\ndetails of this methodology.\n2.4.3. PCI DSS Penetration Testing guidance\nPayment Card Industry Data Security Standard (PCI DSS) [35] is a set of security requirements designed\nto protect payment card information during transactions. Developed by the PCI Security Standards Coun-\ncil, it applies to all organisations that accept, process, store, or transmit payment card data. PCI DSS\nestablishes requirements for data security, network management, application protection, and other measures\nto prevent credit card fraud. The Penetration Testing Guide [36] is divided into four parts: Penetration\nTester Components, Qualification of a Penetration Tester, Methodology and Reporting and Documentation.\nOrganisations must comply with these requirements to ensure the security of credit card transactions and\nprotect cardholders\u2019 sensitive data.\n2.4.4. ISSAF\nThe Information Systems Security Assessment Framework [37] is a standard supported by the Open\nInformation System Security Group (OISSG). It incorporates all possible attack domains, and the main\nfeature is that the penetration testing activity is divided into three phases: Planning and Preparation,\nAssessment and Reporting, Cleanup, and Artefact Destruction.\n5\n2.4.5. OSSTMM\nThe Open Source Security Testing Methodology Manual [38] is a set of guidelines and procedures for\nconducting security tests and assessing the security of information systems.\nDeveloped by the Institute\nfor Security and Open Methodologies (ISECOM), OSSTMM aims to provide an open-source standardised\nmethodology for cybersecurity professionals. It focuses on testing operational security through five channels:\nHuman Security, Physical Security, Wireless Communications, Telecommunications, and Data Networks.\n2.4.6. NIST800-115\nNIST800-115 [39] is a methodology published by the National Institute of Standards and Technology\n(NIST) in the United States. This standard provides detailed guidelines for conducting tests and assessments\nof information security in computer environments. It covers a wide range of security testing and assessment\nactivities. The standard includes planning, information gathering, vulnerability analysis, test execution, risk\nassessment, and documentation. It offers practical and detailed recommendations for performing various\ntests, including tool selection and management of information collected during the testing process. Although\npublished by NIST, the standard is designed to be adopted in both the public and private sectors, providing\na flexible framework that can be applied to different environments.\n2.4.7. OWASP\nThe Open Worldwide Application Security Project [40] was launched in 2001 as an open-source project\nthat provides guidelines, tools, and methodologies to improve the security of applications, collected into\na guide named OTG 4.0 (Owasp Testing Guide) [41]. This document is divided into five parts: Before\ndevelopment begins, During definition and design, During development, During deployment and Maintenance\nand operations. By completing these procedures, developers can significantly reduce the risk of data breaches\ncaused by attacks facilitated by poor code quality.\n3. Survey Methodology\nA three-step approach was devised to investigate Ethical Hacking tools developed by the research com-\nmunity over the past decade (Figure 1). First, clear guidelines were established to determine the inclusion of\ntools in the survey. Second, relevant papers and tools satisfying the above criteria were identified. Finally,\nthese tools were categorised based on established cybersecurity frameworks.\nCriteria for Inclusion\nIdentification of\nPapers and Tools\nCategorisation\nof Tools\nAcademic and\nresearch context\nPeer-reviewed\nresearch papers\nPotential for\noffensive use\nAuthorship by\ntool developers\nOpen source\navailability\nPTES\nMitre ATT&CK\nCyBOK\nACM CCS\nFigure 1: Survey Methodology\n6\n3.1. Criteria for Inclusion of Ethical Hacking Tools in the Paper\nThis survey established specific conditions to determine the inclusion of state-of-the-art EH tools in the\npaper. The following criteria were adhered to:\n\u2022 Academic and research context: The tool has been developed within an academic/research project:\nthis excludes any tools developed primarily as practitioner tools (e.g. they are included in a popular\nEH distribution, like Kali Linux).\n\u2022 Peer-reviewed research papers: Each EH tool included in the survey must be published in a peer-\nreviewed venue. Peer review validates the tool\u2019s architecture, functionalities, and relevance.\n\u2022 Potential for offensive use: The tool has at least the potential to be used in an offensive context even\nif authors do not state that explicitly, as the tool could have been developed for another purpose (e.g.\nsoftware testing, supporting software or system development).\n\u2022 Authorship by tool developers:\nThe survey also requires that the authors of the papers have de-\nsigned/developed the tool.\nThis criterion ensures credibility and depth of insight, as the creators\nare directly involved in its conception and development.\n\u2022 Open source availability: The tool should be open source, and the source code (or distribution package)\nshould be freely available.\nHowever, this requirement was relaxed throughout the research as we\nacknowledge that some tools may not be open-source for various reasons, such as proprietary nature,\npending patents, or limited accessibility.\n3.2. Collating Research-Informed Ethical Hacking Tools\nThe inclusion of 100 EH tools was driven by the aim of achieving a balance between depth and breadth\nin our analysis. The selection process was systematic and rigorous, inspired by the PRISMA methodology\n[42], with identification, screening and inclusion phases.\nInitially, we initiated a collaborative research project involving cohorts of students from the MSc Cy-\nbersecurity program at Teesside University (United Kingdom). Despite the absence of a dedicated module\non EH in their curriculum, the students showed considerable interest in working within this domain. This\nproject allowed them to integrate EH professionalism with their research interests.\nThe students\u2019 initial submissions yielded over 200 academic references. However, after a careful review\nprocess conducted by the authors, approximately 30 tools aligned with the research scope and were included\nin this paper. Many tools found by the students were excluded for these reasons:\n\u2022 Difficulty of the students in distinguishing between research-informed and practitioner tools.\n\u2022 Confusion between papers describing the design and implementation of a tool and those describing its\napplication.\n\u2022 The approach of identifying tools first and then searching for papers to support the findings leads to\nthe above misconceptions.\nFollowing the criteria outlined in Section 3.1, the authors expanded the total count of EH tools to 185.\nThese tools were then resampled, and 100 tools were finally selected. The final selection was based not only\non adherence to the criteria in Section 3.1 but also on the fact that these tools were not merely applications\nof existing methodologies, frameworks, or aggregations of practitioner tools.\nIn fact, among the 85 candidates excluded in the final round, 28 focused on mitigation tools and tech-\nniques, 18 on methodologies and frameworks, 14 on the application of practitioner tools, 13 were surveys, 5\naddressed socio-technical aspects, 4 were simulation tools, and 3 focused on education.\nFor details of the 100 tools surveyed in this paper, see Table 1.\nMoreover, as discussed in Section 6, to include a significant number of tools that could reflect the current\nstate of the art, we had to relax on the criteria of availability of the source code. Therefore, in this survey,\nwe have 41 tools that satisfy all other criteria, but no source code has been published.\nFor a detailed description of each tool included in this survey, please refer to Appendix C.\n7\n3.3. Classification of Identified Ethical Hacking Tools\nIn the second phase of the research, the identified EH tools were classified according to established\ncybersecurity frameworks. This task was undertaken by the authors, who have extensive expertise in EH\nfrom years of teaching, research, and professional experience in the field.\nEthical Hacking Tools\nProcess Based\nFrameworks\nKnowledge Based\nFrameworks\nPenetration Testing\nExecution Standard\n(PTES)\nMitre Adversarial\nTactics, Techniques,\nand Common Know-\nledge (ATT&CK)\nNCSC Cyber Security\nBody of Knowledge\n(CyBOK)\nACM Computing\nClassification Sys-\ntem (CCS)\nFigure 2: Classification Criteria applied in this survey\nAll 100 identified tools were categorised according to the following classifications (Figure 2):\n1. Penetration Testing Execution Standard (PTES) [10]\n2. Mitre ATT&CK Framework [11]\n3. NCSC CyBOK [12]\n4. ACM Computing Classification System (CCS) [13]\nIncorporating process-based classifications such as the PTES and the Mitre ATT&CK Frameworks\nensures that the survey covers the practical aspects of EH tools. On the other hand, knowledge-based\nclassifications such as NCSC CyBOK and ACM CCS focus on the theoretical and conceptual aspects of\ncomputing and cybersecurity domains, thereby exploring the underlying theoretical bases of EH tools.\nThe next section provides an in-depth discussion of these frameworks.\n4. Cybersecurity Frameworks used for Tools Classification\nThis section delves into a detailed examination of the cybersecurity frameworks used to categorise the\nEthical Hacking tools surveyed in this paper. These frameworks include PTES, MITRE ATT&CK frame-\nwork, CyBOK, and ACM CCS).\n4.1. Penetration Testing Execution Standard\nPTES [10] is a standardised methodology for planning, executing, and reporting security tests and\nit is widely used within the cybersecurity industry as one of the most significant standards for conducting\npenetration tests. PTES was proposed by a group of penetration testers and security professionals to provide\nguidance and best practices for conducting effective penetration tests within legal and ethical boundaries.\nIt consists of seven phases (Figure 3):\n1. Pre-engagement Interactions: In this phase, the scope and rules of engagement are defined through an\nagreement between the pen-testing team and the system\u2019s owner. The system\u2019s owner must provide\npermissions and authorizations, and communication lines must be established between the testers and\nthe target organization.\n8\nPre-engagement Interactions\nIntelligence Gathering\nThreat Modelling\nVulnerability Analysis\nExploitation\nPost Exploitation\nReporting\nFigure 3: Penetration Testing phases according to PTES methodology\n2. Intelligence Gathering: Information about the target organization or system is collected using tech-\nniques such as open-source intelligence (OSINT) gathering, reconnaissance, and network scanning.\nActive and passive information gathering methods are distinguished based on direct interaction with\nthe target system.\n3. Threat Modelling: This phase identifies potential vulnerabilities and threats specific to the target or-\nganization or system. It involves analysing collected information, understanding infrastructure and\narchitecture, prioritizing attack vectors, and assigning risks to threats to inform vulnerability mitiga-\ntion.\n4. Vulnerability Analysis: Vulnerabilities and weaknesses in the target\u2019s systems and applications are\nidentified and assessed, typically using classification systems like the Common Vulnerability Scoring\nSystem (CVSS). Manual and automated testing, configuration analysis, and examination of insecure\napplication design may be involved.\n5. Exploitation: Vulnerabilities previously identified are exploited to compromise the target system, gain\nunauthorized access, or execute malicious activities. The goal is to demonstrate the impact of vulner-\nabilities and their potential exploitation, bypassing security mechanisms.\n6. Post-Exploitation: After successful exploitation, the focus shifts to determining the value of the com-\npromised system, maintaining access, escalating privileges, and pivoting to other systems within the\nnetwork. This simulates an attacker\u2019s post-compromise activities, considering the data\u2019s importance\nand the advantage provided for further attacks.\n7. Reporting: the final phase involves documenting the findings, including identified vulnerabilities, their\nimpact, and recommendations for remediation. The report should be clear, concise, and actionable for\nthe target organization, tailored to various audiences ranging from senior managers to technical staff.\nThe PTES methodology can be applied to various systems to assess their security, including networks\nand critical infrastructures [43].\n4.2. Mitre Att&ck Framework\nMitre ATT&CK (Adversarial Tactics, Techniques, and Common Knowledge) [11] is a framework that\ncategorises the tactics, techniques, and procedures (TTPs) used by real-world threat actors during cyberat-\ntacks (Figure 4). It provides a standardised and comprehensive mapping of the various stages of an attack\nand consists of a matrix that categorises adversary behaviours across different stages of the attack lifecycle.\nWithin each tactic, specific techniques and procedures are listed, which outline the specific actions and\nmethods used by adversaries to accomplish their objectives.\nMitre ATT&CK consists of fourteen phases [44]:\n9\n1\n3\n5\n7\n9\n11\n13\n2\n4\n6\n8\n10\n12\n14\nPre-attack\nEnterprise Attack\nPost-Attack\n1. Reconnaissance\n3. Initial Access\n11. Collection\n2. Resource Development\n4. Execution\n12. Command and Control\n5. Persistence\n13. Exfiltration\n6. Privilege Escalation\n14. Impact\n7. Defence Evasion\n8. Credential Access\n9. Discovery\n10. Lateral Movement\nFigure 4: Mitre ATT&CK Framework: Phases and Tactics (inspired by [2])\n1. Reconnaissance: Collecting information on the target to plan and execute attacks. Methods include:\nActive Scanning, Passive Scanning, Social Engineering and OSINT.\n2. Resource Development: Acquiring resources required for further exploitation and maintaining access.\nMethods include: Developing Tools and Developing and Executing Malware.\n3. Initial Access: Techniques performed to gain access to the target environment. Methods to achieve\nthis include: Spear-Phishing, Exploiting Vulnerabilities and Stolen Credentials.\n4. Execution: Techniques performed executing Malicious Software (Malware) on a target system. Methods\ninclude: Executing Binaries, Scripts and System Tools.\n5. Persistence: Techniques performed around maintaining system access over a significant period of time.\nMethods include: Backdoor Creation and Scheduled Tasks.\n6. Privilege Escalation: Increasing the Access Control levels in the compromised environment. Methods\ninclude: Vulnerability Exploitation, Configuration Manipulation and Credential Theft.\n7. Defence Evasion: Techniques to avoid detection or target defensive mechanisms. Methods include:\nAnti-Virus Evasion,Obfuscation and Living-off-the-land Techniques.\n8. Credential Access: Techniques for stealing credentials for unauthorised access. Methods include: Cre-\ndential Dumping, Keylogging and Brute-Force Attacks.\n9. Discovery: Techniques for identifying information about the target system. Methods include: Network\nScanning, System Enumeration and Querying Systems.\n10. Lateral Movement: Methods for moving through the network for accessing additional systems by using:\nRDP, Trust Relationships and Lateral Tool Transfer.\n11. Collection: Acquiring and consolidating target system information. Methods include: Data Mining,\nScraping and Information Capture.\n12. Command and Control: Creating and Maintaining communication channels between the attacker and\ncompromised systems. Methods include: Command and Control (C2), Covert Channels and Network\nProtocols.\n13. Exfiltration: Techniques around the unauthorised data transfer external to the target environment.\nMethods include: Network Data Exfiltration, Encryption Channels and Scheduled Transfer.\n14. Impact: Achieving the desired outcome or effect could involve damaging a target. Methods include:\nDestroying Data, System Operation Disruption and Deploying Malware.\nThe Mitre ATT&CK framework can be applied to broad kinds of targets, including, financial systems\n[45], healthcare [46] and Industrial Control Systems (ICS) [47].\n4.3. NCSC CyBOK\nThe Cyber Security Body of Knowledge (CyBOK) [12] is a project developed by the United Kingdom\u2019s\nNational Cyber Security Centre (NCSC), a child agency of the Government Communications Headquarters\n(GCHQ), in collaboration with academia, industry, and government partners.\nCyBOK aims to provide\n10\nCyBOK\nKnowledge Areas\nIntroductory\nConcepts\nHuman,\nOrganisational\n& Regulatory\nAspects\nAttacks &\nDefences\nSystems\nSecurity\nSoftware and\nPlatform\nSecurity\nInfrastructure\nSecurity\nRisk Mgmt &\nGovernance\nLaw and\nRegulation\nHuman\nFactors\nPrivacy and\nOnline Rights\nMalware\nand Attack\nTechnologies\nAdversarial\nBehaviours\nSecurity\nOperations\nand Incident\nManagement\nForensics\nCryptography\nOperating\nSystems and\nVirtualisation\nSecurity\nDistributed\nSystems\nSecurity\nFormal\nMethods\nfor Security\nAuthentication,\nAuthorisation,\nand Ac-\ncountability\nSoftware\nSecurity\nWeb and\nMobile\nSecurity\nSecure\nSoftware\nLifecycle\nApplied\nCryptography\nNetwork\nSecurity\nHardware\nSecurity\nCyber\nPhysical\nSystems\nPhysical\nLayer and\nTelecom\nSecurity\nFigure 5: Cyber Security Body Of Knowledge (CyBOK) Knowledge Areas\na comprehensive and authoritative reference for the knowledge, skills, and competencies on which various\neducational programmes and job descriptions may be aligned.\nThe CyBOK is divided into 21 top-level\nKnowledge Areas (KAs) and five broad categories, along with the introductory concepts, as shown in Figure 5.\nThese categories, while orthogonal, are not entirely separate from each other, reflecting the interdisciplinary\nnature of cyber security.\nIn summary, Knowledge Areas in CyBOK version 1.1 [48] are organised as follows:\n1. Introductory Concepts: Introduction to CyBOK.\n2. Human, Organisational & Regulatory Aspects: (a) Risk Management and Governance, (b) Law and\nRegulation, (c) Human Factors and (d) Privacy and Online Rights.\n3. Attacks & Defences: (a) Malware and Attack Technologies, (b) Adversarial Behaviours, (c) Security\nOperations and Incident Management and (d) Forensics.\n4. Systems Security: (a) Cryptography, (b) Operating Systems and Virtualisation Security, (c) Distrib-\nuted Systems Security, (d) Formal Methods for Security and (e) Authentication, Authorisation, and\nAccountability.\n5. Software and Platform Security: (a) Software Security, (b) Web and Mobile Security and (c) Secure\nSoftware Lifecycle.\n6. Infrastructure Security: (a) Applied Cryptography, (b) Network Security, (c) Hardware Security, (d)\nCyber Physical Systems and (e) Physical Layer and Telecommunications Security.\nThe CyBOK can be applied in various ways to enhance the security posture of businesses. It can be\nused to assess skills, develop workforces, curriculum design in higher education, and certification programs\n[49, 50].\n4.4. ACM Computing Classification System (CCS)\nThe Computing Classification System (CCS) [13] is a taxonomy developed by the Association for Com-\nputing Machinery (ACM). It is designed to categorise and organise the various areas of research and practice\n11\nwithin the field of computing. The CCS provides a hierarchical structure that classifies research papers,\narticles, conference proceedings, and other scholarly works in computing.\nAuthors use appropriate CSS\ncategories when submitting publication manuscripts to journals and conferences for classification and organ-\nisation. This system helps to locate relevant literature, understand the structure of the field, and facilitate\ncommunication within the computing community. The root concepts of ACM CSS include [13]:\n1. General and Reference: Fundamental concepts and cross-disciplinary topics in computing.\n2. Hardware: Physical components and architecture of computing systems.\n3. Computer Systems Organisation: Organisation and structure of computer systems.\n4. Networks: Communication and connectivity in computing environments.\n5. Software and Its Engineering: Development, design, and maintenance of software systems.\n6. Theory of Computation: Mathematical and theoretical aspects of computation.\n7. Mathematics of Computing: Mathematical foundations of algorithms and computation.\n8. Information Systems: Management, retrieval, and processing of information in computing.\n9. Security and Privacy: Protection of computing systems and data privacy concerns.\n10. Human-Centred Computing: Interaction between humans and computing technologies.\n11. Computing Methodologies: Methodological approaches in computing research and practice.\n12. Applied Computing: Application of computing techniques in various domains.\n13. Social and Professional Topics: Ethical, legal, and social aspects of computing.\n5. Classification\nThe complete list of identified tools is available in Table 1. We include the availability of source code,\nthe license type, the source code repository and the year of publication. For readability reasons, we put the\nother classification tables in Appendix B. The description of individual tools is presented in Appendix C.\nTool Name\nYear\nLicense Type\nSource Code Repository\nADaMs [51]\n2021\nMIT License\nhttps://github.com/TheAdamProject/adams\nAIBugHunter [52]\n2023\nMIT License\nhttps://github.com/awsm-research/aibughunter\nARMONY [53]\n2013\nNot Available\nNot Available\nAutosploit [54]\n2020\nNot Available\nNot Available\nAVAIN [55]\n2019\nMIT License\nhttps://github.com/ra1nb0rN/Avain\nBbuzz [56]\n2017\nMIT License\nhttps://github.com/lockout/Bbuzz\nBlack Ostrich [57]\n2023\nNot Available\nNot Available\nBlack Widow [58]\n2021\nNot Specified\nhttps://github.com/SecuringWeb/BlackWidow\nBleem [59]\n2023\nNot Available\nNot Available\nCairis [60]\n2020\nApache 2.0\nhttps://github.com/cairis-platform/cairis\nCensys [61]\n2015\nApache 2.0 + ISC\nhttps://github.com/zmap/zgrab2\nChainsaw [62]\n2016\nNot Available\nNot Available\nChucky [63]\n2013\nGPLv3\nhttps://github.com/a0x77n/chucky-ng/\nCommix [64]\n2019\nGPLv3\nhttps://github.com/commixproject/commix\nCryptoGuard [65]\n2019\nGPLv3\nhttps://github.com/CryptoGuardOSS/cryptoguard\nCuPerFuzzer [66]\n2021\nNot Specified\nhttps://github.com/little-leiry/CuPerFuzzer\nDeemon [67]\n2017\nGPLv3\nhttps://github.com/tgianko/deemon\nDelta [68]\n2017\nNot Specified\nhttps://github.com/seungsoo-lee/DELTA\nDFBC [69]\n2021\nNot Available\nNot Available\nDiane [70]\n2021\nNot Specified\nhttps://github.com/ucsb-seclab/diane\nEBF [71]\n2021\nMIT License\nhttps://github.com/fatimahkj/EBF\nELAID [72]\n2020\nNot Available\nNot Available\nESASCF [73]\n2023\nAvailable upon\nrequest\nAvailable upon request\nESRFuzzer [74]\n2021\nNot Available\nNot Available\nESSecA [75]\n2022\nNot Specified\nhttps://github.com/DanieleGranata94/SlaGenerator\nFirmaster [76]\n2018\nNot Available\nNot Available\nFUGIO [77]\n2022\nNot Specified\nhttps://github.com/WSP-LAB/FUGIO\nFUSE [78]\n2020\nNot Specified\nhttps://github.com/WSP-LAB/FUSE\nGail-PT [79]\n2023\nNot Specified\nhttps://github.com/Shulong98/GAIL-PT/\n12\nTool Name\nYear\nLicense Type\nSource Code Repository\nGNPassGAN [80]\n2022\nMIT License\nhttps://github.com/fangyiyu/GNPassGAN/\nHARMer [81]\n2020\nMIT License\nhttps://github.com/whistlebee/harmat\nHILTI [82]\n2014\nNot Specified\nhttps://github.com/rsmmr/hilti\nIoTFuzzer [83]\n2018\nNot Specified\nhttps://github.com/zyw-200/IOTFuzzer_Full\nJCOMIX [84]\n2019\nNot Specified\nhttps://github.com/SERG-Delft/JCOMIX\nLAID [85]\n2018\nNot Available\nNot Available\nLink [86]\n2022\nNot Specified\nhttps://github.com/WSP-LAB/Link\nLore [87]\n2023\nNot Available\nNot Available\nLTESniffer [88]\n2023\nNot Specified\nhttps://github.com/SysSec-KAIST/LTESniffer\nMace [89]\n2014\nNot Available\nNot Available\nMAIT [90]\n2021\nNot Available\nNot Available\nMAL [91]\n2018\nApache 2.0\nhttps://github.com/mal-lang/malcompiler/\nMaliceScript [92]\n2018\nNot Available\nNot Available\nMasat [93]\n2015\nNot Available\nNot Available\nMirage [94]\n2019\nMIT License\nhttps://github.com/RCayre/mirage\nMitch [95]\n2019\nNot Specified\nhttps://github.com/alviser/mitch\nMoScan [96]\n2021\nUPL 1.0\nhttps://github.com/baigd/moscan\nNAUTILUS [97]\n2023\nApache 2.0\nhttps://github.com/chenleji/nautilus\nNAVEX [98]\n2018\nGPLv3\nhttps://github.com/aalhuz/navex\nNetCAT [99]\n2020\nNot Available\nNot Available\nNeuralNetworkCracking [100]\n2016\nApache 2.0\nhttps://github.com/cupslab/neural_network_cracking\nNo Name (CSRF) [101]\n2020\nNot Available\nNot Available\nNo Name (TTCN-3) [102]\n2018\nNot Available\nNot Available\nNoCrack [103]\n2015\nMIT License\nhttps://github.com/rchatterjee/nocrack\nNodeXP [104]\n2021\nNot Specified\nhttps://github.com/esmog/nodexp\nObjectMap [105]\n2019\nMIT License\nhttps://github.com/georlav/objectmap\nOMEN [106]\n2015\nMIT License\nhttps://github.com/RUB-SysSec/OMEN\nOSV [107]\n2017\nGPLv3\nhttps://github.com/Emoform/OSV\nOwfuzz [108]\n2023\nGPLv3\nhttps://github.com/alipay/Owfuzz\nPassGAN [109]\n2019\nMIT License\nhttps://github.com/brannondorsey/PassGAN\nPassGPT [110]\n2023\nCC BY-NC 4.0\nhttps://github.com/javirandor/passgpt\nPasswordCrackingTraining\n[111]\n2022\nMIT License\nhttps://github.com/focardi/PasswordCrackingTraining\nPenQuest [112]\n2020\nProprietary\nhttps://www.pen.quest/\nPentestGPT [113]\n2023\nMIT License\nhttps://github.com/GreyDGL/PentestGPT\nPhpSAFE [114]\n2015\nGPLv2\nhttps://github.com/JoseCarlosFonseca/phpSAFE\nPJCT [115]\n2015\nNot Available\nNot Available\nProject Achilles [116]\n2019\nLGPLv3\nhttps://github.com/secure-software-engineering/\nachilles-benchmark-depscanners\nPURITY [117]\n2015\nProprietary\nNot Available\nPyciuti [118]\n2023\nNot Available\nNot Available\nRAT [119]\n2022\nAvailable upon\nrequest\nAvailable upon request\nRevealer [120]\n2021\nGPLv2\nhttps://github.com/cuhk-seclab/Revealer\nRiscyROP [121]\n2022\nNot Available\nNot Available\nRobin [122]\n2020\nNot Specified\nhttps://github.com/olmps/Robin\nROSploit [123]\n2019\nMIT License\nhttps://github.com/seanrivera/rosploit\nRT-RCT [124]\n2021\nNot Available\nNot Available\nScanner++ [125]\n2023\nNot Available\nNot Available\nSemanticGuesser [126]\n2014\nNot Specified\nhttps://github.com/vialab/semantic-guesser\nSerialDetector [127]\n2021\nNot Specified\nhttps://github.com/yuske/SerialDetector\nShoVAT [128]\n2016\nNot Available\nNot Available\nSnout [129]\n2019\nNot Specified\nhttps://github.com/nislab/snout/\nSOA-Scanner [130]\n2013\nNot Available\nNot Available\nSpicy [131]\n2016\nMIT License\nhttps://github.com/zeek/spicy/\nSuperEye [132]\n2019\nNot Available\nNot Available\nSVED [133]\n2016\nNot Available\nNot Available\nTAMELESS [134]\n2023\nNot Specified\nhttps://github.com/FulvioValenza/TAMELESS\nTChecker [135]\n2022\nNot Available\nNot Available\nTORPEDO [136]\n2015\nNot Available\nNot Available\nUE Security Reloaded [137]\n2023\nNot Available\nNot Available\nUntangle [138]\n2023\nNot Specified\nhttps://github.com/untangle-tool/untangle\nVAPE-BRIDGE [139]\n2022\nNot Available\nNot Available\nVERA [140]\n2013\nNot Available\nNot Available\n13\nTool Name\nYear\nLicense Type\nSource Code Repository\nVUDDY [141]\n2017\nMIT License\nhttps://github.com/squizz617/vuddy\nVulcan [142]\n2013\nNot Available\nNot Available\nVulCNN [143]\n2022\nNot Specified\nhttps://github.com/CGCL-codes/VulCNN\nVulDeePecker [144]\n2018\nApache 2.0\nhttps://github.com/CGCL-codes/VulDeePecker\nVulnet [145]\n2019\nNot Available\nNot Available\nVulnsloit [146]\n2020\nAvailable upon\nrequest\nAvailable upon request\nVulPecker [147]\n2016\nNot Specified\nhttps://github.com/vulpecker/Vulpecker\nWAPTT [148]\n2014\nNot Available\nNot Available\nWebFuzz [149]\n2021\nGPLv3\nhttps://github.com/ovanr/webFuzz\nWebVIM [150]\n2020\nNot Available\nNot Available\nTable 1: Classified tools, licence type and source code availability\n5.1. Process Based Classification: PTES and Mitre ATT&CK\nPTES Phase\nNo.\nVulnerability Analysis\n80\nExploitation\n39\nPost Exploitation\n21\nIntelligence Gathering\n20\nThreat Modelling\n6\nReporting\n4\nPre-engagement Interactions\n0\n(a) Number of Tools identified according to PTES phases\nMitre ATTA&CK Phase\nNo.\nReconnaissance\n84\nInitial Access\n48\nResource Development\n21\nDiscovery\n11\nExecution\n9\nCredential Access\n9\nCollection\n2\nImpact\n1\nPersistence\n0\nPrivilege Escalation\n0\nDefense Evasion\n0\nLateral Movement\n0\nCommand and Control\n0\nExfiltration\n0\n(b) Number of Tools identified according to Mitre ATT&CK\nphases\nTable 2: Tool counts for process-based classification\nTable B.7 shows the tools identified and classified for the different PTES phases. The tools distribution\naccording to steps in the Ethical Hacking process is reported in Table 2a. The absence of tools in the Pre-\nengagement Interactions phase aligns with expectations, considering its non-technical nature, which typically\ninvolves scoping, planning, and agreement on the terms of engagement between the penetration tester and\nthe client. This may potentially explain the lack of interest from the research community.\nThe significant presence of tools in the Vulnerability Analysis phase (80 tools) reflects the importance of\nidentifying and assessing vulnerabilities within target systems, which is essential for any security assessment\nactivity. In particular, many scanners were developed.\nAdditionally, 20 tools possess Intelligence Gathering capabilities, primarily because this phase sometimes\noverlaps with vulnerability analysis attackers interact with target systems.\nExploitation (39 tools) has a substantial number of tools designed to exploit identified vulnerabilities to\ngain unauthorised access to systems. Post Exploitation has slightly fewer tools than other phases (21 tools).\nWe found 6 tools for Threat Modelling.\nHowever, other researchers have developed some methodologies\nwhich are not implemented as tools that we discuss in Section 5.3.\nThe Mitre ATT&CK classification table (Table B.8) shows tools associated with different stages of the\nattack process. The Reconnaissance (84 tools) and Initial Access (48 tools) stages exhibit a higher concen-\ntration of tools (Table 2b), indicating the significance of these phases. This aligns with PTES findings, where\nmost research effort seems to be put into vulnerability analysis. Resource Development (21) and Discovery\n(11) are also well represented. In contrast, stages such as Persistence and Privilege Escalation appear to have\n14\nno tools directly associated with them, implying potential areas of development of novel research-informed\ntools. Further details on the classification, with sub areas, are presented in Table B.9.\nOverall, researchers seem to have focused more on the technical aspects of the penetration testing process,\nand most of the tools have vulnerability analysis capability.\n5.2. Knowledge Based Classification: NCSC CyBOK and ACM CCS\nCyBOK Knowledge Area\nNo.\nSoftware and Platform Security: Software Security\n77\nSoftware and Platform Security: Web & Mobile Security\n38\nInfrastructure Security: Network Security\n26\nAttacks & Defences: Adversarial Behaviours\n9\nSystems Security: Authentication, Authorisation & Accountability\n9\nSystems Security: Distributed Systems Security\n3\nInfrastructure Security: Applied Cryptography\n2\nHuman, Organisational & Regulatory Aspects: Human Factors\n2\nAttacks & Defences: Malware & Attack Technology\n1\nInfrastructure Security: Physical Layer & Telecommunications Security\n1\nHuman, Organisational & Regulatory Aspects: Privacy & Online Rights\n1\nTable 3: Number of Tools identified according to CyBOK, for KAs with at least 1 tool\nTable B.10 presents the classification of tools according to NCSC CyBOK. The distribution of tools\nacross different Knowledge Areas (KAs) reflects the range of cybersecurity domains and disciplines covered\nby penetration testing activities. From the categorisation in Table 3, it is evident that certain areas, such as\nSoftware & Platform Security and Networks Security, are unsurprisingly more prominent, indicating areas of\nemphasis within cybersecurity practice. It should also be noted that while each category addresses specific\naspects of cybersecurity, many tools may span multiple categories.\nMost of the tools are classified under Software & Platform Security: Software Security: Detection of\nVulnerabilities (57 tools), which is a subcategory of Software & Platform Security: Software Security. The\nsignificant number of tools in this area reflects the recognition of software as a primary attack vector and\ndemonstrates the research community\u2019s effort. Moreover, 38 tools are classified in the Software & Platform\nSecurity: Web & Mobile Security, highlighting the research work done to address the challenges posed by\nthe development and deployment of web and mobile applications.\nThe 26 tools falling under Infrastructure Security: Network Security demonstrate the academic efforts in\nthis area, ranging from network traffic monitoring and anomaly detection to implementing robust encryption\nprotocols.\nNine tools classified under the Attacks & Defences: Adversarial Behaviours category indicate research\naimed at understanding and simulating the techniques used by attackers.\nAmong the various categories within the ACM CCS, EH tools in Table B.11 predominantly fall into\nthe Security and Privacy root category, specifically within the subcategories of Systems Security, Software\nand Application Security, and Network Security. In general, ACM CSS categories are too coarse to capture\ncertain peculiarities of the tools. As CyBOK is specific to cybersecurity, it is more granular than ACM CSS\nfor our purpose. We discuss the limitations in the classification in Section 5.4.\nSoftware And Application Security: Vulnerability Management: Vulnerability Scanners has the highest\nnumber of tools: 73. This indicates the proactive measures the research community is taking to detect\nvarious issues, from misconfigurations and missing patches to software flaws and weak passwords.\nThe\ncategorisation of 35 tools under the Software and Application Security: Web Applications Security highlights\nthe focus on developing specialised tools designed to test and secure web applications. These tools analyse web\napplications for vulnerabilities like SQL injection, cross-site scripting (XSS), and security misconfigurations.\n22 tools were categorised under the Network Security domain and sub-domains, focusing on protecting\nthe data during its transmission across networks. These tools are essential for detecting intrusions, monit-\noring network traffic for suspicious activities, and implementing preventive measures such as firewalls and\n15\nencryption. EH tools within this category enable security professionals to simulate attacks on the network\nto identify vulnerabilities and assess the network\u2019s resilience against cyber threats.\n5.3. A note on Threat Modelling tools and methodologies\nThe PTES classification shows that the number of tools identified for Threat Modelling is relatively small.\nHowever, the research field is somewhat active, but some contributions only propose new methodologies\nwithout implementing specific tools, so we did not include them in the classification. Some threat modelling\nmethodologies discussed here cover different frameworks, each designed to improve security in cyber-physical\nsystems (CPS), information technology, and critical infrastructure areas.\nDing et al.\u2019s [151] framework integrates vulnerability assessment with reliability and threat analysis\n(both external and internal) within a unified model focused on critical infrastructures integrated with CPS.\nSimilarly, Agadakos et al. [152] present a novel method for modelling cyber and physical interactions within\nIoT networks. The study emphasises the identification of unexpected event chains that could lead to security\nvulnerabilities. Additionally, Castiglione et al. [153] proposed a hazard-driven threat modelling methodology\ntailored for CPS, focusing on the interplay between security, reliability, and safety.\nTo highlight the critical role of human factors in information security, Evans et al. [154] introduce a\nmethodology that systematically evaluates information security incidents caused by human error, adopting\nthe HEART methodology from high-reliability sectors like aviation and energy. Also, David et al. [155]\npropose using timed automata to model socio-technical attacks, offering a method that incorporates time\nand cost into analysing socio-technical systems and attacks.\nFurthermore, using formal methods for security analysis, Malik et al. [156] introduce an algorithm that\ntransforms Attack Trees into Markov Decision Process models, aiming to address the limitations of scalability,\nstate explosion, and manual interaction inherent in Attack Trees.\nCollectively, these methodologies demonstrate a shift towards integrating diverse analytical tools and\nperspectives, from human factors to formal methods and system theory, to address the increasingly complex\nand interconnected nature of modern systems.\n5.4. Limitations surrounding the classification of tools\nThe four classification systems identified in this study were chosen due to their overall topic coverage\nand relevance to computing topics and concepts. When combined, the classifications can give a precise idea\nof what a tool can do and the cybersecurity field it falls under.\nAlthough these four classifications are fit for purpose when considered within the scope and the goal\nof this survey and its goals, there are some challenges and potential limitations in classifying tools in this\nmanner. The first issue is an inconsistency within the specificity of the tools.\nFor example, within MITRE [11], despite having hundreds of individual attack techniques and vectors,\nsuch as Enterprise: Privilege Escalation: Access Token Manipulation: SID-History injection and Enterprise:\nDefence Evasion: Hijack Execution Flow: Path Interception by PATH Environment Variable, which are\nvery specific vectors down to the operating system architecture within individual target systems, MITRE\nlumps the entire concept of compromising a web application under Enterprise: Initial Access: Exploit Public-\nFacing Application. There are other means of gaining specificity within this classification system, such as\nthe Reconnaissance: Vulnerability Scanning field. All together, these give a more specific view of the tool.\nHowever, both fields do not offer the specificity of the SID-History Injection or Path Interception by PATH\nEnvironment Variable fields.\nAnother issue relates to tools that can be used for activities potentially unintended by the application\ndesigner. Deciding whether to include the ACM CSS Security and privacy: Network security: Denial-of-\nservice attacks field when considering a web application fuzzer that could potentially crash the target web\napplication (and making similar decisions throughout the classification of the many tools within this survey),\nposed a significant challenge, as opinions on whether to include the field may vary between researchers.\nAnother issue was found when trying to discern the exact scope of any given tools. There were many\ninstances when, in the paper, a tool would present itself as one thing, for example, being capable of completing\n16\na specific task within the abstract and majority of the discussion in the associated paper, only to reveal that\nthe tool itself is a proof-of-concept, with limited capabilities than was assumed initially.\nTo fully understand each tool\u2019s potential, an in-depth evaluation involving running the tools and testing\ntheir capabilities would be necessary. However, this is beyond the scope of this survey. Future work could\nfocus on specific subject clusters to provide an in-depth comparison of the tools.\n6. Evaluation\nThis section evaluates 100 research-informed Ethical Hacking tools developed within the past decade\nand included in this study. The discussion will focus on several key aspects: their licensing, release dates,\navailability of source code, the activity level of their development, whether the papers publishing them\nunderwent peer review and their alignment with recognised cybersecurity frameworks.\n6.1. Peer Review Analysis and Date of Publication\nOf the 100 tools discussed in this study, 96% were disseminated through peer-reviewed journals and\nconferences (Table 4a).\nPeer Reviewed\nNo.\n%\nY\n96\n96.00%\nN\n4\n4.00%\nTotal\n100\n100.00%\n(a) Peer Reviewed\nSource Code Avail.\nNo.\n%\nY\n59\n59.00%\nN\n41\n41.00%\nTotal\n100\n100.00%\n(b) Source Code Available\nTable 4: Classification\nThis indicates that the proposed tools have undergone rigorous validation, guaranteeing their effectiveness\nand reliability. This emphasis on peer-reviewed tools in our study reflects our commitment to ensuring readers\nhave confidence in the credibility and utility of the tools presented. The remaining tools, which were not\nyet peer-reviewed at the time of our survey but are available as pre-print (e.g., [113, 54]), potentially under\nreview or to be submitted in the near future.\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\nYear\n0\n2\n4\n6\n8\n10\n12\n14\n16\nNumber of Tools\nDistribution of Tools Across Years\nFigure 6: Distribution of Tool Releases Over Last Decade\n17\nFurthermore, the distribution of tool releases over the years, as illustrated in Figure 6, shows an increase\nin development activities in recent years, with 16 tools released in 2023, 14 in 2021, and 13 in 2019. This\ntrend mirrors the evolution of cybersecurity threats and the response from the research community to address\nthese problems.\n6.2. Types of Licensing and Source Code Availability\nThis section delves into the licensing types, development activity, and source code availability for the\ntools discussed in this paper. The evaluation found that out of the 100 tools included in this study, 59 have\ntheir source code readily available on GitHub, while 41 are unavailable (Table 4b).\n0\n5\n10\n15\n20\n25\n30\n35\nNumber of Tools\nNot Available\nOpen Source - Not Specified\nOpen Source - MIT License\nOpen Source - GPLv3\nOpen Source - Apache 2.0\nAvailable upon request\nProprietary\nOpen Source - GPLv2\nOpen Source - Apache 2.0 + ISC\nOpen Source - LGPLv3\nOpen Source - CC BY-NC 4.0\nOpen Source - UPL 1.0\nLicence Type\nDistribution of Tools by Licence Type\nFigure 7: Distribution of Tools by License Type\nThe types of licenses for the tools available on GitHub vary widely (Figure 7), mostly open source\nlicences, ranging from the MIT License (17 tools), GPLv3 (8 tools). However, for 23 tools, the licence is\nNot Specified. The lack of clear licensing information could be an oversight by developers regarding the\nimportance of transparent communication of usage rights. This ambiguity may potentially hinder adoption\nand adaptability. In the absence of a license, default copyright laws apply, meaning that authors retain all\nrights to their source code and reproduction, distribution, or creation of derivative works is prohibited.\nOverall, the fact that source code is available for more than half of the tools (59 tools) demonstrates\nthe cybersecurity researchers\u2019 dedication to openness and active community participation.\nHowever, 41\ninaccessible tools in this study highlight an ongoing debate: the need to balance transparency with security,\nprivacy, and commercial interests.\n6.3. Tools Development and Maintenance\nWe examined the GitHub repositories of the 59 publicly available tools to understand specific features\nrelated to tool development and maintenance. Specifically, we collected data on the number of Commits and\nthe dates of the first and the last commits. We believe analysing commit activity in GitHub repositories\nprovides insights into the development intensity and duration. However, we must consider that projects can\nmove from one repository to another and that a private repository is used alongside a private one, and the\npublic one is used only for dissemination purposes. Therefore, we can only attempt to capture some trends\nwith this analysis, but we must be cautious about making statements regarding specific projects.\nTable 5a provides an overview of the distribution of project activity periods. We measured the difference\nin months between the first and last commit for the considered projects. The data shows that approximately\n18\nPeriod (Months)\nNo.\n%\n0-3\n19\n32.20%\n4-6\n3\n5.08%\n6-12\n6\n10.17%\n13-24\n6\n10.17%\n25-36\n10\n16.95%\n37-60\n8\n13.56%\n61-inf\n7\n11.86%\nTotal\n59\n100.00%\n(a) Distribution of Period of Project Activity (last \u2013 first commit)\nCommits Range\nNo.\n%\n1-10\n17\n28.81%\n11-50\n19\n32.20%\n51-100\n4\n6.78%\n101-250\n6\n10.17%\n251-500\n5\n8.47%\n501-inf\n8\n13.56%\nTotal\n59\n100.00%\n(b) Distribution of Number of Project\u2019s Commits\nTable 5: Distribution of Project Activity and Commits\n% of Project Activity\nNo\n%\n0-0\n5\n8.47%\n1-25\n12\n20.34%\n26-50\n15\n25.42%\n51-75\n5\n8.47%\n76-99\n2\n3.39%\n100-100\n20\n33.90%\nTotal\n59\n100.00%\nTable 6: Distribution of Project Activity within 3 Years after Release\none-third of the projects have a relatively short activity span of less than 3 months. This may indicate that\nthe publication of the source code has likely been instrumental to the publication of the paper.\nComparing the year of publication of the paper and the date of the first commit, we can see that around\n90% of the projects have been active sometime in the year before or after the publication.\nThis is not\nsurprising. However, fewer than 10% of the projects have been active 2 or more years before the publication,\naccording to data publicly available.\nAnother parameter we considered is the number of commits (Table 5b). The data highlights the diversity\nin project engagement and development intensity within the examined dataset. Around 30% of the projects\nhave just up to 10 commits. As the commit ranges increase, the percentage of projects gradually decreases.\nProjects with a higher number of commits (500+) account for 13.33% of the total, indicating a smaller but\nnotable proportion of projects with an extensive development history.\nTable 6 represents the activity level as a percentage of the time between a project\u2019s release and the\npresent. 100\u2013100 indicates continuous activity throughout the period, while 0\u20130 signifies no activity at all.\nFor example, 26\u201350 means that the project was active for at least 26% up to 50% of the considered time\ninterval (9\u201318 months).\nThe data shows that one-third of the projects remained active within three years after their release.\nHowever, over half of these projects ceased activity after just 1.5 years.\nThis trend sheds light on the\ndevelopment lifecycle of these projects, indicating a high initial engagement that tends to taper off relatively\nquickly for a significant number of projects.\n6.4. Recommendations\nTo improve the dissemination and enhance the impact of research on the wider community of practitioners,\nwe suggest that researchers should:\n\u2022 Distribute the software open source without exception and keep the software repository alive. Other-\nwise, it would be impossible for any dissemination within the practitioner community [157].\n\u2022 Clearly specify the licence type and adopt standard FOSS licences [158], like GNU GPLv3, so that\nusers may know precisely what they can do with the tools.\n19\n\u2022 Produce comprehensive documentation and tutorials on how to use the tools. Currently, this is partially\ndone, but the existing documentation is primarily intended to support the peer-review process, as noted\nby Mirhosseini (2020) [159].\n\u2022 Try to maintain the software by implementing bug fixes and improvements after publishing the paper.\nThis is particularly challenging for academic projects as they operate with limited availability of human\nresources and funding. Once the project ends or the paper is published, the interest of the researcher\ntends to move to new projects [157].\n\u2022 Some tools may become obsolete due to several reasons: incompatibility with more recent versions of\nother software (OSs, libraries, applications, etc.) or the vulnerability covered by the tool being patched.\nIn those cases, authors should update the documentation and clearly specify the requirements, scope,\ncontext and limitations of the tool.\n\u2022 Try to implement their solutions in modular tools utilised by practitioners like Metasploit and Nmap.\nWhile this can be possible for certain solutions, in general, some tools are so different and innovative\nthat they cannot fit into the API of existing tools.\n\u2022 Consider that public dissemination mitigates the risk of weaponizing tools by promoting a level playing\nfield approach.\nAnother question is: what can practitioners and industry do? We cannot expect many individual prac-\ntitioners to engage directly with the research outputs except when driven by intellectual curiosity. However,\nthe IT and cybersecurity industry should try to incentivise collaboration with academia. Industry and ven-\nture capitalists likely monitor academic research to understand the state-of-the-art and gain inspiration for\nnew ideas. However, more effective engagement from the industry may help academic research to enhance\nits impact.\nFor example, the industry currently invests in bug bounty programs, providing monetary incentives to\nsecurity researchers to identify and report vulnerabilities. This informs bug fixes and improves the quality\nof the product overall. However, this process is typically ex-post and not something an academic researcher\nwould be directly involved in, except if finding a bug is a by-product of the research work. However, in many\ncases, academic researchers would likely engage in a responsible disclosure process.\nConcretely, the industry could redirect some funding from bug bounty programs [160] to grant schemes\nsupporting open source projects, for example, the Google Summer of Code, which could enable researchers to\ndevelop and enhance their tools. This is likely something that medium to large companies could be interested\nin. Still, it requires a shift in perspective beyond the immediate rewards and limited risks and commitments\nof current bug bounty programs.\nFinally, an important aspect is that most research-informed tools are developed by small teams, sometimes\neven by a single individual, for non-profit reasons. Given the working conditions in many higher education\ninstitutions, especially in countries where the sector is very competitive and commercialised [161], it is often\nthe case that, unless a research grant supports the project, the developers end up working significant hours\nduring their own free time [162].\n6.5. Related Work\nExisting reviews of Ethical Hacking tools typically focus on industry practitioner tools, with occasional\nconsideration of research-informed tools. Many popular practitioner tools included in these reviews (e.g., [15,\n2, 163, 164]) are recurrent: Nmap, Metasploit Framework, OpenVAS/GVM, Nessus, Burp Suite, OWASP\nZAP, SQLMap, BeEF, Nikto, W3AF, and others.\nYaacoub et al. [15] survey and classify around 40 practitioner tools and OSs (e.g., Kali Linux and\nParrotOS), focusing on challenges and issues associated with EH activities. The paper maps the tools and\ntechniques for vulnerability assessment, network scanning tools, crimeware toolkits, etc., considering different\nattack types and application domains. Duque Anton et al. [2] include in their review around 25 popular\npractitioner tools, and their capabilities are evaluated using criteria such as active maintenance, licensing,\n20\ncommercial aspects (paid vs. free), and technical elements like programming language and interaction with\nother technology.\nMoreover, Alhamed et al. [163] analyse around 20 mostly practitioner tools, with good coverage of network\nvulnerability and exploitation in particular. However, they consider existing research proposals for mitigating\ntechniques. Additionally, Sarker et al. [164] reviewed penetration testing frameworks, processes, tools, and\nscoring methods, encompassing around 15 practitioner EH tools.\nIn some cases, authors restrict their focus to a specific domain. For example, Yaacoub et al. [6] provide\ngood coverage of practitioner commercial and open-source solutions for EH in IoT, while Altulaihan et al. [8]\nreview and compare industry practitioner tools for web application penetration testing. Similarly, Shahid\net al. [165] provide a comparative analysis of commercial and open-source tools for Web Application Se-\ncurity with a focus on accuracy and precision. Alzahrani et al. [166] and Ravindran et al. [167] compare\nmany EH tools, including both industry practitioner tools and a few research-informed tools for web vul-\nnerability assessment and exploitation, e.g., XSS and SQL injection. Kowta et al. [168] analysed a variety\nof reconnaissance and information-gathering tools and techniques including Google Dorking, Shodan, Web\nCrawler, Recon-ng, Photon, Final Recon, and Sherlock. The tools are compared with criteria such as up-\ndate frequency, languages used, and supported OSs, with some research-informed tools also included in the\nreview.\nIn a few cases, authors systematically classify the tools according to some methodology or taxonomy.\nDuque Anton et al. [2] compared and classified practitioner tools, mapping them to the Mitre ATT&CK\nframework. Moreover, Zilberman et al. [169] provide a review of threat emulators while mapping to the\nMitre ATT&CK matrix tactics.\nShanley et al. [9] review and compare several methodologies and frameworks, including PTES, Build-\ning Security in Maturity Model (BSIMM), Metasploit Framework (MSF), OWASP Testing Guide (OTG),\nInformation Systems Security Assessment Framework (ISSAF), and the Open Source Security Testing Meth-\nodology Manual (OSSTMM). However, no tools are reviewed; therefore, no classification is attempted.\nOur study significantly differs from previously published papers in both the number of tools covered\nand its exclusive focus on research-informed EH tools. By categorising the tools into process-based and\nknowledge-based classifications, we organise them according to specific phases, demonstrating where and\nwhen they are utilised in EH processes. While other reviews include classifications, the main contribution\nof our work is a more comprehensive and unique exploration. We surveyed 100 tools and classified them\naccording to four different frameworks: PTES, Mitre ATT&CK, CyBOK, and ACM CCS. Additionally, we\nidentify and analyze trends in developing, maintaining, and disseminating novel research-informed tools.\n7. Conclusion and Future work\nAddressing emerging cyber security threats requires developing Ethical Hacking tools to identify vulner-\nabilities in networks, systems, and applications. While practitioners design most EH tools for immediate use\nin the industry, academic researchers have also significantly contributed to developing security tools. How-\never, there is a noticeable gap in awareness among practitioners about academic contributions in this domain.\nThis paper evaluates 100 research-informed tools, examining aspects such as licensing, release dates, source\ncode availability, development activity, and peer review status. These tools are then aligned with established\nframeworks like PTES, the Mitre ATT&CK framework, CyBOK, and ACM CCS.\nKey findings indicate that 96% of these tools originate from peer-reviewed research, with 59% having their\nsource code readily accessible on GitHub. Activity analysis shows that 90% of projects were active around\ntheir publication year, yet activity dwindles significantly within 1.5 years post-release. Under the PTES\nframework classification, most tools are designed for vulnerability analysis, whereas threat modelling tools\nare relatively few. The CyBOK and ACM CCS classifications emphasise tools for detecting vulnerabilities,\nparticularly under the Software & Platform Security and Security And Privacy, respectively. For the Mitre\nATT&CK framework, most tools primarily focus on reconnaissance, highlighting the vital role of information\ngathering in identifying network and system details. Future directions involve experimental evaluations and\ncomparisons of specific tools, integration of existing practitioner tools, and exploration of using large language\n21\nmodels in penetration testing.\nThis approach aims to bridge the gap between industry and academia,\nenhancing the development and effectiveness of Ethical Hacking tools.\nAcknowledgement\nThe authors express their gratitude to Zia Ush Shamszaman, Sachin Manakkil Jolly, and the Advanced\nPractice students of the MSc Cybersecurity course at Teesside University for engaging in constructive dis-\ncussions and recommending certain tools for inclusion in this survey.\nAuthor Contributions\nConceptualization, P.M.; methodology, P.M .; software, P.M.; validation, P.M. and L.H.; formal analysis,\nP.M.; investigation, P.M., L.G., L.H, C.O and M.M.; resources, P.M.; data curation, P.M and L.H.; writing\u2014\noriginal draft preparation, P.M., L.G., L.H, C.O and M.M.; writing\u2014review and editing, P.M., L.G., L.H,\nC.O and M.M.; visualization, P.M., L.G., and C.O.; project administration, P.M., L.G., and C.O.; funding\nacquisition, N/A. All authors have read and agreed to the published version of the manuscript.\nAppendix A. List of Abbreviations\nABAC\nAttribute-Based Access Control\nACL\nAccess Control Lists\nAE\nAuthenticated Encryption\nAPT\nAdvanced Persistent Threats\nAP\nAccess Point\nATT&CK\n(Mitre) Adversarial Tactics, Techniques, and Common Knowledge\nC2\nCommand and Control\nCBAC\nCode-Based Access Control\nCI\nContinuous Integration\nCLI\nCommand Line Interface\nCPE\nCommon Platform Enumeration\nCSRF\nCross Site Request Forgery\nCSS\n(ACM) Computing Classification System\nCTI\nCyber Threat Intelligence\nCVE\nCommon Vulnerabilities and Exposures\nCVSS\nCommon Vulnerability Scoring System\nCWE\nCommon Weakness Enumeration\nCyBOK\nCyber Security Body of Knowledge\nDFBC\nDigital Footprint and Breach Check\nDFD\nData Flow Diagrams\nDoS\nDenial of Service\nDPI\nDeep Packet Inspection\nDRL\nDeep Reinforcement Learning\nE2E\nEnd-to-End\nEH\nEthical Hacking\nETSI\nEuropean Telecommunications Standards Institute\nFTP\nFile Transfer Protocol\nGAIL\nGenerative Adversarial Imitation Learning\nGAN\nGenerative Adversarial Network\nGUI\nGraphical User Interface\nHARM\nHierarchical Attack Representation Model\nICS\nIndustrial Control Systems\n22\nIO2BO\nInteger-Overflow-to-Buffer-Overflow\nIoMT\nInternet of Medical Things\nIoT\nInternet of Things\nISAAF\nInformation System Security Assessment Framework\nLFA\nLink Flooding Attacks\nMAC\nMessage Authentication Code\nMITM\nMan-In-The-Middle\nNFC\nNear-Field Communications\nNHS\nNational Health Service\nNVD\nNational Vulnerability Database\nOSINT\nOpen-Source INTelligence\nOSPF\nOpen Shortest Path First\nOSSTMM\nOpen-Source Security Testing Methodology Manuel\nOS\nOperating System\nOWASP\nOpen Web Application Security Project\nPCI DSS\nPayment Card Industry Data Security Standard\nPOI\nPHP Object Injection\nPTES\nPenetration Testing Execution Standard\nRBAC\nRole-Based Access Control\nRDP\nRemote Desktop Protocol\nRL\nReinforcement Learning\nSDN\nSoftware Defined Networking\nSDR\nSoftware Defined Radio\nSET\nSocial Engineering Toolkit\nSOHO\nSmall Office and Home Office\nSP\nSpecial Publication\nSQLIA\nSQL Injection Attacks\nSSJI\nServer-Side Javascript Injection\nTPM\nTrusted Platform Module\nTTP\nTactics, Techniques, and Procedures\nUEFU\nUnrestricted Executable File Upload\nUFU\nUnrestricted File Upload\nVAPT\nVulnerability Assessment and Penetration Testing\nVM\nVirtual Machine\nWCMS\nWeb Content Management Systems\nXMLi\nXML injection\nXSS\nCross Site Scripting\n23\nAppendix B. Classification\nPTES Phase\nTools\nPre-Engagement In-\nteractions\nIntelligence Gathering\nBbuzz [56], DFBC [69], ESASCF [73], ESRFuzzer [74], Firmaster [76], IoTFuzzer\n[83], LTESniffer [88], Lore [87], MaliceScript [92], Owfuzz [108], Pyciuti [118], RT-\nRCT [124], SVED [133], Scanner++ [125], ShoVAT [128], SuperEye [132], TOR-\nPEDO [136], UE Security Reloaded [137], Vulcan [142], Vulnsloit [146]\nThreat Modelling\nCairis [60], ESSecA [75], HARMer [81], MAL [91], PenQuest [112], TAMELESS\n[134]\nVulnerability Analysis\nAIBugHunter [52], ARMONY [53], AVAIN [55], Autosploit [54], Bbuzz [56], Black\nOstrich [57], Black Widow [58], Bleem [59], Censys [61], Chainsaw [62], Chucky [63],\nCommix [64], CryptoGuard [65], CuPerFuzzer [66], Deemon [67], Delta [68], Diane\n[70], EBF [71], ELAID [72], ESASCF [73], ESRFuzzer [74], FUGIO [77], FUSE [78],\nFirmaster [76], Gail-PT [79], HILTI [82], IoTFuzzer [83], JCOMIX [84], LAID [85],\nLink [86], Lore [87], Mace [89], MaliceScript [92], Masat [93], Mirage [94], Mitch\n[95], MoScan [96], NAUTILUS [97], NAVEX [98], No Name (CSRF) [101], No Name\n(TTCN-3) [102], NodeXP [104], OSV [107], ObjectMap [105], Owfuzz [108], PJCT\n[115], PURITY [117], PentestGPT [113], PhpSAFE [114], Project Achilles [116], Py-\nciuti [118], RAT [119], ROSploit [123], RT-RCT [124], Revealer [120], RiscyROP\n[121], Robin [122], SOA-Scanner [130], SVED [133], Scanner++ [125], SerialDe-\ntector [127], ShoVAT [128], Snout [129], Spicy [131], SuperEye [132], TChecker\n[135], TORPEDO [136], UE Security Reloaded [137], VAPE-BRIDGE [139], VERA\n[140], VUDDY [141], VulCNN [143], VulDeePecker [144], VulPecker [147], Vulcan\n[142], Vulnet [145], Vulnsloit [146], WAPTT [148], WebFuzz [149], WebVIM [150]\nExploitation\nChainsaw [62], Commix [64], ELAID [72], ESASCF [73], FUGIO [77], Firmaster\n[76], Gail-PT [79], LAID [85], LTESniffer [88], Lore [87], MAIT [90], Mace [89],\nMaliceScript [92], Mirage [94], Mitch [95], NAUTILUS [97], NAVEX [98], NetCAT\n[99], No Name (TTCN-3) [102], NodeXP [104], OSV [107], Owfuzz [108], PURITY\n[117], PentestGPT [113], Pyciuti [118], ROSploit [123], Revealer [120], RiscyROP\n[121], Robin [122], SOA-Scanner [130], SVED [133], SerialDetector [127], Snout\n[129], TORPEDO [136], Untangle [138], VAPE-BRIDGE [139], Vulnsloit [146],\nWAPTT [148], WebVIM [150]\nPost Exploitation\nADaMs [51], AVAIN [55], Delta [68], Diane [70], ESRFuzzer [74], GNPassGAN [80],\nHILTI [82], IoTFuzzer [83], Mirage [94], NeuralNetworkCracking [100], NoCrack\n[103], OMEN [106], OSV [107], PassGAN [109], PassGPT [110], PasswordCrack-\ningTraining [111], Pyciuti [118], SemanticGuesser [126], Snout [129], Spicy [131],\nUntangle [138]\nReporting\nESASCF [73], Firmaster [76], No Name (TTCN-3) [102], Pyciuti [118]\nTable B.7: PTES classification\n24\nMitre ATT&CK\nTools\nReconnaissance\nAIBugHunter [52], ARMONY [53], AVAIN [55], AVAIN [55], Autosploit [54], Bbuzz\n[56], Black Ostrich [57], Black Widow [58], Bleem [59], Cairis [60], Censys [61],\nChainsaw [62], Chucky [63], Commix [64], CryptoGuard [65], CuPerFuzzer [66],\nDFBC [69], Deemon [67], Delta [68], Delta [68], Diane [70], EBF [71], ELAID [72],\nESASCF [73], ESRFuzzer [74], ESSecA [75], FUGIO [77], FUSE [78], Firmaster\n[76], Gail-PT [79], Gail-PT [79], HILTI [82], HILTI [82], IoTFuzzer [83], JCOMIX\n[84], LAID [85], LTESniffer [88], Link [86], Lore [87], Mace [89], MaliceScript [92],\nMaliceScript [92], Masat [93], Mirage [94], Mirage [94], Mitch [95], MoScan [96],\nNAUTILUS [97], NAVEX [98], No Name (CSRF) [101], No Name (TTCN-3) [102],\nNo Name (TTCN-3) [102], NodeXP [104], OSV [107], ObjectMap [105], Owfuzz\n[108], PURITY [117], PenQuest [112], PentestGPT [113], PhpSAFE [114], Pyciuti\n[118], Pyciuti [118], RAT [119], ROSploit [123], RT-RCT [124], RT-RCT [124], Re-\nvealer [120], RiscyROP [121], Robin [122], SOA-Scanner [130], SVED [133], Scan-\nner++ [125], SerialDetector [127], ShoVAT [128], ShoVAT [128], Snout [129], Snout\n[129], Spicy [131], Spicy [131], SuperEye [132], TAMELESS [134], TChecker [135],\nTORPEDO [136], UE Security Reloaded [137], VAPE-BRIDGE [139], VERA [140],\nVUDDY [141], VulCNN [143], VulDeePecker [144], VulPecker [147], Vulcan [142],\nVulnet [145], Vulnsloit [146], WAPTT [148], WebFuzz [149], WebVIM [150]\nResource Develop-\nment\nAIBugHunter [52], Autosploit [54], Chucky [63], CuPerFuzzer [66], ELAID [72],\nESASCF [73], HARMer [81], HILTI [82], LAID [85], MAIT [90], MAL [91], Ow-\nfuzz [108], PJCT [115], PJCT [115], Project Achilles [116], Revealer [120], Spicy\n[131], UE Security Reloaded [137], Untangle [138], VUDDY [141], VulCNN [143],\nVulPecker [147]\nInitial Access\nBlack Ostrich [57], Black Widow [58], Censys [61], Chainsaw [62], Commix [64],\nDeemon [67], ESASCF [73], ESSecA [75], FUGIO [77], FUSE [78], Firmaster [76],\nGail-PT [79], JCOMIX [84], Link [86], Lore [87], MAL [91], Mace [89], MaliceScript\n[92], Masat [93], Mitch [95], NAUTILUS [97], NAVEX [98], NetCAT [99], No Name\n(CSRF) [101], NodeXP [104], OSV [107], ObjectMap [105], PURITY [117], Pentest-\nGPT [113], PhpSAFE [114], Pyciuti [118], RAT [119], Revealer [120], Robin [122],\nSOA-Scanner [130], SVED [133], Scanner++ [125], SerialDetector [127], ShoVAT\n[128], TChecker [135], TORPEDO [136], VAPE-BRIDGE [139], VERA [140], Vulcan\n[142], Vulnet [145], WAPTT [148], WebFuzz [149], WebVIM [150]\nExecution\nBbuzz [56], ESASCF [73], Lore [87], Mirage [94], PentestGPT [113], ROSploit [123],\nRiscyROP [121], SVED [133], Vulnsloit [146]\nPersistence\nPrivilege Escalation\nDefense Evasion\nCredential Access\nADaMs [51], Firmaster [76], GNPassGAN [80], LTESniffer [88], NeuralNetwork-\nCracking [100], NoCrack [103], OMEN [106], PassGAN [109], PassGPT [110], Pass-\nwordCrackingTraining [111], SemanticGuesser [126]\nDiscovery\nAVAIN [55], Cairis [60], Firmaster [76], HILTI [82], Masat [93], PenQuest [112], RT-\nRCT [124], Snout [129], Spicy [131], TAMELESS [134], Vulcan [142]\nLateral Movement\nCollection\nHILTI [82], Spicy [131]\nCommand And Con-\ntrol\nExfiltration\nImpact\nRevealer [120], TORPEDO [136]\nTable B.8: Mitre ATT&CK classification\n25\nMitre ATT&CK\nTools\nCollection: Adversary-In-\nThe-Middle\nHILTI [82], Spicy [131]\nCredential Access: Brute\nForce: Password Cracking\nGNPassGAN [80], PassGAN [109], PasswordCrackingTraining [111]\nDiscovery: Cloud Infra-\nstructure Discovery\nMASAT [93], VULCAN [142]\nDiscovery: Network Ser-\nvice Discovery\nAVAIN [55], Firmaster [76], HILTI [82], RT-RCT [124], Snout [129], Spicy [131]\nEnterprise: Credential\nAccess: Brute Force\nFirmaster [76]\nEnterprise: Credential\nAccess: Network Sniffing\nLTESniffer [88]\nEnterprise: Impact: Ser-\nvice Stop\nTORPEDO [136]\nEnterprise: Initial Access:\nExternal Remote Services\nNetCAT [99]\nExecution\nBbuzz [56], Lore [87], Mirage [94], PentestGPT [113], ROSploit [123], SVED\n[133], Vulnsloit [146]\nExecution: Inter-Process\nCommunication\nRiscyROP [121]\nGather Victim Network\nInformation\nLore [87], PentestGPT [113], SVED [133]\nImpact: Endpoint Denial\nOf Service\nRevealer [120]\nInitial Access\nGail-PT [79], Lore [87], OSV [107], PentestGPT [113], SVED [133]\nInitial Access: Exploit\nPublic Facing Application\nCommix [64], JCOMIX [84], Mitch [95], No Name (CSRF) [101], PURITY\n[117], Puciuty [118], Robin [122], Vulnet [145], WebVIM [150], ZGrab [61]\nInitial Access: Exploit\nPublic Facing-Application\nWAPTT [148]\nInitial Access: Exploit\nPublic-Facing Application\nBlack Ostrich [57], Black Widow [58], Chainsaw [62], Deemon [67], FUGIO [77],\nFUSE [78], Firmaster [76], Link [86], MASAT [93], Mace [89], MaliceScript [92],\nNAUTILUS [97], NAVEX [98], NodeXP [104], ObjectMap [105], PhpSAFE\n[114], Revealer [120], SOA-Scanner [130], Scanner++ [125], SerialDetector [127],\nShoVAT [128], TChecker [135], TORPEDO [136], VAPE-BRIDGE [139], VERA\n[140], VULCAN [142], WebFuzz [149]\nReconnaissance: Active\nScanning\nLTESniffer [88], TORPEDO [136]\nReconnaissance: Active\nScanning Vulnerability\nScanning\nNodeXP [104]\n26\nMitre ATT&CK\nTools\nReconnaissance: Active\nScanning: Vulnerability\nScanning\nAIBugHunter [52], ARMONY [53], AVAIN [55], Autosploit [54], Bbuzz [56],\nBlack Ostrich [57], Black Widow [58], Chainsaw [62], Chucky [63], Commix [64],\nCryptoGuard [65], CuPerFuzzer [66], DELTA [68], DIANE [70], Deemon [67],\nEBF [71], ELAID [72], ESRFuzzer [74], FUGIO [77], FUSE [78], Firmaster [76],\nGail-PT [79], HILTI [82], IoTFuzzer [83], JCOMIX [84], LAID [85], Link [86],\nLore [87], MASAT [93], Mace [89], MaliceScript [92], Mirage [94], Mitch [95],\nNAUTILUS [97], NAVEX [98], No Name (CSRF) [101], No Name (TTCN-3)\n[102], OSV [107], ObjectMap [105], Owfuzz [108], PURITY [117], PentestGPT\n[113], PhpSAFE [114], Puciuty [118], ROSploit [123], RT-RCT [124], Revealer\n[120], RiscyROP [121], Robin [122], SOA-Scanner [130], SVED [133], Scan-\nner++ [125], SerialDetector [127], ShoVAT [128], Snout [129], Spicy [131], Su-\nperEye [132], TChecker [135], UE Security Reloaded [137], VAPE-BRIDGE\n[139], VERA [140], VUDDY [141], VULCAN [142], VulCNN [143], VulDeeP-\necker [144], VulPecker [147], Vulnet [145], Vulnsloit [146], WAPTT [148], Web-\nFuzz [149], WebVIM [150], ZGrab [61]\nReconnaissance: Gather\nVictim Identity Informa-\ntion\nDFBC [69]\nReconnaissance: Gather\nVictim Network Informa-\ntion\nAVAIN [55], DELTA [68], Gail-PT [79], HILTI [82], MaliceScript [92], Mirage\n[94], Puciuty [118], RT-RCT [124], ShoVAT [128], Snout [129], Spicy [131]\nReconnaissance: Gather\nVictim Network Informa-\ntion: Network Topology\nNo Name (TTCN-3) [102]\nReconnaissance: Resource\nDevelopment\nHARMer [81]\nResource Development:\nDevelop Capabilities\nHILTI [82], PICT [115], Spicy [131]\nResource Development:\nDevelop Capabilities: Ex-\nploits\nELAID [72], LAID [85], Owfuzz [108], Project Achilles [116], UE Security Re-\nloaded [137], VulCNN [143]\nResource Development:\nDevelop Capabilities: Mal-\nware\nMAIT [90]\nResource Development:\nObtain Capabilities: Ex-\nploits\nAIBugHunter [52], Autosploit [54], Chucky [63], CuPerFuzzer [66], PICT [115],\nRevealer [120], VUDDY [141], VulPecker [147]\nTable B.9: Mitre ATT&CK classification (Details)\n27\nCyBOK\nTools\nAttacks & Defences: Adversarial Behaviours\nCairis [60], ESASCF [73], ESSecA [75], HARMer\n[81], Lore [87], MAL [91], PenQuest [112], PenQuest\n[112], SVED [133], TAMELESS [134]\nAttacks & Defences: Malware & Attack Technology:\nMalware Analysis: Analysis Techniques: Static Ana-\nlysis/Dynamic Analysis\nMAIT [90]\nHuman, Organisational & Regulatory Aspects: Hu-\nman Factors\nESSecA [75], TAMELESS [134]\nHuman, Organisational & Regulatory Aspects: Pri-\nvacy & Online Rights: Privacy Engineering: Privacy\nEvaluation\nDFBC [69]\nInfrastructure Security: Applied Cryptography:\nCryptographic Implementation: Api Design For\nCryptographic Libraries\nCryptoGuard [65]\nInfrastructure Security: Applied Cryptography:\nCryptographic Implementation: Cryptographic Lib-\nraries\nFirmaster [76]\nInfrastructure Security: Cyber Physical Systems\nESSecA [75], TAMELESS [134]\nInfrastructure Security: Network Security\nAVAIN [55], Cairis [60], Delta [68], ESASCF [73],\nGail-PT [79], HARMer [81], HILTI [82], Lore [87],\nMasat [93], NetCAT [99], SVED [133], Spicy [131]\nInfrastructure Security: Network Security: Network\nProtocols And Their Security\nOSV [107], SuperEye [132], Vulnsloit [146]\nInfrastructure Security: Network Security: Network\nProtocols And Their Security: Security At The Inter-\nnet Layer\nBbuzz [56]\nInfrastructure Security: Network Security: Network\nProtocols And Their Security: Security At The Inter-\nnet Layer: Ipv6 Security\nNo Name (TTCN-3) [102]\nInfrastructure Security: Network Security: Network-\ning Applications\nVulcan [142]\nInfrastructure Security: Network Security: Network-\ning Applications: Local Area Networks\nESRFuzzer [74], Firmaster [76], HILTI [82], No Name\n(TTCN-3) [102], Pyciuti [118], Spicy [131]\nInfrastructure Security: Network Security: Network-\ning Applications: Wireless Networks\nESRFuzzer [74], Firmaster [76], LTESniffer [88], Ow-\nfuzz [108], RT-RCT [124], Snout [129], UE Security\nReloaded [137]\nInfrastructure Security: Network Security: Other\nNetwork Security Topics: Cloud And Data Center\nSecurity\nMasat [93], Vulcan [142]\nInfrastructure Security: Network Security: Software-\nDefined Networking And Network Function Virtual-\nization\nDelta [68]\nInfrastructure Security: Physical Layer & Telecom-\nmunications Security: Identification: Attacks On\nPhysical Layer Identification\nSnout [129]\nOperating Systems & Virtualization Security: Oper-\nating System Hardening\nROSploit [123]\nPhysical Layer & Telecommunications Security:\nPhysical Layer Security Of Selected Communication\nTechnologies: Cellular Networks: 4G (Lte)\nLTESniffer [88]\n28\nCyBOK\nTools\nPhysical Layer & Telecommunications Security:\nPhysical Layer Security Of Selected Communication\nTechnologies: Cellular Networks: 5G\nUE Security Reloaded [137]\nResource Development: Develop Capabilities: Ex-\nploits\nESASCF [73]\nSoftware And Platform Security: Software Security:\nCategories Of Vulnerabilities: Memory Management\nVulnerabilities\nARMONY [53], ELAID [72], IoTFuzzer [83], LAID\n[85], WAPTT [148]\nSoftware And Platform Security: Software Security:\nDetection Of Vulnerabilities\nARMONY [53], AVAIN [55], Autosploit [54], Bbuzz\n[56], Black Ostrich [57], Black Widow [58], Cairis\n[60], Censys [61], Chainsaw [62], Commix [64], Cryp-\ntoGuard [65], Deemon [67], EBF [71], ESASCF [73],\nFUGIO [77], FUSE [78], Firmaster [76], HILTI [82],\nJCOMIX [84], Link [86], Mace [89], MaliceScript [92],\nMirage [94], Mitch [95], MoScan [96], NAUTILUS\n[97], NAVEX [98], No Name (CSRF) [101], No Name\n(TTCN-3) [102], NodeXP [104], OSV [107], Ob-\njectMap [105], Owfuzz [108], PJCT [115], PURITY\n[117], PentestGPT [113], Project Achilles [116], Py-\nciuti [118], RAT [119], ROSploit [123], RT-RCT\n[124], Revealer [120], SOA-Scanner [130], Scan-\nner++ [125], SerialDetector [127], ShoVAT [128],\nSnout [129], Spicy [131], SuperEye [132], TChecker\n[135], TORPEDO [136], UE Security Reloaded [137],\nVAPE-BRIDGE [139], VERA [140], VulDeePecker\n[144], Vulcan [142], Vulnet [145], Vulnsloit [146],\nWAPTT [148], WebFuzz [149], WebVIM [150]\nSoftware And Platform Security: Software Security:\nDetection Of Vulnerabilities: Dynamic Detection\nBbuzz [56], Black Ostrich [57], CuPerFuzzer [66], Di-\nane [70], EBF [71], Project Achilles [116]\nSoftware And Platform Security: Software Security:\nDetection Of Vulnerabilities: Dynamic Detection:\nBlack-Box Fuzzing\nBleem [59], Delta [68], IoTFuzzer [83], Owfuzz [108]\nSoftware And Platform Security: Software Security:\nDetection Of Vulnerabilities: Dynamic Detection:\nGenerating Relevant Executions: Dynamic Symbolic\nExecution\nRiscyROP [121]\nSoftware And Platform Security: Software Security:\nDetection Of Vulnerabilities: Static Detection\nAIBugHunter [52], Chucky [63], ELAID [72], LAID\n[85], PhpSAFE [114], Untangle [138], VUDDY [141],\nVulCNN [143], VulPecker [147]\nSoftware And Platform Security: Software Security:\nDynamic Detection\nWebFuzz [149]\nSoftware And Platform Security: Software Security:\nSide-Channel Vulnerabilities\nNetCAT [99]\nSoftware And Platform Security: Web & Mobile Se-\ncurity\nBlack Ostrich [57], EBF [71], Mace [89], MoScan [96],\nNAUTILUS [97], NAVEX [98], RAT [119], Revealer\n[120], Robin [122], Scanner++ [125], ShoVAT [128],\nVAPE-BRIDGE [139]\nSoftware And Platform Security: Web & Mobile Se-\ncurity: Client Side Vulnerabilities And Mitigations\nMaliceScript [92]\n29\nCyBOK\nTools\nSoftware And Platform Security: Web & Mobile Se-\ncurity: Server Side Vulnerabilities And Mitigations\nCensys [61], PURITY [117], Pyciuti [118], Robin\n[122], SOA-Scanner [130], TORPEDO [136], VERA\n[140], Vulnet [145]\nSoftware And Platform Security: Web & Mobile Se-\ncurity: Server Side Vulnerabilities And Mitigations:\nInjection Vulnerabilities\nCommix [64], FUGIO [77], ObjectMap [105], Serial-\nDetector [127]\nSoftware And Platform Security: Web & Mobile Se-\ncurity: Server Side Vulnerabilities And Mitigations:\nInjection Vulnerabilities: Command Injection\nJCOMIX [84], NodeXP [104]\nSoftware And Platform Security: Web & Mobile Se-\ncurity: Server Side Vulnerabilities And Mitigations:\nInjection Vulnerabilities: Cross-Site Request Forgery\n(Csrf)\nDeemon [67], Mitch [95], No Name (CSRF) [101]\nSoftware And Platform Security: Web & Mobile Se-\ncurity: Server Side Vulnerabilities And Mitigations:\nInjection Vulnerabilities: Cross-Site Scripting (Xss)\nBlack Widow [58], Chainsaw [62], PhpSAFE [114],\nTChecker [135], WAPTT [148], WebFuzz [149]\nSoftware And Platform Security: Web & Mobile Se-\ncurity: Server Side Vulnerabilities And Mitigations:\nInjection Vulnerabilities: Cross-Site Scripting (Xss):\nReflected Xss\nLink [86]\nSoftware And Platform Security: Web & Mobile Se-\ncurity: Server Side Vulnerabilities And Mitigations:\nInjection Vulnerabilities: Sql-Injection\nChainsaw [62], PhpSAFE [114], TChecker [135],\nWAPTT [148], WebVIM [150]\nSoftware And Platform Security: Web & Mobile Se-\ncurity: Server Side Vulnerabilities And Mitigations:\nInjection Vulnerabilities: User Uploaded Files\nFUSE [78]\nSystems Security: Authentication, Authorisation &\nAccountability: Authentication: Passwords\nADaMs [51], GNPassGAN [80], NeuralNetwork-\nCracking [100], NoCrack [103], OMEN [106],\nPassGAN [109], PassGPT [110], PasswordCrack-\ningTraining [111], SemanticGuesser [126]\nSystems Security: Distributed Systems Security\nCairis [60], MAL [91], PenQuest [112]\nTable B.10: CyBOK classification\n30\nACM CCS\nTools\nHardware: Emerging Technologies: Analysis And\nDesign Of Emerging Devices And Systems: Emerging\nArchitectures\nAVAIN [55], Diane [70], EBF [71], IoTFuzzer [83],\nMirage [94], ROSploit [123], RT-RCT [124], Snout\n[129]\nHuman-Centered Computing: Human Computer In-\nteraction (Hci): Interactive Systems And Tools\nTAMELESS [134]\nNetworks: Network Components: Intermediate\nNodes: Routers\nESRFuzzer [74]\nNetworks: Network Protocols: Network Layer Proto-\ncols: Routing Protocols\nNo Name (TTCN-3) [102], OSV [107]\nSecurity And Privacy: Cryptography\nEBF [71]\nSecurity And Privacy: Human And Societal Aspects\nOf Security And Privacy\nDFBC [69]\nSecurity And Privacy: Intrusion/Anomaly Detection\nAnd Malware Mitigation: Malware And Its Mitiga-\ntion\nMAIT [90]\nSecurity And Privacy: Network Security\nAVAIN [55], Bbuzz [56], Censys [61], NetCAT [99],\nNo Name (TTCN-3) [102], OSV [107], Pyciuti\n[118], RT-RCT [124], SuperEye [132], Vulcan [142],\nVulnsloit [146]\nSecurity And Privacy: Network Security: Mobile\nAnd Wireless Security\nESRFuzzer [74], Firmaster [76], LTESniffer [88], Ow-\nfuzz [108], Scanner++ [125], Snout [129], UE Secur-\nity Reloaded [137]\nSecurity And Privacy: Network Security: Security\nProtocols\nHILTI [82], No Name (TTCN-3) [102], Spicy [131]\nSecurity And Privacy: Network Security: Web Pro-\ntocol Security\nBbuzz [56]\nSecurity And Privacy: Security Services: Authoriza-\ntion\nADaMs [51], GNPassGAN [80], NeuralNetwork-\nCracking [100], NoCrack [103], OMEN [106],\nPassGAN [109], PassGPT [110], PasswordCrack-\ningTraining [111], SemanticGuesser [126]\nSecurity And Privacy: Software And Application Se-\ncurity\nCryptoGuard [65], VulDeePecker [144]\nSecurity And Privacy: Software And Application Se-\ncurity: Domain-Specific Security And Privacy Archi-\ntectures\nESSecA [75], MAL [91], PenQuest [112]\nSecurity And Privacy: Software And Application Se-\ncurity: Software Reverse Engineering\nRiscyROP [121], VulCNN [143]\nSecurity And Privacy: Software And Application Se-\ncurity: Software Security Engineering\nAIBugHunter [52], Chucky [63], CuPerFuzzer [66],\nELAID [72], LAID [85], PJCT [115], Project Achilles\n[116], Untangle [138], VUDDY [141], VulPecker [147]\n31\nACM CCS\nTools\nSecurity And Privacy: Software And Application Se-\ncurity: Web Applications Security\nBlack Ostrich [57], Black Widow [58], Censys [61],\nChainsaw [62], Commix [64], Deemon [67], FUGIO\n[77], FUSE [78], JCOMIX [84], Link [86], Mace\n[89], MaliceScript [92], Mitch [95], MoScan [96],\nNAUTILUS [97], NAVEX [98], No Name (CSRF)\n[101], NodeXP [104], ObjectMap [105], PURITY\n[117], PhpSAFE [114], Pyciuti [118], RAT [119],\nRobin [122], SOA-Scanner [130], SerialDetector [127],\nShoVAT [128], TChecker [135], TORPEDO [136],\nVAPE-BRIDGE [139], VERA [140], Vulnet [145],\nWAPTT [148], WebFuzz [149], WebVIM [150]\nSecurity And Privacy: Systems Security: Denial Of\nService Attacks\nRevealer [120]\nSecurity And Privacy: Systems Security: Distributed\nSystems Security\nMAL [91], PenQuest [112]\nSecurity And Privacy: Systems Security: Vulnerabil-\nity Management: Penetration Testing\nCairis [60], Diane [70], ESASCF [73], ESSecA [75],\nGail-PT [79], HARMer [81], Lore [87], MAL [91],\nMirage [94], PenQuest [112], PentestGPT [113], Py-\nciuti [118], SVED [133], TAMELESS [134]\nSecurity And Privacy: Systems Security: Vulnerabil-\nity Management: Vulnerability Scanners\nAIBugHunter [52], ARMONY [53], AVAIN [55],\nAutosploit [54], Black Ostrich [57], Black Widow\n[58], Bleem [59], Censys [61], Chainsaw [62], Chucky\n[63], Commix [64], CryptoGuard [65], CuPerFuzzer\n[66], Deemon [67], Delta [68], EBF [71], ELAID\n[72], ESSecA [75], FUGIO [77], FUSE [78], Firmas-\nter [76], HILTI [82], IoTFuzzer [83], JCOMIX [84],\nLAID [85], Link [86], Mace [89], MaliceScript [92],\nMasat [93], Mitch [95], MoScan [96], NAUTILUS\n[97], NAVEX [98], No Name (CSRF) [101], No Name\n(TTCN-3) [102], NodeXP [104], OSV [107], Ob-\njectMap [105], Owfuzz [108], PJCT [115], PURITY\n[117], PhpSAFE [114], Project Achilles [116], Pyciuti\n[118], RAT [119], ROSploit [123], RT-RCT [124],\nRevealer [120], RiscyROP [121], Robin [122], SOA-\nScanner [130], Scanner++ [125], SerialDetector [127],\nShoVAT [128], Snout [129], Spicy [131], SuperEye\n[132], TChecker [135], TORPEDO [136], UE Secur-\nity Reloaded [137], Untangle [138], VAPE-BRIDGE\n[139], VERA [140], VUDDY [141], VulCNN [143],\nVulDeePecker [144], VulPecker [147], Vulcan [142],\nVulnet [145], Vulnsloit [146], WAPTT [148], Web-\nFuzz [149], WebVIM [150]\nTable B.11: ACM CCS classification\n32\nAppendix C. Review of Tools\nWe present a review of the EH tools included in our survey, in alphabetical order according to their\nnames.\nAppendix C.1. Reducing bias in modelling real-world password strength via deep learning and dynamic dic-\ntionaries\nADaMs (2021, Pasquini et al. [51]) is an advanced tool aimed at improving the precision of modelling\nreal-world password strengths. This tool leverages deep neural networks to simulate the methodology used\nby adversaries when constructing attack configurations. The efficiency of AdaMs was demonstrated through\ncase studies involving MyHeritage and Youku using the rules-set generated and RockYou as the external\ndictionary. For MyHeritage, ADaMs\u2019 attack matches the precision of the optimal dictionary approach and\nachieves a comparable number of successful guesses. Similarly, for Youku, Adams outperforms the optimal\ndictionary in terms of guessing speed, achieving faster results within the initial (1011) guesses, demonstrating\nits effectiveness in real-world scenarios.\nAppendix C.2. AIBugHunter: A Practical tool for predicting, classifying and repairing software vulnerabilit-\nies\nAIBugHunter (2023, Fu et al. [52]) is a machine learning-based approach to detecting and mitigating\nsoftware security bugs within C and C++. This package is integrated into Visual Studio Code to better bridge\nthe gap between real-world developers and academic contributions to vulnerability detection frameworks.\nThe tool was around 10% to 141% more effective than the compared baseline models at predicting CWE-ID\nwithin evaluated code samples.\nAppendix C.3. ARMORY: An automatic security testing tool for buffer overflow defect detection\nARMONY (2013, Chen et al. [53]) is a kernel-based tool for detecting zero-day Buffer Overflow vulnerabilities\nto prevent the overflowing of sensitive data structures by testing the system and recording the results in a\ndump file. The components of the software include a coordinator, a checker, and two message storages.\nAppendix C.4. Autosploit: A Fully Automated Framework for Evaluating the Exploitability of Security Vul-\nnerabilities\nAutosploit (2020, Moscovich et al. [54]) is a framework for virtualising and evaluating the components\nwithin a system that are required for exploitation via a given vector. Although in the paper the authors\noutline several factors that can affect exploitation, but the simulation agent only supports four actions:\nstopping services , deleting packages, changing system firewall rules, and modifying file permissions. The\ntool was tested against a Metasploitable 2 machine, which is designed to be intentionally vulnerable against\na set number of attacks, and the attacker agent only supported Metasploit-based attacks, once again limiting\nwhat exploits can and cannot be assessed to those supported with a Metasploit module.\nAppendix C.5. AVAIN \u2013 A Framework for Automated Vulnerability Indication for the IoT in IP-based Net-\nworks\nAVAIN (2019, Egert et al.\n[55]) is a framework for Automated Vulnerability Indication in IP-based\nInternet of Things (IoT) networks. It aims at enhancing security practices of IoT system administrators by\nautomatically deploying existing tools to generate results, presented according to the Common Vulnerability\nScoring System (CVSS). The framework\u2019s modular design enables the user to integrate arbitrary vulnerability\nscanners and analysis methods. AVAIN includes four components: the Controller processes user instructions\nto orchestrate the tasks. The Module Updater keeps modules up to date, the Scanner performs vulnerability\nscanning, and the Analyser processes the collected data.\n33\nAppendix C.6. Bbuzz: A bit-aware fuzzing framework for network protocol systematic reverse engineering\nand analysis\nBbuzz (2017, Blumbergs et al. [56]) is an open-source bit-aware network protocol fuzzing framework\ndesigned for systematic reverse engineering and analysis of network protocols. Operating at Layer-2, Bbuzz\nfacilitates rapid protocol assessment, automatic test case creation, and user-friendly fuzzing. In a propriet-\nary NATO Link-1 protocol case study, researchers used Bbuzz to efficiently reverse engineer the protocol,\nrevealing critical components within a single day.\nAppendix C.7. Black Ostrich: Web Application Scanning with String Solvers\nBlack Ostrich (2023, Eriksson et al. [57]) is a tool for crawling web applications with a content-aware\napproach.\nThe tool is able to differentiate expected input formats such as email addresses, usernames,\netc., using regex interpretation to discover more pages on web applications than other crawling approaches.\nThis tool was shown to be effective when compared against existing web application crawlers such as ZAP,\nEnemy, and Arachni. This tool was shown to achieve 99% coverage, achieving high effectiveness in crawling\ncapability. The tool also showed a 52% improvement over existing methods when discovering vulnerable\npatterns within those same web pages.\nAppendix C.8. Black Widow: Blackbox Data-driven Web Scanning\nBlack Widow (2021, Eriksson et al. [58]) uses a black box data-driven approach for deep crawling and\nscanning of modern web apps. It focuses on three core pillars: navigation modelling, traversing, and tracking\ninter-state dependencies. Black Widow demonstrates significant code coverage improvements compared to\nother crawlers. Moreover, it excels in vulnerability scanning, detecting more cross-site scripting vulnerab-\nilities without false positives, identifying missed vulnerabilities in older applications, and uncovering new\nvulnerabilities in production software like HotCRP, osCommerce, PrestaShop, and WordPress.\nAppendix C.9. Bleem: Packet Sequence Oriented Fuzzing for Protocol Implementations\nBleem (2023, Luo et al. [59]) is a novel black-box fuzzer designed to enhance the vulnerability detection\nof protocol implementations through packet-sequence-oriented fuzzing. It features a noninvasive feedback\nmechanism that examines system outputs (packet sequences) to deduce the internal state transitions within\nthe protocol implementation. This feedback guides the fuzzing process, including generating packet sequences\nthat align with the protocol\u2019s logic. Bleem significantly outperforms state-of-the-art protocol fuzzers in terms\nof branch coverage and vulnerability detection. It achieves up to a 175% increase in branch coverage within 24\nhours compared to tools like Peach. Furthermore, Bleem discovered 15 security-critical vulnerabilities across\nprominent protocol implementations, resulting in 10 CVEs being attributed, showcasing its effectiveness in\nidentifying previously undetected vulnerabilities.\nAppendix C.10. Contextualisation of Data Flow Diagrams for Security Analysis\nCairis (2020, Faily et al. [60]) is a novel tool for identifying tainted data flows through the contex-\ntualisation of Data Flow Diagrams (DFDs) with other models related to usability and requirements. This\nadaptation of taint analysis, traditionally employed in code analysis to detect insecure data handling, is\napplied to design-level analysis. The Cairis tool identifies potential taint sources from human interactions\nor system processes, as represented in DFDs. The practical viability and the possibility of incorporating\nit into this tool\u2019s current security analysis workflows are demonstrated through its implementation in an\nopen-source software platform.\nAppendix C.11. A Search Engine Backed by Internet-Wide Scanning\nCensys (2015, Durumeric et al. [61]) is a vulnerability scanning tool that leverages data from continuous\nInternet-wide scans. Censys uses existing tools, specifically ZMap [170] and ZGrab, for hosting discovery\nscans across the IPv4 address spaces and application-layer handshakes. Case studies demonstrate Censys\u2019s\napplication in analyzing Industrial Control Systems, vulnerabilities like Heartbleed and SSLv3, and insti-\ntutional attack surfaces. The application of the tool shows Censys\u2019s ability to identify vulnerable devices\nand networks quickly, generate statistical reports on usage patterns, and provide insights into the security\nposture of devices across the internet.\n34\nAppendix C.12. Chainsaw: Chained Automated Workflow-based Exploit Generation\nChainsaw (2016, Alhuzali et al. [62]) offers a solution for automated exploit generation in web applications,\nsurpassing existing methods in identifying and exploiting web injection vulnerabilities. It adeptly handles\nchallenges posed by diverse web app structures, user input, and database back-ends by constructing precise\nmodels of application workflows, schemes, and native functions. Evaluated across 9 open-source applications,\nChainsaw produced over 199 high-quality first- and second-order injection exploits, showcasing its superiority\nover comparable approaches in exploit generation for web vulnerabilities.\nAppendix C.13. Chucky: exposing missing checks in source code for vulnerability discovery\nChucky (2013, Yamaguchi et al. [63]) is a tool aimed at expediting the auditing of software by exposing\nmissing checks in source code, particularly focusing on input validation. By using static tainting techniques,\nChucky identifies anomalies and omitted security-critical conditions, effectively pinpointing 12 previously\nundiscovered vulnerabilities in Pidgin and LibTIFF among five popular open-source projects. This method\nenhances the process of discovering security flaws by highlighting crucial areas of missing input validation\nchecks.\nAppendix C.14. Commix: automating evaluation and exploitation of command injection vulnerabilities in\nWeb applications\nCommix (2019, Stasinopoulos et al. [64]), short for COMMand Injection eXploiter, is an open-source\ntool aimed at automating the detection and exploitation of command injection flaws in web applications.\nCommix\u2019s methodology encompasses attack vector generation, a vulnerability detection module, and an\nexploitation module. The vulnerability detection module utilises the generated attack vectors to probe for\npotential command injection vulnerabilities within target web applications by injecting and attempting com-\nmand execution. Subsequently, the exploitation module leverages any confirmed vulnerabilities, exploiting\nthem with the successful attack vector to facilitate the execution of arbitrary commands by the attacker.\nCommix underwent threefold experimentation\u2014in a virtual lab, against other tools, and within real-world ap-\nplications\u2014demonstrating its efficacy in identifying and exploiting command injection vulnerabilities across\nthese scenarios, thereby demonstrating its significant value in cybersecurity practices.\nAppendix C.15. CryptoGuard: High Precision Detection of Cryptographic Vulnerabilities in Massive-sized\nJava Projects\nCryptoGuard (2019, Rahaman et al. [65]) is a tool with efficient slicing algorithms in Java programs that\nreduce false alerts by 76% to 80% in cryptographic API misuse threats. Running on large-scale projects\nlike Apache and Android apps, CRYPTOGUARD provided security insights and aided projects like Spark,\nRanger, and Ofbiz in code hardening. The tool achieved 98.61% precision by manually confirming 1,277\ntrue positives out of 1,295 Apache alerts. Additionally, it established a benchmark with basic and advanced\ncases, extensively comparing with CrySL, SpotBugs, and Coverity.\nAppendix C.16. Android Custom Permissions Demystified: From Privilege Escalation to Design Shortcom-\nings\nCuPerFuzzer (2021, Li et al. [66]) is an automatic fuzzing tool designed to detect vulnerabilities within\nthe Android OS related to custom permissions.\nThrough extensive testing, it uncovered 2,384 effective\ncases and identified 30 critical paths, exposing severe design shortcomings within the Android permission\nframework.\nThese issues include dangling custom permissions, inconsistent permission group mapping,\npermission elevating, and inconsistent permission definition, potentially allowing malicious apps to gain\nunauthorised system permissions.\n35\nAppendix C.17. Deemon: Detecting CSRF with Dynamic Analysis and Property Graphs\nDeemon (2017, Pellegrino et al. [67]) introduces an automated security testing framework for CSRF vul-\nnerability detection. Utilising a novel modelling paradigm capturing web app aspects in a unified property\ngraph, it autonomously constructs models from dynamic traces and identifies potentially vulnerable opera-\ntions via graph traversals. Deemon\u2019s validation approach conducts security tests, and 14 previously unknown\nCSRF vulnerabilities across 10 open-source web applications have been discovered, showing its efficacy in\ndetecting exploitable issues threatening user accounts and entire websites.\nAppendix C.18. Delta: A security assessment framework for software-defined networks.\nDelta (2017, Lee et al. [68]) is a novel vulnerability analysis tool that focuses specifically on Software\nDefined Networking (SDN) and utilizes known published attacks.\nThe tool uses a fuzzing module that\nautomatically detects zero-day vulnerabilities and has been designed specifically for OpenFlow controller\nplatforms.\nAppendix C.19. DFBC Recon Tool: Digital Footprint and Breach Check Reconnaissance Tool\nDFBC (2021, Yusof et al. [69]) is a reconnaissance tool that provides a Digital Footprint and Breach Check.\nThis software can extract user information that is publicly available and check the breach activity status\nfor accounts with high speed. The tool has both a CLI and GUI and focuses on gathering data on social\nnetworks such as Facebook and X/Twitter, as well as email breaches.\nAppendix C.20. Diane: Identifying fuzzing triggers in apps to generate under-constrained inputs for iot\ndevices\nDiane (2021, Redini et al. [70]) is a tool for vulnerability analysis in IoT targeting Android applications\nused to control IoT devices, at the network level and UI level by detecting fuzzing triggers. The software has\nbeen tested and has successfully identified nine zero-day vulnerabilities. This tool can be applied to discover\nvulnerabilities in Smart Home appliances such as door Smart Locks. Given its reliance on dynamic analysis,\nDiane lacks the capability to detect fuzzing triggers that are not executed by the application. Additionally,\nit is unable to perform fuzzing on nested Java objects.\nAppendix C.21. Finding Security Vulnerabilities in IoT Cryptographic Protocol and Concurrent Implement-\nations\nEBF (2021, Aljaafari et al. [71]) is a tool used for the discovery of vulnerabilities within IoT devices.\nIt uses static and dynamic analysis to discover issues surrounding memory safety, race conditions, thread\nleak and arithmetic overflow. The tool simulates a server and a client in order to detect such vulnerabilities\nwithin the implemented protocol. The tool demonstrated its effectiveness by detecting a previously unknown\nrace condition bug within WOLFMQTT in only 15 minutes with 22 MB memory consumption. The tool\nwas also verified against pre-existing vulnerabilities within OpenSSL and successfully identified the issues as\nexpected.\nAppendix C.22. ELAID: detecting integer-Overflow-to-Buffer-Overflow vulnerabilities by light-weight and ac-\ncurate static analysis\nELAID (2020, Xu et al. [72]) (Enhanced Lightweight and Accurate method of static IO2BO vulnerabil-\nity Detection) is a tool designed for detecting Integer-Overflow-to-Buffer-Overflow (IO2BO) vulnerabilities.\nBuilt on LLVM [171], ELAID\u2019s indirect call analysis aims to eliminate false positives. It has been tested\non NIST\u2019s SAMATE Juliet 1.2 suite [172] and other real-world applications, demonstrating the ability to\ndetect 152 vulnerabilities without false positives. However, the authors acknowledge the need for a combined\nsymbolic execution and fuzzing approach to enhance practicality.\n36\nAppendix C.23. ESASCF: Expertise Extraction, Generalization and Reply Framework for Optimized Auto-\nmation of Network Security Compliance\nESASCF (2023, Ghanem et al. [73]) is a tool designed to address the resource-intensity and repetitiveness\nof the network security auditing process by automating the extraction, processing, storage, and reuse of\nexpertise in similar scenarios or during periodic re-testing. ESASCF leverages industrial and open-source\nvulnerability assessment and penetration testing tools to automate the security compliance (SC) process. It\nis designed to autonomously handle SC re-testing, offloading human experts from repetitive SC segments,\nallowing them to focus on more critical tasks in ad-hoc compliance tests. The framework was tested on\nnetworks of different sizes, demonstrating time efficiency and testing effectiveness improvements. Specifically,\nESASCF significantly reduces the time required for an expert to complete the first security compliance of\ntypical corporate networks by 50% and 20% in re-testing scenarios.\nAppendix C.24. ESRFuzzer: an enhanced fuzzing framework for physical SOHO router devices to discover\nmulti-Type vulnerabilities\nESRFuzzer (2021, Zhang et al. [74]) (Enhanced SOHO Router Fuzzing Framework) is as a vulnerability\ndiscovery tool tailored for small office and home office (SOHO) routers. It operates through an automated\nFWSR fuzzing framework, incorporating KEY-VALUE and CONF-READ semantic models with power man-\nagement for testing environment recovery. Equipped with diverse mutation rules and monitoring mechanisms,\nthe tool efficiently identifies various vulnerability types. ESRFuzzer excels in discovering CONF and READ\noperation issues, particularly in general and D-CONF modes. Testing on 10 routers revealed 136 issues, with\n120 of them confirmed as 0-day vulnerabilities.\nESRFuzzer (2021, Zhang et al. [74]) (Enhanced SOHO Router Fuzzing Framework) is a vulnerability\ndiscovery tool for small office and home office (SOHO) routers, employing an automated FWSR fuzzing\nframework. It uses KEY-VALUE and CONF-READ semantic models with power management for testing\nenvironment recovery. With diverse mutation rules and monitoring mechanisms, it identifies various vulner-\nability types. In general and D-CONF modes, ESRFuzzer excels in discovering CONF and READ operation\nissues. Testing on 10 routers unveiled 136 issues, 120 confirmed as 0-day vulnerabilities.\nAppendix C.25. ESSecA: An automated expert system for threat modelling and penetration testing for IoT\necosystems\nESSecA (2022, Rak et al. [75]) is an autonomous system for Threat Modelling. It employs an algorithm\nthat correlates attacks to threats in the penetration testing of IoT systems using a threat catalogue as a query\ntable. This approach involves mapping threats to attacks and filtering out those that are not relevant. The\ntool is designed with a modular architecture and produces two main outputs: a threat model and a testing\nplan table. It utilises databases, such as Cyber Threat Intelligence (CTI), to enhance its functionality.\nAppendix C.26. Firmaster: Analysis Tool for Home Router Firmware\nFirmaster (2018, Visoottiviseth et al. [76]) is a tool designed to analyse home router firmware source\ncode vulnerabilities. By emulating router firmware, Firmaster identifies, evaluates, and simulates potential\nvulnerabilities. Its functions include Password Cracking, SSL Scanning, and Web Static Analysis, addressing\nthe OWASP Top 10 2014 IoT vulnerabilities. The tool validates the uploaded firmware, attempts to crack\nroot passwords, and verifies secure connections. Furthermore, it conducts static and dynamic web analysis\nto identify PHP source code vulnerabilities.\nAppendix C.27. FUGIO: Automatic Exploit Generation for PHP Object Injection Vulnerabilities\nFUGIO (2022, Park et al. [77]) is a tool addressing PHP Object Injection (POI) vulnerabilities, enabling\nautomatic exploit generation. It uses static and dynamic analyses to create gadget chains, serving as exploit\nblueprints.\nBy running fuzzing campaigns, FUGIO successfully generated exploit objects, producing 68\nexploits from 30 vulnerable applications without false positives. Additionally, it uncovered two previously\nunreported POI vulnerabilities and created five functional exploits, showing its effectiveness in automatic\nexploit creation for POI vulnerabilities.\n37\nAppendix C.28. FUSE: Finding File Upload Bugs via Penetration Testing\nFUSE (2020, Lee et al. [78]) is a penetration testing tool specifically created to uncover Unrestricted\nFile Upload (UFU) and Unrestricted Executable File Upload (UEFU) vulnerabilities in PHP-based server-\nside web applications. It effectively generates exploit payloads via upload requests, overcoming content-\nfiltering checks while preserving file execution semantics. FUSE identified 30 previously unreported UEFU\nvulnerabilities, including 15 CVEs, across 33 real-world web applications.\nAppendix C.29. GAIL-PT: An intelligent penetration testing framework with generative adversarial imitation\nlearning\nGail-PT (2023, Chen et al. [79]) as a framework to automate penetration testing. The tool provides\nadvice to the penetration testers for enhanced decision making reducing the reliance on manual testing\nwhilst utilising Generative Adversarial Imitation Learning (GAIL) based on Reinforcement Learning (RL)\nand Deep Reinforcement Learning (DRL) that innovates the testing process. The tool has been observed to\nachieve state-of-the-art results when applied to the Metasploitable2 penetration testing target VM.\nAppendix C.30. GNPassGAN: Improved Generative Adversarial Networks For Trawling Offline Password\nGuessing\nGNPassGAN (2022, Yu et al. [80]) is designed to enhance offline password guessing by leveraging generative\nadversarial networks (GANs) to generate password guesses by training on datasets obtained from real-world\nbreaches. The tool is benchmarked against PassGAN and other password-guessing methods, using datasets\nlike Rockyou and phpbb for training and evaluation. GNPassGAN demonstrates a significant improvement\nover PassGAN, achieving 88.03% more accurate password guesses and producing 31.69% fewer duplicates\nwhen generating a large number of guesses (108).\nAppendix C.31. HARMer: Cyber-Attacks Automation and Evaluation\nHARMer (2020, Enoch et al.\n[81]) is an automation framework for cyber-attack generation, that ad-\ndresses limitations in manual attack execution by red teams. Using the Hierarchical Attack Representation\nModel (HARM), it outlines requirements, key phases, and security metrics-based attack planning strategies.\nThrough experiments conducted in both enterprise networks and Amazon Web Services, HARMer demon-\nstrates effective modelling of attackers\u2019 operations. This framework offers automated assessment capabilities,\nenabling security administrators to evaluate diverse threats and attacks systematically, facilitating a more\nefficient defence against cyber threats in networked systems.\nAppendix C.32. HILTI: an Abstract Execution Environment for Deep, Stateful Network Traffic Analysis\nHILTI (2014, Sommer et al. [82]) is a tool that employs an abstract machine model specifically designed\nfor deep stateful network traffic analysis. It addresses the significant gap between the high-level conceptu-\nalisation of network analysis tasks (such as pattern searching in HTTP requests) and the intricate low-level\nimplementation details required to execute these tasks efficiently and securely. The system facilitates the\ndevelopment of network traffic analysis applications by providing built-in support for common data types,\nstate management, concurrency models, and a secure memory model. This foundation enables developers\nto create robust applications capable of handling the vast and varied data flows in network traffic, all while\noperating within real-time performance constraints.\nAppendix C.33. IoTFuzzer: Discovering Memory Corruptions in IoT Through App-based Fuzzing\nIoTFuzzer (2018, Chen et al. [83]) is a vulnerability scanning tool designed to detect memory corruption\nvulnerabilities in IoT devices. It utilises an app-based fuzzing framework that operates without the need for\naccess to the devices\u2019 firmware images. The process involves UI analysis to identify network event triggers\nand data-flow analysis to monitor the movement of fields related to the application protocol. By altering\nthe original fields, it generates fuzzing messages. The effectiveness of IoTFuzzer is demonstrated through\nexperiments, where it successfully uncovered 15 serious vulnerabilities in 9 out of 17 evaluated IoT devices.\nThese vulnerabilities range from stack-based and heap-based buffer overflows to null pointer de-references\nand unidentified crashes, highlighting the framework\u2019s capability to reveal critical security flaws.\n38\nAppendix C.34. JCOMIX: a search-based tool to detect XML injection vulnerabilities in web applications\nJCOMIX (2019, Stallenberg et al. [84]) is a tool developed in Java that is designed to generate attacks\n(test objectives) to identify XML injection threats in web applications. It assesses information sanitation\nand validation in micro-service frameworks, aiding in the identification of vulnerabilities.\nAppendix C.35. A Light-Weight and Accurate Method of Static Integer-Overflow-to-Buffer-Overflow Vulner-\nability Detection\nLAID (2018, Hu et al. [85]) is framework designed to accurately identify potential Integer-Overflow-to-\nBuffer-Overflow (IO2BO) vulnerabilities in software. The framework combines inter-procedural dataflow\nanalysis and taint analysis to identify potential vulnerabilities and employs a lightweight method for further\nfiltering out false positives.\nThe framework\u2019s effectiveness was evaluated using NIST\u2019s SAMATE Juliet\ntest suite [172] and six known IO2BO vulnerabilities in real-world applications. The framework effectively\ndetected all known IO2BO vulnerabilities in the test suite without any false positives.\nAppendix C.36. Link: Black-box detection of cross-site scripting vulnerabilities using reinforcement learning\nLink (2022, Lee et al. [86]) is an autonomous black-box web scanner that operates without any input\nfrom humans, using Reinforcement Learning (RL). This software has been observed to decrease the quantity\nof attack attempts and finds more true positives with fewer showing as false. Particular success has been\nobserved in XSS vulnerability detection, which can be leveraged in penetration testing.\nAppendix C.37. Lore a Red Team Emulation Tool\nLore (2023, Holm et al. [87]) is a red team emulation tool utilising boolean logic and trained models\nfor automated red team actions, avoiding manual approaches in cyber defence exercises. Empirical tests\ndemonstrate its model accuracy, achieving twice the compromised machines compared to expert-defined\nmodels and five times more than random action selection.\nLore\u2019s unique approach enhances red team\nautomation, offering a more engaging and educational experience in cyber defence simulations.\nAppendix C.38. LTESniffer: An Open-Source LTE Downlink/Uplink Eavesdropper\nLTESniffer (2023, Hoang et al.\n[88]) is designed to capture both uplink and downlink LTE traffic\npassively. Its architecture encompasses key components such as the conversion of analogue signals to digital\nsamples, identification of modulation schemes and other radio configurations, and data channel decoding,\nwhich processes uplink and downlink signals according to their configurations. The results demonstrate that\nLTESniffer significantly surpasses existing tools and commercial sniffers, achieving a success rate more than\ntwice that of AirScope, particularly in decoding LTE packets within high-throughput scenarios and LTE-A\n(Advanced) environments.\nAppendix C.39. Mace: Detecting privilege escalation vulnerabilities in web applications\nMace (2014, Monshizadeh et al. [89]) is an automatic privilege escalation vulnerability analysis tool for\nweb applications. It analyses large code bases to discover zero-day vulnerabilities by observing inconsistencies\nin the authorisation context and understanding flaws within the application using fundamental abstractions.\nImplementing the tool has been observed to save weeks of labour-intensive work for security professionals in\npenetration testing.\nAppendix C.40. MAIT: Malware Analysis and Intelligence Tool\nMAIT (2021, Yucel et al.[90]) (Malware Analysis and Intelligence Tool) utilises state-of-the-art static and\ndynamic malware analysers alongside open-source malware databases to generate malware signatures and\nintelligence reports. The tool offers chronological data for malicious files, revealing related vulnerabilities\nand providing insights into attribution, techniques, tactics, and procedures employed by Advanced Persistent\nThreat groups in attacks.\n39\nAppendix C.41. A meta-language for threat modelling and attack simulations\nMAL (2018, Johnson et al. [91]) is a tool designed to facilitate the creation of domain-specific attack\nlanguages for cybersecurity threat modelling and attack simulations.\nMAL enables the semi-automated\ngeneration and efficient computation of large attack graphs, distinguishing it from traditional, manual attack\ngraph constructions.\nAppendix C.42. Malicescript: A novel browser-based intranet threat\nMaliceScript (2018, Liu et al. [92]) is a tool that introduces a novel browser-based Web attack model\nallowing browsers to collect intranet topology and infiltrate websites from within. The tool is designed to\nexploit vulnerabilities, insert foreground JavaScript code into malicious web pages, and monitor intranet\ntopology to ensure successful infiltration. Its significance lies in its potential ease of deployment and the\nchallenges associated with detection, emphasising the need for proactive security measures.\nAppendix C.43. Masat: Model-based automated security assessment tool for cloud computing\nMASAT (2015, Mjihil et al. [93]) (Model-based Automated Security Assessment Tool) is a tool designed\nto address security issues of cloud computing. Focused on adaptive security assessments, MASAT utilises\ndistributed agents to evaluate the security of virtual machines at different virtualisation levels. These agents\nemploy vulnerability scanners, representation tools for attack models like graphs, and a communication\nmechanism to share analysis results. MASAT\u2019s contributions include comprehensive security assessments for\nboth the cloud infrastructure and virtual machines, efficient task distribution among agents, and parallelised\nsubsystem assessments to reduce analysis time.\nAppendix C.44. Mirage: towards a Metasploit-like framework for IoT\nMirage (2019, Cayre et al. [94]) is an open-source attack framework applied to IoT by exploiting wireless\ncommunication protocols such as Bluetooth Classic/BLE, Zigbee, Enhanced ShockBurst, Mosart, and Wi-Fi.\nThe software is modular and has the potential for future expansion with additional functionality, which is\nuseful for the development of new wireless protocols. The tool was tested using a Smart Bulb, demonstrating\nsuccess in assessing the attack surface and reverse-engineering the wireless protocol.\nAppendix C.45. Mitch: A Machine Learning Approach to the Black-Box Detection of CSRF Vulnerabilities\nThe study by Mitch (2019, Calzavara et al. [95]) introduced a browser extension that leverages supervised\nmachine learning to identify Cross-Site Request Forgery (CSRF) vulnerabilities. This extension features an\nautomated system that spots sensitive HTTP requests which need CSRF protection for enhanced security. It\nwas trained using nearly 6,000 HTTP requests from popular websites, enabling it to surpass the effectiveness\nof existing detection methods. This advancement was evidenced by finding three CSRF vulnerabilities in\nproduction software that had previously gone unnoticed by the most advanced tools available.\nAppendix C.46. MoScan: a model-based vulnerability scanner for web single sign-on services\nMoScan (2021, Wei et al. [96]) is a vulnerability scanning tool for identifying security vulnerabilities in\nSingle Sign-On (SSO) implementations through model-based scanning. By capturing network traces during\nthe execution of SSO services, MoScan incrementally constructs and refines the state machine. This refined\nstate machine enables MoScan to generate specific payloads for testing protocol participants, aiming to\nidentify security vulnerabilities. MoScan\u2019s adaptability is demonstrated by testing it against other SSO ser-\nvices, such as Twitter, LinkedIn, and GitHub\u2019s authentication plugin in Jenkins. Despite minor adjustments\nneeded for parameter names, MoScan\u2019s primary state machine required minor modifications to accommodate\ndifferent implementations of the OAuth 2.0 standard.\n40\nAppendix C.47. NAUTILUS: Automated RESTful API Vulnerability Detection\nNAUTILUS (2023, Deng et al. [97]) is proposed to improve RESTful API vulnerability scanning by ad-\ndressing limitations in existing black box scanners. It utilises a novel annotation strategy to identify proper\noperation relations and generate meaningful sequences for vulnerability detection. Compared to four state-\nof-the-art tools, NAUTILUS demonstrates superior performance, detecting 141% more vulnerabilities on av-\nerage and covering 104% more API operations across six tested services. In real-world scenarios, NAUTILUS\ndetected 23 unique 0-day vulnerabilities, including a remote code execution flaw in Atlassian Confluence and\nhigh-risk issues in Microsoft Azure.\nAppendix C.48. NAVEX: Precise and Scalable Exploit Generation for Dynamic Web Applications\nNAVEX (2018, Alhuzali et al. [98]) is a tool addressing complex vulnerabilities in multi-tier web applications\nby combining dynamic and static analysis. It integrates both techniques to automatically detect vulnerab-\nilities and create functional exploits. Evaluated over 3.2 million lines of PHP code, NAVEX successfully\nidentified and created 204 exploits, showcasing its scalability and effectiveness in vulnerability analysis and\nexploit generation for large-scale applications.\nAppendix C.49. NetCAT: Practical Cache Attacks from the Network\nNetCAT (2020, Kurth et al.\n[99]) is a tool designed to exploit Data-Direct I/O (DDIO) to observe\nand manipulate Last-Level Cache (LLC) states, thereby leaking sensitive information from a remote target\nserver without requiring local access or execution privileges. NetCAT reverse engineers the behaviour of\nDDIO on Intel processors and develops a network-based PRIME+PROBE cache attack technique by crafting\nspecific network packets to manipulate and observe changes in the LLC\u2019s state. The efficiency of NetCAT\nis demonstrated in various attack scenarios, including creating covert channels between network clients and\nexecuting keystroke timing attacks to infer sensitive information from encrypted SSH sessions.\nAppendix C.50. Fast, lean, and accurate: modelling password guessability using neural networks\nNeuralNetworkCracking (2016, Melicher et al. [100]) is a tool designed to predict the guessability of\npasswords accurately and efficiently in real-time. By harnessing the power of neural networks for generating\nsequential data, the model utilizes an Artificial Neural Network (ANN) to anticipate the next character in a\npassword sequence, thereby estimating the password\u2019s guessability. The effectiveness of the ANN model was\nbenchmarked against traditional password guessability models, where it demonstrated superior performance\nacross various scenarios. Notably, the neural networks were able to guess 70% of 4class8 passwords within\n10151015 guesses, significantly outperforming the next best guessing method, which guessed 57%.\nAppendix C.51. Identification and Mitigation Tool For Cross-Site Request Forgery (CSRF)\nNo Name (CSRF) (2020, Rankothge and Randeniya [101]) focuses on the automated detection and mitiga-\ntion of Cross-Site Request Forgery (CSRF) vulnerabilities in PHP-based web applications [101]. It identifies\nand mitigates CSRF vulnerabilities by scanning form tags and automatically adding security solutions.\nHowever, the evaluation is limited to a few test websites, and the tool is applicable exclusively to PHP.\nAppendix C.52. Development of a suite of IPv6 vulnerability scanning tests using the TTCN-3 language\nThe No Name (TTCN-3) tool, (2018, Leal and Teixeira [102]), is a collection of tests designed to find\nsecurity weaknesses in IPv6 setups.\nIt uses TTCN-3, a language for defining and executing tests that\nis endorsed by the European Telecommunications Standards Institute. The tool was evaluated using the\nSAMATE Juliet 1.2 suite from NIST [172] and proved its effectiveness by identifying and exploiting flaws,\nparticularly focusing on preventing DOS attacks on the IPv6 ICMPv6 protocol over Ethernet networks.\n41\nAppendix C.53. Cracking-Resistant Password Vaults Using Natural Language Encoders\nNoCrack (2015, Chatterjee et al. [103]) is a password-cracking tool that overcomes the limitations of a\nprevious design, Kamouflage [173], which was shown to degrade security. NoCrack utilizes Natural Language\nEncoder (NLE) as a scheme for secure encoding. This approach utilises natural language processing (n-gram\nmodels) with probabilistic context-free grammars, to construct NLEs. These encoders can create realistic\ndecoy passwords, thereby significantly enhancing the resistance of password vaults against cracking efforts.\nAppendix C.54. NodeXP: NOde. js server-side JavaScript injection vulnerability DEtection and eXPloitation\nNodeXP (2021, Ntantogian et al. [104]) is a tool addressing security vulnerabilities in web applications,\nparticularly Server-Side JavaScript Injection (SSJI) threats in Node.js. It detects and automatically exploits\nSSJI vulnerabilities, using obfuscation for enhanced stealth. NodeXP employs dynamic analysis with result\nand blind-based injection techniques for detection and automated exploitation. Its advanced functionalities,\nincluding attack vector obfuscation, distinguish it from other tools, allowing evasion of filtering mechanisms\nand security measures. Thorough assessments show NodeXP outperforming existing scanners. Released as\nopen-source, it aims to drive research in SSJI vulnerabilities. Contributions include SSJI analysis, a novel\ndetection method, and the discovery of a 0-day SSJI.\nAppendix C.55. ObjectMap: detecting insecure object deserialization\nObjectMap (2019, Koutroumpouchos et al. [105]) is a tool designed to address serialization-based vul-\nnerabilities prevalent in web applications, particularly in Java and PHP. It aims to fill the existing gap\nby detecting implementation-agnostic deserialization and object injection vulnerabilities. Additionally, it\nintroduces the first deserialization test environment, serving as a platform for vulnerability detection tool\nevaluation and educational purposes. Both tools are highly extendable and represent a unique combina-\ntion of features in this domain, potentially fostering further research and aiding the development of more\ncomprehensive solutions.\nAppendix C.56. OMEN: Faster password guessing using an ordered Markov enumerator\nOMEN (2015, Durmuth et al. [106]) employs an advanced Markov model algorithm that generates pass-\nwords in order of decreasing probability, a departure from earlier approaches [174]. This method involves\ndiscretising probabilities into bins and iterating over them to identify all passwords corresponding to each\nbin\u2019s probability. OMEN has shown a significant improvement in guessing speed over existing methods,\naccurately guessing over 40% of passwords within the first 90 million attempts, marking a notable effi-\nciency gain against other methods such as John the Ripper (JtR) and probabilistic context-free grammar\n(PCFG)-based strategies [175].\nAppendix C.57. OSV: OSPF vulnerability checking tool\nOSV (2017, Kasemsuwan et al. [107]) is a tool that targets OSPF (Open Shortest Path First) network\nvulnerabilities prevalent in enterprise networks. Typically, OSPF vulnerabilities in router implementations\ncan be mitigated through firmware updates. The tool conducts penetration tests and generates reports, aiding\nnetwork operators in identifying and rectifying security issues. The tool has been validated on Quagga and\nCisco routers.\nAppendix C.58. Owfuzz: Discovering Wi-Fi Flaws in Modern Devices through Over-The-Air Fuzzing\nOwfuzz (2023, Cao et al. [108]) is a fuzzing tool designed for discovering security flaws in Wi-Fi protocols\nthrough over-the-air fuzzing methods. Owfuzz sets itself apart from other Wi-Fi fuzzers by offering the\ncapability to conduct fuzzing tests on any Wi-Fi device, enabling the fuzzing of all three Wi-Fi frame types\n(management, control, and data) across every version of the 802.11 standards, and facilitating interactive\ntesting for a variety of protocol models. In experiments conducted on over 40 contemporary Wi-Fi devices\nfrom 7 chipset manufacturers, Owfuzz identified 23 security issues, resulting in the assignment of 8 CVE\nIDs.\n42\nAppendix C.59. PassGAN: A Deep Learning Approach for Password Guessing\nPassGAN (2019, Hitaj et al. [109]) utilises a Generative Adversarial Network (GAN) trained on real-world\ndatasets to make accurate password guesses. By autonomously learning the distribution of real passwords\nfrom actual leaks, PassGAN eliminates the need for manual rule creation. When combined with HashCat,\nPassGAN\u2019s output successfully matches 51%-73% more passwords than HashCat alone. This demonstrates\nthe tool\u2019s capacity to automatically extract nuanced password properties not encompassed by current state-\nof-the-art rules.\nAppendix C.60. PassGPT: Password modelling and (Guided) Generation with Large Language Models\nPassGPT (2023, Rando et al. [110]) is a tool utilizing GPT-2 architecture and trained on leaked passwords,\naiming to improve password guessing and strength estimation. PassGPT incorporates vector quantization to\nenhance the complexity of password generation (PassVQT). Comprehensive tests were conducted to evaluate\nPassGPT\u2019s efficacy against current password-guessing tools and to assess its generalization capabilities across\nvarious datasets. PassGPT recovers 41.9% of the test set among 109109 guesses, whereas state-of-the-art\nGAN models matched 23.33%.\nAppendix C.61. The Revenge of Password Crackers: Automated Training of Password Cracking Tools\nPasswordCrackingTraining (2022, Di Campi et al. [111]) is a password-cracking trainer combining vari-\nous password-cracking techniques, trained and tested on a dataset of over 700 million real passwords. Their\nmethodology includes evaluating existing hashcat rules and dictionaries and developing efficient algorithms\nto simulate mask attacks without actual password cracking. This approach nearly doubles the success rate\nof password-cracking tools compared to off-the-shelf configurations, achieving over 70% success in certain\ninstances.\nAppendix C.62. PenQuest: a gamified attacker/defender meta model for cyber security assessment and edu-\ncation\nPenQuest (2020, Luh et al. [112]) is a tool designed as a dynamic, multiplayer game that captures the\nbehaviour of attackers and defenders over time, using a rule set based on established information security\nsources such as STIX CAPEC, CVE/CWE, and NIST SP 800-53. The tool is designed to improve cyberse-\ncurity risk assessments and serve as a platform for simulating specific attack scenarios within an abstracted\nIT infrastructure. PenQuest is structured around three main layers: the service layer, the information layer,\nand the event layer, each contributing to a comprehensive representation of a cybersecurity scenario.\nAppendix C.63. PentestGPT: An LLM-empowered Automatic Penetration Testing Tool\nPentestGPT (2023, Deng et al. [113]) utilises Large Language Models (LLMs) for penetration testing,\nrevealing their proficiency in specific tasks but struggles in holistic understanding. Based on LLM-powered\nautomatic penetration testing tool, PENTESTGPT has been released with three modules addressing distinct\nsub-tasks. Evaluation demonstrates PentestGPT\u2019s 228.6% improvement over GPT-3.5 and effectiveness in\nreal-world challenges. The tool employs Reasoning, Generation, and Parsing Modules, simulating human-like\nbehaviour and adopting a divide-and-conquer problem-solving approach.\nAppendix C.64. phpSAFE: A Security Analysis Tool for OOP Web Application Plugins\nPhpSAFE (2015, Nunes et al. [114]) is introduced as a solution to identify security vulnerabilities in PHP\nplugins developed with Object-Oriented Programming (OOP) for web applications. In contrast to existing\nfree tools that lack OOP support, PhpSAFE excels in static code analysis, outperforming two well-known\ntools when evaluated with 35 plugins in a popular Content Management System.\nThe results highlight\nthe prevalence of vulnerabilities in these plugins, indicating an increasing trend over time, emphasizing the\nnecessity of robust security measures in plugin development.\n43\nAppendix C.65. PJCT: Penetration testing based JAVA code testing tool\nPJCT (2015, Jain et al. [115]) is a tool designed to secure attributes in Java code. This addresses a crucial\naspect of secure software development while emphasizing early detection of vulnerabilities during the devel-\nopment process. PJCT highlights seven essential security attributes for identifying vulnerabilities in Java\napplications. These attributes include network and security packages, techniques for handling exceptions,\nsecure data packet transmission and multithreading.\nAppendix C.66. Project Achilles: A Prototype Tool for Static Method-Level Vulnerability Detection of Java\nSource Code Using a Recurrent Neural Network\nProject Achilles (2019, Saccente et al. [116]) is a prototype tool for static method-level vulnerability\ndetection in Java source code, leveraging LSTM Recurrent Neural Networks.\nThe tool utilizes NIST\u2019s\nJuliet Java Suite [172], which includes several examples of defective Java methods for various vulnerabilities.\nEmploying an array of LSTM networks, the tool achieves over 90% accuracy for 24 out of 29 Common\nWeakness Enumeration (CWE) vulnerabilities in an evaluation with around 45,000 test cases.\nAppendix C.67. PURITY: a Planning-based secURITY testing tool\nPURITY (2015, Bozic and Wotawa [117]) is a security testing tool that employs a planning-centric methodo-\nlogy to preemptively identify and rectify vulnerabilities during the software development cycle. By executing\nautomated test cases, PURITY focuses on detecting prevalent security flaws like SQL injections and cross-site\nscripting, simulating malicious activities through predetermined sequences of actions. PURITY generates\nconcrete test cases from plans based on specific initial values and predefined actions, mimicking the beha-\nviours of potential attackers, providing a versatile platform for both automated and manual evaluation of\nweb applications throughout the software development life cycle.\nAppendix C.68. Pyciuti: A Python Based Customizable and Flexible Cybersecurity Utility Tool for Penetra-\ntion Testing\nPyciuti (2023, Muralidharan et al. [118]) is a Python-based general-purpose tool that integrates cus-\ntom scanners, crawlers, malware functionalities, and more, offering flexibility and customisation for both\nbeginners and experienced professionals. Users can access various subdomains such as OSINT, network-\nbased tools, web-based tools, malware tools, and documentation, streamlining the execution of tasks. The\ntool records findings, scans, and exploits, providing a consolidated report while prioritising accuracy and\nperformance.\nAppendix C.69. RAT: Reinforcement-Learning-Driven and Adaptive Testing for Vulnerability Discovery in\nWeb Application Firewalls\nRAT (2022, Amouei et al. [119]) (Reinforcement-Learning-Driven and Adaptive Testing) is a tool for\ndiscovering vulnerabilities, specifically SQL injection (SQLi) and Cross-site Scripting (XSS), in Web Ap-\nplication Firewalls (WAFs). The tool\u2019s methodology begins with clustering similar attack samples, followed\nby applying a reinforcement learning technique that efficiently identifies bypassing attack patterns. The\napproach is further refined by integrating an adaptive search algorithm, which aids in discovering almost all\npossible bypassing payloads with higher efficiency. RAT outperforms existing methods by significant margins\n(33.53% and 63.16% on average) when tested against well-configured WAFs.\nAppendix C.70. Revealer: Detecting and Exploiting Regular Expression Denial-of-Service Vulnerabilities\nRevealer (2021, Liu et al. [120]) is a tool designed to detect and exploit Regular expression Denial-of-\nService (ReDoS) vulnerabilities present in extended-featured regular expressions (regexes). Revealer employs\na combined method using static and dynamic analyses to identify vulnerable regex structures and generate\nattack strings that induce recursive backtracking. In evaluation against 29,088 regexes and comparison with\nthree state-of-the-art tools, Revealer outperformed existing solutions, detecting all known vulnerabilities,\nfinding 213 new vulnerabilities whilst surpassing the highest performing tool by 140.64%. Additionally, it\ndetected 45 vulnerable regexes in real-world applications, demonstrating its effectiveness and efficiency in\ndetecting and exploiting ReDoS vulnerabilities.\n44\nAppendix C.71. RiscyROP: Automated Return-Oriented Programming Attacks on RISC-V and ARM64\nRiscyROP (2022, Cloosters et al. [121]) is an automated Return-Oriented Programming (ROP) tool spe-\ncifically designed for RISC-V and ARM64 architectures. It employs symbolic execution to analyze available\ngadgets and autonomously generate complex multi-stage chains for arbitrary function calls. The tool\u2019s ef-\nfectiveness is evidenced by its analysis of real-world software from public repositories, demonstrating its\ncapability to identify usable gadgets for executing attacker-controlled function calls.\nAppendix C.72. Robin: A Web Security Tool\nRobin (2020, Girotto and Zorzo [122]) is a web security tool that includes a Proxy module for listing,\nintercepting, and editing HTTP and HTTPS requests. Robin\u2019s capabilities extend to active scanning, brute-\nforce attack simulations, encoding/decoding contents using various hashing patterns, and providing a detailed\nWiki module for understanding and safeguarding against common vulnerabilities. The tool\u2019s potential is\ndemonstrated through a real case study involving a news company\u2019s website.\nAppendix C.73. ROSploit: Cybersecurity Tool for ROS\nROSploit (2019, Rivera et al. [123]) is a tool for the assessment of the security of the Robot Operating\nSystem (ROS). The tool covers reconnaissance and exploitation. Its reconnaissance component integrates\nwith Nmap, offering two scripts for master node scans and wide port scans, identifying ROS nodes and\nservices. The exploitation component, built in Python, mirrors Metasploit\u2019s modular design. Moreover,\nROSploit enables simulated attacks without a complete ROS installation.\nAppendix C.74. RT-RCT: an online tool for real-time retrieval of connected things\nRT-RCT (2021, Fagroud et al.\n[124]) utilises network port scanning techniques [176] to extract real-\ntime data from connected devices within the IoT domain. The main goal is to introduce a retrieval tool\nthat swiftly provides users with current information about each requested entity. Real-time device data is\ncollected through network port scanning, with a specific emphasis on the Python-nmap library. The data\ncollection process involves a series of scans, each targeting specific information that may take considerable\ntime to retrieve. To reduce time, parallel scans are implemented, ensuring simultaneous and accelerated\nexecution of all scans to improve overall retrieval speed and efficiency.\nAppendix C.75. Scanner++: Enhanced Vulnerability Detection of Web Applications with Attack Intent Syn-\nchronization\nScanner++ (2023, Yin et al. [125]) demonstrates an enhancement of vulnerability assessment scanning\ntechnology in web applications.\nBy utilizing purification mechanisms to refine attack intents from the\nrequest packets in the base scanners. The scanner has a synchronisation mechanism for runtime intent for\nthe scanner\u2019s detection spots. This has been evaluated against four practitioner tools including BurpSuite,\nAWVS, Arachni, and ZAP testing on real-world finance web apps where the tool demonstrated to have a\nhigher coverage when being compared to the practitioner tools by approximately 15%-70%.\nAppendix C.76. On the Semantic Patterns of Passwords and their Security Impact\nSemanticGuesser (2014, Veras et al. [126]) is a framework that uses Natural Language Processing (NLP)\ntechniques for the segmentation, semantic classification, and generalisation of passwords. The methodology\nbegins with password segmentation to isolate distinct words or elements found within the passwords. Follow-\ning this, it employs part-of-speech tagging and semantic classification through NLP methodologies, primarily\nutilising resources such as WordNet to decipher the meanings of the segments. Experimental results have\nshown that this method can guess about 67% more passwords from the LinkedIn data breach and 32%\nmore from the MySpace leak, demonstrating its effectiveness in understanding and exploiting the semantic\nstructures of passwords.\n45\nAppendix C.77. SerialDetector: Principled and Practical Exploration of Object Injection Vulnerabilities for\nthe Web\nSerialDetector (2021, Shcherbakov et al. [127]) employs taint-based dataflow analysis to automatically\ndetect OIV (Object Injection Vulnerability) patterns in .NET assemblies. By identifying untrusted inform-\nation flow from public entry points to sensitive methods, it uncovers vulnerabilities and matches them with\navailable gadgets, validating the feasibility of OIV attacks. The evaluation conducted on Azure DevOps\nServer showcased SerialDetector\u2019s effectiveness by discovering three CVEs and demonstrating its capability\nin identifying remote code execution vulnerabilities. Additionally, it performed a broad security analysis of\nrecent CVEs, affirming its efficiency and effectiveness in OIV detection.\nAppendix C.78. ShoVAT: Shodan-based vulnerability assessment tool for Internet-facing services\nShoVAT (2016, Genge et al. [128]) a vulnerability analysis tool based on Shodan. This software acquires\nthe output of traditional queries in Shodan to analyse service-specific data by leveraging the search engine.\nBy adding to existing modules this tool provides the opportunity to analyse other targets in the penetration\ntest.\nAppendix C.79. Snout: An Extensible IoT Pen-Testing Tool\nSnout (2019, Mikulskis et al. [129]) is a Software-Defined Radio (SDR)-based utility toolkit for passive\nsniffing and interaction with various IoT protocols, including Zigbee, Bluetooth, and Wi-Fi. Available as\na Python 3 package or as a Docker container, Snout enables enumeration and analysis of multiple wireless\nprotocols, including non-IP IoT protocols.\nAppendix C.80. SOA-Scanner: an integrated tool to detect vulnerabilities in service-based infrastructures\nSOA-Scanner (2013, Antunes et al. [130]) is a vulnerability analysis tool designed for service-oriented\narchitectures (SOA) after the application has been deployed. The tool tests services based on their level of\naccess using an iterative process to discover services, resources, and interactions in real-time. Additionally, it\nprovides anomaly detection, categorising services based on whether they are within reach, under full control,\nor under partial control.\nAppendix C.81. Spicy: a unified deep packet inspection framework for safely dissecting all your data\nSpicy (2016, Sommer et al. [131]) includes a format specification language, a compiler toolchain, and\nan API to address the challenges of deep packet inspection (DPI) across diverse network protocols and\nfile formats. The Spicy framework automates the dissection process, enhancing DPI efficiency and safety.\nEnabling developers to create specific dissectors for varied protocols, Spicy is a reliable DPI tool. Its flexibility\nmakes it valuable for processing network data from untrusted sources in diverse formats.\nAppendix C.82. SuperEye: A Distributed Port Scanning System\nSuperEye (2019, Li et al. [132]) is an advanced distributed port scanning system adopting a distributed\nstructure with task redundancy and real-time state display. SuperEye\u2019s core control subsystem efficiently\nmanages distributed nodes, tasks, and result processing, leveraging a custom protocol stack to optimise\nresource utilisation. The distributed architecture significantly boosts scanning speed, mitigating risks asso-\nciated with Intrusion Detection Systems (IDS). Innovative features include a script for port scanning and\nvisualisation tools offering real-time updates.\nAppendix C.83. SVED: Scanning, Vulnerabilities, Exploits and Detection\nSVED (2016, Holm et al. [133]) is a tool designed for secure and replicable experiments, enabling controlled\nexecution and logging of malicious activities, including software exploits and intrusion detection alerts. Its\ndistributed architecture supports extensive experiments involving numerous attackers, sensors, and targets.\nSVED automatically integrates threat intelligence from diverse services, ensuring up-to-date information for\nenhanced experimentation and analysis in cybersecurity.\n46\nAppendix C.84. A Hybrid Threat Model for Smart Systems\nTAMELESS (2023, Valenza et al.\n[134]) is an automated threat modelling tool that includes a threat\nmodelling approach integrating cyber, physical, and human elements, and a threat analysis method designed\nto evaluate the security posture of system components. TAMELESS can analyse threats, verify security\nproperties, and produce graphical outputs of its analyses, thereby assisting security architects in identifying\noptimal prevention and mitigation solutions.\nThe efficiency and applicability of TAMELESS have been\ndemonstrated through case study evaluations involving unauthorised access to safe boxes, web servers, and\nwind farms, showcasing its effectiveness in real-world scenarios.\nAppendix C.85. TChecker: Precise Static Inter-Procedural Analysis for Detecting Taint-Style Vulnerabilities\nin PHP Applications\nTChecker (2022, Luo et al. [135]) introduces a context-sensitive inter-procedural static taint analysis\ntool specifically tailored for PHP applications, addressing the challenge of taint-style vulnerabilities like SQL\ninjection and cross-site scripting.\nBy modelling PHP objects and dynamic language features, TChecker\nconducts iterative data-flow analysis to refine object types and accurately identify call targets. Comprehens-\nive evaluations across diverse modern PHP applications showcased TChecker\u2019s effectiveness, discovering 18\npreviously unknown vulnerabilities while outperforming existing static analysis tools in vulnerability detec-\ntion. It not only detected more vulnerabilities but also maintained a relatively good precision, surpassing\ncompetitors while releasing its source code to foster further research in this domain.\nAppendix C.86. Detecting and exploiting second order denial-of-service vulnerabilities in web applications\nTORPEDO (2015, Olivo et al. [136]) is a second-order vulnerability scanning tool that detects Denial of\nService (DoS), Cross-Site Scripting (XSS), and SQL Injection. The program searches for two-phased DoS\nattacks that work by polluting a database with junk entries and resource exhaustion. When applied to six\nhighly used web apps, it detected thirty-seven vulnerabilities and eighteen false positives.\nAppendix C.87. UE Security Reloaded: Developing a 5G Standalone User-Side Security Testing Framework\nUE Security Reloaded (2023, Hoang et al. [137]) is an open-source security testing framework specific-\nally developed for 5G Standalone (SA) User Equipment (UE). This tool enhances existing open-source suites\n(Open5GS and srsRAN) by creating an extensive range of test cases for both the 5G Non-Access Stratum\n(NAS) and Radio Resource Control (RRC) layers. Such an approach offers in-depth insights through exper-\niments on 5G SA mobile phones. The framework allows for the transmission of 5G control-plane messages\n(NAS and RRC) to a UE and facilitates the modification of these messages to examine the UE\u2019s reactions\nunder a variety of conditions.\nAppendix C.88. Untangle: Aiding Global Function Pointer Hijacking for Post-CET Binary Exploitation\nUntangle (2023, Bertani et al. [138]) is a tool that exploit global function pointer hijacking in order\nto defeat Intel\u2019s Control-Flow Enforcement Technology (CET) The method combines symbolic execution\nand static code analysis to identify global function pointers within C libraries, which, when compromised,\nfacilitate control-flow hijacking attacks. Experimental results demonstrated the effectiveness of Untangle in\nidentifying global function pointers across eight widely used open-source C libraries.\nAppendix C.89. VAPE-BRIDGE: Bridging OpenVAS Results for Automating Metasploit Framework\nVAPE-BRIDGE (2022, Vimala et al. [139]) is a tool designed to streamline the transition between vulner-\nability assessment (VA) and penetration testing (PenTest) processes by automating the conversion of scan\nresults from the Open Vulnerability Assessment Scanner (OpenVAS) into executable scripts for the Metas-\nploit Framework. The VAPE-BRIDGE system comprises three main components: Scan result extraction,\nresponsible for parsing the VA scan results from OpenVAS; Target list repository, accountable for maintain-\ning a database of identified vulnerabilities to be used in the PenTest process; and the Automated shell scripts\nexploitation, which generates shell scripts based on the extracted vulnerabilities, which are then executed\nwithin Metasploit to simulate attacks and test the system\u2019s resilience.\n47\nAppendix C.90. Vera: A flexible model-based vulnerability testing tool\nVERA (2013, Blome et al. [140]) is an automated tool that supports Penetration Testers to define attacker\nmodels (separating payloads and behaviour) using state machines for vulnerability analysis in web applica-\ntions. The models acquired are then converted into libraries for specific vulnerability targeting. The tool is\nhighly flexible with the availability to expand and integrate custom libraries to enhance functionality.\nAppendix C.91. VUDDY: A Scalable Approach for Vulnerable Code Clone Discovery\nVUDDY (2017, Kim et al. [141]) aims to detect defective code in large open-source programs. In particular,\nit is capable to process a billion lines of code in under 15 hours and quickly identify code clones using\nfunction-level granularity and a length-filtering technique. The evaluation included comparison with four\nother code clone detection methods and VUDDY showed better scalability and accuracy. For example, it\nwas possible to find zero-day vulnerabilities popular software like Apache Web Server and Ubuntu Linux OS.\nAppendix C.92. Vulcan: Vulnerability assessment framework for cloud computing\nVulcan (2013, Kamongi et al. [142]) is a tool for vulnerability analysis and remediation in cloud and\nmobile computing. This tool provides software and zero-day vulnerability modelling and assessments. The\ntool is very flexible, presenting the opportunity to add original modules by developers and the integration\nof Vulcan into other vulnerability analysis tools that, for example, focus on web application vulnerabilities\nto expand their assessment to cloud and mobile technology.\nAppendix C.93. VulCNN: An Image-Inspired Scalable Vulnerability Detection System\nVulCNN (2022,(Wu et al. [143]) is designed to address the limitations of existing text-based and graph-\nbased vulnerability detection methods. The tool converts the source code of functions into images that\npreserve program details and then uses these images to detect vulnerabilities through a Convolutional Neural\nNetwork (CNN) model. VulCNN was evaluated on a dataset of 13,687 vulnerable and 26,970 non-vulnerable\nfunctions.\nWith an accuracy of 82% and a True Positive Rate (TPR) of 94%, VulCNN outperformed\neight other state-of-the-art vulnerability detectors, including both commercial tools and deep learning-based\napproaches.\nAppendix C.94. VulDeePecker: A Deep Learning-Based System for Vulnerability Detection\nVulDeePecker (2018, Zhen et al. [144]) employs deep learning for software vulnerability detection, aiming\nto reduce reliance on human-defined features and mitigate false negatives. It uses code gadgets to represent\nand transform programs into vectors suitable for deep learning. The system\u2019s evaluation, using the first\nvulnerability dataset for deep learning, demonstrates significantly fewer false negatives compared to other\nmethods, with reasonable false positives.\nVulDeePecker successfully detects four previously unreported\nvulnerabilities in Xen, Seamonkey, and Libav, unnoticed by other detection systems, highlighting its efficacy\nin uncovering vulnerabilities missed by existing approaches.\nAppendix C.95. An Intelligent and Automated WCMS Vulnerability-Discovery Tool: The Current State of\nthe Web\nVulnet (2019, Cigoj and Blazic [145]) is characterized by its capability to conduct automated, rapid, and\ndynamic vulnerability scans across a wide array of internet websites. Specifically, VulNet focuses on those\nutilising the WordPress Web Content Management Systems (WCMS) and its associated plugins. A crucial\naspect of the tool involves the application of a scoring mechanism tailored to evaluate known vulnerabilities.\nIt\u2019s important to note that VulNet\u2019s vulnerability detection is limited to WordPress web applications and\ntheir associated plugins.\n48\nAppendix C.96. Vulsploit: A Module for Semi-automatic Exploitation of Vulnerabilities\nVulnsloit (2020, Castiglione et al.\n[146]) is a semi-automatic penetration testing tool that collects\nvulnerability data using existing tools like the Nmap Scripting Engine (NSE) and the Vulscan scanner [176].\nThis data is then processed to identify relevant exploits from various repositories, including local and remote\nsources. In preliminary testing on Metasploitable2, Vulnsloit identified 23 open ports and approximately\n220,000 vulnerabilities.\nAppendix C.97. VulPecker: an automated vulnerability detection system based on code similarity analysis\nVulPecker (2016, Li et al. [147]) automatically detects specific vulnerabilities within software source\ncode. Leveraging a set of defined features characterizing patches and utilizing code-similarity algorithms\ntailored for different vulnerability types, VulPecker successfully identifies 40 vulnerabilities not listed in the\nNational Vulnerability Database (NVD). Among these, 18 previously unknown vulnerabilities (anonymized\nfor ethical considerations) are confirmed, while 22 vulnerabilities have been patched silently by vendors in\nlater product releases.\nAppendix C.98. WAPTT-Web application penetration testing tool\nWAPTT (2014, Duric et al. [148]) is designed for web application penetration testing using page similarity\ndetection.\nThe structure of the tool is modular and when compared to tools such as Nikto, Vega, and\nZAP, the tool detected similar or greater quantity of vulnerabilities in the area of XSS, but at the price of\nincreasing detection time.\nAppendix C.99. webFuzz: Grey-Box Fuzzing for Web Applications\nWebFuzz (2021, van Rooij et al. [149]) is a gray-box fuzzing tool designed for web applications, with\na focus on discovering vulnerabilities like cross-site scripting (XSS). It effectively utilises instrumentation,\noutperforming black-box fuzzers by identifying XSS vulnerabilities swiftly and covering more code. WebFuzz\nhas demonstrated its capability by discovering one zero-day vulnerability in WordPress and five in CE-\nPhoenix.\nAppendix C.100. Identification and Mitigation Tool for Sql Injection Attacks (SQLIA)\nWebVIM (2020, Rankothge et al. [150]) is a tool designed for identifying SQL injection vulnerabilities in\nPHP-based web applications during the development phase. When vulnerabilities are detected, WebVIM\nautomatically adds security solutions to the source code. However, the evaluation is very limited, and the\ntool focuses exclusively on PHP applications.\n49\nReferences\n[1] P. Modesti, L. Golightly, L. Holmes, C. Opara, M. Moscini, Bridging the Gap: A Survey and Classific-\nation of Research-Informed Ethical Hacking Tools, Journal of Cybersecurity and Privacy 4 (3) (2024)\n410\u2013448. doi:10.3390/jcp4030021.\n[2] S. D. Duque Anton, D. Fraunholz, D. Schneider, Investigating the ecosystem of offensive information\nsecurity tools, arXiv e-prints (2020). arXiv:2012.08811, doi:10.48550/arXiv.2012.08811.\n[3] M. M. Leal, P. Musgrave, Backwards from zero: How the u.s. public evaluates the use of zero-day\nvulnerabilities in cybersecurity, Contemporary Security Policy 44 (3) (2023) 437\u2013461. doi:10.1080/\n13523260.2023.2216112.\n[4] A. Valenza, G. Costa, A. Armando, Never trust your victim: Weaponizing vulnerabilities in security\nscanners, in: 23rd International Symposium on Research in Attacks, Intrusions and Defenses ({RAID}\n2020), 2020, pp. 17\u201329. arXiv:2006.09769, doi:10.48550/arxiv.2006.09769.\n[5] M. Denis, C. Zena, T. Hayajneh, Penetration testing: Concepts, attack methods, and defense strategies,\nin: 2016 IEEE Long Island Systems, Applications and Technology Conference (LISAT), IEEE, 2016,\npp. 1\u20136. doi:10.1109/lisat.2016.7494156.\n[6] J.-P. A. Yaacoub, H. N. Noura, O. Salman, A. Chehab, Ethical hacking for iot: Security issues,\nchallenges, solutions and recommendations, Internet of Things and Cyber-Physical Systems 3 (2023)\n280\u2013308. doi:10.1016/j.iotcps.2023.04.002.\n[7] P. S. Aarya, A. Rajan, K. P. S. Sachin, R. Gopi, G. Sreenu, Web scanning: Existing techniques\nand future, in: 2018 Second International Conference on Intelligent Computing and Control Systems\n(ICICCS), IEEE, 2018, pp. 123\u2013128. doi:10.1109/iccons.2018.8662934.\n[8] E. A. Altulaihan, A. Alismail, M. Frikha, A survey on web application penetration testing, Electronics\n12 (5) (2023) 1229. doi:10.3390/electronics12051229.\n[9] A. Shanley, M. N. Johnstone, Selection of penetration testing methodologies: A comparison and eval-\nuation (2015). doi:10.4225/75/57b69c4ed938d.\n[10] PTES Working Group, The penetration testing execution standard (2011).\nURL http://www.pentest-standard.org/\n[11] B. E. Strom, A. Applebaum, D. P. Miller, K. C. Nickels, A. G. Pennington, C. B. Thomas, Mitre\natt&ck: Design and philosophy, in: Technical report, The MITRE Corporation, 2018.\n[12] A. Rashid, H. Chivers, G. Danezis, E. Lupu, A. Martin (Eds.), Cyber Security Body of Knowledge,\nThe National Cyber Security Centre, 2021, version 1.1.0.\nURL https://www.cybok.org/knowledgebase1_1/\n[13] B. Rous, Major update to acm\u2019s computing classification system, Commun. ACM 55 (11) (2012) 12.\ndoi:10.1145/2366316.2366320.\n[14] M. Bishop, Computer Security: Art and Science, Pearson Education, 2018.\nURL https://books.google.ch/books?id=bz58DwAAQBAJ\n[15] J. A. Yaacoub, H. N. Noura, O. Salman, A. Chehab, A survey on ethical hacking: Issues and challenges,\nCoRR abs/2103.15072 (2021). arXiv:2103.15072, doi:10.48550/arxiv.2103.15072.\n[16] M. Walker, CEH Certified Ethical Hacker All-in-One Exam Guide, Fifth Edition, McGraw Hill LLC,\n2021.\nURL https://books.google.ch/books?id=EuBIEAAAQBAJ\n50\n[17] S. L. N. Hald, J. M. Pedersen, An updated taxonomy for characterizing hackers according to their\nthreat properties, in: 2012 14th International Conference on Advanced Communication Technology\n(ICACT), IEEE, 2012, pp. 81\u201386.\n[18] D. Oliver, A. B. Randolph, Hacker definitions in information systems research, J. Comput. Inf. Syst.\n62 (2) (2022) 397\u2013409. doi:10.1080/08874417.2020.1833379.\n[19] M. Aljaidi, A. Alsarhan, G. Samara, R. Alazaidah, S. Almatarneh, M. Khalid, Y. A. Al-Gumaei, Nhs\nwannacry ransomware attack: Technical explanation of the vulnerability, exploitation, and counter-\nmeasures, in: 2022 International Engineering Conference on Electrical, Energy, and Artificial Intelli-\ngence (EICEEAI), IEEE, 2022, pp. 1\u20136. doi:10.1109/eiceeai56378.2022.10050485.\n[20] M. Qin, G. Mogos, Cyber-attacks on swift systems of financial institutions, in: Proceedings of the 5th\nInternational Conference on Computer Science and Software Engineering, 2022, pp. 596\u2013599.\ndoi:\n10.1145/3569966.3570116.\n[21] D. P. Fidler, The us election hacks, cybersecurity, and international law, American Journal of Inter-\nnational Law 110 (2016) 337\u2013342.\n[22] T. Steffens, Attribution of Advanced Persistent Threats - How to Identify the Actors Behind Cyber-\nEspionage, Springer, 2020. doi:10.1007/978-3-662-61313-9.\n[23] Z. Liu, C. Chen, L. Y. Zhang, S. Gao, Working Mechanism of Eternalblue and Its Applic-\nation in Ransomworm, Springer International Publishing, 2022, pp. 178\u2013191.\ndoi:10.1007/\n978-3-031-18067-5_13.\n[24] Concil of Europe, Convention on cybercrime, European Treaty Series - No. 185 (2001).\n[25] Council of the European Union, European Parliament, Directive 2013/40/eu of the european parlia-\nment and of the council of 12 august 2013 on attacks against information systems and replacing council\nframework decision 2005/222/jha (2013).\nURL https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=celex:32013L0040\n[26] United Kingdom Parliament, Computer misuse act 1990 (1990).\nURL https://www.legislation.gov.uk/ukpga/1990/18/contents\n[27] V. V. Gehring, The Internet in public life, Rowman & Littlefield, 2004.\n[28] D.-O. Jaquet-Chiffelle, M. Loi, Ethical and unethical hacking, The ethics of cybersecurity (2020) 179\u2013\n204doi:10.1007/978-3-030-29053-5_9.\n[29] G. Vishnuram, K. Tripathi, A. K. Tyagi, Ethical hacking: Importance, controversies and scope in\nthe future, in: 2022 International Conference on Computer Communication and Informatics (ICCCI),\nIEEE, 2022, pp. 01\u201306. doi:10.1109/iccci54379.2022.9740860.\n[30] E. Filiol, F. Mercaldo, A. Santone, A method for automatic penetration testing and mitigation: A red\nhat approach, Procedia Computer Science 192 (2021) 2039\u20132046. doi:10.1016/j.procs.2021.08.210.\n[31] V. Chandrika, Ethical hacking: Types of ethical hackers, International Journal of Emerging Technology\nin Computer Science & Electronics (IJETCSE) 11 (1) (2014) 44\u201345.\n[32] E. I. Egho-Promise, M. Sitti, Big data security management in digital environment, American Journal\nof Multidisciplinary Research & Development (AJMRD) 6 (02) (2024) 01\u201334.\n[33] MITRE, Common vulnerabilities and exposures.\nURL https://cve.mitre.org/\n51\n[34] MITRE, Common weakness enumeration.\nURL https://cwe.mitre.org/\n[35] PCI Security Standards Council, Payment card industry data security standard: Requirements and\ntesting procedures, v4.0 (2022).\nURL https://docs-prv.pcisecuritystandards.org/PCI%20DSS/Standard/PCI-DSS-v4_0.pdf\n[36] PCI Security Standards Council, Pci data security standard - penetration testing guidance (2017).\nURL https://listings.pcisecuritystandards.org/documents/Penetration-Testing-Guidance-v1_\n1.pdf\n[37] B. Rathore, M. Brunner, M. Dilaj, O. Herrera, P. Brunati, R. Subramaniam, S. Raman, U. Chavan,\nInformation systems security assessment framework (issaf), Draft 0.2 B 1 (2006) 2006.\n[38] P. Herzog, The open source security testing methodology manual (2010).\nURL https://www.isecom.org/OSSTMM.3.pdf\n[39] K. A. Scarfone, M. P. Souppaya, A. Cody, A. D. Orebaugh, Sp 800-115. technical guide to information\nsecurity testing and assessment (2008).\n[40] F. E. Cerullo, Owasp top 10 2009, in: C. Serr\u00e3o, V. Aguilera D\u00edaz, F. Cerullo (Eds.), Web Ap-\nplication Security, Springer Berlin Heidelberg, Berlin, Heidelberg, 2010, pp. 19\u201319.\ndoi:10.1007/\n978-3-642-16120-9_10.\n[41] M. Meucci, A. Muller, Owasp testing guide v4.0 (2014).\nURL\nhttps://owasp.org/www-project-web-security-testing-guide/assets/archive/OWASP_\nTesting_Guide_v4.pdf\n[42] D. Moher, L. Shamseer, M. Clarke, D. Ghersi, A. Liberati, M. Petticrew, P. Shekelle, L. A. Stewart,\nP.-P. Group, Preferred reporting items for systematic review and meta-analysis protocols (prisma-p)\n2015 statement, Systematic reviews 4 (2015) 1\u20139.\n[43] D. N. Astrida, A. R. Saputra, A. I. Assaufi, Analysis and evaluation of wireless network security with\nthe penetration testing execution standard (ptes), Sinkron: jurnal dan penelitian teknik informatika\n7 (1) (2022) 147\u2013154. doi:10.33395/sinkron.v7i1.11249.\n[44] P. Rajesh, M. Alam, M. Tahernezhadi, A. Monika, G. Chanakya, Analysis of cyber threat detection\nand emulation using mitre attack framework, in: 2022 International Conference on Intelligent Data\nScience Technologies and Applications (IDSTA), IEEE, 2022, pp. 4\u201312.\ndoi:10.1109/idsta55301.\n2022.9923170.\n[45] A. Georgiadou, S. Mouzakitis, D. Askounis, Assessing mitre att&ck risk using a cyber-security culture\nframework, Sensors 21 (9) (2021) 3267. doi:10.3390/s21093267.\n[46] S. Messinis, N. Temenos, N. E. Protonotarios, I. Rallis, D. Kalogeras, N. Doulamis, Enhancing internet\nof medical things security with artificial intelligence: A comprehensive review, Computers in Biology\nand Medicine (2024) 108036doi:10.1016/j.compbiomed.2024.108036.\n[47] O. Alexander, M. Belisle, J. Steele, Mitre att&ck for industrial control systems: Design and philosophy,\nThe MITRE Corporation: Bedford, MA, USA 29 (2020).\n[48] L. Williams, The Cyber Security Body of Knowledge v1.1.0, 2021, University of Bristol, 2021, Ch.\nSecure Software Lifecycle, kA Version 1.0.2.\nURL https://www.cybok.org/\n[49] L. Nautiyal, A. Rashid, J. Hallett, B. Shreeve, The uk\u2019s cyber security degree certification programme:\nA cybok case study, Tech. rep. (2020).\n52\n[50] S. Attwood, A. Williams, Exploring the uk cyber skills gap through a mapping of active job listings\nto the cyber security body of knowledge (cybok), in: Proceedings of the 27th International Conference\non Evaluation and Assessment in Software Engineering, 2023, pp. 273\u2013278. doi:10.1145/3593434.\n3593459.\n[51] D. Pasquini, M. Cianfriglia, G. Ateniese, M. Bernaschi, Reducing bias in modeling real-world password\nstrength via deep learning and dynamic dictionaries, in: M. D. Bailey, R. Greenstadt (Eds.), 30th\nUSENIX Security Symposium, USENIX Security 2021, August 11-13, 2021, USENIX Association,\n2021, pp. 821\u2013838.\nURL https://www.usenix.org/conference/usenixsecurity21/presentation/pasquini\n[52] M. Fu, C. Tantithamthavorn, T. Le, Y. Kume, V. Nguyen, D. Phung, J. Grundy, Aibughunter: A\npractical tool for predicting, classifying and repairing software vulnerabilities, Empirical Software En-\ngineering 29 (1) (Nov. 2023). doi:10.1007/s10664-023-10346-3.\n[53] L.-H. Chen, F.-H. Hsu, Y. Hwang, M.-C. Su, W.-S. Ku, C.-H. Chang, Armory: An automatic security\ntesting tool for buffer overflow defect detection, Computers & Electrical Engineering 39 (7) (2013)\n2233\u20132242. doi:10.1016/j.compeleceng.2012.07.005.\n[54] N. Moscovich, R. Bitton, Y. Mallah, M. Inokuchi, T. Yagyu, M. Kalech, Y. Elovici, A. Shabtai,\nAutosploit: A fully automated framework for evaluating the exploitability of security vulnerabilities\n(2020). doi:10.48550/arXiv.2007.00059.\n[55] R. Egert, T. Grube, D. Born, M. M\u00fchlh\u00e4user, AVAIN \u2013 a framework for automated vulnerability\nindication for the iot in ip-based networks, in: 2019 International Conference on Networked Systems,\nNetSys 2019, Munich, Germany, March 18-21, 2019, IEEE, 2019, pp. 1\u20133. doi:10.1109/NetSys.2019.\n8854493.\n[56] B. Blumbergs, R. Vaarandi, Bbuzz: A bit-aware fuzzing framework for network protocol systematic\nreverse engineering and analysis, in: 2017 IEEE Military Communications Conference, MILCOM 2017,\nBaltimore, MD, USA, October 23-25, 2017, IEEE, 2017, pp. 707\u2013712.\ndoi:10.1109/MILCOM.2017.\n8170785.\n[57] B. Eriksson, A. Stjerna, R. De Masellis, P. R\u00fcemmer, A. Sabelfeld, Black ostrich: Web application\nscanning with string solvers, in: Proceedings of the 2023 ACM SIGSAC Conference on Computer and\nCommunications Security, CCS \u201923, ACM, 2023. doi:10.1145/3576915.3616582.\n[58] B. Eriksson, G. Pellegrino, A. Sabelfeld, Black widow: Blackbox data-driven web scanning, in: 42nd\nIEEE Symposium on Security and Privacy, SP 2021, San Francisco, CA, USA, 24-27 May 2021, IEEE,\n2021, pp. 1125\u20131142. doi:10.1109/SP40001.2021.00022.\n[59] Z. Luo, J. Yu, F. Zuo, J. Liu, Y. Jiang, T. Chen, A. Roychoudhury, J. Sun, Bleem: Packet sequence\noriented fuzzing for protocol implementations, in: J. A. Calandrino, C. Troncoso (Eds.), 32nd USENIX\nSecurity Symposium, USENIX Security 2023, Anaheim, CA, USA, August 9-11, 2023, USENIX Asso-\nciation, 2023, pp. 4481\u20134498.\nURL https://www.usenix.org/conference/usenixsecurity23/presentation/luo-zhengxiong\n[60] S. Faily, R. Scandariato, A. Shostack, L. Sion, D. Ki-Aries, Contextualisation of data flow diagrams for\nsecurity analysis, in: H. E. III, O. Gadyatskaya (Eds.), Graphical Models for Security - 7th International\nWorkshop, GraMSec 2020, Boston, MA, USA, June 22, 2020 Revised Selected Papers, Vol. 12419 of\nLecture Notes in Computer Science, Springer, 2020, pp. 186\u2013197. doi:10.1007/978-3-030-62230-5_\n10.\n[61] Z. Durumeric, D. Adrian, A. Mirian, M. Bailey, J. A. Halderman, A search engine backed by Internet-\nwide scanning, in: 22nd ACM Conference on Computer and Communications Security, 2015, pp.\n542\u2013553. doi:10.1145/2810103.2813703.\n53\n[62] A. Alhuzali, B. Eshete, R. Gjomemo, V. N. Venkatakrishnan, Chainsaw: Chained automated workflow-\nbased exploit generation, in: E. R. Weippl, S. Katzenbeisser, C. Kruegel, A. C. Myers, S. Halevi\n(Eds.), Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security,\nVienna, Austria, October 24-28, 2016, ACM, 2016, pp. 641\u2013652. doi:10.1145/2976749.2978380.\n[63] F. Yamaguchi, C. Wressnegger, H. Gascon, K. Rieck, Chucky: exposing missing checks in source\ncode for vulnerability discovery, in: A. Sadeghi, V. D. Gligor, M. Yung (Eds.), 2013 ACM SIGSAC\nConference on Computer and Communications Security, CCS\u201913, Berlin, Germany, November 4-8,\n2013, ACM, 2013, pp. 499\u2013510. doi:10.1145/2508859.2516665.\n[64] A. Stasinopoulos, C. Ntantogian, C. Xenakis, Commix: automating evaluation and exploitation of\ncommand injection vulnerabilities in web applications, Int. J. Inf. Sec. 18 (1) (2019) 49\u201372.\ndoi:\n10.1007/s10207-018-0399-z.\n[65] S. Rahaman, Y. Xiao, S. Afrose, F. Shaon, K. Tian, M. Frantz, M. Kantarcioglu, D. D. Yao, Cryp-\ntoguard: High precision detection of cryptographic vulnerabilities in massive-sized java projects, in:\nL. Cavallaro, J. Kinder, X. Wang, J. Katz (Eds.), Proceedings of the 2019 ACM SIGSAC Conference\non Computer and Communications Security, CCS 2019, London, UK, November 11-15, 2019, ACM,\n2019, pp. 2455\u20132472. doi:10.1145/3319535.3345659.\n[66] R. Li, W. Diao, Z. Li, J. Du, S. Guo, Android custom permissions demystified: From privilege escalation\nto design shortcomings, in: 42nd IEEE Symposium on Security and Privacy, SP 2021, San Francisco,\nCA, USA, 24-27 May 2021, IEEE, 2021, pp. 70\u201386. doi:10.1109/SP40001.2021.00070.\n[67] G. Pellegrino, M. Johns, S. Koch, M. Backes, C. Rossow, Deemon: Detecting CSRF with dynamic\nanalysis and property graphs, in: B. Thuraisingham, D. Evans, T. Malkin, D. Xu (Eds.), Proceedings of\nthe 2017 ACM SIGSAC Conference on Computer and Communications Security, CCS 2017, Dallas, TX,\nUSA, October 30 - November 03, 2017, ACM, 2017, pp. 1757\u20131771. doi:10.1145/3133956.3133959.\n[68] S. Lee, C. Yoon, C. Lee, S. Shin, V. Yegneswaran, P. A. Porras, Delta: A security assessment framework\nfor software-defined networks., in: NDSS, 2017. doi:10.14722/ndss.2017.23457.\n[69] C. K. Ng, Y. Yusof, N. S. N. Ab Aziz, Dfbc recon tool: Digital footprint and breach check reconnais-\nsance tool, in: 2021 14th International Conference on Developments in eSystems Engineering (DeSE),\nIEEE, 2021, pp. 526\u2013530. doi:10.1109/dese54285.2021.9719440.\n[70] N. Redini, A. Continella, D. Das, G. De Pasquale, N. Spahn, A. Machiry, A. Bianchi, C. Kruegel,\nG. Vigna, Diane: Identifying fuzzing triggers in apps to generate under-constrained inputs for iot\ndevices, in: 2021 IEEE Symposium on Security and Privacy (SP), IEEE, 2021, pp. 484\u2013500.\ndoi:\n10.1109/sp40001.2021.00066.\n[71] F. Aljaafari, R. Menezes, M. A. Mustafa, L. C. Cordeiro, Finding security vulnerabilities in iot cryp-\ntographic protocol and concurrent implementations (2021). doi:10.48550/arXiv.2103.11363.\n[72] L. Xu, M. Xu, F. Li, W. Huo, ELAID: detecting integer-overflow-to-buffer-overflow vulnerabilit-\nies by light-weight and accurate static analysis, Cybersecur. 3 (1) (2020) 1\u201319.\ndoi:10.1186/\ns42400-020-00058-2.\n[73] M. C. Ghanem, T. M. Chen, M. A. Ferrag, M. E. Kettouche, Esascf: Expertise extraction, generaliz-\nation and reply framework for optimized automation of network security compliance, IEEE Access 11\n(2023) 129840\u2013129853. doi:10.1109/access.2023.3332834.\n[74] Y. Zhang, W. Huo, K. Jian, J. Shi, L. Liu, Y. Zou, C. Zhang, B. Liu, Esrfuzzer: an enhanced fuzzing\nframework for physical SOHO router devices to discover multi-type vulnerabilities, Cybersecur. 4 (1)\n(2021) 24. doi:10.1186/s42400-021-00091-9.\n54\n[75] M. Rak, G. Salzillo, D. Granata, Esseca: An automated expert system for threat modelling and\npenetration testing for iot ecosystems, Computers and Electrical Engineering 99 (2022) 107721. doi:\n10.1016/j.compeleceng.2022.107721.\n[76] V. Visoottiviseth, P. Jutadhammakorn, N. Pongchanchai, P. Kosolyudhthasarn, Firmaster: Analysis\ntool for home router firmware, in: 2018 15th International Joint Conference on Computer Science and\nSoftware Engineering (JCSSE), 2018, pp. 1\u20136. doi:10.1109/JCSSE.2018.8457340.\n[77] S. Park, D. Kim, S. Jana, S. Son, FUGIO: automatic exploit generation for PHP object injection\nvulnerabilities, in: K. R. B. Butler, K. Thomas (Eds.), 31st USENIX Security Symposium, USENIX\nSecurity 2022, Boston, MA, USA, August 10-12, 2022, USENIX Association, 2022, pp. 197\u2013214.\n[78] T. Lee, S. Wi, S. Lee, S. Son, FUSE: finding file upload bugs via penetration testing, in: 27th An-\nnual Network and Distributed System Security Symposium, NDSS 2020, San Diego, California, USA,\nFebruary 23-26, 2020, The Internet Society, 2020. doi:10.14722/ndss.2020.23126.\n[79] J. Chen, S. Hu, H. Zheng, C. Xing, G. Zhang, Gail-pt: An intelligent penetration testing framework\nwith generative adversarial imitation learning, Computers & Security 126 (2023) 103055.\ndoi:10.\n1016/j.cose.2022.103055.\n[80] F. Yu, M. V. Martin, Gnpassgan: Improved generative adversarial networks for trawling offline pass-\nword guessing, in: 2022 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW),\nIEEE, 2022. doi:10.1109/eurospw55150.2022.00009.\n[81] S. Y. Enoch, Z. Huang, C. Y. Moon, D. Lee, M. K. Ahn, D. S. Kim, Harmer: Cyber-attacks automation\nand evaluation, IEEE Access 8 (2020) 129397\u2013129414. arXiv:2006.14352, doi:10.1109/ACCESS.2020.\n3009748.\n[82] R. Sommer, M. Vallentin, L. De Carli, V. Paxson, Hilti: an abstract execution environment for deep,\nstateful network traffic analysis, in: Proceedings of the 2014 Conference on Internet Measurement\nConference, IMC \u201914, ACM, 2014. doi:10.1145/2663716.2663735.\n[83] J. Chen, W. Diao, Q. Zhao, C. Zuo, Z. Lin, X. Wang, W. C. Lau, M. Sun, R. Yang, K. Zhang,\nIotfuzzer: Discovering memory corruptions in iot through app-based fuzzing, in: 25th Annual Network\nand Distributed System Security Symposium, NDSS 2018, San Diego, California, USA, February 18-21,\n2018, The Internet Society, 2018. doi:10.14722/ndss.2018.23159.\n[84] D. M. Stallenberg, A. Panichella, JCOMIX: a search-based tool to detect XML injection vulnerabilities\nin web applications, in: Proceedings of the 2019 27th ACM Joint Meeting on European Software\nEngineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE\n2019, Association for Computing Machinery, New York, NY, USA, 2019, pp. 1090\u20131094.\ndoi:10.\n1145/3338906.3341178.\n[85] M. Xu, S. Li, L. Xu, F. Li, W. Huo, J. Ma, X. Li, Q. Huang, A light-weight and accurate method\nof static integer-overflow-to-buffer-overflow vulnerability detection, in: F. Guo, X. Huang, M. Yung\n(Eds.), Information Security and Cryptology - 14th International Conference, Inscrypt 2018, Fuzhou,\nChina, December 14-17, 2018, Revised Selected Papers, Vol. 11449 of Lecture Notes in Computer\nScience, Springer, 2018, pp. 404\u2013423. doi:10.1007/978-3-030-14234-6_22.\n[86] S. Lee, S. Wi, S. Son, Link: Black-box detection of cross-site scripting vulnerabilities using rein-\nforcement learning, in: Proceedings of the ACM Web Conference 2022, 2022, pp. 743\u2013754.\ndoi:\n10.1145/3485447.3512234.\n[87] H. Holm, Lore a red team emulation tool, IEEE Trans. Dependable Secur. Comput. 20 (2) (2023)\n1596\u20131608. doi:10.1109/TDSC.2022.3160792.\n55\n[88] T. D. Hoang, C. Park, M. Son, T. Oh, S. Bae, J. Ahn, B. Oh, Y. Kim, Ltesniffer: An open-source lte\ndownlink/uplink eavesdropper, in: Proceedings of the 16th ACM Conference on Security and Privacy\nin Wireless and Mobile Networks, WiSec \u201923, Association for Computing Machinery, New York, NY,\nUSA, 2023, pp. 43\u201348. doi:10.1145/3558482.3590196.\n[89] M. Monshizadeh, P. Naldurg, V. N. Venkatakrishnan, Mace: Detecting privilege escalation vulnerab-\nilities in web applications, in: Proceedings of the 2014 ACM SIGSAC Conference on Computer and\nCommunications Security, 2014, pp. 690\u2013701. doi:10.1145/2660267.2660337.\n[90] C. Yucel, A. Lockett, I. Chalkias, D. Mallis, V. Katos, Mait: Malware analysis and intelligence tool,\nInformation & Security 50 (1) (2021) 49\u201365. doi:10.11610/isij.5024.\n[91] P. Johnson, R. Lagerstr\u00f6m, M. Ekstedt, A meta-language for threat modelling and attack simulations,\nin: Proceedings of the 13th International Conference on Availability, Reliability and Security, 2018,\npp. 1\u20138. doi:10.1145/3230833.3232799.\n[92] C. Liu, X. Cui, Z. Wang, X. Wang, Y. Feng, X. Li, Malicescript: A novel browser-based intranet\nthreat, in: 2018 IEEE Third International Conference on Data Science in Cyberspace (DSC), IEEE,\n2018, pp. 219\u2013226. doi:10.1109/dsc.2018.00039.\n[93] O. Mjihil, D. S. Kim, A. Haqiq, Masat: Model-based automated security assessment tool for cloud\ncomputing, in: 2015 11th International Conference on Information Assurance and Security (IAS),\nIEEE, 2015, pp. 97\u2013103. doi:10.1109/isias.2015.7492752.\n[94] R. Cayre, V. Nicomette, G. Auriol, E. Alata, M. Kaaniche, G. Marconato, Mirage:\ntowards a\nmetasploit-like framework for iot, in: 2019 IEEE 30th International Symposium on Software Reli-\nability Engineering (ISSRE), IEEE, 2019, pp. 261\u2013270. doi:10.1109/issre.2019.00034.\n[95] S. Calzavara, M. Conti, R. Focardi, A. Rabitti, G. Tolomei, Mitch: A machine learning approach\nto the black-box detection of CSRF vulnerabilities, in: IEEE European Symposium on Security and\nPrivacy, EuroS&P 2019, Stockholm, Sweden, June 17-19, 2019, IEEE, 2019, pp. 528\u2013543.\ndoi:10.\n1109/EuroSP.2019.00045.\n[96] H. Wei, B. Hassanshahi, G. Bai, P. Krishnan, K. Vorobyov, Moscan: a model-based vulnerability\nscanner for web single sign-on services, in: C. Cadar, X. Zhang (Eds.), ISSTA \u201921: 30th ACM SIGSOFT\nInternational Symposium on Software Testing and Analysis, Virtual Event, Denmark, July 11-17, 2021,\nACM, 2021, pp. 678\u2013681. doi:10.1145/3460319.3469081.\n[97] G. Deng, Z. Zhang, Y. Li, Y. Liu, T. Zhang, Y. Liu, G. Yu, D. Wang, NAUTILUS: automated\nrestful API vulnerability detection, in: J. A. Calandrino, C. Troncoso (Eds.), 32nd USENIX Security\nSymposium, USENIX Security 2023, Anaheim, CA, USA, August 9-11, 2023, USENIX Association,\n2023.\n[98] A. Alhuzali, R. Gjomemo, B. Eshete, V. N. Venkatakrishnan, NAVEX: precise and scalable exploit\ngeneration for dynamic web applications, in: W. Enck, A. P. Felt (Eds.), 27th USENIX Security\nSymposium, USENIX Security 2018, Baltimore, MD, USA, August 15-17, 2018, USENIX Association,\n2018, pp. 377\u2013392.\n[99] M. Kurth, B. Gras, D. Andriesse, C. Giuffrida, H. Bos, K. Razavi, Netcat: Practical cache attacks\nfrom the network, in: 2020 IEEE Symposium on Security and Privacy (SP), IEEE, 2020. doi:10.\n1109/sp40000.2020.00082.\n[100] W. Melicher, B. Ur, S. Komanduri, L. Bauer, N. Christin, L. F. Cranor, Fast, lean, and accurate:\nModeling password guessability using neural networks, in: D. D. Silva, B. Ford (Eds.), 2017 USENIX\nAnnual Technical Conference, USENIX ATC 2017, Santa Clara, CA, USA, July 12-14, 2017, USENIX\nAssociation, 2017.\nURL https://www.usenix.org/conference/atc17/technical-sessions/presentation/melicher\n56\n[101] W. H. Rankothge, S. M. N. Randeniya, Identification and mitigation tool for cross-site request forgery\n(csrf), in: 2020 IEEE 8th R10 Humanitarian Technology Conference (R10-HTC), 2020, pp. 1\u20135. doi:\n10.1109/R10-HTC49770.2020.9357029.\n[102] A. G. Leal, I. C. Teixeira, Development of a suite of ipv6 vulnerability scanning tests using the TTCN-3\nlanguage, in: 2018 International Symposium on Networks, Computers and Communications, ISNCC\n2018, Rome, Italy, June 19-21, 2018, IEEE, 2018, pp. 1\u20136. doi:10.1109/ISNCC.2018.8530888.\n[103] R. Chatterjee, J. Bonneau, A. Juels, T. Ristenpart, Cracking-resistant password vaults using natural\nlanguage encoders, in: 2015 IEEE Symposium on Security and Privacy, SP 2015, San Jose, CA, USA,\nMay 17-21, 2015, IEEE Computer Society, 2015, pp. 481\u2013498. doi:10.1109/SP.2015.36.\n[104] C. Ntantogian, P. Bountakas, D. Antonaropoulos, C. Patsakis, C. Xenakis, Nodexp: Node. js server-\nside javascript injection vulnerability detection and exploitation, Journal of Information Security and\nApplications 58 (2021) 102752. doi:10.1016/j.jisa.2021.102752.\n[105] N. Koutroumpouchos, G. Lavdanis, E. Veroni, C. Ntantogian, C. Xenakis, Objectmap:\ndetect-\ning insecure object deserialization, in:\nY. Manolopoulos, G. A. Papadopoulos, A. Stassopoulou,\nI. Dionysiou, I. Kyriakides, N. Tsapatsoulis (Eds.), Proceedings of the 23rd Pan-Hellenic Confer-\nence on Informatics, PCI 2019, Nicosia, Cyprus, November 28-30, 2019, ACM, 2019, pp. 67\u201372.\ndoi:10.1145/3368640.3368680.\n[106] M. D\u00fcrmuth, F. Angelstorf, C. Castelluccia, D. Perito, A. Chaabane, Omen: Faster password guessing\nusing an ordered markov enumerator, in: Engineering Secure Software and Systems: 7th International\nSymposium, ESSoS 2015, Milan, Italy, March 4-6, 2015. Proceedings 7, Springer, 2015, pp. 119\u2013132.\ndoi:10.1007/978-3-319-15618-7_10.\n[107] P. Kasemsuwan, V. Visoottiviseth, Osv: Ospf vulnerability checking tool, in: 2017 14th International\nJoint Conference on Computer Science and Software Engineering (JCSSE), IEEE, 2017, pp. 1\u20136.\ndoi:10.1109/jcsse.2017.8025919.\n[108] H. Cao, L. Huang, S. Hu, S. Shi, Y. Liu, Owfuzz: Discovering wi-fi flaws in modern devices through\nover-the-air fuzzing, in: Proceedings of the 16th ACM Conference on Security and Privacy in Wireless\nand Mobile Networks, WiSec \u201923, Association for Computing Machinery, New York, NY, USA, 2023,\npp. 263\u2013273. doi:10.1145/3558482.3590174.\n[109] B. Hitaj, P. Gasti, G. Ateniese, F. P\u00e9rez-Cruz, Passgan: A deep learning approach for password\nguessing, in: R. H. Deng, V. Gauthier-Uma\u00f1a, M. Ochoa, M. Yung (Eds.), Applied Cryptography\nand Network Security - 17th International Conference, ACNS 2019, Bogota, Colombia, June 5-7,\n2019, Proceedings, Vol. 11464 of Lecture Notes in Computer Science, Springer, 2019, pp. 217\u2013237.\ndoi:10.1007/978-3-030-21568-2_11.\n[110] J. Rando, F. P\u00e9rez-Cruz, B. Hitaj, Passgpt: Password modeling and (guided) generation with large\nlanguage models, in: G. Tsudik, M. Conti, K. Liang, G. Smaragdakis (Eds.), Computer Security -\nESORICS 2023 - 28th European Symposium on Research in Computer Security, The Hague, The\nNetherlands, September 25-29, 2023, Proceedings, Part IV, Vol. 14347 of Lecture Notes in Computer\nScience, Springer, 2023, pp. 164\u2013183. doi:10.1007/978-3-031-51482-1_9.\n[111] A. M. D. Campi, R. Focardi, F. L. Luccio, The revenge of password crackers: Automated training\nof password cracking tools, in: V. Atluri, R. D. Pietro, C. D. Jensen, W. Meng (Eds.), Computer\nSecurity - ESORICS 2022 - 27th European Symposium on Research in Computer Security, Copenhagen,\nDenmark, September 26-30, 2022, Proceedings, Part II, Vol. 13555 of Lecture Notes in Computer\nScience, Springer, 2022, pp. 317\u2013336. doi:10.1007/978-3-031-17146-8_16.\n57\n[112] R. Luh, M. Temper, S. Tjoa, S. Schrittwieser, H. Janicke, Penquest: a gamified attacker/defender\nmeta model for cyber security assessment and education, J. Comput. Virol. Hacking Tech. 16 (1)\n(2020) 19\u201361. doi:10.1007/S11416-019-00342-X.\n[113] G. Deng, Y. Liu, V. M. Vilches, P. Liu, Y. Li, Y. Xu, T. Zhang, Y. Liu, M. Pinzger, S. Rass,\nPentestgpt: An llm-empowered automatic penetration testing tool, CoRR abs/2308.06782 (2023).\narXiv:2308.06782, doi:10.48550/arXiv.2308.06782.\n[114] P. J. C. Nunes, J. Fonseca, M. Vieira, phpsafe: A security analysis tool for OOP web application\nplugins, in: 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks,\nDSN 2015, Rio de Janeiro, Brazil, June 22-25, 2015, IEEE Computer Society, 2015, pp. 299\u2013306.\ndoi:10.1109/DSN.2015.16.\n[115] S. Jain, R. Johari, A. Kaur, Pjct: Penetration testing based java code testing tool, in: International\nConference on Computing, Communication & Automation, IEEE, 2015, pp. 800\u2013805. doi:10.1109/\nccaa.2015.7148483.\n[116] N. Saccente, J. Dehlinger, L. Deng, S. Chakraborty, Y. Xiong, Project achilles: A prototype tool\nfor static method-level vulnerability detection of java source code using a recurrent neural network,\nin: 34th IEEE/ACM International Conference on Automated Software Engineering Workshops, ASE\nWorkshops 2019, San Diego, CA, USA, November 11-15, 2019, IEEE, 2019, pp. 114\u2013121.\ndoi:10.\n1109/ASEW.2019.00040.\n[117] J. Bozic, F. Wotawa, Purity: a planning-based security testing tool, in: 2015 IEEE International\nConference on Software Quality, Reliability and Security-Companion, IEEE, 2015, pp. 46\u201355. doi:\n10.1109/qrs-c.2015.19.\n[118] M. Muralidharan, K. B. Babu, G. Sujatha, Pyciuti:\nA python based customizable and flexible\ncybersecurity utility tool for penetration testing, in:\n2023 International Conference on Innovat-\nive Data Communication Technologies and Application (ICIDCA), IEEE, 2023, pp. 679\u2013683.\ndoi:\n10.1109/icidca56705.2023.10099938.\n[119] M. Amouei, M. Rezvani, M. Fateh, RAT: reinforcement-learning-driven and adaptive testing for vul-\nnerability discovery in web application firewalls, IEEE Trans. Dependable Secur. Comput. 19 (5) (2022)\n3371\u20133386. doi:10.1109/TDSC.2021.3095417.\n[120] Y. Liu, M. Zhang, W. Meng, Revealer: Detecting and exploiting regular expression denial-of-service\nvulnerabilities, in: 42nd IEEE Symposium on Security and Privacy, SP 2021, San Francisco, CA, USA,\n24-27 May 2021, IEEE, 2021, pp. 1468\u20131484. doi:10.1109/SP40001.2021.00062.\n[121] T. Cloosters, D. Paa\u00dfen, J. Wang, O. Draissi, P. Jauernig, E. Stapf, L. Davi, A.-R. Sadeghi, Riscyrop:\nAutomated return-oriented programming attacks on risc-v and arm64, in: Proceedings of the 25th\nInternational Symposium on Research in Attacks, Intrusions and Defenses, RAID \u201922, Association for\nComputing Machinery, New York, NY, USA, 2022, pp. 30\u201342. doi:10.1145/3545948.3545997.\n[122] G. Girotto, A. F. Zorzo, Robin: A web security tool, CoRR abs/2007.06629 (2020). arXiv:2007.06629,\ndoi:10.48550/arxiv.2007.06629.\n[123] S. Rivera, S. Lagraa, R. State, Rosploit: Cybersecurity tool for ROS, in: 3rd IEEE International\nConference on Robotic Computing, IRC 2019, Naples, Italy, February 25-27, 2019, IEEE, 2019, pp.\n415\u2013416. doi:10.1109/IRC.2019.00077.\n[124] F. Z. Fagroud, H. Toumi, Y. Baddi, S. El Filali, et al., Rt-rct: an online tool for real-time retrieval\nof connected things, Bulletin of Electrical Engineering and Informatics 10 (5) (2021) 2804\u20132810. doi:\n10.11591/eei.v10i5.2901.\n58\n[125] Z. Yin, Y. Xu, F. Ma, H. Gao, L. Qiao, Y. Jiang, Scanner++: Enhanced vulnerability detection of\nweb applications with attack intent synchronization, ACM Trans. Softw. Eng. Methodol. 32 (1) (Feb.\n2023). doi:10.1145/3517036.\n[126] R. Veras, C. Collins, J. Thorpe, On semantic patterns of passwords and their security impact, in: 21st\nAnnual Network and Distributed System Security Symposium, NDSS 2014, San Diego, California,\nUSA, February 23-26, 2014, The Internet Society, 2014. doi:10.14722/ndss.2014.23103.\n[127] M. Shcherbakov, M. Balliu, Serialdetector: Principled and practical exploration of object injection\nvulnerabilities for the web, in: 28th Annual Network and Distributed System Security Symposium,\nNDSS 2021, virtually, February 21-25, 2021, The Internet Society, 2021. doi:10.14722/ndss.2021.\n24550.\n[128] B. Genge, C. Enachescu, Shovat: Shodan-based vulnerability assessment tool for internet-facing ser-\nvices, Secur. Commun. Networks 9 (15) (2016) 2696\u20132714. doi:10.1002/SEC.1262.\n[129] J. Mikulskis, J. K. Becker, S. Gvozdenovic, D. Starobinski, Snout: An extensible iot pen-testing tool,\nin: L. Cavallaro, J. Kinder, X. Wang, J. Katz (Eds.), Proceedings of the 2019 ACM SIGSAC Conference\non Computer and Communications Security, CCS 2019, London, UK, November 11-15, 2019, ACM,\n2019, pp. 2529\u20132531. doi:10.1145/3319535.3363248.\n[130] N. Antunes, M. Vieira, Soa-scanner: an integrated tool to detect vulnerabilities in service-based infra-\nstructures, in: 2013 IEEE International Conference on Services Computing, IEEE, 2013, pp. 280\u2013287.\ndoi:10.1109/scc.2013.28.\n[131] R. Sommer, J. Amann, S. Hall, Spicy: a unified deep packet inspection framework for safely dissecting\nall your data, in: S. Schwab, W. K. Robertson, D. Balzarotti (Eds.), Proceedings of the 32nd Annual\nConference on Computer Security Applications, ACSAC 2016, Los Angeles, CA, USA, December 5-9,\n2016, ACM, 2016, pp. 558\u2013569. doi:10.1145/2991079.2991100.\n[132] Z. Li, X. Yu, D. Wang, Y. Liu, H. Yin, S. He, Supereye: A distributed port scanning system, in:\nX. Sun, Z. Pan, E. Bertino (Eds.), Artificial Intelligence and Security - 5th International Conference,\nICAIS 2019, New York, NY, USA, July 26-28, 2019, Proceedings, Part IV, Vol. 11635 of Lecture Notes\nin Computer Science, Springer, 2019, pp. 46\u201356. doi:10.1007/978-3-030-24268-8_5.\n[133] H. Holm, T. Sommestad, SVED: scanning, vulnerabilities, exploits and detection, in:\nJ. Brand,\nM. C. Valenti, A. Akinpelu, B. T. Doshi, B. L. Gorsic (Eds.), 2016 IEEE Military Communications\nConference, MILCOM 2016, Baltimore, MD, USA, November 1-3, 2016, IEEE, 2016, pp. 976\u2013981.\ndoi:10.1109/MILCOM.2016.7795457.\n[134] F. Valenza, E. Karafili, R. V. Steiner, E. C. Lupu, A hybrid threat model for smart systems, IEEE\nTrans. Dependable Secur. Comput. 20 (5) (2023) 4403\u20134417. doi:10.1109/TDSC.2022.3213577.\n[135] C. Luo, P. Li, W. Meng, Tchecker: Precise static inter-procedural analysis for detecting taint-style\nvulnerabilities in PHP applications, in: H. Yin, A. Stavrou, C. Cremers, E. Shi (Eds.), Proceedings\nof the 2022 ACM SIGSAC Conference on Computer and Communications Security, CCS 2022, Los\nAngeles, CA, USA, November 7-11, 2022, ACM, 2022, pp. 2175\u20132188. doi:10.1145/3548606.3559391.\n[136] O. Olivo, I. Dillig, C. Lin, Detecting and exploiting second order denial-of-service vulnerabilities in web\napplications, in: Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications\nSecurity, 2015, pp. 616\u2013628. doi:10.1145/2810103.2813680.\n[137] E. Bitsikas, S. Khandker, A. Salous, A. Ranganathan, R. Piqueras Jover, C. P\u00f6pper, Ue security\nreloaded: Developing a 5g standalone user-side security testing framework, in: Proceedings of the 16th\nACM Conference on Security and Privacy in Wireless and Mobile Networks, WiSec \u201923, Association\nfor Computing Machinery, New York, NY, USA, 2023, pp. 121\u2013132. doi:10.1145/3558482.3590194.\n59\n[138] A. Bertani, M. Bonelli, L. Binosi, M. Carminati, S. Zanero, M. Polino, Untangle: Aiding global function\npointer hijacking for post-cet binary exploitation, in: D. Gruss, F. Maggi, M. Fischer, M. Carminati\n(Eds.), Detection of Intrusions and Malware, and Vulnerability Assessment - 20th International Con-\nference, DIMVA 2023, Hamburg, Germany, July 12-14, 2023, Proceedings, Vol. 13959 of Lecture Notes\nin Computer Science, Springer, 2023, pp. 256\u2013275. doi:10.1007/978-3-031-35504-2_13.\n[139] K. Vimala, S. Fugkeaw, Vape-bridge: Bridging openvas results for automating metasploit framework,\nin: 2022 14th International Conference on Knowledge and Smart Technology (KST), IEEE, 2022.\ndoi:10.1109/kst53302.2022.9729085.\n[140] A. Blome, M. Ochoa, K. Li, M. Peroli, M. T. Dashti, Vera: A flexible model-based vulnerability testing\ntool, in: 2013 IEEE Sixth International Conference on Software Testing, Verification and Validation,\nIEEE, 2013, pp. 471\u2013478. doi:10.1109/icst.2013.65.\n[141] S. Kim, S. Woo, H. Lee, H. Oh, VUDDY: A scalable approach for vulnerable code clone discovery, in:\n2017 IEEE Symposium on Security and Privacy, SP 2017, San Jose, CA, USA, May 22-26, 2017, IEEE\nComputer Society, 2017, pp. 595\u2013614. doi:10.1109/SP.2017.62.\n[142] P. Kamongi, S. Kotikela, K. Kavi, M. Gomathisankaran, A. Singhal, Vulcan: Vulnerability assessment\nframework for cloud computing, in: 2013 IEEE 7th international conference on software security and\nreliability, IEEE, 2013, pp. 218\u2013226. doi:10.1109/sere.2013.31.\n[143] Y. Wu, D. Zou, S. Dou, W. Yang, D. Xu, H. Jin, Vulcnn: An image-inspired scalable vulnerability\ndetection system, in: Proceedings of the 44th International Conference on Software Engineering, ICSE\n\u201922, Association for Computing Machinery, New York, NY, USA, 2022, pp. 2365\u20132376. doi:10.1145/\n3510003.3510229.\n[144] Z. Li, D. Zou, S. Xu, X. Ou, H. Jin, S. Wang, Z. Deng, Y. Zhong, Vuldeepecker: A deep learning-\nbased system for vulnerability detection, in: 25th Annual Network and Distributed System Security\nSymposium, NDSS 2018, San Diego, California, USA, February 18-21, 2018, The Internet Society,\n2018. doi:10.14722/ndss.2018.23158.\n[145] P. Cigoj, B. J. Blazic, An intelligent and automated wcms vulnerability-discovery tool: The current\nstate of the web, IEEE Access 7 (2019) 175466\u2013175473. doi:10.1109/ACCESS.2019.2957573.\n[146] A. Castiglione, F. Palmieri, M. Petraglia, R. Pizzolante, Vulsploit: A module for semi-automatic\nexploitation of vulnerabilities, in: V. Casola, A. De Benedictis, M. Rak (Eds.), Testing Software\nand Systems, Springer, Springer International Publishing, Cham, 2020, pp. 89\u2013103.\ndoi:10.1007/\n978-3-030-64881-7_6.\n[147] Z. Li, D. Zou, S. Xu, H. Jin, H. Qi, J. Hu, Vulpecker: an automated vulnerability detection system\nbased on code similarity analysis, in: S. Schwab, W. K. Robertson, D. Balzarotti (Eds.), Proceedings\nof the 32nd Annual Conference on Computer Security Applications, ACSAC 2016, Los Angeles, CA,\nUSA, December 5-9, 2016, ACM, 2016, pp. 201\u2013213. doi:10.1145/2991079.2991102.\n[148] Z. \u00d0uri\u0107, Waptt-web application penetration testing tool, Advances in Electrical and Computer En-\ngineering 14 (1) (2014) 93\u2013102. doi:10.4316/AECE.2014.01015.\n[149] O. van Rooij, M. A. Charalambous, D. Kaizer, M. Papaevripides, E. Athanasopoulos, webfuzz: Grey-\nbox fuzzing for web applications, in: E. Bertino, H. Schulmann, M. Waidner (Eds.), Computer Security\n- ESORICS 2021 - 26th European Symposium on Research in Computer Security, Darmstadt, Germany,\nOctober 4-8, 2021, Proceedings, Part I, Vol. 12972 of Lecture Notes in Computer Science, Springer,\n2021, pp. 152\u2013172. doi:10.1007/978-3-030-88418-5_8.\n60\n[150] W. H. Rankothge, M. Randeniya, V. Samaranayaka, Identification and mitigation tool for sql injection\nattacks (SQLIA), in: 15th IEEE International Conference on Industrial and Information Systems, ICIIS\n2020, Rupnagar, India, November 26-28, 2020, IEEE, 2020, pp. 591\u2013595. doi:10.1109/ICIIS51140.\n2020.9342703.\n[151] J. Ding, Y. Atif, S. F. Andler, B. Lindstr\u00f6m, M. Jeusfeld, Cps-based threat modeling for critical\ninfrastructure protection, ACM SIGMETRICS Performance Evaluation Review 45 (2) (2017) 129\u2013132.\ndoi:10.1145/3152042.3152080.\n[152] I. Agadakos, C.-Y. Chen, M. Campanelli, P. Anantharaman, M. Hasan, B. Copos, T. Lepoint,\nM. Locasto, G. F. Ciocarlie, U. Lindqvist, Jumping the air gap: Modeling cyber-physical attack paths\nin the internet-of-things, in: Proceedings of the 2017 workshop on cyber-physical systems security and\nprivacy, 2017, pp. 37\u201348. doi:10.1145/3140241.3140252.\n[153] L. M. Castiglione, E. C. Lupu, Hazard driven threat modelling for cyber physical systems, in: Pro-\nceedings of the 2020 Joint Workshop on CPS&IoT Security and Privacy, 2020, pp. 13\u201324.\ndoi:\n10.1145/3411498.3419967.\n[154] M. Evans, Y. He, L. Maglaras, H. Janicke, Heart-is: A novel technique for evaluating human error-\nrelated information security incidents, Computers & Security 80 (2019) 74\u201389. doi:10.1016/j.cose.\n2018.09.002.\n[155] N. David, A. David, R. R. Hansen, K. G. Larsen, A. Legay, M. C. Olesen, C. W. Probst, Model-\nling social-technical attacks with timed automata, in: Proceedings of the 7th acm ccs international\nworkshop on managing insider security threats, 2015, pp. 21\u201328. doi:10.1145/2808783.2808787.\n[156] S. U. R. Malik, A. Anjum, S. A. Moqurrab, G. Srivastava, Towards enhanced threat modelling and\nanalysis using a markov decision process, Computer Communications 194 (2022) 282\u2013291. doi:10.\n1016/j.comcom.2022.07.038.\n[157] E. Kalliamvakou, G. Gousios, K. Blincoe, L. Singer, D. M. German, D. Damian, An in-depth study\nof the promises and perils of mining github, Empirical Software Engineering 21 (2016) 2035\u20132071.\ndoi:10.1007/s10664-015-9393-5.\n[158] A. Metzger, Free and open source software (FOSS) and other alternative license models: a comparative\nanalysis, Vol. 12, Springer, 2015.\n[159] S. Mirhosseini, C. Parnin, Docable: Evaluating the executability of software tutorials, in: Proceedings\nof the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the\nFoundations of Software Engineering, 2020, pp. 375\u2013385. doi:10.5281/zenodo.3903727.\n[160] T. Walshe, A. Simpson, An empirical study of bug bounty programs, in: 2020 IEEE 2nd interna-\ntional workshop on intelligent bug fixing (IBF), IEEE, 2020, pp. 35\u201344. doi:10.1109/ibf50092.2020.\n9034828.\n[161] K. Lynch, M. Ivancheva, Academic freedom and the commercialisation of universities: a critical ethical\nanalysis, Ethics in Science and Environmental Politics 15 (1) (2015) 71\u201385. doi:10.3354/esep00160.\n[162] University College and Union, Workload survery 2021 data report (Jun. 2022).\nURL\nhttps://www.ucu.org.uk/media/12905/UCU-workload-survey-2021-data-report/pdf/\nWorkloadReportJune22.pdf\n[163] M. Alhamed, M. M. H. Rahman, A systematic literature review on penetration testing in networks:\nFuture research directions, Applied Sciences 13 (12) (2023) 6986. doi:10.3390/app13126986.\n61\n[164] K. U. Sarker, F. Yunus, A. Deraman, Penetration taxonomy: A systematic review on the penetration\nprocess, framework, standards, tools, and scoring methods, Sustainability 15 (13) (2023) 10471. doi:\n10.3390/su151310471.\n[165] J. Shahid, M. K. Hameed, I. T. Javed, K. N. Qureshi, M. Ali, N. Crespi, A comparative study of web\napplication security parameters: Current trends and future directions, Applied Sciences 12 (8) (2022)\n4077. doi:10.3390/app12084077.\n[166] A. Alzahrani, A. Alqazzaz, Y. Zhu, H. Fu, N. Almashfi, Web application security tools analysis, in:\n2017 ieee 3rd international conference on big data security on cloud (bigdatasecurity), ieee international\nconference on high performance and smart computing (hpsc), and ieee international conference on\nintelligent data and security (ids), IEEE, 2017, pp. 237\u2013242. doi:10.11114/smc.v5i2.2663.\n[167] U. Ravindran, R. V. Potukuchi, A review on web application vulnerability assessment and penetration\ntesting., Review of Computer Engineering Studies 9 (1) (2022). doi:10.18280/rces.090101.\n[168] A. S. L. Kowta, K. Bhowmick, J. R. Kaur, N. Jeyanthi, Analysis and overview of information gathering\n& tools for pentesting, in: 2021 International Conference on Computer Communication and Informatics\n(ICCCI), IEEE, 2021, pp. 1\u201313. doi:10.1109/iccci50826.2021.9457015.\n[169] P. Zilberman, R. Puzis, S. Bruskin, S. Shwarz, Y. Elovici, Sok: A survey of open-source threat emu-\nlators, arXiv preprint arXiv:2003.01518 (2020).\n[170] Z. Durumeric, E. Wustrow, J. A. Halderman, {ZMap}: fast internet-wide scanning and its security\napplications, in: 22nd USENIX Security Symposium (USENIX Security 13), 2013, pp. 605\u2013620.\n[171] C. Lattner, V. S. Adve, LLVM: A compilation framework for lifelong program analysis & trans-\nformation, in: 2nd IEEE / ACM International Symposium on Code Generation and Optimization\n(CGO 2004), 20-24 March 2004, San Jose, CA, USA, IEEE Computer Society, 2004, pp. 75\u201388.\ndoi:10.1109/CGO.2004.1281665.\n[172] P. E. Black, P. E. Black, Juliet 1.3 test suite: Changes from 1.2, US Department of Commerce, National\nInstitute of Standards and Technology, 2018. doi:10.6028/NIST.TN.1995.\n[173] H. Bojinov, E. Bursztein, X. Boyen, D. Boneh, Kamouflage: Loss-resistant password management, in:\nComputer Security\u2013ESORICS 2010: 15th European Symposium on Research in Computer Security,\nAthens, Greece, September 20-22, 2010. Proceedings 15, Springer, 2010, pp. 286\u2013302. doi:10.1007/\n978-3-642-15497-3_18.\n[174] A. Narayanan, V. Shmatikov, Fast dictionary attacks on passwords using time-space tradeoff, in:\nProceedings of the 12th ACM conference on Computer and communications security, 2005, pp. 364\u2013\n372. doi:10.1145/1102120.1102168.\n[175] M. Weir, S. Aggarwal, B. De Medeiros, B. Glodek, Password cracking using probabilistic context-\nfree grammars, in: 2009 30th IEEE symposium on security and privacy, IEEE, 2009, pp. 391\u2013405.\ndoi:10.1109/sp.2009.8.\n[176] P. C. Pale, Mastering the Nmap Scripting Engine, Packt Publishing Ltd, 2015.\n62\n", "metadata": {"Published": "2024-07-19", "Title": "Bridging the Gap: A Survey and Classification of Research-Informed Ethical Hacking Tools", "Authors": "Paolo Modesti, Lewis Golightly, Louis Holmes, Chidimma Opara, Marco Moscini", "Summary": "The majority of Ethical Hacking (EH) tools utilised in penetration testing\nare developed by practitioners within the industry or underground communities.\nSimilarly, academic researchers have also contributed to developing security\ntools. However, there appears to be limited awareness among practitioners of\nacademic contributions in this domain, creating a significant gap between\nindustry and academia's contributions to EH tools. This research paper aims to\nsurvey the current state of EH academic research, primarily focusing on\nresearch-informed security tools. We categorise these tools into process-based\nframeworks (such as PTES and Mitre ATT\\&CK) and knowledge-based frameworks\n(such as CyBOK and ACM CCS). This classification provides a comprehensive\noverview of novel, research-informed tools, considering their functionality and\napplication areas. The analysis covers licensing, release dates, source code\navailability, development activity, and peer review status, providing valuable\ninsights into the current state of research in this field.", "entry_id": "http://arxiv.org/abs/2407.14255v1", "published_first_time": "2024-07-19", "comment": "This is the extended version of the paper published in the Journal of\n  Cybersecurity and Privacy, 4, no. 3: pp 410-448, 2024", "journal_ref": "Volume 4, Issue 3: pp 410-448, 2024", "doi": "10.3390/jcp4030021", "primary_category": "cs.CR", "categories": ["cs.CR"], "links": ["http://dx.doi.org/10.3390/jcp4030021", "http://arxiv.org/abs/2407.14255v1", "http://arxiv.org/pdf/2407.14255v1"]}, "type": "Document"}
{"page_content": "Leveraging Reinforcement Learning in Red Teaming\nfor Advanced Ransomware Attack Simulations\nCheng Wanga\u2217, Christopher Redinoa, Ryan Clarka, Abdul Rahmana, Sal Aguinagaa Sathvik Murlia,\nDhruv Nandakumara, Roland Raoa, Lanxiao Huangb, Daniel Radkea, Edward Bowena\naDeloitte & Touche LLP\nbNational Security Institute, Virginia Tech\n\u2217Corresponding author: chengwang@deloitte.com\nAbstract\u2014Ransomware presents a significant and increasing\nthreat to individuals and organizations by encrypting their\nsystems and not releasing them until a large fee has been\nextracted. To bolster preparedness against potential attacks,\norganizations commonly conduct red teaming exercises, which\ninvolve simulated attacks to assess existing security measures.\nThis paper proposes a novel approach utilizing reinforcement\nlearning (RL) to simulate ransomware attacks. By training an RL\nagent in a simulated environment mirroring real-world networks,\neffective attack strategies can be learned quickly, significantly\nstreamlining traditional, manual penetration testing processes.\nThe attack pathways revealed by the RL agent can provide\nvaluable insights to the defense team, helping them identify net-\nwork weak points and develop more resilient defensive measures.\nExperimental results on a 152-host example network confirm the\neffectiveness of the proposed approach, demonstrating the RL\nagent\u2019s capability to discover and orchestrate attacks on high-\nvalue targets while evading honeyfiles (decoy files strategically\nplaced to detect unauthorized access).\nIndex\nTerms\u2014reinforcement\nlearning,\ncyber\nattack,\nran-\nsomware, red teaming, simulated attack, honeyfile, RL, AI\nI. INTRODUCTION\nAs a form of malicious software, ransomware aims to\nencrypt files or lock computer systems until a ransom is\npaid (typically in cryptocurrency) to the attacker. It is a form\nof cyber extortion where the attacker demands payment in\nexchange for restoring access to the encrypted files or unlock-\ning the affected system. Ransomware attacks are increasingly\nprevalent and sophisticated, and have targeted individuals,\nbusinesses, and governmental institutions [1], [2], with notable\nincidents in recent years including the WannaCry outbreak in\n2017 affecting thousands of systems worldwide [3].\nMitigating ransomware attacks can be accomplished through\nregularly conducting red teaming exercises [4] aimed at sim-\nulating such attacks to enhance preparedness. These exer-\ncises serve to test the efficacy of existing security measures\nand infrastructure. Organizations can develop and implement\ntargeted security measures by gaining insight into potential\nvulnerabilities within their systems, empowering them to better\nsafeguard against ransomware threats and mitigate associated\nrisks.\nOne approach to achieving this involves constructing a sim-\nulated environment, often referred to as a \u201cdigital twin\u201d, that\nmirrors the real network infrastructure. Instead of enumerating\nall potential attack pathways or manually selecting them based\non deep domain expertise, an RL agent can be trained to\nautomatically identify effective attack strategies by directly\ninteracting with the simulated environment. Leveraging RL\nnot only lessens the burden of manual testing, thereby en-\nhancing the efficiency and scalability of penetration testing,\nbut also enables adaptive learning and continual refinement\nof defense strategies. The findings generated by the RL agent\ncan provide valuable insights that enable the defense (blue)\nteam to refine existing strategies or develop new ones. The\nnew environment can then be leveraged to train new agents,\nfurther testing the robustness of the defense measures. Through\nthis iterative learning and improvement process, weaknesses\nin the defense mechanisms can be continuously identified\nand addressed. Consequently, this iterative approach can help\nfoster a proactive defense posture, tested against objective-\ndriven (as opposed to rule-based) dynamic attacking strategies,\nthereby enhancing resilience against ransomware threats.\nTo our knowledge, this study represents the first exploration\nof using RL to simulate ransomware attacks at the network\nlevel. We introduce a novel ransomware attack simulation\nmodel designed to replicate real-world scenarios where at-\ntackers seek to encrypt sensitive hosts within a limited time\nframe. The attacker\u2019s strategic dilemma is central to our\nmodel: exploring the network to uncover valuable targets or\nimmediately encrypt known hosts. The latter risks trigger-\ning prompt defense responses and prematurely ending the\nattacker\u2019s campaign. Additionally, the attacker must navigate\nthe network while avoiding encrypting honeyfiles [5]. This\ncomplex decision-making process underscores the nontriv-\nial nature of coordinating attacks on high-value assets. A\ndetailed RL formulation for this attack simulation is then\npresented. Experiment results on a 152-host medium-sized\nnetwork demonstrate the effectiveness and efficiency of the\nattack strategies learned by the RL agents with different risk\nprofiles. In addition, we show how, based on the initial results,\nhoneyfiles can be strategically added to improve security and\nhow, by retraining the RL agent in the new environment,\nadditional insights are revealed, which may help the blue\nteam continue to devise and implement more robust defense\nmeasures.\nThis paper is organized as follows: Section II reviews\nrelated work on ransomware and RL-based penetration testing.\nSection III provides the necessary background on RL. The\narXiv:2406.17576v1  [cs.CR]  25 Jun 2024\nattack simulation and its RL model are presented in Section\nIV. Section V details the experimentation setup and results.\nFinally, section VI concludes by discussing the limitations of\nthe current work and suggesting avenues for future research.\nII. RELATED WORK\nIncreasing interest in the application of machine learning\n(ML) to detection and classification of ransomware [1], [6]\nhas led to multitude of classifiers being proposed, with notable\nalgorithms or architectures including support vector machine\n[7], [8], random forest [9], [10], convolutional neural network\n[11], long short-term Memory [12], and self-attention [13],\n[14]. These models are trained on various features, such as\napplication programming interface (API) calls, network traffic,\nand file entropy, which are often derived through dynamic\nanalysis where a sample of malicious code is executed in a\ncontrolled environment [15]. These ML based approaches have\ndemonstrated high accuracy along with a low false-positive\nrate.\nHowever, the exploration of utilizing RL for ransomware\nsimulation is still in its nascent stages. In [16], an RL-\nbased ransomware simulator is proposed to evade a rule-based\ndetection system on a single host machine. The RL agent\naims to encrypt as many files as possible while keeping the\nnumber of files with a second extension, high entropy, or\nsimilar modification time below a given threshold to avoid\ndetection. In their experiments, there are only 11 distinct states\nin total, which correspond to the number of encrypted files\n(i.e., 0, 1, ..., 10). The action space is also limited, consisting\nof just 16 possible actions, based on a combination of three\nfactors: the number of files to encrypt (such as 1, 2, 5, or 10),\nthe decision to add an extension to encrypted files, and the\nchoice to encode files with Base64 to reduce their entropy. The\nresults showcased the potential of using RL to identify attack\nstrategies that can bypass an existing rule-based detection\nsystem on individual hosts.\nOther notable applications of RL in red teaming exercises\ninclude crown-jewel (CJ) analysis [17], exfiltration (exfil) path\ndiscovery [18], [19], surveillance detection routes (SDR) [20],\nand command and control (C2) [21]. These studies integrate\ncyber terrain [22], [23] into the RL environment through\nmeticulous but manual reward engineering and adjustment of\ntransition probabilities. In these works, the underlying net-\nworks are derived directly from scanning results of enterprise\nnetworks, typically comprising hundreds to thousands of hosts.\nExperiment results have shown the effectiveness and efficiency\nof using RL to automate the discovery process of attack paths\nin various penetration testing tasks.\nIII. PRELIMINARIES ON REINFORCEMENT LEARNING\nIn RL, an agent learns to optimize its behaviors by interact-\ning with the environment [24]. The environment is defined as\na Markov decision process (MDP): (S, A, P, r, \u03b3), where S is\nthe state space, A is the action space, P : S \u00d7 A \u00d7 S \u2192[0, 1]\nis the transition probability function, r : S \u00d7 A \u00d7 S \u2192R\nis the reward function and \u03b3 \u2208(0, 1] is the discount factor,\nwhich determines the present value of future rewards. At\neach step t, the agent observes a state st and selects an\naction at according to its policy \u03c0 : S \u00d7 A \u2192[0, 1],\nwhich is a probabilistic distribution over each action. It then\ntransitions to the next state st+1 according to P and receives\na reward rt = r(st, at, st+1). The goal of the agent is to\nlearn a policy that maximizes the expected cumulative rewards\nGt \u2261P\u221e\nk=0 \u03b3krt+k, which is also referred to as return.\nOne approach to learning a policy involves optimizing a\nperformance measure J(\u03b8), such as the expected return, where\n\u03b8 is the parameters of the policy. According to the Policy\nGradient Theorem [25], the gradient of the policy can be\nestimated as\n\u2207\u03b8J(\u03b8) \u2248E\nh\nT\nX\nt=0\n\u2207\u03b8 log\u03b8 \u03c0(at|st)A\u03c0\u03b8(st, at)\ni\n,\n(1)\nwhere A\u03c0\u03b8(st, at) = Q\u03c0\u03b8(st, at) \u2212V \u03c0\u03b8(st) is the advantage\nfunction. Here V \u03c0\u03b8(st) is the expected return from state st\nand Q\u03c0\u03b8(st, at) represents the state-action value, i.e., the\nexpected return of taking action at in state st and thereafter\nfollowing policy \u03c0\u03b8. The advantage function quantifies the\nrelative benefit of choosing a specific action at in a given\nstate st, compared to the expected value of the average action\nunder the current policy.\nTo improve training stability and avoid large updates be-\ntween steps, the Proximal Policy Optimization (PPO) algo-\nrithm [26] instead uses a clipped surrogate objective function:\nL(\u03b8) = E\nh\nmin\n\u0000\u03c1t(\u03b8)At, clip\n\u0000\u03c1t(\u03b8), 1 \u2212\u03f5, 1 + \u03f5\n\u0001\nAt\n\u0001i\n, (2)\nwhere \u03c1t(\u03b8) = \u03c0\u03b8(at|st)/\u03c0\u03b8old(at|st) is the probability ratio\nof the new policy over the old policy. The advantage function\nAt in (2) can be estimated using the generalized advantage\nestimation (GAE) [27], truncated after T steps:\n\u02c6\nAt = \u03b4t + (\u03b3\u03bb)\u03b4t+1 + \u00b7 \u00b7 \u00b7 + (\u03b3\u03bb)T \u2212t+1\u03b4T \u22121,\n(3)\nwhere \u03b4t = rt + \u03b3V (st+1) \u2212V (st).\n(4)\nFinally, as a means to encourage sufficient exploration, an\nentropy bonus \u03b2H(\u03c0\u03b8) is often added to the objective function\n(2), where \u03b2 is a hyperparameter. The PPO algorithm is shown\nin Algorithm 1 for reference.\nIV. REINFORCEMENT LEARNING MODEL FOR\nRANSOMWARE ATTACK SIMULATION\nA. Attack Simulation Overview\nWe consider a scenario where an attacker, having gained\nan initial foothold on a host in a network, seeks to identify,\ncompromise, and encrypt high-value targets in a swift and\nstealthy manner for maximum impact and ransom leverage.\nIn this red teaming exercise, we aim to emulate adversary\nstrategies tailored to evade deployed defensive measures and\nto identify the optimal time and placement for delivering\noffensive capabilities.\nIt is assumed that different hosts in a given network\nhave varying levels of importance, each characterized by a\nAlgorithm 1: Proximal Policy Optimization (PPO)\nInitialize: actor network \u03c0\u03b8 and critic network Vw\nfor iteration = 1, 2, ... do\nSet \u03b8old = \u03b8\nRun \u03b8old for T steps\nCompute advantage estimates \u02c6\nAt and targets \u02c6\nVt\nfor epoch = 1, 2, ..., K do\nCompute surrogate objective Lact(\u03b8)\nCompute entropy H(\u03b8)\nCompute mean-squared-error Lcrt(w)\nUpdate actor \u03b8 \u2190\u03b8 + \u03b1\u03b8\u2207\n\u0002\nLact(\u03b8) + \u03b2H(\u03b8)\n\u0003\nUpdate critic w \u2190w \u2212\u03b1w\u2207Lcrt(w)\nend\nend\nnumerical value. Upon getting initial access to a network,\nattackers often refrain from immediate aggressive actions to\nevade alerting by defensive infrastructure. Instead, adversaries\ninitiate careful and quiet exploration while moving laterally to\nidentify the most valuable assets. By avoiding early detection,\nthe chances of accessing high-value targets and inflicting\nmore significant damage are quite high, thereby maximizing\neffectiveness and payoff.\nThe following defensive mechanisms are assumed to be in\nplace based on information technology (IT) leading practices\n[28]. First, it is assumed that each system is regularly updated\nand patched. This causes attackers to access to compromised\nhosts after a period of time if no further action is taken.\nConsequently, they have only a limited time window to\nperform follow-up actions such as scanning or encrypting the\nunderlying host before losing their initial access. Second, once\na device is encrypted and the ransom note is posted, there is\na delay (e.g., one hour) before the defense team isolates it\nfrom the rest of the network. During this time, the attacker\nmay continue to move laterally, discovering and compromising\nadjacent systems. Thirdly, honeyfiles are strategically deployed\non selected hosts. Attempts to encrypt these files will imme-\ndiately trigger an alert, leading to the swift isolation of the\naffected host. Finally, when the total number of isolated hosts\nexceeds a predefined threshold, in scope systems will be taken\noffline and examined. This measure prevents further damage\nfrom occuring and effectively terminates the current attack\ncampaign.\nIn addition to the traditional time steps in MDPs, a simu-\nlated wall clock tracks the progress of attacks and responses.\nDifferent actions require varying amounts of time to execute,\nand certain defense measures, as previously described, auto-\nmatically activate upon meeting a predefined criterion.\nB. States\nThe state of the RL environment consists of a number of\nfeatures from each host in the network, such as its address,\noperating system (OS), running services and processes, in-\nfection and encryption status, and so on (see Table I for a\nlist). It is important to note whether a host has honey files\nTABLE I: Overview of the state space.\nHost Feature\nDescription\nSubnet ID\nOne-hot encoding of the host\u2019s subnet.\nLocal ID\nOne-hot encoding of the host\u2019s local address.\nDiscovered\nWhether the host has been discovered.\nOS\nWhether an OS is running on the host.\nServices\nWhether a service is running on the host.\nProcesses\nWhether a process is running on the host.\nHas Honeyfiles\nWhether the host has honeyfiles.\nFound Honeyfiles\nWhether honeyfiles has been found on the host.\nExploited\nWhether the host has been compromised.\nAccess\nAccess level gained on the host.\nScanned\nWhether the host\u2019s file system has been scanned.\nEncrypted\nWhether the host has been encrypted.\nIsolated\nWhether the host has been isolated by defenders.\nValue\nValue of encrypting the host.\nInfection Time\nTime elapsed since the host was compromised.\nEncryption Time\nTime elapsed since the host was encrypted.\n(i.e., HAS_Honeyfiles) is not directly observable to the RL\nagent. However, the agent can potentially discover honey files\nwith a certain probability by taking a File_Scan action. If\nhoney files are detected on a host, the corresponding feature\nFound_Honeyfiles, observable to the agent, will be set\nto True.\nC. Actions\nThere are four types of actions in the action space (Ta-\nble II). The first type, Subnet_scan, is used to discover\nneighboring hosts and find out their OS, running services and\nprocesses. Access to the underlying host must be gained to\nperform a subnet scan. A successful scan will reveal each of\nthe hosts within the same subnet, as well as some hosts from\nadjacent subnets, subject to firewall rules.\nNext, a suitable Exploit action must be selected and\nexecuted to gain control of a discovered host. Each exploit\ntargets a specific OS, service, or process, and is associated with\na corresponding vulnerability in the Common Vulnerabilities\nand Exposures database.\nAfter establishing a foothold, the agent may conduct a thor-\nough scan of the host\u2019s file system by initiating a File_scan\naction, enabling the agent to assess the host\u2019s significance\nand identify potential honeyfiles. This may be done through\nmetadata analysis, without directly accessing or opening the\nfiles themselves. If honeyfiles are present on a system, the\nagent can detect them with a certain probability and then set\nthe host\u2019s attribute Found_Honeyfiles to True.\nFinally, the agent can initiate the encryption process by\nexecuting the Encrypt action. When honeyfiles are modi-\nfied, alerts will be triggered and the underlying host will be\nisolated to prevent further unauthorized activities or network\ninfiltration. However, if honeyfiles have been identified on a\nTABLE II: Overview of the action space.\nAction\nDescription\nSubnet scan\nDiscover nearby hosts and their configurations.\nExploit\nExploit a vulnerability to establish a foothold.\nFile scan\nScan file system to identify potential honeyfiles.\nEncrypt\nEncrypt file system to restrict access by original users.\nFig. 1: Experiment network topology overview: Nodes depict\nsubnets, with sizes proportional to the number of hosts within.\nOnly subnet 15 (green node) is public.\nsystem, the attacker agent will skip those files and encrypt\nthe remaining files without triggering an alert. As a means to\nexpedite the attack campaign, the agent may choose to bypass\nthe file scanning step for some hosts and proceed directly to\nthe encryption phase, although this may lead to undesirable\nconsequences, such as accessing decoy files or encrypting\nhosts of lesser significance.\nD. Rewards\nThe reward function encompasses a positive component\nr+, rewarding successful outcomes in discovery, exploitation,\nand encryption, coupled with a negative component, \u03c1r\u2212,\naccounting for the associated costs of traversing cyber terrain,\nwhere \u03c1 symbolizes the level of the risk aversion:\nr(s, a, s\u2032) = r(s, a, s\u2032)+ \u2212\u03c1r\u2212(s, a, s\u2032).\n(5)\nIt is worth mentioning that the penalty term depends not\nonly on the type of the action but also on its target host. As\ndevices within a network typically serve different roles and\nfunctionalities, the defensive measures around them usually\nvary. For instance, critical assets such as databases are usually\nmore closely monitored than other systems. Although the exact\ndefense measures in place may not be known, experienced\nhackers or penetration testers can often deduce the level\nof security surrounding a target based on the services it is\nrunning. By varying the penalties for taking actions towards\ndifferent targets, the reward function (5) hence incorporates\nthe heterogeneity in cyber terrains as introduced in [23].\nV. EXPERIMENTATION AND RESULTS\nA. Network Configuration\nThe experimental network is designed by domain profes-\nsionals to emulate a mid-size enterprise network, intentionally\nincorporating certain weaknesses. The entire network (Fig.\n1) comprises 152 hosts distributed across 22 subnets, each\nrepresenting distinct functionalities or areas of operation. In\nparticular, subnet 15 serves as the demilitarized zone (DMZ),\nTABLE III: PPO hyperparameters.\nHyperparameter\nValue\nHorizon (T)\n4096\nMinibatch size\n64\nEpochs\n10\nClipping ratio (\u03f5)\n0.1\nEntropy bonus (\u03b2)\n0.005\nDiscount factor (\u03b3)\n0.999\nAdvantage discount factor (\u03bb)\n0.95\nLearning rate (critic)\n3 \u00d7 10\u22124\nLearning rate (actor)\n1 \u00d7 10\u22125\nrepresenting the network\u2019s sole public-facing subnet. It is\nassumed that the attacker has gained an initial foothold on\nhost (15, 12), where 12 is the host\u2019s local ID in subnet 15.\nThis host provides multiple services, including web hosting,\nmail, and file transfer.\nOut of the 152 hosts across the whole network, 14 have been\ndesignated as sensitive hosts, and 23 have been placed with\nhoneyfiles. It\u2019s important to note that not all hosts are reachable\nor exploitable by the RL agent. It is the agent\u2019s responsibility\nto identify vulnerable high-value targets and coordinate its\nattacks accordingly.\nB. Training setup\nThe rewards for successfully discovering, exploiting, and\nencrypting a host are 10, 10 and 50, respectively. In addition,\nupon successfully encrypting a host, the agent receives a bonus\nreward equivalent to the predetermined value assigned to the\nhost. This value ranges from 1000 for sensitive hosts to 0 for\nnon-critical hosts. The penalty for an action depends on its\ntype and the services running on its target host, ranging from\n1 to 6. An episode ends when more than 3 hosts are flagged\nor isolated. A host is immediately flagged if its honeyfiles are\naccessed. Otherwise, if the host is encrypted, it will be isolated\nfrom the rest of the network within one hour, assuming there\nis a delay in the response from defense teams. The wall-clock\ntimes for the actions subnet scan, exploit, file scan, and encrypt\nare set to 30, 10, 60, and 300 seconds, respectively.\nThree RL models are trained using the PPO algorithm [26],\nas listed in Algorithm 1, with varying risk aversion factors:\nlow (\u03c1 = 1), medium (\u03c1 = 5), and high (\u03c1 = 20). Both actor\n(policy) and critic (value) networks consist of 2-layer multi-\nperceptron neural networks with 200 neurons in each layer.\nTable III lists the main hyperparameters used for training.\nC. Results\nThe three models, each with different risk aversion factors,\nconverged within 50,000 episodes, as evidenced by the gradual\nincrease in episode rewards depicted in Fig. 2. Furthermore,\nthe number of steps in an episode decreases as training\nprogresses, as illustrated in Fig. 3, indicating the improved\nefficiency of the RL agent\u2019s operations. It is worth noting that\nthe agent with high-risk aversion takes fewer steps compared\nto the agent with low-risk aversion. This is due to actions\nincurring increased penalties, prompting the agent to avoid\nunnecessary or exploratory steps.\nFig. 2: Episode rewards under different risk aversion factors:\n\u03c1 = 1 (top), \u03c1 = 5 (middle), and \u03c1 = 20 (bottom).\nFig. 3: Episode lengths under different risk aversion factors.\nHigher risk aversion also results in a lower number of\nencrypted hosts, as shown in Fig. 4. With \u03c1 = 20, the\nagent encrypts just over 5 hosts as training approaches 50,000\nepisodes, whereas under \u03c1 = 1, the number of encrypted hosts\nmore than doubles to over 12.\nWe generated 100 trajectories using the final model for\neach risk aversion factor to delve deeper into the hosts being\nencrypted under various risk profiles. Fig. 5 displays the most\nfrequently encrypted hosts under each factor. Notably, five\nhosts consistently stand out, being encrypted more than 90\npercent of the time, irrespective of the agent\u2019s risk preference.\nFig. 4: Number of encrypted hosts under different risk aversion\nfactors.\nThese hosts, namely (8, 0), (9, 0), (10, 5), (12, 0), and (21,\n3), are sensitive hosts valued at 1000. Table IV presents an\noverview of the key services operating on these hosts along-\nside their respective roles. As evident from the table, these\nhosts fulfill critical roles within the network, encompassing\nfunctions such as authentication, database management, file\ntransfer, logging, network configuration, and printing services.\nAnother notable observation from Fig. 5 is that the agent\nsometimes encrypts host (15, 12), where it gains the initial\naccess to the network, despite it being a non-sensitive host\nvalued at 0 and yielding a reward of only 50 upon successful\nencryption. However, as the penalty factor increases, this\noccurs less often due to the increased costs and diminishing\nincentives.\nD. Impacts of Introducing New Honeyfiles\nBy analyzing the behaviors and outcomes of the RL agents,\nthe blue team can devise and implement different defensive\nstrategies in response. For instance, an immediate measure is\nto deploy honeyfiles on the vulnerable sensitive hosts identified\nin Table IV. After the introduction of these new honeyfiles,\nthe attacking agent\u2019s performance significantly deteriorated.\nOut of 100 episodes, it averaged a reward of -197 and\nencrypted only 2.6 hosts per episode, compared to the previous\naverages of 4818 reward and 10.9 encrypted hosts per episode,\nrespectively (refer to Table V).\nHowever, this remedy may offer only temporary protection,\nassuming the attacker possesses some capabilities 1 to detect\nhoneyfiles. Upon re-training the RL agent in this altered\nenvironment, it partially recovers its previous performance,\nachieving an average reward close to 3000 and encrypting\n5.3 hosts per episode (Table V). An example attack path is\nshown in Table VI. It is evident that the agent has learned\nto conduct file-scans before attempting to encrypt sensitive\nhosts. Despite incurring additional costs, these additional steps\nrepresent essential precautions that the agent must take when\nconducting attacks in a more fortified environment.\nTable VI also highlights the key pivot point in the attack\npath, namely host (18, 4), which runs multiple services in-\n1In the experiment, it is assumed that the agent can identify honeyfiles with\na probability of 0.8 after performing a file scanning action.\nFig. 5: Top 15 most frequently encrypted hosts from 100 attack paths under different risk-aversion profiles: \u03c1 = 1 (top), \u03c1 = 5\n(middle), \u03c1 = 20 (bottom).\nTABLE IV: Sensitive hosts overview: roles and key services.\nHost\nRole\nKey Services*\n(8, 0)\nWeb services and secure access\nHTTPS, Terminal server, OpenSSH\n(9, 0)\nNetwork services and file sharing\nNetBIOS-DGM, FTP\n(10, 5)\nDatabase and logging services\nSQL monitor, SYSLOG, Subroutine caller\n(12, 0)\nNetwork management and file sharing\nNetBIOS-SSN, SNMP, FTP\n(21, 3)\nNetwork configuration and printing services\nDHCP, Directory service, IPP\n* Acronyms of services refer to the following: DHCP (Dynamic Host Configuration Protocol), FTP (File Transfer Protocol), HTTPS (Hypertext Transfer Protocol Secure),\nIPP (Internet Printing Protocol), NetBIOS-DGM (Network Basic Input/Output System Datagram service), NetBIOS-SSN (NetBIOS-Session Service), OpenSSH (Open\nSecure Shell), SNMP (Simple Network Management Protocol), SYSLOG (System Logging),\ncluding OpenSSH, HTTP, HTTPS, and MS-SQL-M. Gaining\ncontrol of this host enables communication to the other sub-\nnets, a capability not feasible from the starting DMZ (i.e.,\nsubnet 15), which is only connected to subnets 5, 6, 12, 18,\n19, and 20. These findings suggest several solutions to enhance\nnetwork security. For instance, strengthening access control\nand promptly applying patches to address vulnerabilities at\ncritical junctures, as well as refining network segmentation to\nbetter isolate critical assets from less secure areas. Once these\nimprovements are made, RL agents can again be trained to\nfurther evaluate their effectiveness. As a result, the iterative\nprocess between blue and red teams can facilitate the building\nof a more robust and secure network environment.\nTABLE V: Comparison of performance (mean \u00b1 sd) on the\noriginal network, modified network with new honeyfiles, and\nretrained model on the new network (\u03c1 = 1).\nOriginal model\nNew honeyfiles\nRetrained model\nRewards\n4818 \u00b1 356\n-197 \u00b1 563\n2996 \u00b1 1126\nSteps\n200 \u00b1 35\n109 \u00b1 45\n172 \u00b1 61\nCompromised\n39.2 \u00b1 5.8\n26.0 \u00b1 7.0\n29.2 \u00b1 8.8\nEncrypted\n10.9 \u00b1 1.9\n2.6 \u00b1 2.3\n5.3 \u00b1 1.4\nVI. CONCLUSION\nWe have proposed a ransomware attack simulation and its\nRL model as a red teaming tool to streamline the penetra-\ntion testing process. By leveraging RL, potential attacking\nstrategies or pathways can be quickly identified. We demon-\nTABLE VI: Example attack path.\nSteps\nAction\nTarget\n1\nSubnet Scan\n(15, 12)\n2\nExploit\n(18, 4)\n3\nSubnet Scan\n(18, 4)\n4\nExploit\n(12, 0)\n5\nFile Scan\n(12, 0)\n6\nExploit\n(10, 5)\n7\nExploit\n(9, 0)\n8\nFile Scan\n(9, 0)\n9\nFile Scan\n(10, 5)\n10\nExploit\n(8, 0)\n11\nFile Scan\n(8, 0)\n12\nExploit\n(21, 3)\n13\nFile Scan\n(15, 12)\n14\nFile Scan\n(21, 3)\n15\nEncrypt\n(10, 5)\n16\nEncrypt\n(9, 0)\n17\nExploit\n(16, 7)\n18\nEncrypt\n(8, 0)\n19\nExploit\n(15, 14)\n20\nEncrypt\n(21, 3)\n21\nEncrypt\n(12, 0)\nstrate this on a medium-sized network, where effective attack\nstrategies with varying risk aversion factors can be learned.\nThe RL agent is capable of discovering high-value targets\nwithin the network and coordinating its attacks to maximize\ndamage. These findings provide valuable insights and can\nhelp blue teams develop more resilient defensive measures,\nwhich may, in turn, be used to train more advanced attacking\nagents, thereby revealing additional weaknesses in the security\nposture.\nOne extension of the current work is to consider the\nadversarial multi-agent RL framework, where the attacker and\ndefender compete with each other directly in the same envi-\nronment. Additionally, instead of statically placing honeyfiles\non the same hosts, defenders may opt to deploy honeyfiles or\nhoneypots dynamically to distract or deter attackers.\nAnother direction for future work is to integrate the at-\ntack model with the multi-objective reinforcement learning\n(MORL) framework, which allows the RL agent to optimize\nmultiple (and potentially conflicting) objectives simultane-\nously, thus enabling it to handle complex decision-making\nscenarios. Unlike the current RL formulation, which requires\nmeticulous crafting of rewards and poses hard thresholds\non termination conditions, MORL offers a multi-dimensional\nreward function that can directly incorporate various metrics of\nthe attack campaign. This will also provide greater flexibility\nto end-users based on their preferences.\nREFERENCES\n[1] S. Razaulla, C. Fachkha, C. Markarian, A. Gawanmeh, W. Mansoor,\nB. C. Fung, and C. Assi, \u201cThe age of ransomware: A survey on the\nevolution, taxonomy, and research directions,\u201d IEEE Access, 2023.\n[2] M. Benmalek, \u201cRansomware on cyber-physical systems: Taxonomies,\ncase studies, security gaps, and open challenges,\u201d Internet of Things\nand Cyber-Physical Systems, 2024.\n[3] Q. Chen and R. A. Bridges, \u201cAutomated behavioral analysis of malware:\nA case study of wannacry ransomware,\u201d in 2017 16th IEEE International\nConference on machine learning and applications (ICMLA).\nIEEE,\n2017, pp. 454\u2013460.\n[4] S. Mansfield-Devine, \u201cThe best form of defence\u2013the benefits of red\nteaming,\u201d Computer Fraud & Security, vol. 2018, no. 10, pp. 8\u201312,\n2018.\n[5] J. Yuill, M. Zappe, D. Denning, and F. Feer, \u201cHoneyfiles: deceptive files\nfor intrusion detection,\u201d in Proceedings from the Fifth Annual IEEE SMC\nInformation Assurance Workshop, 2004.\nIEEE, 2004, pp. 116\u2013122.\n[6] H. Oz, A. Aris, A. Levi, and A. S. Uluagac, \u201cA survey on ransomware:\nEvolution, taxonomy, and defense solutions,\u201d ACM Computing Surveys\n(CSUR), vol. 54, no. 11s, pp. 1\u201337, 2022.\n[7] Y. Takeuchi, K. Sakai, and S. Fukumoto, \u201cDetecting ransomware using\nsupport vector machines,\u201d in Workshop Proceedings of the 47th Inter-\nnational Conference on Parallel Processing, 2018, pp. 1\u20136.\n[8] M. E. Ahmed, H. Kim, S. Camtepe, and S. Nepal, \u201cPeeler: Profil-\ning kernel-level events to detect ransomware,\u201d in Computer Security\u2013\nESORICS 2021: 26th European Symposium on Research in Computer\nSecurity, Darmstadt, Germany, October 4\u20138, 2021, Proceedings, Part I\n26.\nSpringer, 2021, pp. 240\u2013260.\n[9] M. Almousa, S. Basavaraju, and M. Anwar, \u201cApi-based ransomware\ndetection using machine learning-based threat detection models,\u201d in 2021\n18th International Conference on Privacy, Security and Trust (PST).\nIEEE, 2021, pp. 1\u20137.\n[10] B. M. Khammas, \u201cRansomware detection using random forest tech-\nnique,\u201d ICT Express, vol. 6, no. 4, pp. 325\u2013331, 2020.\n[11] M. Basnet, S. Poudyal, M. H. Ali, and D. Dasgupta, \u201cRansomware\ndetection using deep learning in the scada system of electric vehicle\ncharging station,\u201d in 2021 IEEE PES Innovative Smart Grid Technolo-\ngies Conference-Latin America (ISGT Latin America). IEEE, 2021, pp.\n1\u20135.\n[12] R. M. A. Molina, S. Torabi, K. Sarieddine, E. Bou-Harb, N. Bouguila,\nand C. Assi, \u201cOn ransomware family attribution using pre-attack para-\nnoia activities,\u201d IEEE Transactions on Network and Service Manage-\nment, vol. 19, no. 1, pp. 19\u201336, 2021.\n[13] B. Zhang, W. Xiao, X. Xiao, A. K. Sangaiah, W. Zhang, and J. Zhang,\n\u201cRansomware classification using patch-based cnn and self-attention net-\nwork on embedded n-grams of opcodes,\u201d Future Generation Computer\nSystems, vol. 110, pp. 708\u2013720, 2020.\n[14] K. C. Roy and Q. Chen, \u201cDeepran: Attention-based bilstm and crf\nfor ransomware early detection and classification,\u201d Information Systems\nFrontiers, vol. 23, pp. 299\u2013315, 2021.\n[15] A. Damodaran, F. D. Troia, C. A. Visaggio, T. H. Austin, and M. Stamp,\n\u201cA comparison of static, dynamic, and hybrid analysis for malware\ndetection,\u201d Journal of Computer Virology and Hacking Techniques,\nvol. 13, pp. 1\u201312, 2017.\n[16] A. Adamov and A. Carlsson, \u201cReinforcement learning for anti-\nransomware testing,\u201d in 2020 IEEE East-West Design & Test Symposium\n(EWDTS).\nIEEE, 2020, pp. 1\u20135.\n[17] R. Gangupantulu, T. Cody, A. Rahman, C. Redino, R. Clark, and\nP. Park, \u201cCrown jewels analysis using reinforcement learning with attack\ngraphs,\u201d arXiv preprint arXiv:2108.09358, 2021.\n[18] T. Cody, A. Rahman, C. Redino, L. Huang, R. Clark, A. Kakkar,\nD. Kushwaha, P. Park, P. Beling, and E. Bowen, \u201cDiscovering exfiltration\npaths using reinforcement learning with attack graphs,\u201d arXiv preprint\narXiv:2201.12416, 2022.\n[19] R. Rishu, A. Kakkar, C. Wang, A. Rahman, C. Redino, D. Nan-\ndakumar, T. Cody, R. Clark, D. Radke, and E. Bowen, \u201cEnhancing\nexfiltration path analysis using reinforcement learning,\u201d arXiv preprint\narXiv:2310.03667, 2023.\n[20] L. Huang, T. Cody, C. Redino, A. Rahman, A. Kakkar, D. Kushwaha,\nC. Wang, R. Clark, D. Radke, P. Beling et al., \u201cExposing surveillance\ndetection routes via reinforcement learning, attack graphs, and cyber\nterrain,\u201d arXiv preprint arXiv:2211.03027, 2022.\n[21] C. Wang, A. Kakkar, C. Redino, A. Rahman, A. S, R. Clark, D. Radke,\nT. Cody, L. Huang, and E. Bowen, \u201cDiscovering command and control\nchannels using reinforcement learning,\u201d in SoutheastCon 2023, 2023,\npp. 685\u2013692.\n[22] G. Conti and D. Raymond, On cyber: towards an operational art for\ncyber conflict.\nKopidion Press, 2018.\n[23] R. Gangupantulu, T. Cody, P. Park, A. Rahman, L. Eisenbeiser,\nD. Radke, and R. Clark, \u201cUsing cyber terrain in reinforcement learning\nfor penetration testing,\u201d Submitted ACM ASIACCS 2022, 2021.\n[24] R. S. Sutton and A. G. Barto, Reinforcement learning: An introduction.\nMIT press, 2018.\n[25] R. S. Sutton, D. McAllester, S. Singh, and Y. Mansour, \u201cPolicy gradi-\nent methods for reinforcement learning with function approximation,\u201d\nAdvances in neural information processing systems, vol. 12, 1999.\n[26] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, \u201cProx-\nimal policy optimization algorithms,\u201d arXiv preprint arXiv:1707.06347,\n2017.\n[27] J. Schulman, P. Moritz, S. Levine, M. Jordan, and P. Abbeel, \u201cHigh-\ndimensional continuous control using generalized advantage estimation,\u201d\narXiv preprint arXiv:1506.02438, 2015.\n[28] A. Hochstein, R. Zarnekow, and W. Brenner, \u201cItil as common practice\nreference model for it service management: formal assessment and\nimplications for practice,\u201d in 2005 IEEE International Conference on\ne-Technology, e-Commerce and e-Service.\nIEEE, 2005, pp. 704\u2013710.\n", "metadata": {"Published": "2024-06-25", "Title": "Leveraging Reinforcement Learning in Red Teaming for Advanced Ransomware Attack Simulations", "Authors": "Cheng Wang, Christopher Redino, Ryan Clark, Abdul Rahman, Sal Aguinaga, Sathvik Murli, Dhruv Nandakumar, Roland Rao, Lanxiao Huang, Daniel Radke, Edward Bowen", "Summary": "Ransomware presents a significant and increasing threat to individuals and\norganizations by encrypting their systems and not releasing them until a large\nfee has been extracted. To bolster preparedness against potential attacks,\norganizations commonly conduct red teaming exercises, which involve simulated\nattacks to assess existing security measures. This paper proposes a novel\napproach utilizing reinforcement learning (RL) to simulate ransomware attacks.\nBy training an RL agent in a simulated environment mirroring real-world\nnetworks, effective attack strategies can be learned quickly, significantly\nstreamlining traditional, manual penetration testing processes. The attack\npathways revealed by the RL agent can provide valuable insights to the defense\nteam, helping them identify network weak points and develop more resilient\ndefensive measures. Experimental results on a 152-host example network confirm\nthe effectiveness of the proposed approach, demonstrating the RL agent's\ncapability to discover and orchestrate attacks on high-value targets while\nevading honeyfiles (decoy files strategically placed to detect unauthorized\naccess).", "entry_id": "http://arxiv.org/abs/2406.17576v1", "published_first_time": "2024-06-25", "comment": null, "journal_ref": null, "doi": null, "primary_category": "cs.CR", "categories": ["cs.CR", "cs.AI", "cs.LG"], "links": ["http://arxiv.org/abs/2406.17576v1", "http://arxiv.org/pdf/2406.17576v1"]}, "type": "Document"}
{"page_content": "The Power of Words: Generating PowerShell Attacks from Natural Language\nPietro Liguori*, Christian Marescalco**, Roberto Natella*, Vittorio Orbinato*, Luciano Pianese*\nDIETI, Universit\u00e0 degli Studi di Napoli Federico II, Naples, Italy\n*{pietro.liguori, roberto.natella, vittorio.orbinato, luciano.pianese}@unina.it\n**c.marescalco@studenti.unina.it\nAbstract\nAs the Windows OS stands out as one of the most targeted\nsystems, the PowerShell language has become a key tool for\nmalicious actors and cybersecurity professionals (e.g., for\npenetration testing). This work explores an uncharted domain\nin AI code generation by automatically generating offensive\nPowerShell code from natural language descriptions using\nNeural Machine Translation (NMT). For training and evalua-\ntion purposes, we propose two novel datasets with PowerShell\ncode samples, one with manually curated descriptions in nat-\nural language and another code-only dataset for reinforcing\nthe training. We present an extensive evaluation of state-of-\nthe-art NMT models and analyze the generated code both\nstatically and dynamically. Results indicate that tuning NMT\nusing our dataset is effective at generating offensive Power-\nShell code. Comparative analysis against the most widely\nused LLM service ChatGPT reveals the specialized strengths\nof our fine-tuned models.\n1\nIntroduction\nOffensive security practices, such as red teaming and adver-\nsary emulation, play a crucial role by helping us to understand\nhow attackers take advantage of vulnerabilities and how to\nmitigate attacks [1, 2]. In these attacks, cybersecurity pro-\nfessionals emulate malicious post-exploitation actions, such\nas credential stealing, lateral movement across accounts and\nmachines, data obfuscation and exfiltration, and more [3].\nAs Windows stands out as one of the most targeted OS [4],\nthe PowerShell language has become a key tool for both mali-\ncious actors and cybersecurity professionals. This language is\nwidely used to perform attacks since it can perform complex\nactions, such as establishing connections and accessing OS\nservices and APIs without the need to deliver a malicious\nbinary executable or payload on the target machine (e.g., \u201cfile-\nless\u201d malware), making them harder to detect [5\u20138].\nUnfortunately, writing offensive code demands a high de-\ngree of expertise and effort, restricting the adoption of offen-\nsive security practices. Therefore, the rise of automatic AI\ncode generators represents an appealing solution to unlock\nthese practices to a broader spectrum of users [9].\nAI code generators leverage ML models for Neural Ma-\nchine Translation (NMT) to produce (offensive) code starting\nfrom inputs in Natural Language (NL), e.g., in the English\nlanguage. The usage of NMT models is widespread across\ndiverse software engineering tasks [10], yet their application\nin security-related scenarios is infrequent and not widely ex-\nplored. This gap stems primarily from the lack of suitable\ncorpora for training and evaluating code generators. The short-\nage of corpora for offensive code generation is an evident\nlimitation: existing benchmarks [11\u201313] are derived from\nprogramming competitions and software interview questions\n(e.g., about algorithms and mathematics), or they focus on pro-\ngrams and languages that are not related to security (e.g., web\napplications in Python). Only a few security-oriented datasets\nare publicly available, targeting shellcodes in low-level pro-\ngramming languages [14]. As a result, there is a significant\ngap in the literature on offensive PowerShell code generation.\nThis work presents an assessment of AI code generators\nfor PowerShell offensive code, a novel application of NMT.\nGiven that generative models are predominantly trained on\nmainstream programming languages like Python and Java,\nwe investigate strategies to repurpose these models for the\nPowerShell domain. To this aim, we adopt a combination of\nunlabeled and labeled datasets to train and evaluate models.\nSpecifically, we first use a large collection of unlabeled (i.e.,\ncode only) samples of general-purpose PowerShell from var-\nious online repositories to pre-train ML models and refine\ntheir capabilities to comprehend and generate PowerShell\ncode. Then, we build from scratch a manually annotated la-\nbeled dataset consisting of PowerShell code samples specif-\nically crafted for security applications, which we pair with\ncurated NL descriptions in English. We use this dataset to\nfine-tune three state-of-the-art NMT models (CodeT5+ [15],\nCodeGPT [16], and CodeGen [17]) to generate offensive Pow-\nerShell code. The dataset also serves as a ground truth for\n1\narXiv:2404.12893v1  [cs.CR]  19 Apr 2024\nthe evaluation. We publicly share code, models 1 and datasets\nas open data2 to encourage further experimentation on this\ntopic.\nTo perform our experiments, we formulate four key re-\nsearch questions (RQs) aimed at evaluating the models\u2019 capa-\nbilities and the impact of the training strategies, performing\nstatic and execution analysis to assess the generated code, and\ncomparing privately fine-tuned models with ChatGPT, the\nmost widely used LLM service from OpenAI [18]. Table 1\nsummarizes the key findings of our analysis. To the best of our\nknowledge, this is the first work on the automatic generation\nof offensive PowerShell code from NL descriptions.\nIn the following, Section 2 discusses related work; Sec-\ntion 3 describes the research study; Section 4 shows the ex-\nperimental results; Section 5 discusses the threats to validity;\nSection 6 discusses the ethical considerations; Section 7 con-\ncludes the paper.\n2\nRelated Work\nThis work focuses on offensive code generation, involving\nmachine translation techniques applied to the security domain\nfor PowerShell code generation. Thus, we reviewed related\nliterature in these areas.\nML for security-related PowerShell. Li et al. [19] designed\na subtree-based de-obfuscation method and a semantic-aware\nPowerShell attack detection system. This work also demon-\nstrates how the presented de-obfuscation method improves the\nperformance of detection systems such as Windows Defender\nand Virus-Total. PowerDP [20] is a solution that aims to auto-\nmatically identify malicious PowerShell commands through\ncharacter distribution features and obfuscation multi-label\nclassification also proposing a de-obfuscator method for re-\ncovering obfuscated commands. Even ML-based methodolo-\ngies have arisen for detection purposes, as shown by Hendler\net al. [21], who proposed several ML-based detectors demon-\nstrating their effectiveness on malicious scripts. The authors\nalso devised another solution [22] to achieve the same objec-\ntive by retrieving information from Microsoft\u2019s AMSI inter-\nface. Mimura and Tajiri [23] presented a lighter methodology,\nrestricting detection only to word embeddings. Mezawa et\nal. [24] proposed an evaluation methodology for ML-based de-\ntectors based on a word-level machine learning model. Given\nthe effectiveness of Abstract Syntax Trees (ASTs) in detect-\ning obfuscated PowerShell scripts, Rusak et al. [25] proposed\na hybrid approach that combines ASTs and deep learning to\nenhance detection methods for high-level obfuscation Pow-\nerShell malicious programs. We remark that research of ML\nfor PowerShell focuses on defensive uses (i.e., detecting and\nde-obfuscating attacks), but none of these studies analyzed the\noffensive uses of ML (i.e., generating attacks), which are also\n1HuggingFace repo\n2GitHub repo\nAnalysis\nMain Findings\nCapability\nAssessment\n\u2022 Models without fine-tuning (zero-shot learn-\ning) showed a limited ability to generate Pow-\nerShell code, often defaulting to Python syntax\nor incorrect PowerShell code.\n\u2022 The fine-tuning phase significantly enhanced\nthe models\u2019 ability to generate syntactically\ncorrect and semantically relevant PowerShell\ncode. Among the models, CodeT5+ and\nCodeGPT demonstrated notable improvements\nin generating offensive PowerShell code.\n\u2022 Pre-training on a large PowerShell corpus had\na varying impact on different models. While\npre-training generally improved CodeT5+ and\nCodeGPT, especially with a limited number of\nepochs for fine-tuning, CodeGen did not con-\nsistently benefit from pre-training.\nStatic and\nExecution\nAnalysis\n\u2022 All models achieved high syntax accuracy, in-\ndicating their strong capability to generate syn-\ntactically correct code. However, a significant\nnumber of warnings were identified, suggesting\npotential issues or suboptimal coding practices.\n\u2022 The execution analysis showed that, despite\ntextual differences between the ground truth\nand the generated code, the models are still able\nto generate offensive PowerShell code closely\naligned with the intended malicious activities,\nin terms of events occurring in the system (e.g.,\non the filesystem, network, registry).\nComparison\nwith public\nAI model\n\u2022 Our fine-tuned models outperform ChatGPT\nacross all the metrics, showing that specializing\nthe models on our fine-tuning dataset provides\nan advantage in the offensive PowerShell code\ngeneration task.\nTable 1: Main findings.\nrelevant for red teaming and adversary emulation purposes,\nand which are in the scope of this paper.\nOffensive Code Generation. Research on AI code genera-\ntors for offensive security is still at an early stage. Gupta et\nal. [26] presented an outlook of the possibilities opened by\nChatGPT for generating various types of cyber attacks, such\nas social engineering, phishing attacks, and malware creation.\nFor each attack scenario, the paper shows qualitative examples\nof prompts submitted to ChatGPT, and the attack payloads\ngenerated as a result, including some snippets of PowerShell\ncode. Similarly, Charan et al. [27] presented qualitative exam-\nples with ChatGPT and Google BARD to generate malicious\n2\nscripts (mainly in Python, Bash, and PowerShell) for the top\n10 prevalent MITRE Techniques of 2022, showing the poten-\ntial of these AI models for security applications. However,\nnone of these studies systematically analyzed AI code genera-\ntors, lacking in several aspects: (i) the evaluation was limited\nto a few examples, while systematic evaluation requires much\nlarger datasets; (ii) the study lacked a ground truth for evalu-\nating the correctness of generated code; (iii) they did not yet\nexplore the potential of fine-tuning ML models for security-\nrelated code generation. The few studies in this direction\nfocused on generating exploits in low-level languages (e.g.,\nto attack memory management vulnerabilities). However, ex-\nploitation is only a limited part of the cyber kill chain, over-\nlooking several more types of malicious code. Among these\nstudies, Liguori et al. [28] proposed a dataset and approach for\ntraining and evaluating AI code generators for code security,\nby generating shellcodes in Assembly language. EVIL [29]\nautomatically generates exploits for conducting code injec-\ntion attacks via NMT by targeting both the generation of\nshellcodes in Assembly language and related Python code\nfor encoding and obfuscating the shellcodes. DualSC [30]\nformalizes the automatic generation and summarization of\nshellcodes via a \"Shallow\" Transformer inspired by the T5\nmodel and dual learning using the corpus provided by Liguori\net al. [28]. ExploitGen [31] is an approach for generating\nexploit code in Python and Assembly based on the Code-\nBERT model. Differently from these studies, we presented a\ndedicated model for generating offensive PowerShell code,\ncovering the entire cyber kill chain (e.g., including credential\nstealing, lateral movement, data exfiltration, and more tactics\nfrom the MITRE ATT&CK taxonomy). Moreover, we system-\natically analyzed the quality of generated PowerShell code by\nintroducing a manually curated dataset to serve as a ground\ntruth and evaluating the code statically and dynamically.\n3\nResearch Study\nThe main objective of our research study is to understand\nwhether NMT models can translate NL descriptions into code\nthat accurately replicates the complexities of cyber attacks in\nPowerShell. This aspect is crucial as it explores the models\u2019\nunderstanding of the unique syntax and semantics of this\nprogramming language.\nFigure 1 provides an overview of this research study. We\nanalyze various deep learning strategies to accurately gener-\nate code and introduce datasets to train and evaluate them.\nWe study several state-of-the-art NMT models and introduce\nvarious approaches to evaluating the generated code, includ-\ning the similarity of the generated code to ground truth and\nstatic and dynamic analysis of the code.\nTo help NMT models in the novel and ambitious task of\ngenerating PowerShell code from NL, we adopt a two-step\nprocess consisting of pre-training and fine-tuning. The pre-\ntraining phase aims to tailor NMT models (already pre-trained\non other programming languages) in the generation of Pow-\nerShell code. Armed with the pre-trained models, we pro-\nceed to the fine-tuning phase. This iterative process refines\nthe models\u2019 capabilities, enabling them to generate offensive\nPowerShell code from NL descriptions.\nThe main problem in using NMT models is to have a suffi-\ncient set of data and to use them effectively to train the models\nthemselves. Recognizing the lack of suitable datasets for of-\nfensive PowerShell code generation, in this study, we collect a\nlarge set of PowerShell programs used for penetration testing\nand adversary emulation. In addition to the code, we create\ndescriptions of these programs in English to allow the model\nto translate English into PowerShell code. This dataset was\ncreated manually to verify that the programs were related to\nsecurity and to ensure that the English language descriptions\nwere complete and consistent with the code. The dataset is\nlabeled since each sample includes both the text to translate\ninto code and the code expected to be produced by the model\n(ground truth).\nThe creation of labeled datasets is inevitably limited by the\navailability of PowerShell security programs and the need to\nmanually create English language descriptions for each pro-\ngram. To increase the amount of training data, in this study, we\ninvestigate an additional strategy, fully automated, to build an\nextended dataset of PowerShell programs, collecting Power-\nShell programs and the related text from the web (for example,\ncomments in the code or description accompanying the code).\nAs the collection is fully automated, this second dataset is\nnon-labeled. The dataset includes programs not strictly re-\nlated to security but includes, in general, PowerShell code\nused for various purposes. This dataset still contributes to the\nability to generate security code since it allows the model\nto learn from further examples how to generate syntactically\nvalid PowerShell code and to correlate the PowerShell code\nwith the English language. We use this dataset to pre-train the\nNMT models, carrying out additional unsupervised training\nrounds.\nTable 2 reports the statistics of both datasets, in terms of\nsize, unique number of tokens, and average number of tokens\nfor NL descriptions (only for fine-tuning data) and code.\nFinally, we evaluate the models as follows:\n\u2022 Capability Assessment: We compare the textual similar-\nity of the code generated by the models with a ground-\ntruth reference through automatic metrics. These met-\nrics are an appealing solution to estimate the generated\ncode since they are easy to tune and time-saving, hence\novercoming the limit of human evaluation, which poses\npractical challenges for large-scale assessments.\n\u2022 Static analysis: We assess the generated code to ensure\nthat it adheres to PowerShell programming conventions\nand does not contain syntax errors.\n\u2022 Execution analysis: We evaluate the capability of the\n3\nData Collection\nPre-training\nFine-tuning\nStockpile\nData Collection\nAtomic\nRed Team\nOnline\nEmpire\nGitHub\nPre-training \nDataset\nFine-tuning \nDataset\nPre-trained\nModels\nPowerShell\nCode\nCapability \nAssessment\nNL Intents\nOutput \nSimilarity\nAI-based Code Generation\nSyntactic\nEvaluation\nExecution \nEvaluation\nStatic \nAnalysis\nExecution \nAnalysis\nLegend\nCode Generation Task \u2013 \u222e4.1, 4.2\nFine-tuning data \u2013 \u222e3.2\nPre-training data \u2013 \u222e3.1\nStatic Analysis \u2013 \u222e4.3\nExecution Analysis\u2013 \u222e4.4\nCodeT5+\nCodeGPT\nCodeGen\nFigure 1: Overview of our research study.\ngenerated offensive PowerShell code in executing ma-\nlicious actions, replicating the behavior of the ground\ntruth commands.\nIn the following of this section, we detail the pre-training\n(\u00a7 3.1) and the fine-tuning data (\u00a7 3.2), and the code genera-\ntion task (\u00a7 3.3).\n3.1\nPre-training data (unlabeled)\nPre-training involves training the model on a large corpus\nof text data to learn general language representations before\nfine-tuning it for specific downstream tasks [32]. In other\nwords, the parameters obtained from this step serve as a start-\ning point for the later supervised training. Unsupervised or\nself-supervised pre-training is particularly attractive in the\nNMT context since large unlabeled data is available on the In-\nternet. In this work, we leverage domain-adaptive pre-training\n(DAPT) [33]: given an NMT model pre-trained on massive,\nheterogeneous corpora, we perform additional rounds of unsu-\npervised training with domain-specific data. Specifically, we\nleverage general-purpose PowerShell code for pre-training.\nThe pre-training dataset aims to provide a valuable resource\nto enable the models\u2019 understanding of general-purpose Pow-\nerShell code. This dataset encompasses \u223c90k samples ex-\ntracted through the GitHub API. Specifically, we queried all\nthe repositories containing PowerShell code from the last\ndecade (2013-2023) to encompass a broad spectrum of Pow-\nerShell code, then parsed the extracted data to remove un-\nnecessary information, such as duplicates (inside the same\nrepository), and logging and echo commands. In addition, we\nfiltered out all the PowerShell commands with sizes greater\nthan 1024, ensuring the dataset maintains a balanced repre-\nsentation of code complexities. This collection encompasses\na diverse array of PowerShell scripts, spanning various appli-\ncation domains such as system administration, automation,\nand network management. Including a wide range of scripts\nreflects the versatility of PowerShell as a scripting language\nand provides models with exposure to the diverse ways Pow-\nerShell is used across different use cases.\nThe pre-training process depends on the model architecture.\nFor decoder-only models, i.e., CodeGPT and CodeGen, we\nchose Causal Language Modeling (CLM), also referred to as\nLanguage Modeling, as the pre-training objective. CLM has\nbeen extensively used as a pre-training task for transformer-\nbased decoder-only models [34], such as in the GPT se-\nries [35\u201337]. CLM refers to language models that predict\nthe next token or sequence of tokens in a sentence in a causal\nor autoregressive manner, where the prediction for each to-\nken depends only on the preceding tokens. By using mask-\ning, the model only attends to the left context in a unidirec-\n4\nStatistic\nPre-training\nDataset\nFine-tuning\nDataset\nDataset size\n89,814\n1,127\nUnique Intents\n-\n1,077\nUnique Commands\n79,410\n1,121\nUnique tokens (Intents)\n-\n2,273\nUnique tokens (Commands)\n85,342\n17,463\nAvg. tokens per Intent\n-\n15.97\nAvg. tokens per Command\n12.71\n15.49\nTable 2: Statistics of the pre-training and fine-tuning datasets.\nThe pre-training dataset does not contain NL descriptions\n(intents).\ntional manner, ensuring that it cannot see \"into the future\". In\nthe probabilistic framework, starting from the text sequence\nx = (x1,x2,x3,...,xT), where x is the original sentence and\nxt (t = 1,2,...,T) is the t-th token, and T is the sequence\nlength, an autoregressive model factorizes the likelihood of\nthe input text sequence as p(x) = \u220fT\nt=1 p(xt | x<t), where p is\nthe likelihood of the input text sequence [38]. Finally, mod-\nels are evaluated by token-level accuracy. For CodeT5+, the\npre-training objective is Masked Language Modeling (MLM),\nas recent works show its effectiveness in code understanding\ntasks [39]. MLM refers to the prediction of missing tokens in\na sentence based on the context provided by the surrounding\ntokens. Unlike the left-to-right language model pre-training,\nMLM considers both the left and right context. The approach\nis inspired by BERT [40], where 15% of the tokens in the\nencoder inputs are randomly replaced with sentinel token\n[MASK], and the decoder is tasked with recovering these\ntokens to reconstruct the complete snippet. The model is eval-\nuated by token level accuracy only on the masked-out tokens.\n3.2\nFine-tuning data (labeled)\nThe overarching purpose of this dataset is to serve as a com-\nprehensive resource for training models in the translation\nof NL intents, i.e., descriptions of code snippets, into exe-\ncutable security-oriented PowerShell commands. Specifically,\nwe focus on offensive PowerShell code, a key resource for cy-\nbersecurity exercises since Microsoft Windows represents the\nmost targeted OS. By encompassing a wide array of sources,\nthe dataset aims to expose models to the intricacies of real-\nworld cybersecurity scenarios, enabling them to understand\nand generate PowerShell commands that align with those typ-\nical of cybersecurity operations. This holistic approach strives\nto ensure that models trained on this dataset are well-equipped\nto handle the complexities of real-world tasks and contribute\nmeaningfully to offensive code generation, specifically Pow-\nerShell commands.\nThe dataset, consisting of 1,127 samples of PowerShell\ncommands, is meticulously curated from the following\nsources:\n\u2022 Atomic Red Team [41]: renowned for its library of tests\nmapped to the MITRE ATT&CK framework3 [42],\nserves the purpose of replicating real-world adversarial\ntactics, techniques, and procedures (TTPs). This inclu-\nsion provides the dataset with a foundation rooted in a\nstandardized and widely accepted framework, ensuring\nthat the PowerShell commands align with recognized\ncybersecurity methodologies.\n\u2022 Stockpile [43]: is a plugin for the CALDERA cyberse-\ncurity framework [1,44] developed by MITRE and in-\ntroduces a layer of sophistication by incorporating struc-\ntured data integral for adversary emulation. Therefore,\nthe dataset does not encompass raw PowerShell com-\nmands only but also captures the contextual information\nand relationships between commands within the broader\ncontext of adversarial scenarios.\n\u2022 Empire [45]: a post-exploitation and adversary emula-\ntion framework integrated with MITRE ATT&CK, pro-\nvides PowerShell commands representative of advanced\nmalicious techniques, further enriching the dataset with\nnuanced and intricate scenarios.\n\u2022 Online sources: we manually verified and selected ad-\nditional offensive samples from several security-related\nonline sources. We gathered samples from HackTricks\n[46], Red Team Recipe [47], and Infosec Matter [48],\ncommunity-driven cybersecurity wikis about ethical\nhacking, penetration testing, and information security.\nBy including diverse examples specific to the offen-\nsive PowerShell dataset, the model acquires a more pro-\nfound understanding of the conventions and best prac-\ntices unique to PowerShell security commands.\nWe manually curated the dataset to cover the highest num-\nber of tactics in the MITRE ATT&CK framework. In particu-\nlar, the dataset covers 12 out of 14 tactics from the MITRE\nATT&CK framework, the de facto standard for adversar-\nial techniques representation, with varying numbers of tech-\nniques and sub-techniques per tactic. Figure 2 illustrates the\nnumber of entries for each ATT&CK tactic. Each entry in the\ndataset is annotated with an NL description extracted from\nthe respective source. We manually annotated every sample\nthat did not come with a predefined description. Moreover,\nwe enriched all those descriptions that did not provide enough\ninformation about the specific PowerShell command. For\ninstance, in the case of Atomic Red Team, the PowerShell\ncommands represent implementations of the techniques in\nthe ATT&CK framework. Consequently, these commands are\n3The ATT&CK framework is a comprehensive knowledge base of the\ntactics, techniques, and procedures (TTPs) that adversaries leverage during\ncyberattacks, developed by MITRE.\n5\n32\n38\n163\n430\n205\n54\n10\n12\n4\n96\n42\n37\n5\n0\n100\n200\n300\n400\n500\nCollection\nCommand and Control\nCredential Access\nDefense Evasion\nDiscovery\nExecution\nExfiltration\nImpact\nInitial Access\nLateral Movement\nPersistence\nPrivilege Escalation\nReconnaissance\nNumber of dataset entries\nMITRE ATT&CK Tactics\nFigure 2: Mapping of fine-tuning dataset samples on the\nMITRE ATT&CK tactics.\noften labeled with the technique name, which provides infor-\nmative content about the technique itself rather than what the\ncommand does. To better understand how programmers and\nsecurity experts describe PowerShell scripts and how to deal\nwith ambiguities in natural language, we referred to popular\nbooks and manuals [49\u201351].\nFinally, we notice that the size of our dataset is in line with\nother state-of-the-art corpora used to fine-tune ML models.\nIn fact, in state-of-the-art code generation, the datasets for\nfine-tuning are relatively limited, in the order of one thousand\nsamples [52].\n3.3\nCode Generation Task\nTo ensure the robustness of our study, we adopt the following\nstate-of-the-art NMT models:\n\u2022 CodeT5+ [15] is a new family of Transformer models\npre-trained with a diverse set of pretraining tasks to learn\nrich representations from both unimodal code data and\nbimodal code-text data. We utilize the variant with model\nsize 220M, trained from scratch following T5\u2019s architec-\nture [53]. It has an encoder-decoder architecture with 12\ndecoder layers, each with 12 attention heads and hidden\nlayer dimension of 768, and 512 for the size of position\nembeddings. We set the learning rate \u03b1 = 0.00005, batch\nsize = 16, and beam size = 10.\n\u2022 CodeGPT [16], a Transformer-based language model\npre-trained on millions of Python functions and Java\nmethods. The model architecture consists of 12 layers of\nTransformer decoders. We followed previous work for\nthe implementation [54].\n\u2022 CodeGen [17], an autoregressive language model for\nprogram synthesis with an architecture that follows a\nstandard transformer decoder with left-to-right causal\nmasking. The family of CodeGen models is trained in\nvarious sizes, including 350M, 2.7B, 6.1B, and 16.1B,\nand utilizes various datasets. Specifically, we leverage\nCodeGen-Multi, initialized from CodeGen-NL and fur-\nther pre-trained on BigQuery [17], a large-scale dataset\nof multiple programming languages from GitHub repos-\nitories, which consists of 119.2B tokens and includes C,\nC++, Go, Java, JavaScript, and Python.\nIn our experiments, we randomly split the fine-tuning\ndataset into training (the set of examples used to fit the param-\neters), validation (the set used to tune the hyperparameters of\nthe models), and test (the set used for the evaluation of the\nmodels) sets using a typical 80%/10%/10% ratio.\nTo assess the performance of the models in generating\noffensive PowerShell code from NL descriptions, we used\noutput similarity metrics, which compare the generated code\nwith the code from the ground truth. This type of metrics is\nwidely used to assess the performance of AI generators in\nmany code generation tasks [55], including the generation of\ncode for security contexts [28\u201331,56]. The metrics are:\n\u2022 Bilingual Evaluation Understudy (BLEU) score [57].\nIt measures the degree of n-gram overlapping between\nthe string of each code snippet produced by the model\nand the reference, for values of n usually ranging be-\ntween 1 and 4 [58, 59]. We implemented BLEU-4\nscore (i.e., with n = 4) computation employing the\nbleu_score module contained in the open-source Natu-\nral Language Toolkit (NLTK) Python suite [60].\n\u2022 Edit Distance (ED). It measures the edit distance be-\ntween two strings, i.e., the minimum number of opera-\ntions on single characters required to make each code\nsnippet produced by the model equal to the reference.\nFor the edit distance, we adopted the Python library\npylcs [61].\n\u2022 METEOR [62]. It measures the alignment between each\ncode snippet produced by the model and the reference.\nThe alignment is defined as a mapping between unigrams\n(i.e., 1-gram), such that every unigram in each string\nmaps to zero or one unigram in the other string and no\nunigrams in the same string. To calculate the METEOR\nmetric, we relied on the Python library evaluate by\nHuggingFace [63].\n\u2022 ROUGE-L. It is a metric based on the longest common\nsubsequence (LCS) between the model output and the\nreference, i.e., the longest sequence of words (not neces-\nsarily consecutive, but still in order) shared between both.\nWe computed the ROUGE-L metric using the Python\npackage rouge [64].\nAll metrics range between 0 and 1, with higher scores corre-\nsponding to a better quality of the generated code. To evaluate\nthe generated PowerShell code, we also introduce additional\nevaluation metrics based on static and dynamic analysis that\nare specific to our context. These metrics will be introduced\nin the following sections.\n6\n3.4\nResearch Questions\nWe designed this research study to answer the following re-\nsearch questions (RQs):\n\u25b7RQ1: To what extent can NMT models effectively generate\noffensive PowerShell code for security applications from NL\ndescriptions?\nRQ1 aims to establish a preliminary assessment of NMT\nmodels in generating PowerShell code for offensive security\napplications. This investigation seeks to shed light on the\nmodels\u2019 efficacy in translating NL descriptions into offensive\ncode.\n\u25b7RQ2: What is the influence of the training strategies on\nNMT models\u2019 performance in offensive PowerShell code gen-\neration?\nRQ2 focuses on the impact of pre-training and fine-tuning\non the quality of generated code. We analyze the influence\nof these training strategies by considering different configu-\nrations of the NMT models and their impact on their perfor-\nmance.\n\u25b7RQ3: How good is the generated code in terms of code\nquality and dynamic behavior?\nRQ3 aims to evaluate the generated PowerShell code in a\ndeeper way than output similarity metrics, in terms of syntac-\ntic correctness and capability of executing malicious actions\nrealistically, through behavioral comparison with the ground\ntruth.\n\u25b7RQ4: How do fine-tuned NMT models, leveraging security-\noriented training data, compared to a publicly available,\nclosed-source model?\nRQ4 introduces a comparative analysis, evaluating the perfor-\nmance of the fine-tuned models against a publicly available\ngeneral-purpose language model, specifically ChatGPT 3.5.\nThis investigation strives to evaluate whether specialization on\nsecurity-focused data provides an advantage in the offensive\nPowerShell code generation domain.\n4\nExperimental Results\nThis section presents an extensive evaluation of NMT models\n(CodeT5+, CodeGPT, and CodeGen) on the generation of\noffensive PowerShell code. First, we assess the models\u2019 capa-\nbility of generating PowerShell code in their original configu-\nration (\u00a7 4.1) without further training. Then, we evaluate the\nimpact of different training strategies, i.e., domain-adaptive\npre-training and fine-tuning, on the performance of such mod-\nels (\u00a7 4.2). To provide further insight into the PowerShell\ncode generation, we analyze the quality of the generated code\nin terms of syntactic correctness (\u00a7 4.3) and dynamic behavior\n(\u00a7 4.4), i.e., its ability to replicate the behavior of the ground\ntruth code. Finally, we compare the fine-tuned models with\na public AI model (ChatGPT) for all the previous analyses\n(\u00a7 4.5) to benchmark their performance against a publicly\navailable, closed-source model.\nModel\nPre-\ntraining\nBLEU-4\n(%)\nED (%)\nMETEOR\n(%)\nROUGE-\nL (%)\nCodeT5+\n\u2717\n0.04\n8.87\n4.69\n1.08\n\u2713\n0.01\n6.96\n1.86\n2.68\nCodeGPT\n\u2717\n0.23\n12.31\n4.08\n1.19\n\u2713\n0.28\n15.67\n2.55\n3.41\nCodeGen\n\u2717\n0.06\n7.58\n2.88\n0.21\n\u2713\n0.00\n0.43\n0.09\n0.00\nTable 3: Performance of models with and without pre-training\non zero-shot.\n4.1\nZero-shot Learning\nTo establish a baseline for the evaluation, we initially used\nthe NMT models in their original configuration, asking them\nto generate PowerShell code. This is a zero-shot learning\ntask, where an NMT model is applied for a different sce-\nnario than the one for which it was trained. In this way, we\nevaluate the current gap of existing models in generating Pow-\nerShell code. Table 3 shows the results of this analysis. In\nthis task, the models are tested without any gradient updates,\nrelying only on the intent provided by the test set for infer-\nence [36,37]. The non-pre-trained versions of the models tend\nto generate Python code, but their performance is generally\nlow for the downstream task of generating offensive Pow-\nerShell code. Pre-training the models with general-purpose\nPowerShell code slightly improves the accuracy but is still not\nhigh. Among the pre-trained versions, CodeGPT is the only\none that provides output close to valid PowerShell code, al-\nthough it does not align well with the expected code indicated\nby the intent in natural language. In summary, regardless of\npre-training, all models demonstrate the need for fine-tuning\non a tailored dataset for optimal performance in generating\noffensive PowerShell code.\n4.2\nImpact of Training Strategies\nThe evaluation of CodeT5+, CodeGPT, and CodeGen in-\nvolved a meticulously designed test plan. More precisely,\nthe models underwent three distinct fine-tuning scenarios: 3\nEpochs, 10 Epochs, and 30 Epochs. This deliberate choice\nallowed us to assess the impact of prolonged fine-tuning on\nthe models\u2019 ability to generate PowerShell code for offensive\nsecurity tasks. In each scenario, we considered two training\nconfigurations: one with pre-training and the other without.\nThis test plan allowed us to systematically explore the models\u2019\ncapabilities under varying conditions, providing a comprehen-\nsive understanding of their strengths and limitations. Table 4\nshows the results.\nIn the 3 epochs setting, CodeT5+ exhibits low perfor-\nmance, regardless of pre-training, with a BLEU-4 score lower\nthan 10%. In contrast, CodeGPT and CodeGen demonstrate\nnotable performance even after a short fine-tuning period,\n7\nModel\nEpochs\nPre-\ntrain.\n(%)\nBLEU-4\n(%)\nED (%)\nMETEOR\n(%)\nROUGE-\nL (%)\nCodeT5+\n3\n\u2717\n4.22\n35.11\n28.83\n22.26\n\u2713\n4.57\n35.96\n30.57\n23.99\n10\n\u2717\n12.64\n46.72\n44.76\n37.65\n\u2713\n11.88\n49.10\n46.11\n37.17\n30\n\u2717\n17.40\n50.92\n47.61\n39.05\n\u2713\n18.50\n50.23\n47.87\n38.86\nCodeGPT\n3\n\u2717\n10.28\n40.71\n31.21\n25.60\n\u2713\n12.80\n42.54\n35.14\n30.35\n10\n\u2717\n16.22\n46.39\n40.50\n33.52\n\u2713\n17.93\n49.88\n45.12\n37.12\n30\n\u2717\n21.71\n50.17\n45.34\n38.63\n\u2713\n19.94\n49.20\n45.45\n38.06\nCodeGen\n3\n\u2717\n16.20\n47.68\n42.27\n35.97\n\u2713\n14.75\n45.88\n39.86\n34.69\n10\n\u2717\n19.15\n50.52\n46.76\n37.63\n\u2713\n19.04\n48.45\n43.25\n35.25\n30\n\u2717\n18.23\n47.53\n44.10\n35.48\n\u2713\n18.53\n48.67\n44.14\n35.45\nTable 4: Performance of models with and without pre-training\nand different number of epochs. Best results for each metric\nare blue/bold.\nachieving a BLEU-4 score higher than 10% and an ED over\n40%. Notably, after 3 epochs, CodeGen demonstrates supe-\nrior performance compared to the other two models. In the 10\nepochs experiment, CodeT5+ shows significant improvement,\nwith BLEU-4 tripling to 12%. Moreover, ED, METEOR,\nand ROUGE-L experience a rise of 12-16%. CodeGPT also\nenhances its performance, surpassing CodeT5+ in terms of\nBLEU-4 score, although it faces challenges in achieving the\nsame level of overall improvement. CodeGen remains ahead\nof the other models, even reaching an ED over 50%. For a\nmore in-depth assessment of the models\u2019 adaptability, the\ntraining duration is extended to 30 epochs. CodeT5+ demon-\nstrates superior performance over CodeGPT in ED, METEOR,\nand ROUGE-L metrics, while CodeGPT exhibits a higher\nBLEU-4 score surpassing 20%. Notably, both models achieve\na high ED value of around 50%. CodeGen establishes its per-\nformance without further improvement compared to the 10\nepochs versions.\nTo provide an estimate of the goodness of the results, we\ncompared the results of the models with the performance of\nthe state-of-the-art (SOTA). Since the task of generating Pow-\nerShell using NMT models is a task never addressed before,\nwe compared the results with recent work investigating the\neffectiveness of existing models in the generation of differ-\nent languages from NL, specifically, Python code [65] and in\nshell language [66]. We found that the best performance is\n21% for BLEU-4 and 38% for METEOR in the case of the\nPython language, and 25% for BLEU-4 and 44% for ED in\nthe case of shell language. We notice that our results are in\nline with the ones of the SOTA. Even better, our best perfor-\nmance, represented by CodeT5+ without pre-training and 30\nfine-tuning epochs, overcomes the SOTA over all the metrics.\nWe also assessed the impact of varying the number of\nepochs on fine-tuning time, with distinct differences observed\nbetween 3, 10, and 30 epochs for each model. For both\nCodeT5+ and CodeGPT, fine-tuning over 3 epochs takes ap-\nproximately 20 minutes, whereas CodeGen requires double\nthat time (40 minutes). Extending to 10 epochs, CodeT5+ and\nCodeGPT need around 35 and 39 minutes, respectively, while\nCodeGen\u2019s training time increases to 90 minutes. For the 30-\nepoch extension, CodeT5+ takes about 80 minutes, CodeGPT\nrequires 110 minutes, and CodeGen extends its training time\nto 270 minutes. Finally, the comparison between the fine-\ntuning times of pre-trained and non-pre-trained models did\nnot reveal evident differences, suggesting that the pre-training\nprocess does not introduce a significant computational over-\nhead during the subsequent fine-tuning phase.\nRQ1: To what extent can state-of-the-art NMT models\neffectively generate offensive PowerShell code for security\napplications from NL descriptions?\nThe evaluation of CodeT5+, CodeGPT, and CodeGen\nunderscores their remarkable effectiveness in generat-\ning offensive PowerShell code for security applications\nfrom NL descriptions. CodeGen surpasses the other\nmodels in the 3 and 10 epochs settings according to all\nmetrics. CodeT5+, designed with a specialized architec-\nture for code generation tasks, consistently outperforms\nCodeGPT and CodeGen across various metrics in the 30\nepochs setting. Particularly noteworthy is the compar-\nison with SOTA performance in code generation tasks\nfor different languages, such as Python and shell lan-\nguages. Our best-performing model, CodeT5+ without\npre-training and 30 fine-tuning epochs, surpasses the\nSOTA results, exhibiting superior performance across\nall metrics.\nConsidering the impact of pre-training further enriched\nour evaluation. Focusing on the 3-epoch experiments,\nCodeT5+ exhibits a slight improvement across all metrics, and\nCodeGPT extends the improvement to 2%-4% across all met-\nrics. Conversely, CodeGen appears to have better performance\nwithout pre-training. Training the models for 10 epochs re-\nveals a more pronounced distinction between the two versions.\nCodeT5+ pre-training results in a 2% increase in both Edit\nDistance (ED) and METEOR metrics. CodeGPT, on the other\nhand, shows a substantial displacement of 1.7%, 3.5%, 4.6%,\nand 3.6% for BLEU-4, ED, METEOR, and ROUGE-L, respec-\ntively. CodeGen maintains a negative displacement between\nthe versions even with the extended training duration. When\nextending the fine-tuning duration to 30 epochs, pre-training\n8\nNatural Language Intent\nGround Truth\nModel Output\nStart a process with DirLister,\nwait for 4 seconds, and stop the\nDirLister process.\nStart-Process ${WebBrowserPassViewPath}\n; Start-Sleep -Second 4 ; Stop-Process\n-Name \"WebBrowserPassView\"\nStart-Process ${WebBrowserPassViewPath}\n; Start-Sleep -Second 4 ; Stop-Process\n-Name \"WebBrowserPassView\"\nInvoke-Mimikatz cmdlet with\nbypassed execution policy.\npowershell.exe -exec bypass -c \u201c\nInvoke-Mimikatz \u201d\npowershell.exe -ExecutionPolicy Bypass\n-Command \u201c Invoke-Mimikatz \u201d\nInvoke compiled HTML Help\n(CHM) file with specific storage\nhandler, HH file path, and CHM\nfile path.\nInvoke-ATHCompiledHelp\n-InfoTechStorageHandler $ {\ninfotech_storage_handler } -HHFilePath\n$ { hh_file_path } -CHMFilePath $ {\nchm_file_path }\nInvoke-ATHCompiledHTMLHelp\n(((((((((((((\n(\n-InfoTechStorageHandler\n((((((((((((((((\n(\n$ { infotech_storage_handler }\n-HHFilePath $ { hh_file_path }\n-CHMFilePath $ { chm_file_path }\nGet the wininit process and\nperform token manipulation to\ncreate a new process for\n\u2019cmd.exe\u2019.\nGet-Process wininit |\nInvoke-TokenManipulation\n-CreateProcess \u2019cmd.exe\u2019\n$wininit = Get-Process wininit |\nInvoke-TokenManipulation\n-CreateProcess \u2019cmd.exe\u2019\nTable 5: Illustrative examples of model output. The prediction errors are red/bold. \u0018\u0018\u0018\n\u0018\nSlashed text refers to omitted predictions.\ndid not consistently yield superior results. In this case, the\nperformance of pre-trained models is comparable to non-pre-\ntrained counterparts.\nRQ2: What is the influence of the training strategies on\nNMT models\u2019 performance in offensive PowerShell code\ngeneration?\nAs the fine-tuning period extends, such as with 10 and 30\nepochs, the benefits of pre-training diminish or even be-\ncome counterproductive. In these cases, the performance\nof pre-trained models consistently falls below that of\ntheir non-pre-trained counterparts. This highlights the\nvariable effectiveness of pre-training, dependent on the\nduration of fine-tuning. These findings underscore the\ninterplay between the duration of training epochs and\nthe usage of pre-training, emphasizing the importance\nof carefully considering these factors in model develop-\nment.\nTable 5 illustrates four cases of model predictions. They\nare examples from our test sets to highlight both success-\nful and failed prediction cases. Row # 1 demonstrates the\nmodels\u2019 ability to generate a PowerShell snippet composed\nof multiple commands (separated by semicolons) without\nerrors. The model correctly predicts the correct variables,\ne.g., WebBrowserPassViewPath, and command names, such\nas Start-Process, Start-Sleep. Row # 2 is indicative\nof the concept of implicit model knowledge. Indeed, the\nmodel can generate a correct command by leveraging al-\nternative equivalent versions of PowerShell\u2019s option flags\n(e.g., -ExecutionPolicy instead of -exec). Row # 3 shows\na relevant example of a failure case. It is possible to no-\ntice how the model correctly predicts the variable names\nand values except for one not referenced in the intent\n(-InfoTechStorageHandler). In addition, the model fails\nto predict the correct command name, generating an addi-\ntional word (HTML) based on the NL description. Finally, row\n# 4 illustrates another incorrect example in which the model\nis capable of generating the ground truth code, except for\nintroducing an additional variable to save the output of the\ncommand ($wininit =).\nOverall, we can conclude that these examples indicate the\nmodel\u2019s ability to generate complex PowerShell snippets, even\nthough there is still some error margin, specifically related to\nomissions (e.g., variable names).\n4.3\nStatic Analysis\nWe evaluated the generated code through static analysis to\nensure that the code adheres to PowerShell conventions and\ndoes not contain syntax errors. The analysis was conducted\non the top-performing models identified in the previous eval-\nuation, namely the 30-epoch versions of CodeT5+ with pre-\ntraining, CodeGPT without pre-training, and CodeGen with\npre-training. The static analysis leverages PSScriptAnalyzer\n[67], a static code checker for PowerShell modules and scripts.\nThe primary purpose of PSScriptAnalyzer is to assess the qual-\nity of PowerShell code by analyzing its syntax, structure, and\nadherence to best practices. The rules are based on Power-\nShell best practices identified by the PowerShell Team and the\ncommunity, organized into categories such as Cmdlet Design,\nScript Functions, Error Handling, Scripting Style, and Script\nSecurity. The severity levels (ParseError, Error, Warning, In-\nformation) associated with each rule indicate the importance\nand impact of adhering to the specific guideline. In this work,\nwe focused on parse errors, which occur during the parsing\nphase of a program\u2019s execution, errors, occurring when code\n9\nPre-trained\nmodels\nStatic Analysis\nTest Set\nReference \ncommands\nPSScript\nAnalyzer\nSyntactic\nEvaluation\nNL Intents\nGenerated\ncommands\nFigure 3: Static analysis workflow.\nModel\nSingle Accuracy\n(%)\nComparative\nAccuracy (%)\nCodeT5+\n91.15\n92.04\nCodeGPT\n98.23\n98.23\nCodeGen\n98.23\n98.23\nTable 6: Syntactic evaluation for the best models.\ndoes not meet specific high-severity rules (e.g., hardcoding\ncomputer names, using plain text passwords), and warnings,\nwhich typically highlight potential issues or coding practices\nthat might lead to errors or security concerns.\nWe developed a syntactic analysis tool to streamline the\nprocess of detecting parse errors, errors, and warnings in\nPowerShell scripts. This tool automatically feeds PSScriptAn-\nalyzer with PowerShell commands generated by the models\nduring the testing phase. By doing so, our tool identifies er-\nrors and warnings in the generated code, assessing the overall\nsyntactic quality of the models.\nThe syntactic analysis process begins with our test set,\nwhich consists of NL intents paired with reference PowerShell\ncommands. These NL intents are fed into fine-tuned models to\nproduce the PowerShell code. Both the generated commands\nand their corresponding references are then subjected to the\nsyntax analyzer.\nTo assess the syntactic quality of the generated commands,\nwe introduce two distinct metrics: Single Syntax Accuracy\nand Comparative Syntax Accuracy. The metrics are defined\nas follows:\n\u2022 Single Syntax Accuracy: evaluates the percentage of\ncommands without parse errors. This evaluation is in-\ndependent of the reference commands from the ground\ntruth.\n\u2022 Comparative Syntax Accuracy: assesses the syntactic\ncorrectness of the generated commands by considering\nthe results alongside the reference commands. When\nboth commands present common parse errors, these are\nexcluded from the counting process. Given that some ref-\nerence commands include stub templates such as <code>\nTest Set\nParseError (%)\nError (%)\nWarning (%)\nCodeT5+\n8.85\n1.94\n35.92\nCodeGPT\n1.77\n2.70\n29.73\nCodeGen\n1.77\n1.80\n31.53\nGround Truth\n2.65\n0.00\n39.09\nTable 7: Summary of ParseError, Error, and Warning percent-\nages for models and ground truth on the test set.\n14\n22\n3\n4\n14\n14\n5\n2\n17\n7\n5\n4\n16\n10\n5\n6\n0\n5\n10\n15\n20\n25\nAvoidUsingInvokeExpression\n AvoidUsingCmdletAliases\n AvoidUsingWMICmdlet\n UseDeclaredVarsMoreThanAssignments\nNumber of Warnings\nWarnings \nCodeT5+\nCodeGPT\nCodeGen\nGround Truth\nFigure 4: Counts for different warning types in each test set.\nor <command>, the analysis filters out parse errors asso-\nciated with these templates, specifically the Redirection-\nNotSupported and MissingFileSpecification errors.\nThe workflow for the syntactic analysis is depicted in Fig-\nure 3. Looking at the results in Table 6, it is possible to notice\nthat all the models achieved a score greater than 90%, assess-\ning their strong capability to generate syntactically correct\ncode. CodeGPT and CodeGen, in general, demonstrate high\nperformance across both syntax metrics. Table 7 summarizes\nthe percentages for various severity types in the test set. Given\nthat warning frequencies are consistently above 30% for all\nmodels, including the ground truth, Figure 4 enumerates the\nvarious warning types within each set.\n4.4\nExecution Analysis\nThe execution analysis aims to evaluate the generated offen-\nsive PowerShell code when running in an actual system. This\ninvolves assessing the ability of the code to behave as intended\nin terms of effects caused on the system. Therefore, we run\nboth code from the ground truth and generated code, monitor\ntheir behavior at runtime, and compare the behavioral events\n10\nExecution Analysis\nWindows 10 VM\nPre-trained\nmodels\nTest Set\nReference \ncommands\nNL Intents\nGenerated\ncommands\nSysmon\nSecurity \nTools\nEvent \nFiltering\nExecution\nEvaluation\nFigure 5: Execution analysis workflow.\nGround truth\nevents\nGenerated code\nevents\n188\n151\n145\npowershell.exe -ExecutionPolicy Bypass -NoLogo -NonInteractive -NoProfile -WindowStyle\nHidden -Command \"IEX (Invoke-WebxRequest \u2013Uri 'https://raw.githubusercontent.com/Powershell-\nScripts-for-Hackers-and-Pentesters/main/scripts/all_in_one_enum.ps1').Content\"Whitecat18\npowershell.exe -NoP -NonI -W Hidden -Exec Bypass -Command \"Invoke-WebRequest\nhttps://raw.githubusercontent.com/Whitecat18/Powershell-Scripts-for-Hackers-and-Pentesters/main/\nscripts/all_in_one_enum.ps1 -OutFile hello.ps1; .\\hello.ps1\"\npwsh.exe>C:\\Windows\\System32\\ntdll.dll\npwsh.exe>C:\\Windows\\System32\\gdi32full.dll\n...\npowershell.exe>C:\\Windows\\System32\\sxs.dll\npowershell.exe>C:\\Windows\\System32\\umpdc.dll\npwsh.exe>C:\\Windows\\System32\\ntdll.dll\npwsh.exe>C:\\Windows\\System32\\gdi32full.dll\n...\npwsh.exe>C:\\Program \nFiles\\PowerShell\\7\\System.Reflection.Metadata.dll\npwsh.exe>C:\\Program \nFiles\\PowerShell\\7\\System.Collections.Immutable.dll\nFigure 6: Comparison between events.\nthat occurred during their execution. The entire workflow for\nthe execution analysis is shown in Figure 5.\nWe performed the experiments in a controlled and dedi-\ncated testing environment. The controlled environment con-\nsists of a virtualized Windows 10 system running in Virtual-\nBox 7. The system is equipped with a set of security-related\ntools, such as PowerSploit [68] and Mimikatz [69], that are\ninvoked by many samples of offensive code in our dataset.\nWe assume that these tools have been previously infiltrated\nby the attacker in a previous stage, as typical of advanced\nmalicious campaigns. To monitor the execution of Power-\nshell code, we integrated Sysmon [70], a popular Windows\nservice for gathering system events, including the filesystem,\nthe network, and the Windows Registry. To be able to run\nthe generated code on the system, we assume the scenario\nin which an attacker already bypassed part of the security\nmechanisms by deactivating the Microsoft Defender Firewall,\nWindows Defender, and Microsoft Defender SmartScreen.\nThe evaluation involved executing each command from\nboth the generated ones and those from ground truth\nmultiple times as a single-line PowerShell script. This\ngenerates a process through the standard Windows Sys-\ntem.Diagnostics.Process. We filter the events recorded by\nSysmon by filtering out records related to previous irrelevant\nModel\nPrecision (%)\nRecall (%)\nF1-Score (%)\nCodeT5+\n97.26\n80.94\n88.35\nCodeGPT\n91.86\n85.23\n88.42\nCodeGen\n96.94\n80.97\n88.24\nTable 8: Execution analysis results.\nevents and selecting records based on the Process ID (PID),\nfocusing on both the parent process responsible for executing\nthe PowerShell command and its child processes. The com-\nparison has been performed comparing the events triggered\nby the generated command (called retrieved records) to those\nfrom the execution profile of the ground truth (called rele-\nvant records). The events that appear both when executing\nthe generated code and the ground truth are relevant records\nretrieved. From these sets of events, we evaluate the precision,\nrecall and F1-score of the generated code, defined as follows:\nprecision = 1\nN\nN\n\u2211\ni\n#(relevant records retrieved)i\n#(retrieved records)i\nrecall = 1\nN\nN\n\u2211\ni\n#(relevant records retrieved)i\n#(relevant records)i\nF1-Score = 2 precision\u2217recall\nprecision+recall\nFigure 6 illustrates an example of event analysis: given\nthe ground truth and the generated PowerShell command,\nwe execute them and compare the set of events triggered by\neach command to measure their overlap. To avoid noise in\nthe analysis due to events that only occur sporadically (e.g.,\nbecause of non-determinism sources in the system), we iden-\ntify such events by performing multiple repeated runs of the\ncode and discard non-reproducible events from the analysis.\nAfter every command execution, the Windows environment\nis restored to a clean state, by reloading the virtual machine\nfrom a snapshot, to avoid interferences caused by the effect\nof previous commands.\nThe results shown in Table 8 outline how all models share\nan overall precision higher than 90% and an overall recall\nhigher than 80%, likewise, the Execution F1-Score is very\nsimilar between the different models and higher than 88%.\nThus, although there were differences found in the textual\nsimilarity analysis, the generated code closely matches the\nground truth in terms of dynamic events.\nRQ3: How good is the generated code in terms of code\nquality and dynamic behavior?\nThe syntactic analysis of the generated code showed that\nthe models are indeed capable of generating high-quality\n11\nFigure 7: Comparison with ChatGPT on output similarity\nmetrics.\nPowerShell code. CodeGPT and CodeGen achieve the\nbest results in terms of Single and Comparative Accu-\nracy, along with an amount of Warnings and ParseErrors\ncomparable to the ground truth. The execution analy-\nsis revealed that the generated PowerShell code closely\nreplicates the behavior of the ground truth code, generat-\ning the same events in the target system. This is indica-\ntive of the generated code\u2019s capability of performing the\nmalicious actions described in the NL intents.\n4.5\nComparison with Public AI Model\nIn this study, we conducted a comprehensive evaluation\nby comparing the performance of our fine-tuned models,\nCodeT5+, CodeGPT, and CodeGen, with ChatGPT, the Ope-\nnAI LLM service widely used for a variety of tasks, including\ncode generation [71]. The purpose was to assess the special-\nized capabilities of our models in generating PowerShell code\nfor offensive security tasks and to benchmark their perfor-\nmance against a publicly available, closed-source model. We\nleveraged ChatGPT 3.5, which represents the most recent free\nversion at the time of this work.\nTo assess the capabilities of the OpenAI model, we first\nprovided a detailed description of the required task, i.e.,\nthe generation of PowerShell commands starting from NL\ndescriptions, including an example of input and the desired\noutput. Then, we provided a list of natural language code\ndescriptions and asked ChatGPT to automatically generate\nthe corresponding PowerShell code. Specifically, following\nworks and guidelines on prompt engineering [71, 72], we\nleveraged the following prompt:\nI want you to act\nas a code generator. Given a natural language\ndescription of a PowerShell command, generate\nthe corresponding PowerShell code.\nFigure 7 shows the results of this analysis. The figure shows\nthat our fine-tuned models consistently outperform ChatGPT\nFigure 8: Comparison with ChatGPT on static and execution\nanalysis evaluation metrics.\nacross multiple evaluation metrics. Specifically, ChatGPT\nexhibits a BLEU-4 score of 7.45%, an ED of 33.84%, a ME-\nTEOR of 22.14%, and a ROUGE-L of 20.61%. In contrast,\nour fine-tuned models showcase superior overall performance\nacross all output similarity metrics. The tailored training on\nthe specialized fine-tuning dataset, designed specifically for\noffensive security code generation, results in more accurate\ncode generation, enabling our models to surpass the capabil-\nities of ChatGPT in this particular task. We also analyzed\nthe syntactical quality of the PowerShell code generated by\nChatGPT, obtaining a Syntax Single Accuracy of 95.58% and\na Syntax Comparative Accuracy of 96.46%. These results\nunderscore the commendable ability of ChatGPT to generate\naccurate and syntactically correct PowerShell code.\nFinally, we extended the execution analysis to ChatGPT,\nfollowing the same strategies described in Section 4.4, ob-\ntaining an overall Execution F1-Score of 82.92%. Despite\nthe strong syntactic performance, ChatGPT remains one step\nbelow the fine-tuned models in the qualitative analysis of the\ngenerated PowerShell code. The results of this analysis are\nshown in Figure 8.\nRQ4: How do fine-tuned NMT models, leveraging\nsecurity-oriented training data, compare to a publicly avail-\nable, closed-source model?\nThe comparative analysis with ChatGPT, a publicly\navailable general-purpose language model, highlights\nthe specialized strengths of privately fine-tuned models,\nCodeT5+, CodeGPT, and CodeGen, in offensive Pow-\nerShell code generation. The fine-tuned models consis-\ntently outperform ChatGPT across BLEU-4, Edit Dis-\ntance, and METEOR scores. While showing notable\nperformance on syntactic accuracy, ChatGPT achieves\npoorer results than the fine-tuned models for the exe-\ncution analysis. This underscores the significance of\n12\ndomain-specific fine-tuning and the benefits of training\non security-oriented datasets, providing an advantage\nin generating offensive PowerShell code compared to\na general-purpose language model. The results affirm\nthe effectiveness of tailored training data for achieving\nsuperior performance in domain-specific tasks.\n5\nThreats To Validity\nModel selection. The external validity of the study might be\nimpacted by the choice of NMT models (CodeT5+, CodeGPT,\nCodeGen). To mitigate this, we carefully selected models with\ndistinct architectures and capabilities, ensuring a representa-\ntion of current advancements in the field [16,73,74]. This care-\nful selection aims to ensure that our findings reflect broader\ntrends in NMT model performance for code generation tasks.\nEvaluation metrics. The reliance on output similarity met-\nrics, although representing the most common solution in the\nfield, poses a potential threat to construct validity, as these\nmetrics may not fully encapsulate the correctness and func-\ntional adequacy of the generated PowerShell commands. To\naddress this issue, our evaluation strategy encompasses a com-\nprehensive suite of metrics, including similarity, syntactic, and\nexecution metrics, each offering unique insights into the mod-\nels\u2019 performance. By considering multiple variants of these\nmetrics and aligning with common practices in code genera-\ntion evaluation, we aim to provide a well-rounded assessment.\nNo single metric is perfect, but analyzing them collectively\nallows for a more comprehensive evaluation of the code.\nFine-tuning data. The construction of our dataset, meticu-\nlously curated from several sources such as online repositories,\nAtomic Red Team, Stockpile, and Empire, introduces poten-\ntial limitations regarding the generalizability of our models\u2019\nperformance across different offensive security contexts. To\nminimize the impact of these limitations, we sourced data\nfrom diverse origins and conducted manual verification of\neach sample in the labeled dataset, ensuring the completeness\nand coherence of descriptions with the intended programs.\nThe diversity in data sources and the thorough verification\nprocess aim to diminish the influence of any singular source\u2019s\npeculiarities and errors in programs or descriptions, thereby\nenhancing the dataset\u2019s applicability and reliability for train-\ning and evaluating AI models in generating offensive Pow-\nerShell code. Furthermore, our approach to crafting NL de-\nscriptions, inspired by established styles found in PowerShell\nliterature, mirrors real-world scenarios where such descrip-\ntions play a critical role in describing PowerShell commands.\nFinally, regarding the size of our dataset, we notice that it is\nin line with other state-of-the-art corpora used to fine-tune\nmodels, which are in the order of one thousand samples [52].\n6\nEthical Considerations\nRecognizing that attackers use attacks as a weapon, it is im-\nportant to specify that the goal of the proof-of-concept (POC)\nis not to cause harm but to surface security weaknesses within\nthe software. Identifying security issues allows companies to\npatch vulnerabilities and protect themselves against attacks.\nOffensive security is a sub-field of security research that\ntests security measures from an adversary or competitor\u2019s\nperspective, employing ethical hackers to probe a system for\nvulnerabilities [75, 76]. Our work aims to automate attack\ngeneration to explore critical vulnerabilities before they are\nexploited by attackers [77]. Indeed, our work simplifies the\nprocess of coding the attacks to surface security weaknesses\nwithin the software and can provide valuable information\nabout the technical skills, degree of experience, and intent of\nthe attackers. With this information, it is possible to imple-\nment measures to detect and prevent attacks [78].\n7\nConclusion\nIn this paper, we assessed the feasibility of using NMT models\nto generate PowerShell code for security contexts. We aimed\nto demonstrate that AI-based code generators are indeed fit to\ngenerate PowerShell code, specifically, offensive PowerShell,\nwhich spans several applications in the cybersecurity domain.\nThe evaluation of CodeT5+, CodeGPT, and CodeGen demon-\nstrated that these models achieve significant performance on\nthe code generation task, both with and without pre-training.\nMoreover, the study showed that domain-specific fine-tuning\nallows our models to outperform state-of-the-art privately fine-\ntuned models, i.e., ChatGPT. We also introduced two novel\ndatasets for PowerShell code generation to use for pre-training\nand fine-tuning AI-code generators.\nFuture work includes further analysis of the generated code,\nsuch as sandbox execution of the offensive scripts, to under-\nstand whether the code can evade detection measures, along\nwith more NMT models spanning several architectures and\ncapabilities.\nAcknowledgments\nThis work has been partially supported by MUR PRIN 2022,\nproject FLEGREA, CUP E53D23007950001 (https://fl\negrea.github.io) and by an Industrial Ph.D. grant (PNRR\n- DM 117/2023) from MUR and DigitalPlatforms S.p.A, CUP\nE66E23000580003.\nReferences\n[1] A. Applebaum, D. Miller, B. E. Strom, C. Korban, and\nR. Wolf, \u201cIntelligent, automated red team emulation,\u201d\n13\nProceedings of the 32nd Annual Conference on Com-\nputer Security Applications, 2016.\n[2] A. B. Ajmal, M. A. Shah, C. Maple, M. N. Asghar,\nand S. U. Islam, \u201cOffensive security: Towards proactive\nthreat hunting via adversary emulation,\u201d IEEE Access,\nvol. 9, pp. 126 023\u2013126 033, 2021.\n[3] E. M. Hutchins, M. J. Cloppert, R. M. Amin et al.,\n\u201cIntelligence-driven computer network defense informed\nby analysis of adversary campaigns and intrusion kill\nchains,\u201d Leading Issues in Information Warfare & Secu-\nrity Research, vol. 1, no. 1, p. 80, 2011.\n[4] B. E. Strom, A. Applebaum, D. P. Miller, K. C. Nickels,\nA. G. Pennington, and C. B. Thomas, \u201cMitre att&ck:\nDesign and philosophy,\u201d in Technical report.\nThe\nMITRE Corporation, 2018.\n[5] Sudhakar and S. Kumar, \u201cAn emerging threat fileless\nmalware: a survey and research challenges,\u201d Cybersecu-\nrity, vol. 3, no. 1, p. 1, 2020.\n[6] I. Kara, \u201cFileless malware threats: Recent advances,\nanalysis approach through memory forensics and re-\nsearch challenges,\u201d Expert Systems with Applications,\nvol. 214, p. 119133, 2023.\n[7] Varonis, \u201cWhat is Fileless Malware? PowerShell Ex-\nploited,\u201d https://www.varonis.com/blog/fileless-malwa\nre.\n[8] Cybersecurity & Infrastructure Security Agency, \u201cIden-\ntifying and Mitigating Living Off the Land Techniques,\u201d\nhttps://www.cisa.gov/sites/default/files/2024-02/Join\nt-Guidance-Identifying-and-Mitigating-LOTL_V350\n8c.pdf.\n[9] R. Natella, P. Liguori, C. Improta, B. Cukic, and\nD. Cotroneo, \u201cAi code generators for security: Friend or\nfoe?\u201d IEEE Security & Privacy, 2024.\n[10] A. Fan, B. Gokkaya, M. Harman, M. Lyubarskiy, S. Sen-\ngupta, S. Yoo, and J. M. Zhang, \u201cLarge language models\nfor software engineering: Survey and open problems,\u201d\narXiv preprint arXiv:2310.03533, 2023.\n[11] M.\nChen, J.\nTworek, H.\nJun, Q.\nYuan, H.\nP.\nde Oliveira Pinto, J. Kaplan, H. Edwards, Y. Burda,\nN. Joseph, G. Brockman, A. Ray, R. Puri, G. Krueger,\nM. Petrov, H. Khlaaf, G. Sastry, P. Mishkin, B. Chan,\nS. Gray, N. Ryder, M. Pavlov, A. Power, L. Kaiser,\nM. Bavarian, C. Winter, P. Tillet, F. P. Such, D. Cum-\nmings, M. Plappert, F. Chantzis, E. Barnes, A. Herbert-\nVoss, W. H. Guss, A. Nichol, A. Paino, N. Tezak, J. Tang,\nI. Babuschkin, S. Balaji, S. Jain, W. Saunders, C. Hesse,\nA. N. Carr, J. Leike, J. Achiam, V. Misra, E. Morikawa,\nA. Radford, M. Knight, M. Brundage, M. Murati,\nK. Mayer, P. Welinder, B. McGrew, D. Amodei, S. Mc-\nCandlish, I. Sutskever, and W. Zaremba, \u201cEvaluating\nLarge Language Models Trained on Code,\u201d arXiv\npreprint arXiv: 2107.03374, 2021.\n[12] H. Yu, B. Shen, D. Ran, J. Zhang, Q. Zhang, Y. Ma,\nG. Liang, Y. Li, Q. Wang, and T. Xie, \u201cCodereval: A\nbenchmark of pragmatic code generation with gener-\native pre-trained models,\u201d in Proceedings of the 46th\nIEEE/ACM International Conference on Software Engi-\nneering, 2024, pp. 1\u201312.\n[13] X. Du, M. Liu, K. Wang, H. Wang, J. Liu, Y. Chen,\nJ. Feng, C. Sha, X. Peng, and Y. Lou, \u201cClassEval: A\nManually-Crafted Benchmark for Evaluating LLMs on\nClass-level Code Generation,\u201d arXiv preprint arXiv:\n2308.01861, 2023.\n[14] P. Liguori, E. Al-Hossami, D. Cotroneo, R. Natella,\nB. Cukic, and S. Shaikh, \u201cShellcode_IA32: A dataset\nfor automatic shellcode generation,\u201d in Proceedings\nof the 1st Workshop on Natural Language Processing\nfor Programming (NLP4Prog 2021), R. Lachmy,\nZ. Yao, G. Durrett, M. Gligoric, J. J. Li, R. Mooney,\nG. Neubig, Y. Su, H. Sun, and R. Tsarfaty, Eds.\nOnline: Association for Computational Linguistics,\nAug. 2021, pp. 58\u201364. [Online]. Available: https:\n//aclanthology.org/2021.nlp4prog-1.7\n[15] Y. Wang, H. Le, A. D. Gotmare, N. D. Bui, J. Li, and\nS. C. Hoi, \u201cCodet5+: Open code large language models\nfor code understanding and generation,\u201d arXiv preprint\narXiv:2305.07922, 2023.\n[16] S. Lu, D. Guo, S. Ren, J. Huang, A. Svyatkovskiy,\nA. Blanco, C. B. Clement, D. Drain, D. Jiang, D. Tang,\nG. Li, L. Zhou, L. Shou, L. Zhou, M. Tufano,\nM. Gong, M. Zhou, N. Duan, N. Sundaresan, S. K.\nDeng, S. Fu, and S. Liu, \u201cCodexglue: A machine\nlearning benchmark dataset for code understanding and\ngeneration,\u201d in Proceedings of the Neural Information\nProcessing Systems Track on Datasets and Benchmarks\n1, NeurIPS Datasets and Benchmarks 2021, December\n2021, virtual, J. Vanschoren and S. Yeung, Eds., 2021.\n[Online]. Available: https://datasets-benchmarks-proce\nedings.neurips.cc/paper/2021/hash/c16a5320fa475530\nd9583c34fd356ef5-Abstract-round1.html\n[17] E. Nijkamp, B. Pang, H. Hayashi, L. Tu, H. Wang,\nY. Zhou, S. Savarese, and C. Xiong, \u201cCodegen: An open\nlarge language model for code with multi-turn program\nsynthesis,\u201d 2023.\n[18] OpenAI, \u201cChatGPT,\u201d https://openai.com/chatgpt.\n[19] Z. Li, Q. A. Chen, C. Xiong, Y. Chen, T. Zhu, and\nH. Yang, \u201cEffective and light-weight deobfuscation and\n14\nsemantic-aware attack detection for powershell scripts,\u201d\nin Proceedings of the 2019 ACM SIGSAC Conference\non Computer and Communications Security, 2019, pp.\n1831\u20131847.\n[20] M.-H. Tsai, C.-C. Lin, Z.-G. He, W.-C. Yang, and C.-\nL. Lei, \u201cPowerdp: De-obfuscating and profiling mali-\ncious powershell commands with multi-label classifiers,\u201d\nIEEE Access, vol. 11, pp. 256\u2013270, 2023.\n[21] D. Hendler, S. Kels, and A. Rubin, \u201cDetecting malicious\npowershell commands using deep neural networks,\u201d in\nProceedings of the 2018 on Asia conference on computer\nand communications security, 2018, pp. 187\u2013197.\n[22] A. Rubin, S. Kels, and D. Hendler, \u201cAmsi-based detec-\ntion of malicious powershell code using contextual em-\nbeddings,\u201d arXiv preprint arXiv:1905.09538, 2019.\n[23] M. Mimura and Y. Tajiri, \u201cStatic detection of malicious\npowershell based on word embeddings,\u201d Internet of\nThings, vol. 15, p. 100404, 2021. [Online]. Available:\nhttps://www.sciencedirect.com/science/article/pii/S2\n542660521000482\n[24] Y. Mezawa and M. Mimura, \u201cEvaluating the possibility\nof evasion attacks to machine learning-based models\nfor malicious powershell detection,\u201d in International\nConference on Information Security Practice and Expe-\nrience.\nSpringer, 2022, pp. 252\u2013267.\n[25] G. Rusak, A. Al-Dujaili, and U.-M. O\u2019Reilly, \u201cAst-based\ndeep learning for detecting malicious powershell,\u201d in\nProceedings of the 2018 ACM SIGSAC Conference\non Computer and Communications Security, 2018, pp.\n2276\u20132278.\n[26] M. Gupta, C. Akiri, K. Aryal, E. Parker, and L. Praharaj,\n\u201cFrom chatgpt to threatgpt: Impact of generative ai in\ncybersecurity and privacy,\u201d IEEE Access, vol. 11, pp.\n80 218\u201380 245, 2023.\n[27] P. Charan, H. Chunduri, P. M. Anand, and S. K. Shukla,\n\u201cFrom text to mitre techniques: Exploring the malicious\nuse of large language models for generating cyber attack\npayloads,\u201d arXiv preprint arXiv:2305.15336, 2023.\n[28] P. Liguori, E. Al-Hossami, D. Cotroneo, R. Natella,\nB. Cukic, and S. Shaikh, \u201cCan we generate shellcodes\nvia natural language? an empirical study,\u201d Automated\nSoftware Engineering, vol. 29, no. 1, pp. 1\u201334, 2022.\n[29] P. Liguori, E. Al-Hossami, V. Orbinato, R. Natella,\nS. Shaikh, D. Cotroneo, and B. Cukic, \u201cEvil: exploit-\ning software via natural language,\u201d in 2021 IEEE 32nd\nInternational Symposium on Software Reliability Engi-\nneering (ISSRE).\nIEEE, 2021, pp. 321\u2013332.\n[30] G. Yang, X. Chen, Y. Zhou, and C. Yu, \u201cDualsc: Auto-\nmatic generation and summarization of shellcode via\ntransformer and dual learning,\u201d in IEEE International\nConference on Software Analysis, Evolution and Reengi-\nneering, SANER 2022, Honolulu, HI, USA, March 15-18,\n2022.\nIEEE, 2022, pp. 361\u2013372.\n[31] G. Yang, Y. Zhou, X. Chen, X. Zhang, T. Han, and\nT. Chen, \u201cExploitgen: Template-augmented exploit code\ngeneration based on codebert,\u201d Journal of Systems and\nSoftware, vol. 197, p. 111577, 2023.\n[32] A. M. Dai and Q. V. Le, \u201cSemi-supervised sequence\nlearning,\u201d Advances in neural information processing\nsystems, vol. 28, 2015.\n[33] S. Gururangan, A. Marasovi\u00b4\nc, S. Swayamdipta, K. Lo,\nI. Beltagy, D. Downey, and N. A. Smith, \u201cDon\u2019t stop\npretraining: Adapt language models to domains and\ntasks,\u201d arXiv preprint arXiv:2004.10964, 2020.\n[34] T. Lin, Y. Wang, X. Liu, and X. Qiu, \u201cA survey of trans-\nformers,\u201d AI Open, 2022.\n[35] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever\net al., \u201cImproving language understanding by generative\npre-training,\u201d 2018.\n[36] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei,\nI. Sutskever et al., \u201cLanguage models are unsupervised\nmultitask learners,\u201d OpenAI blog, vol. 1, no. 8, p. 9,\n2019.\n[37] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Ka-\nplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry,\nA. Askell et al., \u201cLanguage models are few-shot learn-\ners,\u201d Advances in neural information processing systems,\nvol. 33, pp. 1877\u20131901, 2020.\n[38] H. Wang, J. Li, H. Wu, E. Hovy, and Y. Sun, \u201cPre-trained\nlanguage models and their applications,\u201d Engineering,\n2022.\n[39] R. Tufano, L. Pascarella, and G. Bavota, \u201cAutomating\ncode-related tasks through transformers: The impact of\npre-training,\u201d in 2023 IEEE/ACM 45th International\nConference on Software Engineering (ICSE).\nIEEE,\n2023, pp. 2425\u20132437.\n[40] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova,\n\u201cBert: Pre-training of deep bidirectional transform-\ners\nfor language\nunderstanding,\u201d\narXiv preprint\narXiv:1810.04805, 2018.\n[41] Red Canary, \u201cAtomic Red Team,\u201d https://atomicredtea\nm.io/.\n[42] M. Corporation, \u201cMITRE ATT&CK,\u201d https://attack.mit\nre.org/.\n15\n[43] MITRE, \u201cCALDERA plugin: Stockpile,\u201d https://github\n.com/mitre/stockpile.\n[44] MITRE, \u201cCALDERA,\u201d https://github.com/mitre/calde\nra.\n[45] Empire Project, \u201cEmpire,\u201d https://github.com/EmpireP\nroject/Empire.\n[46] Hacktricks, \u201cHacktricks,\u201d https://book.hacktricks.xyz/.\n[47] R. T. Recipe, \u201cPowerShell tips & tricks,\u201d https://redtea\nmrecipe.com/powershell-tips-tricks/.\n[48] I. Matter, \u201cPowerShell commands for pentesters,\u201d https:\n//www.infosecmatter.com/powershell-commands-for\n-pentesters/.\n[49] Tutorial\u2019s Point, \u201cLearn PowerShell,\u201d https://www.tuto\nrialspoint.com/powershell/index.htm.\n[50] T. Lee, K. Mitschke, M. E. Schill, and T. Tanasovski,\nWindows PowerShell 2.0 Bible.\nJohn Wiley & Sons,\n2011.\n[51] L. Holmes, Windows PowerShell Cookbook: The Com-\nplete Guide to Scripting Microsoft\u2019s Command Shell.\nO\u2019Reilly Media, 2012.\n[52] C. Zhou, P. Liu, P. Xu, S. Iyer, J. Sun, Y. Mao, X. Ma,\nA. Efrat, P. Yu, L. Yu, S. Zhang, G. Ghosh, M. Lewis,\nL. Zettlemoyer, and O. Levy, \u201cLIMA: less is more for\nalignment,\u201d CoRR, vol. abs/2305.11206, 2023. [Online].\nAvailable: https://doi.org/10.48550/arXiv.2305.11206\n[53] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang,\nM. Matena, Y. Zhou, W. Li, and P. J. Liu, \u201cExploring\nthe limits of transfer learning with a unified text-\nto-text transformer,\u201d J. Mach. Learn. Res., vol. 21,\npp. 140:1\u2013140:67, 2020. [Online]. Available: http:\n//jmlr.org/papers/v21/20-074.html\n[54] S. Lu, D. Guo, S. Ren, J. Huang, A. Svyatkovskiy,\nA. Blanco, C. B. Clement, D. Drain, D. Jiang, D. Tang,\nG. Li, L. Zhou, L. Shou, L. Zhou, M. Tufano,\nM. Gong, M. Zhou, N. Duan, N. Sundaresan, S. K.\nDeng, S. Fu, and S. Liu, \u201cCodexglue: A machine\nlearning benchmark dataset for code understanding and\ngeneration,\u201d in Proceedings of the Neural Information\nProcessing Systems Track on Datasets and Benchmarks\n1, NeurIPS Datasets and Benchmarks 2021, December\n2021, virtual, J. Vanschoren and S. Yeung, Eds., 2021.\n[Online]. Available: https://datasets-benchmarks-proce\nedings.neurips.cc/paper/2021/hash/c16a5320fa475530\nd9583c34fd356ef5-Abstract-round1.html\n[55] P. Liguori, C. Improta, R. Natella, B. Cukic, and\nD. Cotroneo, \u201cWho evaluates the evaluators? on\nautomatic metrics for assessing ai-based offensive code\ngenerators,\u201d Expert Systems with Applications, vol. 225,\np. 120073, 2023. [Online]. Available: https://www.scie\nncedirect.com/science/article/pii/S0957417423005754\n[56] X. Ruan, Y. Yu, W. Ma, and B. Cai, \u201cPrompt learning\nfor developing software exploits,\u201d in Proceedings of the\n14th Asia-Pacific Symposium on Internetware, 2023, pp.\n154\u2013164.\n[57] K. Papineni, S. Roukos, T. Ward, and W. Zhu, \u201cBleu: a\nmethod for automatic evaluation of machine translation,\u201d\nin Proceedings of the 40th Annual Meeting of the\nAssociation for Computational Linguistics, July 6-12,\n2002, Philadelphia, PA, USA. ACL, 2002, pp. 311\u2013318.\n[Online]. Available: https://aclanthology.org/P02-1040/\n[58] L. Han, \u201cMachine translation evaluation resources and\nmethods: A survey,\u201d arXiv preprint arXiv:1605.04515,\n2016.\n[59] D. Munkova, P. Hajek, M. Munk, and J. Skalka, \u201cEvalu-\nation of machine translation quality through the metrics\nof error rate and accuracy,\u201d Procedia Computer Science,\nvol. 171, pp. 1327\u20131336, 2020.\n[60] NLTK, \u201cNatural Language Toolkit (NLTK), bleu_score\nmodule,\u201d 2023. [Online]. Available: https://www.nltk.o\nrg/api/nltk.translate.bleu_score.html\n[61] pylcs, \u201cPython library pylcs,\u201d 2023. [Online]. Available:\nhttps://pypi.org/project/pylcs/\n[62] A. Lavie and A. Agarwal, \u201cMeteor: An automatic metric\nfor mt evaluation with high levels of correlation with\nhuman judgments,\u201d in Proceedings of the Second Work-\nshop on Statistical Machine Translation, ser. StatMT\n\u201907.\nUSA: Association for Computational Linguistics,\n2007, p. 228\u2013231.\n[63] evaluate, \u201cPython library evaluate,\u201d 2022. [Online].\nAvailable: https://pypi.org/project/evaluate/\n[64] rouge, \u201cPython ROUGE Score Implementation,\u201d 2021.\n[Online]. Available: https://pypi.org/project/rouge/\n[65] J. Shin, M. Wei, J. Wang, L. Shi, and S. Wang, \u201cThe\ngood, the bad, and the missing: Neural code gen-\neration for machine learning tasks,\u201d arXiv preprint\narXiv:2305.09082, 2023.\n[66] J. Shi, S. Jiang, B. Xu, J. Liang, Y. Xiao, and W. Wang,\n\u201cShellgpt: Generative pre-trained transformer model for\nshell language understanding,\u201d in 2023 IEEE 34th Inter-\nnational Symposium on Software Reliability Engineer-\ning (ISSRE).\nIEEE, 2023, pp. 671\u2013682.\n[67] Microsoft, \u201cPSScriptAnalyzer,\u201d https://github.com/Pow\nerShell/PSScriptAnalyzer.\n16\n[68] Will Schroeder, \u201cPowerSploit,\u201d https://github.com/Pow\nerShellMafia/PowerSploit.\n[69] Benjamin Delpy, \u201cMimikatz,\u201d https://github.com/genti\nlkiwi/mimikatz.\n[70] Mark Russinovich,Thomas Garnier, \u201cSystem Monitor,\u201d\nhttps://learn.microsoft.com/en-us/sysinternals/downl\noads/sysmon.\n[71] Y. Dong, X. Jiang, Z. Jin, and G. Li, \u201cSelf-collaboration\ncode\ngeneration\nvia\nchatgpt,\u201d\narXiv\npreprint\narXiv:2304.07590, 2023.\n[72] Microsoft, \u201cPrompt Engineering - Learn how to use AI\nmodels with prompt engineering,\u201d https://microsoft.gith\nub.io/prompt-engineering/.\n[73] Y. Wei, C. S. Xia, and L. Zhang, \u201cCopiloting the copilots:\nFusing large language models with completion engines\nfor automated program repair,\u201d in Proceedings of the\n31st ACM Joint European Software Engineering Con-\nference and Symposium on the Foundations of Software\nEngineering, 2023, pp. 172\u2013184.\n[74] S. Tipirneni, M. Zhu, and C. K. Reddy, \u201cStructcoder:\nStructure-aware transformer for code generation,\u201d arXiv\npreprint arXiv:2206.05239, 2022.\n[75] S. Bratus, I. Arce, M. E. Locasto, and S. Zanero, \u201cWhy\noffensive security needs engineering textbooks,\u201d Yale\nLaw & Policy Review, p. 2, 2013.\n[76] J. G. Oakley, \u201cThe state of modern offensive security,\u201d in\nProfessional Red Teaming.\nSpringer, 2019, pp. 29\u201341.\n[77] T. Avgerinos, S. K. Cha, B. L. T. Hao, and D. Brumley,\n\u201cAeg: Automatic exploit generation,\u201d in NDSS, 2011.\n[78] I. Arce, \u201cThe shellcode generation,\u201d IEEE security &\nprivacy, vol. 2, no. 5, pp. 72\u201376, 2004.\n17\n", "metadata": {"Published": "2024-04-19", "Title": "The Power of Words: Generating PowerShell Attacks from Natural Language", "Authors": "Pietro Liguori, Christian Marescalco, Roberto Natella, Vittorio Orbinato, Luciano Pianese", "Summary": "As the Windows OS stands out as one of the most targeted systems, the\nPowerShell language has become a key tool for malicious actors and\ncybersecurity professionals (e.g., for penetration testing). This work explores\nan uncharted domain in AI code generation by automatically generating offensive\nPowerShell code from natural language descriptions using Neural Machine\nTranslation (NMT). For training and evaluation purposes, we propose two novel\ndatasets with PowerShell code samples, one with manually curated descriptions\nin natural language and another code-only dataset for reinforcing the training.\nWe present an extensive evaluation of state-of-the-art NMT models and analyze\nthe generated code both statically and dynamically. Results indicate that\ntuning NMT using our dataset is effective at generating offensive PowerShell\ncode. Comparative analysis against the most widely used LLM service ChatGPT\nreveals the specialized strengths of our fine-tuned models.", "entry_id": "http://arxiv.org/abs/2404.12893v1", "published_first_time": "2024-04-19", "comment": "18th USENIX WOOT Conference on Offensive Technologies, GitHub Repo:\n  https://github.com/dessertlab/powershell-offensive-code-generation", "journal_ref": null, "doi": null, "primary_category": "cs.CR", "categories": ["cs.CR", "cs.SE"], "links": ["http://arxiv.org/abs/2404.12893v1", "http://arxiv.org/pdf/2404.12893v1"]}, "type": "Document"}
{"page_content": "Offensive AI: Enhancing Directory Brute-forcing Attack with the\nUse of Language Models\nAlberto Castagnaro\nDelft University of Technology\nThe Netherlands\nA.Castagnaro@student.tudelft.nl\nMauro Conti\u2217\nDepartment of Mathematics\nUniversity of Padova\nPadova, Italy\nmauro.conti@unipd.it\nLuca Pajola\u2020\nSpritz Matter Srl\nPadova, Italy\nluca.pajola@unipd.it\nABSTRACT\nWeb Vulnerability Assessment and Penetration Testing (Web VAPT)\nis a comprehensive cybersecurity process that uncovers a range of\nvulnerabilities which, if exploited, could compromise the integrity\nof web applications. In a VAPT, it is common to perform a Direc-\ntory brute-forcing Attack, aiming at the identification of accessible\ndirectories of a target website. Current commercial solutions are\ninefficient as they are based on brute-forcing strategies that use\nwordlists, resulting in enormous quantities of trials for a small\namount of success.\nOffensive AI is a recent paradigm that integrates AI-based tech-\nnologies in cyber attacks. In this work, we explore whether AI can\nenhance the directory enumeration process and propose a novel\nLanguage Model-based framework. Our experiments \u2013 conducted\nin a testbed consisting of 1 million URLs from different web appli-\ncation domains (universities, hospitals, government, companies) \u2013\ndemonstrate the superiority of the LM-based attack, with an aver-\nage performance increase of 969%.\nCCS CONCEPTS\n\u2022 Security and privacy \u2192Penetration testing; \u2022 Computing\nmethodologies \u2192Natural language generation.\nKEYWORDS\nOffensive AI, Language Model, Web Security, Penetration Test\nACM Reference Format:\nAlberto Castagnaro, Mauro Conti, and Luca Pajola. 2018. Offensive AI:\nEnhancing Directory Brute-forcing Attack with the Use of Language Models.\nIn Woodstock \u201918: ACM Symposium on Neural Gaze Detection, June 03\u201305,\n2018, Woodstock, NY. ACM, New York, NY, USA, 13 pages. https://doi.org/\nXXXXXXX.XXXXXXX\n\u2217Also with Delft University of Technology.\n\u2020Also with University of Padova.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\n\u00a9 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-XXXX-X/18/06\nhttps://doi.org/XXXXXXX.XXXXXXX\n1\nINTRODUCTION\nIn its most general sense, hacking refers to modifying or manipu-\nlating a system\u2019s features to achieve a goal outside of the creator\u2019s\noriginal purpose. While often associated with illegal cyber activi-\nties, hacking can also be performed ethically, with permission, to\nimprove system security and uncover vulnerabilities that can be\nfixed before malicious actors exploit them.\nDirectory enumeration is a critical component of security as-\nsessments. It involves identifying accessible directories, files, and\nweb paths in a web application. Effective discovery attacks, such as\ndirectory brute-forcing, can uncover hidden directories and files\nthat may contain sensitive data or critical functionalities.\nOffensive AI uses artificial intelligence technologies to conduct\nor enhance cyber attacks [9, 12]. This emerging field combines AI\u2019s\nadaptability and learning capabilities with traditional attack vectors,\ncreating more sophisticated and automated threats. Offensive AI can\nrapidly analyze vast amounts of data, adapt to defensive measures,\nand execute attacks with increased speed and complexity.\nContribution. This paper contributes to the field by presenting a\nnovel approach that leverages Language Models (LMs) to enhance\nthe efficiency and effectiveness of directory brute-forcing attacks.\nOur method builds on prior knowledge retrieved by different web\napplications and then exploits embedding to extrapolate the context\nof different words that form web paths and language models to\ngenerate new possible URL (Uniform Resource Locator) paths that\ncan be used to send requests. Our contributions are summarized\nbelow:\n(1) We designed a novel dataset containing 4 distinct types of\napplications that are often the targets for attacks, i.e., com-\nmercial, government, hospital and universities, for a total of\n1 million of URLs.\n(2) We propose two novel directory brute-forcing attacks that\nleverage prior knowledge: a probabilistic and a Language\nModel-based approach.\n(3) A systematic evaluation highlights the superiority of prior\nknowledge approaches compared to baselines. LM-based at-\ntacks outperform all 8 proposed baselines, with an average\nperformance increase of 969%. On the other hand, proba-\nbilistic approaches show high performance when the budget\nof spendable requests is limited and, therefore, optimal for\nstealthier attacks.\nEthical Disclaimer. The techniques and methods discussed in\nthis paper are intended for educational purposes and ethical se-\ncurity testing only. The authors do not condone the use of these\narXiv:2404.14138v1  [cs.CR]  22 Apr 2024\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\nTrovato and Tobin, et al.\nmethods for malicious purposes and strongly advocate for respon-\nsible disclosure and remediation of identified vulnerabilities. We\nhope that this research will contribute to the development of more\nsecure web environments and the advancement of cybersecurity\npractices. For this reason, we do not share publicly the collected\ndataset and code. Researchers willing to reproduce our experiment\nare invited to contact the authors.\n2\nBACKGROUND\nThis section describes the theory behind Language Models [15\u201317].\nLanguage Models (LMs) are statistical models that learn the proba-\nbility distribution of sequences of words in a language. Their objec-\ntive is to predict the likelihood of a word given the context of preced-\ning words. Formally, given a sequence of words x = (\ud835\udc65(1), . . . ,\ud835\udc65(\ud835\udc61)),\nLMs computes the probability distribution of the next word \ud835\udc65(\ud835\udc61+1):\n\ud835\udc43(\ud835\udc65(\ud835\udc61+1) |\ud835\udc65(\ud835\udc61), . . . \ud835\udc65(1)),\n(1)\nwhere \ud835\udc65(\ud835\udc61+1) \u2208\ud835\udc49= \ud835\udc641, . . . ,\ud835\udc64|\ud835\udc49|, and \ud835\udc49is a fixed vocabulary.\nGiven a sentence, the goal of a LM is to estimate the probability\nof this sequence \ud835\udc43(x), which is obtained through the chain rule of\nprobability:\n\ud835\udc43((\ud835\udc65(1), . . . ,\ud835\udc65(\ud835\udc47))) = \ud835\udc43(\ud835\udc65(1)) \u00b7 \ud835\udc5d(\ud835\udc65(2) |\ud835\udc65(1)) \u00b7 . . . \u00b7\n\ud835\udc5d(\ud835\udc65(\ud835\udc47) |\ud835\udc65(\ud835\udc47\u22121), . . . ,\ud835\udc65(1))\n=\n\ud835\udc47\n\u00d6\n\ud835\udc61=1\n(\ud835\udc65(\ud835\udc61) |\ud835\udc65(\ud835\udc61\u22121), . . . ,\ud835\udc65(1)).\n(2)\nModern LMs utilize neural networks to learn complex relation-\nships between words and context. Recurrent Neural Networks\n(RNN) are ideal for the task, as they model the generative pro-\ncess of a sequence data (e.g., time series, natural language). Unlike\nother types of NN like feedforward NN, RNNs integrate feedback\nconnections that allow them to retain information from previous\ntime steps (hidden state), and then generate a new sample according\nto a probability distribution given the hidden state. At each time\nstep, a RNN computes an output \ud835\udc66\ud835\udc61based on the current input \ud835\udc65\ud835\udc61\nand the hidden state \u210e\ud835\udc61\u22121 calculated at the previous step.\n\u210e(\ud835\udc61) = \ud835\udc53(\u210e(\ud835\udc61\u22121),\ud835\udc65(\ud835\udc61)).\n(3)\nLMs are trained on large text corpora, and their parameters are\nlearned to maximize the likelihood of observed sequences (max-\nimum likelihood estimation). The loss function at step \ud835\udc61is the\ncross-entropy between predicted probability distribution \u02c6\n\ud835\udc66\ud835\udc61and\nthe true next word \ud835\udc66\ud835\udc61:\n\ud835\udc3d(\ud835\udc61) (\ud835\udf03) = \ud835\udc36\ud835\udc38(y(\ud835\udc61), \u02c6\ny(\ud835\udc61)) = \u2212\n\u2211\ufe01\n\ud835\udc64\u2208\ud835\udc49\ny(\ud835\udc61)\n\ud835\udc64log \u02c6\ny(\ud835\udc61)\n\ud835\udc64\n= \u2212log \u02c6\ny(\ud835\udc61)\nx\ud835\udc61+1.\n(4)\nBy averaging the previous on the entire training set, we obtain the\nfollowing overall loss:\n\ud835\udc3d(\ud835\udf03) = 1\n\ud835\udc47\n\ud835\udc47\n\u2211\ufe01\n\ud835\udc61=1\n\ud835\udc3d\ud835\udc61(\ud835\udf03) = 1\n\ud835\udc47\n\ud835\udc47\n\u2211\ufe01\n\ud835\udc61=1\n\u2212log \u02c6\ny(\ud835\udc61)\nx\ud835\udc61=1.\n(5)\nEmbedding representations play a crucial role in LMs. An em-\nbedding is a numerical representation of words, phrases, sentences,\nor even entire documents. These representations are typically high-\ndimensional vectors that capture the semantic meaning of the text.\nThe importance of embeddings lies in their ability to transform\ntext into a format that machine learning models can understand\nand process. Therefore, embeddings capture the nuanced meanings\nof words based on their context, which is essential for tasks like\nsentiment analysis, translation, and summarization.\n3\nTHREAT MODEL\nAttack Description. A directory enumeration brute-force attack\nis a method that checks for and attempts to access directories and\nfiles on a web server that are not referenced by the application but\nare still accessible. This type of attack is performed by generating a\nlarge number of requests associated with different URLs sent to the\nserver. The attack is commonly based on a wordlist, a list of words\nused to construct the URLs starting from the base one the attacker\nselects.\nThe primary goal of a directory enumeration attack is to uncover\nhidden files, directories, backup files, or administrative interfaces\nthat may contain sensitive information or configuration data. If\nthese resources are not adequately secured, they can be exploited\nto gain unauthorized access, escalate privileges, or launch further\nattacks. Vulnerabilities typically exploited by such attacks include\nmisconfigured permissions, default installations with sample files,\nand outdated or unnecessary files left accessible on the server.\nDirectory enumeration brute-force attacks are often employed\nduring the reconnaissance phase of a penetration test. A penetration\ntest, or pentest, is an authorized simulated cyberattack on a com-\nputer system performed to evaluate its security. However, this type\nof attack may also be performed by malicious actors, so it is essen-\ntial to be aware of this type of attack and to test web application\nsecurity against it properly.\nAutomated tools. Several commercial and open-source tools are\ncommonly used to perform directory brute-force attacks. These\ntools can be specific to this type of attack or be more broad-based\nto provide other functionalities; additionally, they also often come\nwith default wordlists. Popular tools are:\n\u2022 Dirbuster, a Java-based, multi-threaded tool specifically de-\nsigned to brute force directories and file names on web\nor application servers developed by OWASP1. It has nine\ndifferent default wordlists. The tool is freely available at:\nwww.kali.org/tools/dirbuster/.\n\u2022 Wfuzz, an open-source security tool designed to launch\nbrute-force attacks against web applications by fuzzing input\nparameters and assisting penetration testers in identifying\nvulnerabilities. It is designed to perform several attacks, such\nas brute-forcing, fuzzing, and injection attacks. It also comes\nwith several wordlists covering a variety of contexts. The\ntool is freely available at: wfuzz.readthedocs.io.\n\u2022 Burpsuite, a commercial platform that provides a graphical\ntool for conducting security testing on online applications. It\nsupports the entire testing process, from initial mapping and\nanalysis of an application\u2019s attack surface to the discovery\nand exploitation of security flaws. Among these, Burpsuite\ncan perform brute-force attacks to enumerate directories,\n1https://owasp.org/\nOffensive AI: Enhancing Directory Brute-forcing Attack with the Use of Language Models\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\ngiven a target and a wordlist. The tool is available under\ndifferent licences at: portswigger.net/burp.\nWordlists. Wordlists are essentially a set of directories utilized\nin a brute-force attack. Therefore, they play a vital choice when\nusing these tools. A proper choice of wordlist can greatly impact\nthe results, potentially uncovering more vulnerabilities.\nIn the context of directory brute-forcing attacks, there is a range\nof wordlist categories that fit different needs: from general-purpose\nwordlists to backup-file wordlists, CMS-specific (Content manage-\nment system) wordlists, and even more.\nVarious automated tools are provided by default with various\nwordlists. However, many other user-created wordlists can be found\non the Internet, and users may also create ad-hoc wordlists that\nsatisfy their needs. In the scope of this research, we selected four\ngeneral-purpose wordlists to assess:\n\u2022 big_wfuzz [BW]2: a Wfuzz default general-purpose wordlist\nthat contains 3024 words.\n\u2022 top_10k_github [GH]3: a user-created wordlist in GitHub\ncontaining 10000 words, created selecting the most common\nwords found in ten million URLs.\n\u2022 megabeast_wfuzz [MW]4: another Wfuzz default general-\npurpose wordlist that contains 45459 words.\n\u2022 directory-list_dirbuster [DB]5: a Dirbuster default wordlist\ncontaining 141835 words.\n4\nMETHODOLOGY\nOverview. Traditional attacks are essentially inefficient, as they\nare based on brute-forcing mechanisms. In this work, we explore\ntwo different approaches that might improve the attack: one based\non probabilities and one using a Language Model for path gener-\nation. Given the scope of this research, which aims to be general\nand not to focus on specific technologies or sensitive information,\nboth approaches aim to highlight the feasibility of implementing\nmore efficient attacks and aim to exploit two features not used by\nthe traditional wordlist-based brute-forcing approach:\n\u2022 Prior Knowledge. Web applications that belong to similar\ncategories might have a similar structure. Given a target\nwebsite, using knowledge retrieved from similar websites\nto decide what HTTP requests to send to the target website\nmay positively impact the results.\n\u2022 Adaptive decision-making. During a directory brute-force\nattack, having the ability to dynamically decide which URLs\nto generate and which requests to send might improve the hit\nrate of successful responses and reduce ineffective requests.\nTree reconstruction. Before we discuss how traditional tools and\nour proposed approaches work, it is helpful to understand how\nHTTP requests allow us to reconstruct the filesystem of a web\napplication. Since a filesystem has a hierarchical tree structure,\nthe paths of each web application can be used to reconstruct it. In\nparticular, we used the AnyTree class in Python to reconstruct the\nfilesystems of each web application, considering as root the starting\n2https://github.com/xmendez/wfuzz/blob/master/wordlist/general/big.txt\n3https://github.com/xajkep/wordlists/blob/master/discovery/top-10k-web-\ndirectories_from_10M_urlteam_links.txt\n4https://github.com/xmendez/wfuzz/blob/master/wordlist/general/megabeast.txt\n5https://github.com/3ndG4me/KaliLists/blob/master/dirbuster/directory-list-1.0.txt\nURL usually referred to as the target. This strategy allows us to\nperform depth-level analysis and simulations of offline brute-force\nattacks so that we do not perform actual attacks on online web\napplications, thus maintaining an ethical posture that still allows\nus to obtain meaningful results.\nFor example, considering the paths \"/news\", \"/home\", \"/register\",\n\"/news/2024\", \"/news/today\" and \"/news/weather\" as the paths\nextracted from the crawl of a web application, we can visualize the\ncorresponding reconstructed tree in Figure 1.\n/\nnews\nhome \nregister\n2024\ntoday\nweather\nFigure 1: Visualization of a reconstructed tree.\n4.1\nStandard approach\nThe standard wordlist-based approach that we will use to compare\nthe results with our proposed approaches is based on two main\nstrategies: Depth-First and Breadth-First.\nDepth-First. In a directory brute-force attack, the Depth-First\napproach prioritizes the exploration of subdirectories within a dis-\ncovered directory before moving on to other directories at the same\nlevel. The algorithm initiates by sequentially sending HTTP re-\nquests using the entries in a wordlist. Upon receiving a positive\nresponse, which indicates the construction of a valid URL and,\nhence, the discovery of a valid directory, the algorithm shifts its\nfocus to brute-forcing the subdirectories of this newly discovered di-\nrectory. It exhaustively searches within these subdirectories before\nit resumes brute-forcing other directories at the same depth as the\npreviously validated one. This approach ensures a comprehensive\nsearch within each directory before moving on to the next, thereby\nmaximizing the chances of uncovering valuable information nested\ndeep within the directory structure.\nAn algorithmic representation of this approach can be visualized\nin Algorithm 1, where constructURL(URL, word) is a function\nto generate a valid URL appending a word to the path of the URL\nand isValid(response) is a function that checks if the response\nis valid.\nBreadth-First. In contrast to the previous approach, the Breadth-\nFirst approach prioritizes the exploration of directories at the same\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\nTrovato and Tobin, et al.\nAlgorithm 1 Depth-First brute-force attack Pseudocode\n1: procedure DepthFirst(\ud835\udc5f\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc48\ud835\udc45\ud835\udc3f,\ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51\ud835\udc59\ud835\udc56\ud835\udc60\ud835\udc61)\n2:\nfor each \ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51in \ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51\ud835\udc59\ud835\udc56\ud835\udc60\ud835\udc61do\n3:\n\ud835\udc62\ud835\udc5f\ud835\udc59\u2190constructURL(\ud835\udc5f\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc48\ud835\udc45\ud835\udc3f,\ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51)\n4:\n\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc5d\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc52\u2190sendHTTPrequest(\ud835\udc62\ud835\udc5f\ud835\udc59)\n5:\nif isValid(\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc5d\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc52) then\n6:\nDepthFirst(\ud835\udc62\ud835\udc5f\ud835\udc59,\ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51\ud835\udc59\ud835\udc56\ud835\udc60\ud835\udc61)\n7:\nend if\n8:\nend for\n9: end procedure\nlevel before delving into their subdirectories. The algorithm begins\nby sending HTTP requests sequentially using the wordlist entries.\nWhen it receives a positive response, indicating the formation of a\nvalid URL and, hence, the discovery of a valid directory, it continues\nto brute-force the remaining directories at the same depth. Only\nafter it has exhausted all directories at the current level does it\nproceed to brute-force the subdirectories of the discovered directo-\nries. This method ensures a thorough search across each level of\ndirectories before descending deeper into the directory structure,\nthereby maximizing the chances of uncovering valuable informa-\ntion distributed across the directories. The majority of commercial\ntools implement this approach. We also present a pseudocode im-\nplementation in Algorithm 2, using a queue to store and retrieve\nthe URLs used during the process.\nAlgorithm 2 Breadth-First brute-force attack Pseudocode\n1: procedure BreadthFirst(\ud835\udc5f\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc48\ud835\udc45\ud835\udc3f,\ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51\ud835\udc59\ud835\udc56\ud835\udc60\ud835\udc61)\n2:\n\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52\u2190new Queue()\n3:\n\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52.enqueue(\ud835\udc5f\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc48\ud835\udc45\ud835\udc3f)\n4:\nwhile \ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52is not empty do\n5:\n\ud835\udc50\ud835\udc62\ud835\udc5f\ud835\udc5f\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc48\ud835\udc45\ud835\udc3f\u2190\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52.dequeue()\n6:\nfor each \ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51in \ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51\ud835\udc59\ud835\udc56\ud835\udc60\ud835\udc61do\n7:\n\ud835\udc62\ud835\udc5f\ud835\udc59\u2190constructURL(\ud835\udc50\ud835\udc62\ud835\udc5f\ud835\udc5f\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc48\ud835\udc45\ud835\udc3f, \ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51)\n8:\n\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc5d\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc52\u2190sendHTTPrequest(\ud835\udc62\ud835\udc5f\ud835\udc59)\n9:\nif isValid(\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc5d\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc52) then\n10:\n\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc62\ud835\udc52.enqueue(\ud835\udc62\ud835\udc5f\ud835\udc59)\n11:\nend if\n12:\nend for\n13:\nend while\n14: end procedure\n4.2\nProbability-based approach\nApproach. Prior knowledge might be essential to improve the\nattack performance. The intuition is straightforward: if the majority\nof websites contain paths like login and register, it is likely that\nthe tested website contains such directories as well. An algorithm\nthat, therefore, prioritizes directories based on prior knowledge can\nbe effective.\nThe first strategy we present optimizes the depth and breadth-\nfirst strategies described in Section 4.1, where the wordlist is ordered\naccording to prior knowledge (e.g., gathered from web applications\nsimilar to the victim). This adds dynamic decisions on how to go\nabout generating the following HTTP request to maximize the num-\nber of positive requests while minimizing the number of unlikely\nand incorrect requests. The prior knowledge, or training dataset,\ncontains crawls of paths of various web applications, possibly of\nthe same category as the target where the attack will be performed.\nThe prior knowledge can be then infused into the algorithms in\ntwo possible manners:\n(1) Constructing a Weighted Training Tree. Using the same\nreasoning with which we described how it is possible to\nreconstruct a filesystem of a web application from the crawl\nof its paths, we will proceed to construct a single filesys-\ntem tree that unites all the paths that contain our training\ndataset indistinctly from the web application. Furthermore,\nthis tree will be weighted: for each new node in the tree\n(corresponding to a directory), we would maintain a counter\nindicating how many times that particular node is repeated.\nAn example of this is reported in Figure 2.\n/\nnews, \nw=12\nhome, \nw=7 \nregister, \nw=3\n2024, \nw=7\ntoday, \nw=2\nweather, \nw=1\nFigure 2: Visualization of a Weighted Training Tree, obtained\nmerging paths from a Training Dataset.\n(2) Constructing a Weighted Wordlist Tree. A weighted tree\nusing only the words from the wordlist. Starting from a\ngeneral wordlist, we construct a weighted tree similar to the\nWeighted Training Tree. However, this tree only includes\nwords from a pre-designed wordlist (e.g., big_wfuzz). The\nweight of each node (directory) in this tree is determined\nbased on the training set. For example, if we consider the\nwordlist [\"news\", \"home\", \"2024\", \"today\", \"about\"] and the\nWeighted training tree shown in Figure 2, the corresponding\nWordlist Weighted Tree can be visualized in Figure 3. Note\nthat, in this case, folders such as register and weather are\nnot included in the tree, since they are not contained in the\noriginal wordlist.\nIn this way, we can make the best use of parent-child relational\ninformation between directories and subdirectories and give weight\nto words in the wordlist critical for the adaptive selection of re-\nquests to be made. In addition, an interested pruning process takes\nplace of all those words in the wordlists that, for each directory,\nOffensive AI: Enhancing Directory Brute-forcing Attack with the Use of Language Models\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\n/\nnews, \nw=12\nhome, \nw=7 \n2024, \nw=7\ntoday, \nw=2\nFigure 3: Visualization of a Wordlist Weighted Tree, based\non a wordlist and a Weighted training tree.\nare not found to be valid subdirectories and, therefore, less likely\nthan others. The pruning of unlikely words helps, consequently, to\nminimize the number of less probable requests. To give an example\nof how pruning works, considering Figure 2 and Figure 3, we can\nsee that the word \"about\", which was initially in the wordlist from\nwhich the tree is created, is not part of the Wordlist weighted tree\n(so it has a weight of 0 as a possible subdirectory for every direc-\ntory), and \"news\" has a weight of 12 as a subdirectory of the base\nroot, but is pruned from being a child-node of \"home\".\nAlgorithm. The probabilistic approach employs a max heap (a\ndata structure that keeps the maximum element of a given property\non top of it) with tuples of base URLs, a word, and the weight\nassigned to it. The max heap keeps the tuples ordered by probability,\nso we can always pop the highest one to construct and send a\nrequest.\nThe probability of a word being a valid subdirectory of a di-\nrectory is computed dynamically by dividing the weight of the\npossible subdirectory by the sum of the weights of every possible\nsubdirectory to that directory.\nIn the beginning, given a target base URL, the algorithm will\npush in the max heap all the possible subdirectories of the root\ndirectory \"/\" retrieved from the weighted tree with the correspond-\ning probabilities. Whenever we receive a successful response, the\nalgorithm pushes all the possible subdirectories to the response\nURL with the probabilities into the heap. This mechanism allows us\nto implement an adaptive decision-making strategy to consistently\nsend the most likely HTTP request away as new subdirectories are\ndiscovered.\nAn algorithmic exemplification of this approach is presented in\nthe algorithm 3, where getWordswithWeights() returns the word-\nweight pairs taken from the specified URL in the weighted tree, and\ngetProbability() calculates the probability of a word based on\nas described previously.\nAlgorithm 3 Probabilistic brute-force attack Pseudocode\n1: procedure Probabilistic(\ud835\udc5f\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc48\ud835\udc45\ud835\udc3f,\ud835\udc64\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61\ud835\udc52\ud835\udc51\ud835\udc47\ud835\udc5f\ud835\udc52\ud835\udc52)\n2:\n\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc3b\ud835\udc52\ud835\udc4e\ud835\udc5d\u2190new MaxHeap()\n3:\n\ud835\udc5f\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc47\ud835\udc62\ud835\udc5d\ud835\udc59\ud835\udc52\ud835\udc60\n\u2190\ngetWordswithWeights\n(\ud835\udc5f\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc48\ud835\udc45\ud835\udc3f,\n\ud835\udc64\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61\ud835\udc52\ud835\udc51\ud835\udc47\ud835\udc5f\ud835\udc52\ud835\udc52)\n4:\nfor each \ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51,\ud835\udc64\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61in \ud835\udc5f\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc47\ud835\udc62\ud835\udc5d\ud835\udc59\ud835\udc52\ud835\udc60do\n5:\n\ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc4f\u2190getProbability(\ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51, \ud835\udc64\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61\ud835\udc5f\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc47\ud835\udc62\ud835\udc5d\ud835\udc59\ud835\udc52\ud835\udc60)\n6:\n\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc3b\ud835\udc52\ud835\udc4e\ud835\udc5d.push((\ud835\udc5f\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc48\ud835\udc45\ud835\udc3f, \ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51, \ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc4e\ud835\udc4f\ud835\udc56\ud835\udc59\ud835\udc56\ud835\udc61\ud835\udc66))\n7:\nend for\n8:\nwhile \ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc3b\ud835\udc52\ud835\udc4e\ud835\udc5dis not empty do\n9:\n\ud835\udc50\ud835\udc62\ud835\udc5f\ud835\udc5f\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc48\ud835\udc45\ud835\udc3f,\ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51, \ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc4f\ud835\udc4e\ud835\udc4f\ud835\udc56\ud835\udc59\ud835\udc56\ud835\udc61\ud835\udc66\u2190\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc3b\ud835\udc52\ud835\udc4e\ud835\udc5d.pop()\n10:\n\ud835\udc62\ud835\udc5f\ud835\udc59\u2190constructURL(\ud835\udc50\ud835\udc62\ud835\udc5f\ud835\udc5f\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc48\ud835\udc45\ud835\udc3f, \ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51)\n11:\n\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc5d\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc52\u2190sendHTTPrequest(\ud835\udc62\ud835\udc5f\ud835\udc59)\n12:\nif isValidURL(\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc5d\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc52) then\n13:\n\ud835\udc5b\ud835\udc52\ud835\udc64\ud835\udc47\ud835\udc62\ud835\udc5d\ud835\udc59\ud835\udc52\ud835\udc60\n\u2190\ngetWordswithWeights(\ud835\udc62\ud835\udc5f\ud835\udc59,\n\ud835\udc64\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61\ud835\udc52\ud835\udc51\ud835\udc47\ud835\udc5f\ud835\udc52\ud835\udc52)\n14:\nfor each \ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51,\ud835\udc64\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61in \ud835\udc5b\ud835\udc52\ud835\udc64\ud835\udc47\ud835\udc62\ud835\udc5d\ud835\udc59\ud835\udc52\ud835\udc60do\n15:\n\ud835\udc5b\ud835\udc52\ud835\udc64\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f\n\u2190getProbability(\ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51, \ud835\udc64\ud835\udc52\ud835\udc56\ud835\udc54\u210e\ud835\udc61\n\ud835\udc5b\ud835\udc52\ud835\udc64\ud835\udc47\ud835\udc62\ud835\udc5d\ud835\udc59\ud835\udc52\ud835\udc60)\n16:\n\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc3b\ud835\udc52\ud835\udc4e\ud835\udc5d.push((\ud835\udc62\ud835\udc5f\ud835\udc59, \ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51, \ud835\udc5b\ud835\udc52\ud835\udc64\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f))\n17:\nend for\n18:\nend if\n19:\nend while\n20: end procedure\nBecause of aggressive pruning on the wordlist tree or due to a\ntraining dataset that does not contain as much data, the possible\nrequests provided by the weighted tree will be exhausted quickly,\neven before reaching any set request budget. In light of this, when\nall potential requests derived from the existing knowledge within\nthe weighted tree have been explored, it is advisable to employ a\nconventional breadth-first strategy. This approach takes into ac-\ncount the previously successful responses, thereby mitigating the\nneed to reissue redundant HTTP requests.\n4.3\nLanguage-Model based approach\nApproach. Following the intuition of the probabilistic approach\ndescribed in Section 4.2, we design a neural network mechanism\nleveraging Language Models (see Section 2) to generate probable\nsubdirectories to a given path. Given a URL, we can consider its\npath a sequence of words separated by \"/.\" This sequence of words\ncan be fed as input to the neural network mechanism, which will\noutput the words that most likely follow the input sequence. Those\nwords can be used to construct new URLs and send new HTTP\nrequests.\nWith this method, we aim to leverage the power of customized\nembeddings (i.e., embeddings trained on the corpus), and overcome\nthe limitations of the probabilistic approach. In particular, the prob-\nabilistic approach calculates relationships among directories that\nappear in the prior knowledge. On the other hand, with the embed-\nding, the model learns the context, and therefore directories appear-\ning in a similar context will be used to generalize the attack. For\ninstance, suppose that in our prior knowledge, we have URLs such\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\nTrovato and Tobin, et al.\nas \"/account/setting/info\", \"/account/setting/password\",\n\"/account/setting/logout\", \"/profile/setting/ password\"\nand \"/profile/setting/info\": the directories account and\nprofile are utilized in a similar context, and therefore their em-\nbedding will be close. At inference time, a LM might infer the URL\n\"/profile/ setting/password\" even though this information\nwas not available in our prior knowledge. In this example, a proba-\nbility approach would have assigned 0 to this association.\nModel architecture. Leveraging language models in our architec-\nture involves using a crucial component of them: the vocabulary.\nThis component maps words in our sequences (i.e., directories) to\nunique indexes. The vocabulary allows the translation of words\ninto integer indices that the neural network architecture can pro-\ncess. To reduce the dimension of the vocabulary, only words more\nfrequent than a certain threshold are considered. Additionally, vo-\ncabulary helps the architecture understand the structure of the sen-\ntences while handling unknown words and variable-size sequences\nwith special tokens. These tokens are: UNK (Unknown word), PAD\n(Padding token, used to pad sequences to a fixed size), SOS (Start of\nsentence token, used to highlight where a sequence start) and EOS\n(End of sentence token, used to highlight where a sequence end).\nOur designed neural network architecture is primarily based\non the Long-Short-Term Memory (LSTM) network [8], a type of\nRecurrent Neural Network. Our proposed LM architecture consists\nof several key components:\n(1) Embedding Layer. The first layer of the model is an em-\nbedding layer, which transforms the input words into dense\nvectors of fixed size, defined as embedded size. Embedding\nrepresentations are learned at training time.\n(2) LSTM Layer. It follows a LSTM layer, crucial for the learning\nof patterns in sequential data. This layer takes the embed-\ndings of the input words and returns its own hidden states\nand cell states.\n(3) Dropout Layer. To prevent overfitting, dropout layers are\nused after the Embedding and LSTM layers. Dropout is a\nregularization technique that randomly sets a fraction of\ninput units to 0 with a specific frequency of rate at each step\nduring the training.\n(4) Fully Connected Layer: The LSTM outputs (hidden states)\nare then passed through a fully connected (linear) layer to\ntransform them into the desired output shape, which is the\nsize of the vocabulary.\n(5) Softmax Function: A softmax function is applied to trans-\nform the output of the fully connected layer to probabilities\nassigned to each vocabulary word.\nFigure 4 shows an overview of the architecture. Here, we can\nsee how the URL path is split into tokens and mapped into integers\nusing vocabulary. Then, after the sequence of integers is given as\ninput to the model, we observe how the softmax function takes the\noutput of the fully connected layer and assigns the probability that\nit is the next in the sequence to each number. At this point, the\nmost likely word is chosen to form a new path, but the choice can\nalso be made on any other word.\nTraining and Validation. Our architecture\u2019s training process in-\nvolves feeding it with paths and having it predict the following\ndirectory in the path. The model\u2019s predictions are compared to the\nactual following directories in the path, and a loss function is used to\nquantify the difference between the predictions and the truth. This\nloss is minimized using an optimization algorithm, which adjusts\nthe model\u2019s parameters to make its predictions more accurate.\nDuring the training phase, the model performance is periodically\nevaluated on the validation set to prevent overfitting on training\ndata. This strategy allows us to monitor the model\u2019s generalization\nability to unseen data. We utilize an early stopping mechanism to\nstop the training when the model\u2019s performance on the validation\nset starts to deteriorate (a phenomenon known as overfitting) or\ndoes not improve for \ud835\udc5depochs.\nAlgorithm. The algorithm incorporating the proposed neural\nnetwork architecture (Algorithm 4) uses a strategy similar to Algo-\nrithm 3, where a max heap is used to construct the most probable\nURL. Instead of using the wordlist weighted tree, the language\nmodel in the function predict() is used to return a number of\nword-probability pairs with a higher probability specified in the\ntopPredicts hyper-parameter.\nAlgorithm 4 Language-model based brute-force attack Pseudocode\n1: procedure LMattack(\ud835\udc5f\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc48\ud835\udc45\ud835\udc3f, \ud835\udc3f\ud835\udc40,\ud835\udc61\ud835\udc5c\ud835\udc5d\ud835\udc43\ud835\udc5f\ud835\udc52\ud835\udc51\ud835\udc56\ud835\udc50\ud835\udc61\ud835\udc60)\n2:\n\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc3b\ud835\udc52\ud835\udc4e\ud835\udc5d\u2190new MaxHeap()\n3:\n\ud835\udc5f\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc47\ud835\udc62\ud835\udc5d\ud835\udc59\ud835\udc52\ud835\udc60\u2190predict(\ud835\udc5f\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc48\ud835\udc45\ud835\udc3f, \ud835\udc3f\ud835\udc40,\ud835\udc61\ud835\udc5c\ud835\udc5d\ud835\udc43\ud835\udc5f\ud835\udc52\ud835\udc51\ud835\udc56\ud835\udc50\ud835\udc61\ud835\udc60)\n4:\nfor each \ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51, \ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc4fin \ud835\udc5f\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc47\ud835\udc62\ud835\udc5d\ud835\udc59\ud835\udc52\ud835\udc60do\n5:\n\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc3b\ud835\udc52\ud835\udc4e\ud835\udc5d.push((\ud835\udc5f\ud835\udc5c\ud835\udc5c\ud835\udc61\ud835\udc48\ud835\udc45\ud835\udc3f, \ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51, \ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc4f))\n6:\nend for\n7:\nwhile \ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc3b\ud835\udc52\ud835\udc4e\ud835\udc5dis not empty do\n8:\n\ud835\udc50\ud835\udc62\ud835\udc5f\ud835\udc5f\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc48\ud835\udc45\ud835\udc3f,\ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51, \ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc4f\u2190\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc3b\ud835\udc52\ud835\udc4e\ud835\udc5d.pop()\n9:\n\ud835\udc62\ud835\udc5f\ud835\udc59\u2190constructURL(\ud835\udc50\ud835\udc62\ud835\udc5f\ud835\udc5f\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc48\ud835\udc45\ud835\udc3f, \ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51)\n10:\n\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc5d\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc52\u2190sendHTTPrequest(\ud835\udc62\ud835\udc5f\ud835\udc59)\n11:\nif isValidURL(\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc5d\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc52) then\n12:\n\ud835\udc5b\ud835\udc52\ud835\udc64\ud835\udc47\ud835\udc62\ud835\udc5d\ud835\udc59\ud835\udc52\ud835\udc60\u2190predict(\ud835\udc62\ud835\udc5f\ud835\udc59, \ud835\udc3f\ud835\udc40,\ud835\udc61\ud835\udc5c\ud835\udc5d\ud835\udc43\ud835\udc5f\ud835\udc52\ud835\udc51\ud835\udc56\ud835\udc50\ud835\udc61\ud835\udc60)\n13:\nfor each \ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51, \ud835\udc5d\ud835\udc5f\ud835\udc5c\ud835\udc4fin \ud835\udc5b\ud835\udc52\ud835\udc64\ud835\udc47\ud835\udc62\ud835\udc5d\ud835\udc59\ud835\udc52\ud835\udc60do\n14:\n\ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc3b\ud835\udc52\ud835\udc4e\ud835\udc5d.push((\ud835\udc62\ud835\udc5f\ud835\udc59, \ud835\udc64\ud835\udc5c\ud835\udc5f\ud835\udc51, \ud835\udc5b\ud835\udc52\ud835\udc64\ud835\udc43\ud835\udc5f\ud835\udc5c\ud835\udc4f))\n15:\nend for\n16:\nend if\n17:\nend while\n18: end procedure\n5\nDATASET\nIn this section, we present the datasets collected for our experiments.\nIn particular, Section 5.1 describes the data collection process. It\nfollows Section 5.2, presenting an in-depth analysis of our data.\n5.1\nDescription\nSource of data. The data for this research is obtained from Com-\nmonCrawl 6, a non-profit organization that crawls the web and\nfreely provides its archives and datasets. CommonCrawl was se-\nlected due to its comprehensive repository of web crawls that are\nupdated regularly; we utilized CC-MAIN-2023-40 crawl version.\nThis approach not only streamlines the data collection process but\nalso aligns with ethical considerations, avoiding manual spidering\n6https://commoncrawl.org/\nOffensive AI: Enhancing Directory Brute-forcing Attack with the Use of Language Models\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\nInput path:\n\"/Today/Home\"\nToken \nsequence:\n[\"SOS\", \"UNK\", \n\"Home\", \"PAD\", \n\"PAD\" \"EOS\"]\nEncoded \nsequence:\n[0,2,4,3,3,1]\nVocabulary= { \"SOS\" : 0, \"EOS\" :1, \n\"UNK\" : 2, \"PAD\" : 3 , \"Home\" : 4 , \n\"About\" :5 , \"2024\" : 6, \"News\" :7 }\n5\n6\n7\n1\n...\n20%\n10%\n50%\n7%\n\"About\"\n\"2024\"\n\"News\"\n\"EOS\"\n...\nLanguage model\nNew URL path:\n\"/Today/Home/News\"\nFigure 4: Prediction of the next directory from our LM-based architecture.\nand crawling of websites that may be categorized as brute-force\nattacks and not overloading web servers with severe amounts of\nrequests but instead using historical data. Given the scope of the\nsearch and the multitude of data in the CommonCrawl corpus, we\ncollected the URLs from the HTTP responses. We then extracted\nthe domain, path, and response code necessary to identify invalid\nresponses.\nDatasets. Considering the increasing number of cyber attacks\nand the wide variety of possible targets, we decided to consider four\ndifferent datasets representing some most common categories of\norganizations at risk of cyber attacks. In addition, given the scope\nof the search, we maintained only websites written in English. We\nnow list the four distinct datasets we collected:\n\u2022 Universities dataset [UNI]: consisting of the HTTP responses\nfrom 100 English-based web applications of the top univer-\nsities listed in the QS 2023 World University Rankings 7.\nFurthermore, we did not consider universities without an\nEnglish version of their web application.\n\u2022 Hospitals dataset [HOS]: consisting of the HTTP responses\nbelonging to the web applications of the first USA 100 hos-\npitals listed in \"Ranking Web of World Hospitals\" 8.\n\u2022 Companies dataset [COM]: consisting of the HTTP responses\nfrom 100 corporate web applications of companies in the S&P\n500 9, choosing in order of highest capitalization (January\n2024) and avoiding companies that had e-commerce as their\nmain web application.\n\u2022 Government dataset [GOV]: consisting of the HTTP responses\nfrom 336 different USA government web applications 10.\nIn our experiments, we will report the attack performance when\nconsidering the datasets separately and together.\nPreprocessing. After extracting the domain, path, and status code\nfrom each HTTP response for each dataset, we performed addi-\ntional preprocessing steps on the data to reconstruct the hierarchical\nstructure of the file system of the Web applications, guaranteeing\ntheir integrity and enabling more consistent analysis in the datasets.\n7https://www.topuniversities.com/world-university-rankings/2023\n8https://hospitals.webometrics.info/en/americas/usa\n9https://www.slickcharts.com/sp500\n10https://www.usa.gov/agency-index\nFirstly, we applied initial filtering to the HTTP responses, preserv-\ning only the responses with a status code 200, representing most\nof the crawled responses. The HTTP status code 200 indicates that\nthe client request has succeeded. Secondly, eventual queries or files\nthat were part of the path were removed. This choice was mainly\nmade to maintain a manageable scope of analysis. URLs can often\ncontain queries or files with different extensions that introduce a\nsignificant degree of variability and are highly dependent on the\ntechnology with which the web application was developed, thus\ngoing against our intended general approach. Additionally, it is use-\nful to define the depth of a path: considering a path as a sequence\nof words (where each word corresponds to the name of a directory),\nwe define the depth as the number of words that the path consists\nof. The order matters since each directory in that path will be at a\ngiven depth (e.g.: \"/news/2023\" will have depth = 2, where \"news\"\nis at depth 1, and \"2023\" is at depth 2).\n5.2\nDatasets Analyses\nOverview. Following the data preprocessing, we analyzed the\ncharacteristics of each dataset and the similarities and differences\nbetween them, which allowed us to get a general overview of the\ndatasets and highlight what direction the test results might take.\nWe conduct the following analyses:\n\u2022 Dataset description, where we describe datasets\u2019 properties\n(e.g., quantities, distributions) and the nature of their URLs.\n\u2022 Wordlist Coverage Ratio Analysis, where we describe how\nstandard wordlists can cover the retrieved URLs.\n\u2022 Stemming Analysis, where we attempt to understand the\nimpact of small name variations in the directories (e.g., books\nand book) and wordlists coverage.\n\u2022 Dataset Similarity Analysis, where we describe the degree of\nsimilarity between directories in the four collected datasets\n(e.g., how universities and hospital URLs differ).\n5.2.1\nDataset description. We now describe the four distinct datasets\nwe retrieved. For each dataset, we analyzed the following informa-\ntion:\n\u2022 Number of domains (# Domains).\n\u2022 Number of paths in each dataset (# Paths). For instance,\nsuppose a dataset contains two web apps, each with one\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\nTrovato and Tobin, et al.\ndomain (e.g., \"domain1/login\" and \"domain2/login\"), the\nnumber of paths is two, i.e., [\"/login\", \"/login\"]).\n\u2022 The average number (and standard deviation) of paths of the\nweb apps contained in a given dataset (# paths AVG and\n# paths STD). For instance, given two web apps containing\neach 1 URLs, the average is equal to 1, and the standard\ndeviation to 0.\n\u2022 The number of unique paths in the dataset (# U-Paths). For\ninstance, suppose the dataset contains the following sam-\nples \" domain1/account/info \" and \" domain2/account/\ninfo\", the unique paths are defined as the unique directory\n[\"/account/info\"].\n\u2022 The number of directories (# Dir) contained in the dataset.\nFor instance, given \"domain1/account/info\" and \"domain2\n/account/settings\", the dataset contains four directories\n[\"account\", \"info\", \"account\", \"settings\"].\n\u2022 The number of unique directories (# U-Dir) contained in the\ndataset. For instance, given \"domain1/account/info\" and\n\"domain2/account/settings\", the dataset contains three\nunique directories [\"account\", \"info\", \"settings\"].\n\u2022 We analyze the depth of URLs in terms of average and stan-\ndard deviation (Depth AVG and Depth STD). For instance,\nthe URL \"domain1/account/info\" has a depth equal to two.\nHypothesizing that a directory with greater depth is likely\nto be more specialized and, consequently, less common, ana-\nlyzing depth distribution might provide insight into a web\napplication\u2019s granularity and structure.\n\u2022 The average depth and standard deviation of URLs similari-\nties in a given dataset (Sim AVG and Sim STD). In more detail,\nthis metric computes the similarity for each pair of websites\nin each dataset. By defining a website as a set of its own\ndirectories (computed by the retrieved URLs), the similarity\nbetween two websites can be computed using the Jaccard\nSimilarity, defined in Equation 6. This metric is defined be-\ntween 0 and 1, where 0 means that two sets are distinct,\nwhile one means identical.\n\ud835\udc3d(\ud835\udc34, \ud835\udc35) = |\ud835\udc34\u2229\ud835\udc35|\n|\ud835\udc34\u222a\ud835\udc35| .\n(6)\nTable 1 shows the statistics for each dataset.\nDiscussions. It is interesting to observe that websites have differ-\nent structures in terms of number of pages. For instance, universities\nand hospitals tend to have a bigger number of pages (# Path AVG)\ncompared to companies and governments. From a depth perspec-\ntive, university and company websites tend to have deeper web\napp structures compared to hospitals and government. Last, the\nsimilarity analysis clearly shows that websites in the same dataset\ntend to have different types of directories, and the average Jaccard\nsimilarity tends to zero. By considering these statistics together, we\ncan clearly remark why directory enumeration is not trivial, and it\nmight require an enormous amount of requests for a small number\nof hits (i.e., discovered directories).\n5.2.2\nWordlists Coverage Ratio Analysis. By analyzing the coverage\nof the different wordlists on the web applications in each dataset,\nshown in Figure 5, we can see that a low percentage of words are\nfound even at low depths where we would expect them to be more\ncommon and thus present in the wordlist.\nDataset\nfeatures\nUNI\nHOS\nCOM\nGOV\n# Domains\n88\n80\n97\n336\n# Paths\n209657\n211911\n147198\n520571\n# Paths AVG\n2301\n2584\n1479\n1507\n# Paths STD\n2906\n2800\n2360\n2340\n# U-Paths\n201768\n205587\n143067\n502693\n# Dir\n203613\n209945\n143620\n512595\n# U-Dir\n171215\n173394\n106097\n462812\nDepth AVG\n4.11\n3.31\n4.43\n3.40\nDepth STD\n1.69\n1.72\n2.23\n1.66\nSim AVG\n0.022\n0.019\n0.016\n0.016\nSim STD\n0.031\n0.017\n0.023\n0.024\nTable 1: Summary statistics for the four datasets: universities\n[UNI], hospitals [HOS], companies [COM], and government\n[GOV].\nThe coverage ratio across the different datasets shows consid-\nerable variance but overall low values, highlighting how directory\nbrute-force attacks using these wordlists could potentially miss\nmultiple valid requests.\nAlthough the coverage ratio shows an upward trend as depth\nincreases, it is essential to emphasize that although the higher-\ndepth words might be more specific, their number is significantly\nreduced (as highlighted by the depth distribution analyzed earlier).\nIn addition, the most critical point concerns the poor coverage of\nthe initial words, which form the basis of most pathways: higher-\ndepth directories will not be explored if antecedent ones are not\nexplored.\nStemming Analysis. Stemming is a linguistic process that sim-\nplifies words to their base or root form, known as the stem, often\nby removing common prefixes or suffixes. For example, stemming\nremoves plural (dogs \u2212\n\u2192dog), -ing form (running \u2212\n\u2192run), etc. In\nour study, we employed the Porter-Stemmer [4] algorithm to ana-\nlyze the effect of stemming on the total number of unique words\nwithin our datasets. In our analysis, we found a few instances of\nhow a root form represents minimal variations of the same word,\nhighlighting different conventions or singular and plural forms. A\npair of examples are:\n(1) \"articl\" corresponding to \"article\" in 33.5% of cases, \"articles\"\nin 14.4%, \"Article\" in 47.3%, \"Articles\" in 4.7%, and \"ARTICLE\"\nin 0.01%.\n(2) \"project\" corresponding to \"project\" in 46.78% of cases , \"projects\"\nin 53.13, \"Projected\" in 0.04% and \"Projects\" in 0.04%.\nHowever, these represent only a minority of cases, as most root\nforms correspond to only one word, and the percentage reduction\nin the datasets remains marginal, as shown in Table 2. These sta-\ntistics highlight how the words that make up our directory list\ndiffer (although some words have various declinations) and how\nthat should be taken into account when designing new, improved\napproaches.\nSimilarity Analysis. Last, we measure the similarity between any\npair of the collected dataset. We utilize two metrics: the Jaccard\nOffensive AI: Enhancing Directory Brute-forcing Attack with the Use of Language Models\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\n2\n4\n6\n8\n10\nDepth\n0.0\n0.1\n0.2\n0.3\n0.4\nCoverage Ratio\nMW\nBW\nDB\nGH\n(a) University.\n2\n4\n6\n8\n10\nDepth\n0.0\n0.1\n0.2\n0.3\n0.4\nCoverage Ratio\nMW\nBW\nDB\nGH\n(b) Hospital.\n2\n4\n6\n8\n10\nDepth\n0.0\n0.1\n0.2\n0.3\n0.4\nCoverage Ratio\nMW\nBW\nDB\nGH\n(c) Company.\n2\n4\n6\n8\n10\nDepth\n0.0\n0.1\n0.2\n0.3\n0.4\nCoverage Ratio\nMW\nBW\nDB\nGH\n(d) Government.\nFigure 5: Coverage analysis at the varying of the four datasets and four wordlists: ADD.\nDataset\nfeatures\nUNI\nHOS\nCOM\nGOV\n# U-Dir\n171215\n173394\n106097\n462812\n# U-Root\n168462\n171371\n104220\n457912\nReduction\n2753\n2023\n1877\n4900\nReduction (%)\n1.61%\n1.17%\n1.77%\n1.06%\nTable 2: Summary statistics after the STEMMING for the\nfour datasets: universities [UNI], hospitals [HOS], companies\n[COM], and government [GOV].\nsimilarity of each dataset wordlist, and the number of paths in com-\nmon (relative number) between the datasets. Figure 6 shows the\nresults. The first clear outcome is highlighted by the low Jaccard\nsimilarities: each dataset contains different directories. In other\nwords, how websites of universities have almost completely dif-\nferent structures compared to hospital ones. This reasoning can\nbe applied to any pair of datasets we utilized. A second interest-\ning outcome is given by the relative count of common directories\namong different datasets. For instance, government and company\nwebsites contain many common paths. Considering the number of\nunique directories shown in Table 1, it is clear that it is non trivial\nto design an effective directory enumeration brute-force attack.\n6\nRESULTS\n6.1\nExperimental Settings\nTestbed. To set up our brute-force directory attack simulations,\nwe partitioned the datasets into distinct sets for training, validation,\nand testing. We train our proposed approaches (i.e., probabilistic\nand LM-based) in a training set that merges the four presented\nin Section 5.1. Merging the four data sources for the training is\nessential to have a sufficient number of samples to train a LM with.\nWe, therefore, merge the four datasets and divide them into training,\nvalidation, and testing sets with a 70-10-20 split ratio, as mentioned\nin Section 4.3. Note that the split is not random in terms of URLs,\nbut from a domain perspective. In this way, all URLs of a given\nwebsite will appear only in training, validation, or testing set. With\nthis approach, we avoid any data snooping [3].\nRegarding the testing environment, we opted to simulate brute-\nforce attacks offline, utilizing the virtual filesystems reconstructed\nfrom the test applications. This approach permits executing multi-\nple attack simulations using different strategies without actualizing\nUNI\nHOS\nCOM\nGOV\nUNI\nHOS\nCOM\nGOV\n0.013\n0.009\n0.008\n0.012\n0.009\n0.008\n(a)\nJaccard\nsimilarities\nbetween\ndatasets\nwordlist.\nUNI\nHOS\nCOM\nGOV\nUNI\nHOS\nCOM\nGOV\n947\n662\n883\n1792\n2235\n3531\n(b) Number of common paths.\nFigure 6: Similarity analysis for the four dataset: universities\n[UNI], hospitals [HOS], companies [COM], and government\n[GOV].\nreal-time brute-force attacks on live web applications. Furthermore,\nthis approach allows us to work with a high number of simulated\nrequests without introducing latency due to the HTTP requests.\nAdditionally, aligning with our objective to maximize successful\nresponses while minimizing request volume, we established a maxi-\nmum budget of 100,000 requests spendable by each simulated attack\nbefore termination.\nLM validation. We utilize PyTorch [14] to design our architecture.\nLM uses the training set to learn meaningful association, while the\nvalidation set is utilized to select the best LM hyperparameters.\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\nTrovato and Tobin, et al.\nFor the model selection, we use a grid-search validation over the\nfollowing hyper-parameters.\n\u2022 Data representation. We identify hyper-parameters that con-\ntrols the training input: the maximum length of the paths\nutilized in the training phase and the minimum frequency\nthat a directory must have not to be discarded and marked as\n\"Unknown.\" For the former, defined as max_depth, we chose\nvalues [5, 10], while for the latter, defined as min_freq, we\nchose [3, 5].\n\u2022 LM architecture. embedding_size [ES] = [128, 256, 512],\nn_layers [NL] (number of layers in the LSTM) = [2, 3, 4],\ndropout_rate [DR]=[0.2, 0.4, 0.6].\nAn early stopping mechanism is set with patience equal to 10 epochs.\nThe learning phase uses Adam [10] as optimizer, and CrossEntropy\nas loss function. Finally, the best model is chosen based on the lower\nloss at the validation set.\nIn addition, we tested an additional parameter, namely the num-\nber of predictions to be considered whenever a positive response\nis received during the attack and new predictions are made. The\nparameter, defined as topPredicts in Algorithm 4, is tested with\nthe values [100, 250, 500, 750, 1000, 2000, 5000, 10000].\nEvaluation Metric. We utilize the following evaluation metrics:\n\u2022 Average Successful Response Rate, consisting of averaging the\ntotal amount of successfully discovered directories for each\ntested website.\n\u2022 Bins efficiency, consisting of averaging the total amount of\nsuccessfully discovered directories for each tested website\nin a given range of requests. We evaluate the following bins:\n0-100, 101-1000, 1001-10000, 10001-50000, and 50001-100000.\nWe did not consider execution times as they depend on various\nfactors (such as the number of threads used in the attack and time\nbetween request and response variable for each application) and\nare not quantifiable with offline simulations.\n6.2\nResults\nOverview. Table 3 shows the overall results obtained in our ex-\nperiments, at the varying of the dataset, wordlists, and inference\ntechniques. LM-based attack outperforms all the other baselines\nin all datasets, demonstrating the superiority of language mod-\nels compared to naive techniques like brute-force or probabilistic\napproaches. Interestingly, LM\u2019s performances are not equally bal-\nanced on all datasets: for instance, LM struggles with university\nand company websites, while being robust with hospital and gov-\nernment ones. The probabilistic-based approach further shows a\ngood improvement over brute-force attacks since, with a limited\nbudget, the latter might not be able to fully assess all the possibil-\nities. On the other hand, probabilistic approaches, by optimizing\nthe priorities of the requests, are more efficient.\nBins efficiency. The efficiency analysis provides another interest-\ning perspective on how different approaches perform. We analyze\nthe efficiency shown in Figure 7, calculated by considering sim-\nulations on the general test dataset ([ALL]) and on the wordlist\nbig_wfuzz.\nAlthough the mean results obtained using the breadth, depth,\nand probabilistic approaches are the same, the efficiency varies\nWordlist\nDataset\nUNI\nHOS\nCOM\nGOV\nALL\nBreadth\nbig_wfuzz\n28.0\n22.0\n27.0\n35.0\n35.0\ndirectory-list_dirbuster\n8.0\n10.3\n9.6\n11.8\n10.5\nmegabeast_wfuzz\n10.5\n11.6\n11.0\n12.4\n11.7\ntop_10k_github\n21.3\n42.6\n26.8\n27.0\n28.6\nDepth\nbig_wfuzz\n28.0\n22.0\n27.0\n33.0\n33.0\ndirectory-list_dirbuster\n0.5\n0.5\n0.7\n0.4\n0.5\nmegabeast_wfuzz\n2.6\n2.9\n2.7\n2.7\n2.7\ntop_10k_github\n10.1\n10.1\n10.1\n10.0\n10.1\nProbability\nbig_wfuzz\n28.0\n22.0\n27.0\n34.5\n34.5\ndirectory-list_dirbuster\n14.0\n13.1\n11.1\n17.3\n25.4\nmegabeast_wfuzz\n12.5\n13.9\n11.8\n13.8\n13.8\ntop_10k_github\n23.4\n42.9\n26.1\n27.1\n26.7\ntrain-set\n31.9\n60.4\n27.6\n30.8\n42.5\nLM\ntrain-set\n90.0\n175.0\n89.0\n128.0\n175.0\nTable 3: Average successful responses for each approach\nachieved for different test-sets at the varying of the datasets.\nIn bold the best results.\nconsiderably. The probabilistic approach performs very well in\ninitial requests and then declines as requests increase. Although\nthe language model approach registers a 400% increase in average\nsuccessful responses, it performs worse in initial requests than the\nprobabilistic approach but is more efficient in the long run. This\nbehaviour between the two is also observable in the other cases.\nTherefore, adopting a probabilistic approach might be ideal when\nthe budget is more limited.\nFigure 7: Mean Efficiency Ratio of the four approaches on\ndifferent bins, considering wordlist = big_wfuzz and the gen-\neral dataset.\nOffensive AI: Enhancing Directory Brute-forcing Attack with the Use of Language Models\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\n6.3\nDiscussion\nThe impact of topPredicts. Algorithm 4 relies on many hyper-\nparameters, such as topPredicts. It controls the number of most\nlikely predictions to be considered in each new folder found. We\nanalyze how the best LM found changes its performance at the\nvarying of this setting. In particular, we explore the following: 100,\n250, 500, 750, 1000, 2000, 5000, and 10000. As shown in Figure 8,\nas the number of predictions considered increases, the average\nnumber of successful responses received in the attack simulations\ndecreases. In addition, although with a smaller topPredicts the\ninitial average number of successful responses received is better, the\nsimulations end earlier as they have no more new predictions with\nwhich to send new requests. It is, therefore, essential to consider a\nvalue for this parameter that maximizes the results and utilizes the\nentire predetermined request budget. Therefore, it might be ideal\nto set topPredicts to a small number if our budget is limited, as\nthe model reaches the most successful responses in a short time.\nOn the opposite, larger numbers like 500, 750, and 1000 are ideal\nwhen the budget allows an exhaustive search.\nFigure 8: Evolution of average successful responses for dif-\nferent topPredicts values\nResults analysis. The two proposed approaches show substantial\nimprovements in both metrics examined. Of the two standard ap-\nproaches, the breadth-first strategy (also implemented by com-\nmercial tools) emerges as the best.\nThe probabilistic approach improves the performance of the\nbreadth-first approach in 65% of the cases considering the four\ndefault wordlists, while in the remaining, it obtains equal or slightly\nlower results. Depth-first approaches are outperformed in 100% of\nthe cases. In particular, if we consider the breadth-first approach,\nthe probability-based approach using the train-set wordlist has the\nfollowing average improvements: University +141%, hospital +281%,\ncompanies +85%, government +78%, and ALL +159%.\nThe strength of this approach is the efficiency of successful\nresponses received using few requests, which outperforms all other\napproaches considerably.\nThe Language-based approach outperforms the standard ap-\nproach in 100% of the simulations. The LM-based model approach\nhas the following average improvements over the breadth-first\nbaselines: University +582%, hospital +1004%, companies +499%,\ngovernment +639%, and ALL +969%.\nEmbeddings similarity. The ability of embeddings to extract con-\ntext from web application paths and generalize is essential to predict\nvalid directories and URLs. The results, especially in simulations on\ngeneral test sets, highlight how the Language model approach suc-\ncessfully uses the context extrapolated from embeddings to achieve\nsignificantly better results than the other approaches.\nWe can observe this by reporting two examples: given two di-\nrectories, we use the Cosine similarity to measure the top 10 words\nmost similar directories, which should belong to a similar context:\n(1) article: (\u2019stories\u2019, 0.48), (\u2019academics\u2019, 0.43), (\u2019press-release\u2019,\n0.39), (\u2019press-releases\u2019, 0.38), (\u2019video\u2019, 0.32), (\u2019authors\u2019, 0.32),\n(\u2019spotlight\u2019, 0.32), (\u2019articles\u2019, 0.31), (\u2019case\u2019, 0.3), (\u2019impact\u2019, 0.29)\n(2) about: (\u2019locations\u2019, 0.79), (\u2019about-us\u2019, 0.75), (\u2019research\u2019, 0.75),\n(\u2019programs\u2019, 0.74), (\u2019conditions\u2019, 0.7), (\u2019services\u2019, 0.68), (\u2019re-\nsources\u2019, 0.68), (\u2019alumni\u2019, 0.68), (\u2019careers\u2019, 0.67), (\u2019contact\u2019,\n0.66)\nIn both cases, we can see that the words determined similarly by the\nembeddings represent the same word but slightly different, such as\n\u2019about\u2019 with \u2019about-us\u2019 or \u2019article\u2019 with \u2019articles\u2019. In addition,\nwe find other words that relate to the context created by the word\nunder consideration, such as \u2019authors\u2019 or \u2019stories\u2019 for \u2019article.\nThis outcome confirms the superiority of LM in generalizing the\nobserved pattern at training time.\nExamples of LM Patterns. The high average number of successful\nresponses obtained from the LM-based approach testifies to the\nmodel\u2019s ability to predict valid directories that follow recurring pat-\nterns. For example, let us examine the Language model\u2019s predictions\non two different URLs:\n(1) URL: /campus-life-events/calendar. Among the top 10 direc-\ntories predicted with this URL, we have [\u201905\u2019, \u201906\u2019, \u201908\u2019, \u201911\u2019,\n\u2019may\u2019, jun\u2019], which refer to days or months of a calendar.\n(2) URL: /media. Among the top directories predicted with this\nURL, we have [\u2019press-releases\u2019, \u2019news\u2019] that are found in\nmultiple paths in the training dataset and that refer to a\nsimilar context.\n7\nRELATED WORK\nThe emergence of offensive AI in cybersecurity presents a new\nfrontier where artificial intelligence (AI) is leveraged to create so-\nphisticated and automated attacks and enhance the penetration\ntesting process [9, 12]. These attacks represent a new landscape\nthat poses significant challenges and opportunities in cybersecurity,\nespecially with the raising of LLMs and generative AI.\nThe use of generative AI to enhance directory brute-forcing at-\ntacks has yet to be explored. The closest attempt is presented by He\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\nTrovato and Tobin, et al.\net al. [7], where the authors proposed an attack to medical systems\nby adopting semantic clustering of sentences. No much information\nare reported in terms of data, methodology, and results. Similarly,\nAntonelly et al. [2] presented an innovative approach using the\nUniversal Sentence Encoder (USE) for semantic analysis. The K-\nmeans algorithm and the elbow method were used for clustering to\noptimize directory brute-forcing (dirbusting), with an improvement\nin the results of up to 50% on only eight web applications tested.\nSeveral other studies have analyzed the threat that offensive\nAI poses to organizations in other types of attacks. Bontrager et\nal. [5] demonstrated the potential of AI-generated fingerprint deep-\nfakes to compromise biometric systems through dictionary attacks,\nhighlighting the vulnerability of such systems to sophisticated AI\ntechniques. Al-Hababi et al. [1] investigated man-in-the-middle at-\ntacks leveraging machine learning to identify services in encrypted\nnetwork flows. Li et al. [11] presented a generative adversarial net-\nwork designed to evade PDF malware classifiers, illustrating the\nease with which AI can bypass traditional cybersecurity defences.\nNam et al. [13] developed a recurrent GANs-based password cracker\naimed at enhancing IoT password security. While intended for de-\nfensive purposes, the study also signifies how AI can be repurposed\nfor offensive operations.\n8\nCONCLUSIONS\nCurrent directory brute-forcing attacks are notoriously inefficient\nsince they rely on brute-forcing strategies, resulting in an enor-\nmous amount of queries for a few successful discoveries. In this\nwork, we investigated whether the utilization of prior knowledge\nmight result in more efficient attacks. We propose two distinct\nmethods that rely on prior knowledge: a probabilistic model and\na Language Model-based attack. We then experimented with our\nproposed methodology in a dataset containing more than 1 million\nURLs, spanning across distinct web app domains such as universi-\nties, hospitals, companies, and government. Our results show the\nsuperiority of the proposed method, with the LM-based approach\noutperforming brute-force-based approaches in all scenarios (an\naverage performance increase of 969%). Furthermore, the simple\nprobabilistic approach results effective when the budget of requests\nis limited (below 100, for stealthier attacks).\nThe research presented in this paper lays the groundwork for\nseveral promising directions for future investigation. The use of\nArtificial Intelligence to create sophisticated attacks is a topic that is\nconstantly evolving and growing in cybersecurity, especially with\nthe fast development of Language models.\nAdvanced Language Models. Future work could explore improve-\nments of our LM-based architecture, such as attention mecha-\nnisms [18], or even Large Language Models [6]. These models\u2019\nenhanced understanding of context and semantics could signifi-\ncantly refine the process of predicting web application structures.\nCross-Lingual Contextualization. Given that directory predic-\ntions can be constrained by the language in which a web appli-\ncation is developed, there is potential for leveraging pre-trained\nembeddings to understand the context better. This understanding\ncould then be transposed to other languages, maintaining the same\ncontextual relevance.\nVulnerability-Specific Language Model. Additionally, a path that\nmay be explored is the development of a language model trained ex-\nplicitly on paths and files commonly associated with vulnerabilities.\nBy focusing on these critical areas, the model could help preemp-\ntively identify potential security risks, thereby contributing to more\nproactive cybersecurity measures and showing the feasibility of\nsuch attacks.\nThese areas of future work offer the potential to significantly\nimpact the development of more secure web environments and\npose new security challenges to language model usage.\nREFERENCES\n[1] Abdulrahman Al-Hababi and Sezer C Tokgoz. 2020. Man-in-the-middle attacks to\ndetect and identify services in encrypted network flows using machine learning.\nIn 2020 3rd International Conference on Advanced Communication Technologies\nand Networking (CommNet). IEEE, 1\u20135.\n[2] Diego Antonelli, Roberta Cascella, Gaetano Perrone, Simon Pietro Romano, and\nAntonio Schiano. 2021. Leveraging AI to optimize website structure discovery\nduring Penetration Testing. arXiv:2101.07223 [cs.CR]\n[3] Daniel Arp, Erwin Quiring, Feargus Pendlebury, Alexander Warnecke, Fabio\nPierazzi, Christian Wressnegger, Lorenzo Cavallaro, and Konrad Rieck. 2022. Dos\nand don\u2019ts of machine learning in computer security. In 31st USENIX Security\nSymposium (USENIX Security 22). 3971\u20133988.\n[4] Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural language processing\nwith Python: analyzing text with the natural language toolkit. \" O\u2019Reilly Media,\nInc.\".\n[5] Philip Bontrager, Aditi Roy, Julian Togelius, Nasir Memon, and Arun Ross. 2018.\nDeepmasterprints: Generating masterprints for dictionary attacks via latent\nvariable evolution. In 2018 IEEE 9th International Conference on Biometrics Theory,\nApplications and Systems (BTAS). IEEE, 1\u20139.\n[6] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao\nChen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et al. 2023. A survey on\nevaluation of large language models. ACM Transactions on Intelligent Systems\nand Technology (2023).\n[7] Ying He, Cunjin Luo, Jiyuan Zheng, Kuanquan Wang, and Henggui Zhang. 2022.\nAI Based Directory Discovery Attack and Prevention of the Medical Systems. In\n2022 Computing in Cardiology (CinC), Vol. 498. IEEE, 1\u20134.\n[8] Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural\ncomputation 9, 8 (1997), 1735\u20131780.\n[9] Nektaria Kaloudi and Jingyue Li. 2020. The ai-based cyber threat landscape: A\nsurvey. ACM Computing Surveys (CSUR) 53, 1 (2020), 1\u201334.\n[10] Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Opti-\nmization. In 3rd International Conference on Learning Representations, ICLR 2015,\nSan Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, Yoshua Bengio\nand Yann LeCun (Eds.). http://arxiv.org/abs/1412.6980\n[11] Yuanzhang Li, Yaxiao Wang, Ye Wang, Lishan Ke, and Yu-an Tan. 2020. A\nfeature-vector generative adversarial network for evading PDF malware classi-\nfiers. Information Sciences 523 (2020), 38\u201348.\n[12] Yisroel Mirsky, Ambra Demontis, Jaidip Kotak, Ram Shankar, Deng Gelei, Liu\nYang, Xiangyu Zhang, Maura Pintor, Wenke Lee, Yuval Elovici, et al. 2023. The\nthreat of offensive ai to organizations. Computers & Security 124 (2023), 103006.\n[13] Sungyup Nam, Seungho Jeon, Hongkyo Kim, and Jongsub Moon. 2020. Recurrent\ngans password cracker for iot password security enhancement. Sensors 20, 11\n(2020), 3106.\n[14] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory\nChanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban\nDesmaison, Andreas K\u00f6pf, Edward Yang, Zach DeVito, Martin Raison, Alykhan\nTejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith\nChintala. 2019. PyTorch: an imperative style, high-performance deep learning\nlibrary. Curran Associates Inc.\n[15] Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove:\nGlobal vectors for word representation. In Proceedings of the 2014 conference on\nempirical methods in natural language processing (EMNLP). 1532\u20131543.\n[16] Fabio Petroni, Tim Rockt\u00e4schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin,\nYuxiang Wu, and Alexander Miller. 2019. Language Models as Knowledge Bases?.\nIn Proceedings of the 2019 Conference on Empirical Methods in Natural Language\nProcessing and the 9th International Joint Conference on Natural Language Pro-\ncessing (EMNLP-IJCNLP), Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan\n(Eds.). Association for Computational Linguistics, Hong Kong, China, 2463\u20132473.\nhttps://doi.org/10.18653/v1/D19-1250\n[17] Tobias Schnabel, Igor Labutov, David Mimno, and Thorsten Joachims. 2015.\nEvaluation methods for unsupervised word embeddings. In Proceedings of the\n2015 conference on empirical methods in natural language processing. 298\u2013307.\nOffensive AI: Enhancing Directory Brute-forcing Attack with the Use of Language Models\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\n[18] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\nAidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. Advances in neural information processing systems 30 (2017).\n", "metadata": {"Published": "2024-04-22", "Title": "Offensive AI: Enhancing Directory Brute-forcing Attack with the Use of Language Models", "Authors": "Alberto Castagnaro, Mauro Conti, Luca Pajola", "Summary": "Web Vulnerability Assessment and Penetration Testing (Web VAPT) is a\ncomprehensive cybersecurity process that uncovers a range of vulnerabilities\nwhich, if exploited, could compromise the integrity of web applications. In a\nVAPT, it is common to perform a \\textit{Directory brute-forcing Attack}, aiming\nat the identification of accessible directories of a target website. Current\ncommercial solutions are inefficient as they are based on brute-forcing\nstrategies that use wordlists, resulting in enormous quantities of trials for a\nsmall amount of success. Offensive AI is a recent paradigm that integrates\nAI-based technologies in cyber attacks. In this work, we explore whether AI can\nenhance the directory enumeration process and propose a novel Language\nModel-based framework. Our experiments -- conducted in a testbed consisting of\n1 million URLs from different web application domains (universities, hospitals,\ngovernment, companies) -- demonstrate the superiority of the LM-based attack,\nwith an average performance increase of 969%.", "entry_id": "http://arxiv.org/abs/2404.14138v1", "published_first_time": "2024-04-22", "comment": "Under submission", "journal_ref": null, "doi": null, "primary_category": "cs.CR", "categories": ["cs.CR"], "links": ["http://arxiv.org/abs/2404.14138v1", "http://arxiv.org/pdf/2404.14138v1"]}, "type": "Document"}
{"page_content": "Data Value in Distribution System Operations\nMehrnoush Ghazanfariharandi and Robert Mieth\nAbstract\u2014The rise of advanced data technologies in electric\npower distribution systems enables operators to optimize oper-\nations but raises concerns about data security and consumer\nprivacy. Resulting data protection mechanisms that alter or\nobfuscate datasets may invalidate the efficacy of data-driven\ndecision-support tools and impact the value of these datasets\nto the decision-maker. This paper derives tools for distribution\nsystem operators to enrich data-driven operative decisions with\ninformation on data quality and, simultaneously, assess data\nusefulness in the context of this decision. To this end, we derive\nan AC optimal power flow model for radial distribution systems\nwith data-informed stochastic parameters that internalize a data\nquality metric. We derive a tractable reformulation and discuss\nthe marginal sensitivity of the optimal solution as a proxy for\ndata value. Our model can capture clustered data provision,\ne.g., from resource aggregators, and internalize individual data\nquality information from each data provider. We use the IEEE\n33-bus test system, examining scenarios with varying photovoltaic\npenetration, to demonstrate the application of our approach and\ndiscuss the relationship between data quality and its value.\nI. INTRODUCTION\nE\nNHANCED visibility of electrical distribution grids en-\nabled by modern data collection and communication\ntechnology facilitates sophisticated operational strategies for\ndistribution system operators (DSOs). Specifically, the avail-\nability of high-resolution voltage and current data in conjunc-\ntion with an increased deployment of controllable distributed\nresources enables DSOs to guide system operations towards\nachieving safe and efficient optimal power flow (OPF) solu-\ntions [1]. However, the collection of this data can compromise\nthe privacy of electricity consumers [2]. Resulting privacy\nconcerns towards digital data collection and smart meters can\npose significant adoption barriers for data sharing technology\nin distribution systems and, as a result, delay the integration\nof renewable and distributed energy resources [3], [4]. The\nongoing push to utilize data for system operations while pro-\ntecting individual data privacy and data integrity has motivated\nthe development of data obfuscation methods that balance\ndata usefulness and privacy protection [2], [5]. However,\ndealing with obfuscated data and assessing its usefulness for\nDSOs is complicated by the complexity of decision-making\nprocesses influenced by power flow physics. As a result, tools\nfor quantifying data value and informing investments in data\nacquisition are lacking. Motivated by this gap, this paper\npresents a direct data-valuation approach for data-driven active\ndistribution system management. Building on a data quality\nmetric introduced in [6], we derive a stochastic AC OPF\nformulation that internalizes information of data integrity from\nvarious sources (e.g., aggregators) and use the results to obtain\nsituation- and location-aware data value proxies.\nPrompted by the need to deal with increasing levels of un-\ncertainty, mainly from uncontrollable high-wattage grid-edge\nresources such as rooftop solar, residential battery systems,\nand EV charging, various stochastic decision-support tools\nhave been proposed for distribution systems [1], [7]\u2013[9] and\npower systems in general [10]. These approaches rely on data,\ne.g., of historic observations, to estimate the distribution of\nthe underlying uncertainty [1], [9] or directly pursue a data-\ndriven approach that uses observed or sampled data points\n[7], [8]. While the effectiveness of these methods has been\ndemonstrated, the role of the data as a central input to the\nproblem remains overlooked.\nMost proposals, e.g., as in [1], [7]\u2013[9], assume that the\nnecessary data streams are readily accessible at no cost. Yet,\nthe acquisition and dissemination of data can incur expenses,\neither directly from data storage, processing, and transmis-\nsion [11], or indirectly from privacy loss [12], which may\ncall for compensation or incentive payments to data owners\n[13]. If data owners can quantify the cost of sharing data,\nauction mechanisms and optimal data allocation algorithms,\ne.g., based on Shapely Value computations, have been shown\nto deliver interpretable economic insights [14], [15]. While\nsuch market-based approaches have been proposed for power\nsystem applications [13], [16]\u2013[18], they require a bidding\nprocess managed by a third-party entity and a preliminary\nassessment of data cost.\nIn the context of distribution system operations, typical data\nowners are electricity consumers that are often required to\nshare data through contractual agreements, e.g., with their\nmetering service provider or an aggregator of distributed\nresources. However, because this data encodes sensitive private\ninformation [19], many local regulators enforce prudent data\nprotection laws that restrict or completely prohibit the general\nuse or sharing of this data [20], [21]. To unlock the benefits of\ndata-driven operational processes, data protection mechanisms\nbased on algorithmic obfuscation [2] or differential privacy\n[22], [23] have been studied and can be expected to become a\ncentral enabler to digitalized data-driven DSOs [5]. Naturally,\ndata obfuscation such as differential privacy alter the data and\nimpact any downstream decision processes that use this data.\nMotivated by these developments, this paper develops a\ndata-driven AC optimal power flow (AC OPF) formulation for\ndistribution system operations under uncertainty that (i) inter-\nnalizes information on potential data obfuscation or alteration\nrelative to the original data source and (ii) directly computes\na proxy for data value based on those alterations. We build on\nthe results from [6] to accommodate multidimensional datasets\nthat provide information on sets of uncertain parameters, e.g.,\ncollected by an aggregator. As a result, this paper enables an\nadditonal layer of flexibility in data sourcing and utilization\nand offers a tool to measure data usefulness depending on\noperation context (e.g., rooftop solar penetration) and the\nintensity of data alteration. Relative to [6], this paper presents\narXiv:2406.13148v1  [math.OC]  19 Jun 2024\nan AC OPF formulation, a higher-fidelity model of technical\nconstraints tailored to distribution system operations, and\nintroduces a formulation that allows to model the case of\na single data provider supplying data for multiple uncertain\nfeatures with a joint data quality level. We demonstrate our\napproach with numerical case studies for low and high PV\ndeployment scenarios.\nII. DATA-DRIVEN SYSTEM OPERATIONS\nWe first formulate a data-driven AC OPF model for distri-\nbution system operations under uncertainty along the lines of\n[7]. We refer to Table I for an overview of the main symbols\nand notations.\nA. Problem formulation\nWe take the perspective of a DSO who solves an OPF prob-\nlem for a distribution network with N nodes indexed by n =\n1, ..., N. For given active and reactive load pl = [pl,1, ..., pl,N],\nql = [ql,1, ..., ql,N] and maximum available renewable energy\nsource (RES) injections pav = [pav,1, ..., pav,N], the OPF\ncomputes optimal setpoints \u03b1 = [\u03b11, ..., \u03b1n], and qc =\n[qc,1, ..., qc,N] of RES inverters and schedules controllable\nDERs pB = [pB,1, ..., pB,N] and qB = [qB,1, ..., qB,N].\nFor each inverter at bus n, \u03b1n \u2208[0, 1] controls the active\npower output and denotes the fraction of curtailed available\npower pav,n. The same inverter can supply reactive power qc,n\nlimited by its apparent power rating Sn such that:\n((1 \u2212\u03b1n)pav,n)2 + q2\nc,n \u2264S2\nn.\n(1)\nThe objective of the DSO is to minimize a cost function\nC (e.g., minimizing energy payments or minimizing power\nlosses), while ensuring compliance with system voltage limits\nVmax, Vmin. We collect the nodal voltage magnitudes in\nvector \u03c1 := [v1, ..., vN] \u2208RN and leverage an approximate\nlinear relationship between voltage magnitudes and active and\nreactive nodal power injections as:\n\u03c1 \u2248Rp + Bq + a.\n(2)\nThere exist various effective methods in the literature to\ncompute the parameters of R, B, and a [7]. For this paper\nwe rely on the established LinDistFlow model [24] for radial\nnetworks. In this power flow model \u03c1, in fact, represents the\nsquare of the voltage magnitudes. However, we note that the\nmethod we derive below is independent of how R, B, and\na are defined. Accommodating \u03c1 as the squared voltage only\nchanges the definition of the voltage limits. We use (2) to\ndefine the following vector-valued function:\ng\u03c1(\u03b1, qc, pB, qB, \u03b4) = R\n\u0000(I \u2212diag(\u03b1))pav \u2212pl + pB\n\u0001\n+ B\n\u0000qc \u2212ql + qB)\n\u0001\n+ a,\n(3)\nwhich computes the voltage magnitudes from variables\n\u03b1, qc, pB, qB and parameters pav, pl, ql, which we collect in\nvector \u03b4 := (pav, pl, ql).\nAt the time the DSO solves the OPF problem, the exact\nvalues of \u03b4 are unknown. To capture this uncertainty, we model\npav , pl and ql as random variables and the DSO must solve\nthe OPF problem as a stochastic program with probabilistic\nperformance guarantees. Several of such approaches have been\nproposed in the recent literature, e.g., [1], [7], [25]. In this\npaper we build our discussion on results from [7], modified to\nenforce a joint chance constraint on the voltage limits:\nmin\n\u03b1,qc,pB,qB,\u03b4\nEQ [C (\u03b1, qc, pB, qB, \u03b4)]\n(4a)\ns.t.\nPrQ\n(\ng\u03c1,n(\n\u03b1, qc, pB, qB, \u03b4)\u2264Vmax n=1, ..., N\n\u2212g\u03c1,n(\n\u03b1, qc, pB, qB, \u03b4)\u2264\u2212Vmin n=1, ..., N\n)\n\u22651\u2212\u03b7vol\n(4b)\nPrQ[((1\u2212\u03b1n)pav,n)2+ q2\nc,n\u2212S2\nn \u22640]\u22651 \u2212\u03b7inv\nn=1, ..., N\n(4c)\n0 \u2264\u03b1n \u22641\nn = 1, ..., N\n(4d)\npmin\nB,n \u2264pB,n \u2264pmax\nB,n\nn = 1, ..., N\n(4e)\nqmin\nB,n \u2264qB,n \u2264qmax\nB,n\nn = 1, ..., N\n(4f)\nObjective (4a) minimizes the expectation of the cost function\nfor a given distribution Q of \u03b4. Constraints (4b) and (4c)\nensure that for a given decision of inverter and DER setpoints\n\u03b1, qc, pB, qB voltage constraints and inverter capacity limits\nare met with a probability of 1\u2212\u03b7vol and 1\u2212\u03b7inv, respectively.\nHere, g\u03c1,n(\u00b7) denotes the n-th element of g\u03c1(\u00b7). Constraint (4d)\nlimits the share of curtailed renewable injection to [0, 1] and\nconstraint (4e) and (4f) enforce technical DERs constraints.\nIn this paper we define the cost function as the DSO\u2019s cost:\nC(\u03b1, qc, pB, qB, \u03b4)=\nN\nX\nn=1\n\u0000cn[pl,n \u2212pB,n\u2212(\n1 \u2212\u03b1n)pav,n]+\n+ dn[(1 \u2212\u03b1n)pav,n \u2212pl,n + pB,n]+\n+ en||qc,n| + |qB,n|| + hn\u03b1npav,n\n\u0001\n.\n(5)\nParameters c, d, e and h capture the cost of buying power from\nthe grid, DSO feed-in tariff payments, payments for reactive\npower supply inverters and DERs, and reimbursements for\nactive power curtailment, respectively.\nB. Data-driven solution\nThe problem in (4) can be solved in a data-driven manner\nusing historically recorded or sampled realizations {b\n\u03b4i}I\ni=1 of\n\u03b4. With access to such samples, the DSO can replace objective\n(4a) with its sample average approximation\nEb\nPI\n\u0002\nC (\u03b1, qc, pB, qB, \u03b4)\n\u0003\n= 1\nI\nI\nX\ni=1\nC(\u03b1, qc, pB, qB, b\n\u03b4i), (6)\nwhere b\nPI denotes the empirical distribution of the I available\nsamples. Similarly, chance constraints (4b) and (4c) allow a\ntractable data-driven reformulation using conditional value-at-\nrisk (CVaR). For (4b) this reformulation takes the form\n1\nI\nI\nX\ni=1\n\u0002\nmax\nk=1,...,K[\u27e8ak, \u03b4\u27e9+ck]+\u03c6vol\u0003+\u2264\u03c6vol\u03b7vol\ni = 1, ..., I,\n(7)\nwhere ak and ck collect decision variables related to the\nvoltage constraints and K = 2N, and \u03c6vol is an auxiliary\nSymbol\nDescription\ncn\nCost of buying power from the grid at node n\ndn\nDSO feed-in tariff payments at node n\nen\nPayments for reactive power supply at node n\nF\nNumber of data providers (data clusters)\nhn\nReimbursements for active power curtailment at\nnode n\nI\nNumber of samples\nK\nNumber of voltage constraints K = 2N\nN\nNumber of nodes\nNf\nNumber of nodes in cluster f\npav,n\nMaximum available RES active power at node\nn\npB,n\nActive power (dis)charging of DER at node n\npl,n\nActive power load at node n\nqB,n\nReactive power (dis)charging of DER at node n\nqc,n\nReactive power provided by RES inverter at\nnode n\nql,n\nReactive power load at node n\nSn\nRated apparent power of RES inverter at node\nn\nvn\nVoltage magnitude at node n\nVmin, Vmax\nLower and upper limits for voltage magnitudes\n\u03b1n\nFraction of RES active power curtailed at node\nn\npav\nVector of maximum available RES injections\npl\nVector of active power load\nql\nVector of reactive power load\n\u02c7\npav\nVector of maximum available RES injections\nforecast\n\u02c7\npl\nVector of active power load forecast\nqc\nVector of reactive power provided by RES\n\u02c7\nql\nVector of reactive power load forecast\nx\nVector collecting model decision variables\n\u03b1\nVector of fraction of active power curtailed by\nRES\n\u03b4\nVector of uncertain parameters\n\u03b4 := (pav, pl, ql)\n\u03c1\nVector of nodal voltage magnitudes\n\u03f5f\nData quality of cluster f\n\u03b7inv\nRisk-level for inverter constraint violation\n\u03b7vol\nRisk-level for voltage constraint violation\n\u03c6inv\nn\nAuxiliary variable for CVaR related to RES\ncapacity at node n\n\u03c6vol\nAuxiliary variable for CVaR related to voltages\n\u03d6inv\nn\nAuxiliary variable related to RES capacity at\nnode n\n\u03d6vol\nAuxiliary variable related to voltages\n[\u00b7]+\nmax{\u00b7, 0}\nTABLE I: Nomenclature\ndecision variable. We refer to Appendix A for more details on\nthe derivation in the context of this paper and to [6], [7] for\nfurther details on the CVaR reformulation. Similarly, (4c) can\nbe written as\n1\nI\nI\nX\ni=1\n\u0002\n((1 \u2212\u03b1n)b\npav,n,i)2+(qc,n)2\u2212S2\nn + \u03c6inv\nn\n\u0003+\n\u2264\u03c6inv\nn \u03b7inv\ni = 1, ..., I,\nn = 1, ..., N,\n(8)\nwhere \u03c6inv\nn\n\u2208R n = 1, ..., N are auxiliary decision variables.\nThe quality of the data-driven decision using reformulations\n(6)\u2013(8) of (4a),(4b) and (4c), respectively, relies on the ability\nof data set {b\n\u03b4i}I\ni=1 to accurately capture the true distribution\nof the uncertain \u03b4. Therefore, {b\n\u03b4i}I\ni=1 in itself is a crucial\ninput to the decision-making process. In the following section\nwe present a modification of the data-driven solution of (4)\nthat allows the system operator to evaluate the sensitivity of\nthe solution to the input data {b\n\u03b4i}I\ni=1 and model data accuracy\nobtained from various data sources.\nIII. INTERNALIZING DATA QUALITY\nAssume that the DSO obtains the required input data\n{b\n\u03b4i}I\ni=1 from multiple data providers, for example metering\nservice providers, aggregators, forecasting services, or smart\nhome services. Each data provider follows privacy protection\nrules and subjects their data to some form of alteration or\nobfuscation, e.g., using differential privacy [2], [5], [6]. As\na result, the data available to the DSO might be noisy or\nbiased and, as a result, may not accurately represent the\ntrue underlying distribution of the uncertain parameter. As\ndiscussed in [6], the data provider can quantify the resulting\ndiscrepancy between the distribution supported by the submit-\nted data and the true underlying distribution their Wasserstein\ndistance. By submitting this information alongside the data,\neach data provider can signal the quality of their data. A large\nWasserstein distance indicates a higher level of data alteration,\ni.e., a lower data quality, and vice versa. We refer the interested\nreader to [6] for an in-depth discussion. The following section\nshows how this data quality information can be internalized\nin the data-driven OPF.\nA. Multi-source distributional ambiguity\nWe assume that the data making up the available samples\n{b\n\u03b4i}I\ni=1 is obtained from F individual data providers. Each\ndata provider f = 1, ..., F submits data samples for a subset\nof Nf nodes which we call data cluster. As shown in Fig. 1,\nwe assume that each node exists only in exactly one cluster.\nAs a result PF\nf=1 Nf = N and \u03b4 can be rearranged as\n\u03b4 =\n\u0002\n\u03b41, ..., \u03b4f, ..., \u03b4F\n\u0003\u22a4\n(9)\nwhere\n\u03b4f=\n\u0002\npav,f1,pl,f1, ql,f1, ..., pav,fNf ,pl,fNf , ql,fNf\n\u0003\n\u22a4.\n(10)\nTo avoid notational clutter we will not introduce separate\nnotation for the rearranged \u03b4. Each vector \u03b4f \u2208R3Nf and we\nassume that each data provider submits I samples for their\ncluster, i.e.,{b\n\u03b4f,i}I\ni=1. In the special case of F = N, i.e.,\nNf = 1, f = 1, ..., F, the system operator obtains individual\ndata sets from each node. We note that our model can also\naccommodate the case where the different parameters of one\nnode are managed by different data providers, but we will not\ninclude this case here for easier notation.\nAlongside the data set {b\n\u03b4f,i}I\ni=1, each data provider submits\ndata quality information \u03f5f, indicating that the unknown true\ndistribution Pf of \u03b4f is within a Wasserstein distance of\nat most \u03f5f from the empirical distribution b\nPf supported by\n{\u03b4f,i}I\ni=1 with high probability. Intuitively, the DSO can\ninternalize this information into problem (4) by restating it\nas a distributionally robust optimization (DRO) problem:\nmin\n\u03b1,qc,pB,qB,\u03b4\nsup\nQ\u2208A\nEQ [C (\u03b1, qc, pB, qB, \u03b4)]\n(11a)\ns.t. inf\nQ\u2208A\nPrQ\nn\nmax\nk=1,...,K[\u27e8ak, \u03b4\u27e9+ck] \u22640\no\n\u22651\u2212\u03b7vol\n(11b)\ninf\nQ\u2208A\nPrQ\n\b\n((1\u2212\u03b1n)pav,n)2+ q2\nc,n \u2212S2\nn] \u22640\n\t\n\u22651 \u2212\u03b7inv\nn = 1, ..., N\n(11c)\n(4d) \u2212(4f)\n(11d)\n1\n2\n3\n5\n6\n7\n8\n4\n\u00a0\nPV system\nDER\nN\n\u00a0\n\u00a0\nFig. 1: Schematic of notations for clusters and nodes. Each node\nn provides three data points pav,n, pl,n, ql,n. Each data provider\nf collects data from a \u201ccluster\u201d of Nf nodes (indicated by dotted\nboxes). There are N nodes, F clusters, 3N total data points, and\n3Nf data points in a cluster.\nwhere, similar to \u03b4 in (9), we overload the notation of ak\nto match the order of the entries of \u03b4. Here, unlike in\n(4), the distribution Q is selected from a group of potential\ndistributions known as the ambiguity set A, which is informed\nby datasets {b\n\u03b4f,i}I\ni=1 and their quality \u03f5f for all f = 1, ..., F.\nTo reflect the fact that individual data quality information is\navailable for each dataset, we leverage results from [6] and\ndefine A as:\nA =\n\u001a\nQ\u2208P(\u039e)\n\f\n\f\n\f\n\f\nPf#Q = Qf,\nf = 1, ..., F,\nW p\np (\u02c6\nPf, Qf)\u2264\u03f5f,\nf = 1, ..., F,\n\u001b\n,\n(12)\nwhere W p\np (\u02c6\nPf, Qf) denotes the p-Wasserstein distance be-\ntween the empirical distribution \u02c6\nPf supported by {b\n\u03b4f,i}I\ni=1\nand Qf. Set P(\u039e) collects all probability distributions defined\non support \u039e. The support \u039e may be deduced from the\navailable datasets that are accessible, or it can be established\nbased on various technical factors. The support \u039e as utilized\nin our context, specifically denotes a hypercube structure.\nThis effectively represents the multidimensional range for each\nuncertain resource within the vector. Moreover, Pf# denotes\nthe push-forward distribution of the joint measure Q under the\nprojection onto the f-th coordinate, i.e.,\nPf#Q :=\nZ\n\u039e\u2212f\nQ(d\u03b41, . . . , d\u03b4f\u22121, d\u03b4\u2217\nf, d\u03b4f+1, . . . , d\u03b4F )\n(13)\nwith \u039e\u2212f := \u039e1 \u00d7 ... \u00d7 \u039ef\u22121 \u00d7 \u039ef+1 \u00d7 ... \u00d7 \u039eF and \u039ef being\nthe projection of \u039e on the f-th coordinate. As noted in [6],\nambiguity set A in (12) generalizes established Wasserstein\nambiguity sets, e.g., as in [26], to accommodate individual\nWasserstein budgets \u03f5f for each component \u03b4f of \u03b4. The\nfollowing section derives a data-driven solution approach for\n(11) extending upon the established sample-average approach\noutlined in Section II.B.\nB. Solution with clustered data sources\nOur solution approach builds on the results presented in [6].\nAssume a generic DRO problem computing optimal x under\nuncertainty \u03b4 for a cost function c(x, \u03b4):\ninf\nx\u2208X sup\nQ\u2208A\nEQ\n\u0002\nc(x, \u03b4)\n\u0003\n.\n(14)\nFor A as defined in (12), the generic DRO problem in\n(14) allows for a tractable formulation under the following\nassumption:\nAssumption 1. All datasets {b\n\u03b4f,i}I\ni=1, f = 1, ..., F are of\nidentical length I and each index i = 1, ..., I is standardized\nso that all samples {b\n\u03b4f,i}F\nf=1 with the same index i can\nbe related, e.g., in terms of a shared time-stamp. (See [6,\nCondition C-Std.])\nIf Assumption 1 holds, (14) can be reformulated as:\ninf\nx\u2208X,\u03bbf \u22650\nF\nX\nf=1\n\u03bbf\u03f5f + 1\nI\nI\nX\ni=1\nsi\n(15a)\ns.t. si \u2265sup\n\u03b4\u2208\u039e\nc(x, \u03b4)\u2212\nF\nX\nf=1\n\u03bbf\n\r\n\r\n\r\u03b4f \u2212b\n\u03b4f,i\n\r\n\r\n\r\np, i = 1, ..., I.\n(15b)\nWe refer to [6, Propositon 2] for the detailed proof. For the\nDSO problem outlined above, Assumption 1 is reasonable and\nwe use (15) to bring objective (11a) and chance constraints\n(11b) and (11c) into a tractable form.\n1) Chance constraint reformulation\nAs in the direct data-driven approach from Section II.B\nabove, we leverage CVaR to reformulate chance constraints\n(11b) and (11c). Enforcing\nsup\nQ\u2208A\nQCV aR\u03b7vol\n\u001a\n[ max\nk=1,...,K\u27e8ak, \u03b4\u27e9+ck] \u22640\n\u001b\n\u22651\u2212\u03b7vol (16)\nand\nsup\nQ\u2208A\nQCV aR\u03b7inv\b\n(1\u2212\u03b1n)2p2\nav,n+q2\nc,n\u2212S2\nn \u22640\n\t\n\u22651\u2212\u03b7inv\n(17)\nensures that (11b) and (11c) hold, respectively.\nThe resulting reformulations of (16) and (17) are:\nF\nX\nf=1\n\u03bbvol\nf \u03f5f + 1\nI\nI\nX\ni=1\nsvol\ni\n\u2264\u03b7vol\u03d6vol\n(18a)\nsvol\ni\n\u2265c\u2032\nk +\nF\nX\nf=1\n3Nf\nX\nm=1\n(zk,f \u02c6\n\u03b4f,i,m + uk,f,i,m\u03b4f,m \u2212lk,f,i,m\u03b4f,m)\nk = 1, . . . , K + 1\ni = 1, . . . , I\n(18b)\na\u2032\nk,f,m \u2212zk,f,i = uk,f,i,m \u2212lk,f,i,m\n\u2200k, f, i, m\n(18c)\n|zk,f,i| \u2264\u03bbvol\nf\n\u2200k, f, i\n(18d)\nuk,f,i,m, lk,f,i,m \u22650\n\u2200k, f, i, m\n(18e)\nand\n\u03bbinv\nn \u03f5f(n) + 1\nI\nI\nX\ni=1\nsinv\nn,i \u2264\u03b7inv\u03d6inv\nn\nn = 1, ..., N\n(19a)\nsinv\nn,i \u2265winv\nn\n+(1\u2212\u03b1n)2[eT\nn\u03b4\n2\nf(n)]\u2212\u03bbinv\nn ([eT\nn\u03b4f(n)]\u2212[\neT\nn\u02c6\n\u03b4f(n),i]\n)\ni = 1, . . . , I\nn = 1, ..., N\n(19b)\nsinv\nn,i \u2265winv\nn\n+ (1 \u2212\u03b1n)2[eT\nn \u02c6\n\u03b42\nf(n),i]\ni = 1, . . . , I\nn = 1, ..., N\n(19c)\nsinv\nn,i \u22650\ni = 1, . . . , I\nn = 1, ..., N.\n(19d)\nWe refer to Appendix B for the detailed derivation steps.\nUnlike the reformulation of the voltage chance constraint (18),\nwhere data from all data sets {\u03b4f,i}I\ni=1 is used, the formulation\nin (19) accounts for the fact that each inverter constraint only\nrequires data related to a single PV system. We therefore select\na single feature from \u03b4f, expressed as eT\nn\u03b4f, where en is a\ncolumn vector with all zero entries except for its n-th index\nthat corresponds to the index of the pav,n in \u03b4f(n) which is\nequal to one. If a PV is located at node n, then f(n) denotes\nthe cluster that includes node n.\n2) Objective function\nWe reformulate the objective function using the results of [6,\nProposition 1]. To avoid clutter in the main text body we report\nthe final objective in (20a) and additional auxiliary constraints\nin Appendix C.\n3) Complete formulation\nThe final model formulation is:\nmin\nF\nX\nf=1\n\u03bbco\nf \u03f5f +\nN\nX\nn=1\n\u0010\u00001\nI\nI\nX\ni=1\nsco1\nn,i\n\u0001\n+ en||qc,n| + |qB,n||\n+\n\u00001\nI\nI\nX\ni=1\nsco2\nn,i\n\u0001\u0011\n(20a)\ns.t.\n(A.10b) \u2212(A.10j)\n[Objective aux. constraints]\n(4d) \u2212(4e)\n[Deterministic constraints]\n\u03d6vol + \u03c6vol \u22640\n(20b)\n(18)\n[Voltage CVaR aux. constraints]\n\u03d6inv\nn\n+ \u03c6inv\nn\n\u22640\nn = 1, ..., N\n(20c)\n(19)\n[Inverter CVaR aux. constraints]\n\u03c6inv\nn\n\u22640\nn = 1, ..., N\n(20d)\n\u03c6vol \u22640\n(20e)\nC. Marginal value of data quality\nVariables \u03bbco\nf , \u03bbvol\nf\nand \u03bbinv\nn , n = 1, ..., N can be used\nto assess how sensitive the optimal solution of (20) is to\nchanges in the data sets. Specifically, each \u03bbco\nf , \u03bbvol\nf\nand\n\u03bbinv\nn , n = 1, ..., N, denotes the maximal variation of the\nworst-case expected cost in the objective and constraints to\nmarginal changes in the data sets. See also the discussion in\n[27]. We interpret this as a proxy for how much the optimal\nsolution relies on the correctness of a given dataset. We can\ncombine these values into a marginal value of data quality\n\u00b5f as follows. Define L as the Lagrangian of (20), and let\n\u03d5vol and \u03d5inv\nn\ndenote the dual multipliers for constraints (18a)\nand (19a). For a primal-dual optimal solution (20) we can use\nthe Envelope Theorem to assess the sensitivity of the optimal\nsolution to changes in data quality \u03f5f submitted by a data\nprovider f:\n\u00b5f = \u2202L\n\u2202\u03f5f\n= \u03bbco\nf + \u03d5vol\u03bbvol\nf\n+\nX\nn\u2208N\n\u03d5inv\nn \u03bbinv\nn .\n(21)\n19\n20\n21\n22\nCluster 4\nCluster 1\nCluster 2\nCluster 3\nCluster 5\n23\n24\n25\n26 27 28\n29 30 31\n32 33\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11 12 13 14 15 16\n17 18\nPV system\nDER\nFig. 2: Schematic of the modified IEEE 33-bus system with five data\nproviders, each corresponding to a cluster of nodes. Black PV systems\nindicate the Low PV case; Black + red PV systems indicate the High\nPV case.\nThe marginal value of data quality \u00b5f as defined in (21)\nconsists of three components. The first is the immediate effect\nof data quality on the uncertain part of the objective, denoted\nby \u03bbco\nf the second and third are the effect of data quality on\nthe objective that occurs indirectly via the cost of enforcing\nchance constraints (18a) and (19a), denoted by \u03d5vol\u03bbvol\nf\nand\nP\nn\u2208Nn,f \u03d5inv\nn \u03bbinv\nn , respectively.\nIV. CASE STUDY\nWe perform numerical experiments using the multi-source\ndata-driven OPF in (20) to assess data utility depending on\ndata quality and operational situation.\nA. Data and implementation\nWe use the case33bw dataset from MATPOWER [28] as\na basis for our test system. Voltage limits Vmax and Vmin\nare set to 1.1 and 0.9 p.u. (Recall that Vmax, Vmin limit the\nsquare voltage magnitude due to our use of the LinDistFlow\nmodel. See Section II.A above.) We modify the original data\nset by adding 9 and 19 PV systems for a Low PV and High\nPV scenario. The capacities and placements are indicated in\nTable II and Fig. 2, which also shows system topology. We\nuse real PV injection data from the Pecan Street database [29]\nto simulate a 24-hour PV profile as the basis for forecasts\n\u02c7\npav. Similarly, we extend the single-period load data from the\noriginal case33bw dataset to 24 hours by scaling them with\nload profiles from the ENTSO-E Transparency Platform [30].\nWe set cn = 10, dn = 3, en = 30 , hn = 6, for all n and we\nfix qB,n to zero for all n.\nFor this case study we assume 5 aggregators that act as data\nproviders, i.e., data is coming from 5 clusters with 10, 8, 4, 3,\nand 8 nodes, respectively, as shown in Fig. 2. For every cluster\nf = 1, ..., 5 we create a set of I = 25 samples of \u03b4f as follows.\nFor each uncertain parameter pav, pl, ql we use the 24-hour\nprofiles as described above as forecasts \u02c7\n\u03b4 = (\u02c7\npav, \u02c7\npl, \u02c7\nql).\nWe then draw the samples {\u02c6\n\u03b4f,i}I\ni=1, f = 1, ..., F from a\nNode\n3\n5\n6\n8\n11\n12\n14\nCap.\n500\n500\n750\n400\n750\n800\n200\n\u02c7\npav,n 241.6 241.6 362.5 193.3 362.5 386.6 96.7\nNode\n16*\n17*\n18*\n19*\n21\n22*\n23*\nCap.\n500\n200\n500\n200\n500\n500\n200\n\u02c7\npav,n 241.6\n96.7\n241.6\n96.7\n241.6 241.6 96.7\nNode\n25*\n27*\n29\n31*\n33\nCap.\n300\n600\n600\n300\n800\n\u02c7\npav,n\n145\n290\n290\n145\n386.6\nTABLE II: PV capacities and forecasts for 6pm in kW. Nodes with *\nhave 0 PV capacity in the Low PV case.\nNode\n19 20 24 25\nPower limit 50 22 50 50\nTABLE III: DER locations and their power limits in kW.\nnormal distribution N(\u02c7\n\u03b4f, \u03a3f) with \u03a3f = diag\n\u0000(0.2\u02c7\n\u03b4f)2\u0001\n,\ni.e., the sample distribution is centered around the forecast\nwith a standard deviation of 20% of the forecast value and\nno correlation. We highlight that we only use this normal\ndistribution for data generation. It is not a prerequisite for the\nmethod, which is independent from the underlying forecast\nerror distribution or scenario generation process. Finally, the\nsamples are truncated to the support \u039ef = [\u03b4f, \u03b4f], f =\n1, ..., F. In practice, support interval [\u03b4f, \u03b4f] can be defined\nby the DSO, e.g., by inferring it from the available data such\nthat \u03b4f = mini{\u02c6\n\u03b4f,i}, \u03b4f = maxi{\u02c6\n\u03b4f,i} or in terms of the\nphysical limits of each resource in cluster f. In our study we\nset \u03b4f =\n\u0002\n0, 0.5\u02c7\npl,f1, 0.5\u02c7\nql,f1, ..., 0, 0.5\u02c7\npl,fNf , 0.5\u02c7\nql,fNf\n\u0003\n\u22a4and\n\u03b4f =\n\u0002\nSf1, 1.2\u02c7\npl,f1, 1.2\u02c7\nql,f1, ..., SfNf , 1.2\u02c7\npl,fNf , 1.2\u02c7\nql,fNf\n\u0003\n\u22a4.\nAll computations have been implemented in the Julia lan-\nguage using JuMP [31] and solved using the SCS solver [32].\nThey have been performed on a standard MacBook laptop with\n16 GB memory and an Apple M3 processor. The solve time\nfor one time step was around 5 minutes on average.\nB. Decision performance\nWe first validate the ability of the derived multi-source\ndata-driven OPF in (20) to make reliable decisions. We\nwant to confirm that given a set of samples from each data\nprovider alongside the data quality information the model\nensures constraint satisfaction with high probability for the\ntrue distribution. To this end, we select the hour with the\nhighest PV forecast (1pm) and synthesize a large number of\nIfull = 1000 samples for the uncertain parameters covered by\neach data cluster using the method described in Section A\nabove. We define the empirical distribution of these Ifull\nsamples as the true distribution of \u03b4f. This will enable us\nto compute the true data quality information for each data\nprovider in the following step, for which we randomly select\nI samples from the generated Ifull samples for each data\nprovider. We then compute the true Wasserstein distance \u03f5f\nbetween the true distribution supported by the Ifull samples\nand the empirical distribution supported by the I samples.\nFor our specific experiment the resulting values for \u03f5f were\n[0.14, 0.078, 0.021, 0.024, 0.012]. (Note that these values are\nFig. 3: Voltage profile for the Itest = 100 test scenarios in the High\nPV case. Dashed lines indicate upper and lower voltage limits.\nrandom as they depend on the randomly selected I samples\nfor each data provider.) We then solve (20) using the selected\nsamples and their true data quality encoded in \u03f5f to obtain\ndecisions \u03b1\u2217, q\u2217\nc, p\u2217\nB, q\u2217\nB. To test the decision, we then draw\nnew Itest = 100 samples from the true distribution, i.e., the\nset of Ifull original samples.\nFor this experiment the resulting objective of solving (20)\nis 180.2$ and the true average cost from the test scenarios\nis 154.7$. Hence, the proposed approach reliably protects\nthe DSO from underestimating the expected cost. In other\nwords, the DRO approach successfully computes an upper\nbound on the expected cost. See also [26] for a discussion\non this property of DRO. All constraints were satisfied for\nall test-instances. Fig. 3 illustrates this result for the voltage\nconstraints. To further confirm these results we repeated this\nexperiment with higher levels of uncertainty. In this case some\nconstraint violations where observed for the test cases, but the\nempirical probability of constraint violation remained within\nthe desired risk levels \u03b7vol and \u03b7inv.\nC. Data value analysis.\nThis section demonstrates how our method can be used to\nquantify data value. For each PV scenario (Low PV and High\nPV) we solve model (20) 24 times (once for each hour of the\nday) using the respective load and PV forecasts generated as\ndescribed above. In contrast to the experiment in Section B\nabove, we now want to study how data quality impacts the\ndecision and the data value. To this end, we conduct this\nexperiment multiple times with predefined data quality values,\ni.e., 1.0, 0.1,0.01, 0.005, 0.001, and 0.0001. For now we\nassume that each provider submits data of the same quality.\n1) Voltage and Objective\nFig. 4 shows the resulting (expected) voltage profile across\nthe nodes and Table IV shows the resulting objective value.\nTable IV shows that worst-case expected cost decrease with\nimproved data quality. The higher renewable curtailments in\nthe High PV case result in higher objective values compared\nto the Low PV case. We also observe in Fig. 4 that with lower\ndata quality the model chooses a lower voltage baseline to\naccommodate more PV in the High PV scenario.\n2) Data value per constraint\nTables V and\nVI show the resulting values of \u03bbco\nf , \u03bbvol\nf ,\nand \u03bbinv\nn\n, n = 1, ..., N, respectively, exemplary for the High\n\u03f5f\n1\n0.1\n0.01\n0.005\n0.001\n0.0001\nHigh PV\n285.5\n209.6\n171.5\n169\n166.6\n166.1\nLow PV\n204.4\n186.7\n148\n145.4\n143.4\n142.9\nTABLE IV: Objective values [$] for various \u03f5f at 6pm\nFig. 4: Voltage magnitude profiles across all nodes under varying\ndata quality conditions, showcasing two distinct cases: Low PV case\nand High PV case. Horizontal dashed lines indicate upper and lower\nvoltage limits.\nPV scenario at 6pm. We chose this hour because it generally\nproduces the highest \u00b5f across all f = 1, ..., F, highlighting\nthe impact of changes in data quality on the decision most\nprominently. These values allow us to study data usefulness\nfor each data provider f and the various constraints. When \u03f5f\nis set to 1 for all f, i.e., data quality is low, we observe that\n\u03bbvol\nf\n= 0 and \u03bbco\nf\n= 0 except in clusters 1 and 2, that and\n\u03bbinv\nn\n\u2200n = 1, ..., N are small. This indicates inadequate data\nquality for clusters 3, 4 and 5, i.e., data quality is so low that\nthe solution does not rely on the data at all. The small but non-\nzero values of \u03bbco and \u03bbinv for clusters 1 and 2, on the other\nhand, indicate that even low-quality data will still support the\ndecision. Decreasing \u03f5f, i.e., improving data quality, implies\nsmaller required ambiguity sets around the empirical data\ndistributions, allowing the operator to place greater trust in the\ndata and reduce uncertainty surrounding forecast values. This\nleads to reduced system costs (as observed in Table IV), and\nan increase in \u03bbvol\nf , \u03bbinv\nn , n = 1, ..., N, and \u03bbco\nf . The results in\nTables V and VI also show that the relationship between data\nquality \u03f5f and \u03bbvol\nf , \u03bbco\nf , and \u03bbinv\nn\ndoes not strictly adhere to a\nmonotonic progression, e.g., in the transition from \u03f5f = 0.001\nto \u03f5f = 0.0001, f = 1, ..., 5.\n3) Data value per data provider\nWe now turn towards the marginal value of data quality\nfor each data provider, expressed by \u00b5f as analyzed in (21).\nTables VII and VIII show these values for the High PV and\nLow PV cases, respectively. Figs. 5 and 6 visualize \u00b5f over\nthe time of day. In Fig. 6 we observe that the marginal data\nvalue of providers 2 and 5 often dominates the others, which\nwe explain with the high total PV capacity in their respective\nnode clusters. Fig. 5 provides details on Cluster 1, showing\n\u00b51 for 6 different levels of data quality. For \u03f51 = 1, marginal\ndata quality is consistently low across all times of the day,\nf\n\u03f5f\n1\n0.1\n0.01\n0.005\n0.001\n0.0001\n1\n0\n0\n0.0073\n0.0073\n0.0074\n0.0073\n2\n0\n0.0052\n0.04\n0.04\n0.04\n0.04\n3\n0\n0\n0.0011\n0.0012\n0.0012\n0.0012\n4\n0\n0\n0\n0\n0\n0\n5\n0\n0\n0.017\n0.03\n0.04\n0.044\n\u03bbvol\nf\n1\n1.34\n4.06\n9.96\n9.93\n10.004\n19.48\n2\n1.8\n4.78\n9.99\n9.99\n10\n15.28\n3\n0\n3\n10.03\n10.01\n10\n10.1\n4\n0\n10\n10\n10\n10\n19.86\n5\n0\n3.8\n9.97\n9.98\n10.004\n18.42\n\u03bbco\nf\nTABLE V: Results for \u03bbvol\nf , \u03bbco\nf for various \u03f5f in the High PV case.\nf\nn\n\u03f5f\n1\n0.1\n0.01\n0.005\n0.001\n0.0001\n1\n3\n0\n0\n0\n0\n0.034\n0.034\n1\n5\n0.0001\n0\n0\n0.047\n0.047\n0.047\n1\n6\n0.0003\n0.0006\n0\n0.053\n0.054\n0.054\n1\n8\n0\n0\n0\n0\n0\n0\n2\n11\n0.0028\n0.002\n0\n0.0027\n0.057\n0.057\n2\n12\n0.0004\n0.0014\n0.4\n0.083\n0.085\n0.084\n2\n14\n0\n0.0001\n0\n0\n0.02\n0.019\n2\n16\n0.0004\n0.0008\n0.0002\n0\n0.0003\n0.0002\n2\n17\n0.0001\n0.0002\n0\n0\n0.024\n0.021\n2\n18\n0.0018\n0.0006\n0.035\n0.26\n0.036\n0.035\n3\n19\n0\n0\n0\n0\n0.015\n0.015\n3\n21\n0\n0\n0\n0\n0\n0\n3\n22\n0\n0\n0\n0.075\n0.077\n0.077\n4\n23\n0\n0\n0\n0\n0.009\n0.009\n4\n25\n0\n0\n0\n0.017\n0.017\n0.017\n5\n27\n0\n0\n0\n0\n0\n0\n5\n29\n0\n0\n0\n0.0002\n0\n0\n5\n31\n0\n0\n0\n0\n0\n0\n5\n33\n0.0004\n0.0053\n0\n0.0024\n0.08\n0.081\nTABLE VI: Results for \u03bbinv\nn\nfor various \u03f5f in the High PV case.\nindicating that the optimal decision relies very little or not at\nall on the provided data at this quality level. As \u03f51 decreases,\ni.e., data quality increases, the curves tend to have more\nvariation and higher marginal data quality values, suggesting,\nas expected, that the optimal decision relies more on the\ninformation from the provided data if it is of higher quality.\nThe marginal value of data quality for each data provider\nalso depends on the data quality of other data providers.\nTo highlight this, we conducted an experiment where we set\n\u03f5f = 0.01 for all f = 1, 3, 4, 5 (i.e., all except 2) varied only \u03f52\nto observe its effect on the marginal values. Table IX itemizes\nthese results. First, as discussed above, we observe that the\nf\n\u03f5f\n1\n0.1\n0.01\n0.005\n0.001\n0.0001\n1\n1.34\n4.06\n10.99\n10.72\n10.77\n20.3\n2\n1.8\n5.45\n15.5\n14.2\n14.26\n19.78\n3\n0\n3\n10.19\n10.13\n10.12\n10.23\n4\n0\n9.99\n10\n10\n10\n19.86\n5\n0\n3.8\n12.41\n13.08\n14.25\n23.26\n\u00b5f\nTABLE VII: Results for \u00b5f for various \u03f5f in the High PV case.\nFig. 5: Sensitivity of the optimal objective value to changes of the\ndata quality submitted by cluster 1 over 24 hours of the day in the\nHigh PV case.\nFig. 6: \u00b5f, f = 1, ..., 5 over 24 hours of the day in different \u03f5f in\nthe High PV case.\nf\n\u03f5f\n1\n0.1\n0.01\n0.005\n0.001\n0.0001\n1\n0\n0\n9.96\n10\n10.02\n29.64\n2\n0\n2.99\n10.23\n10.2\n10.12\n23.02\n3\n0\n3.08\n9.97\n10\n10\n16.77\n4\n0\n10.01\n10.01\n10.01\n10.01\n22.68\n5\n0\n3.9\n10.04\n10.02\n10.02\n23.41\n\u00b5f\nTABLE VIII: Results for \u00b5f for various \u03f5f in the Low PV case.\nf\n\u03f52\n1\n0.1\n0.01\n0.005\n0.001\n0.0001\n1\n10.61\n11.57\n10.99\n10.78\n10.68\n10.47\n2\n1.79\n5.77\n15.5\n14.13\n13.58\n17.95\n3\n10.1\n10.17\n10.19\n10.17\n10.11\n10.08\n4\n10\n10\n10\n9.99\n10\n9.98\n5\n11.4\n9.96\n12.41\n11.83\n11.67\n12.3\n\u00b5f\nTABLE IX: Results for \u00b5f for various \u03f52 and \u03f5f = 0.01, f =\n1, 3, 4, 5 in the High PV case.\nf\n1\n2\n3\n4\n5\n\u03bbvol\n0.1\n1\n0.1\n0.005\n0.05\n\u03bbinv\n0.5\n2.5\n0.01\n0.01\n0.75\n\u03bbco\n1.1\n1.8\n0.5\n0.125\n0.75\n\u03f5f\nTABLE X: Critical \u03f5f, f = 1, ..., 5.\nmarginal value of data quality does not increase monotonically.\nIncreasing data quality will increase the models reliance on\nthe provided data, leading to a general increase of marginal\ndata quality value. On the other hand, improved data will\nimprove the decision, i.e., reducing cost some marginal cost\ncomponents that contribute to \u00b5f as per (21).\n4) Critical data quality\nThe system operator can apply the proposed method to\nidentify the minimal level of data quality that is required from\neach data provider so that the data offers some utility to the\ndecision-making process. We define:\nDefinition 1 (Critical \u03f5f). The smallest value \u03f5f for which\nany \u03bbvol, \u03bbinv, \u03bbco associated with data provider f is equal\nto zero is called critical \u03f5f with respect to a given constraint.\nWe refer also to [33] for additional discussion on critical\nWasserstein radii in DRO. For each data provider we compute\nthe critical \u03f5f via a line-search process that alters \u03f5f for each f\nwhile keeping all \u03f5\u2032\nf, f \u2032 \u0338= f constant at 0.01. Table X shows\nthe resulting values. Notably, the critical \u03f5f for Cluster 2 is\nsignificantly higher than for the other clusters. We explain this\nobservation with the high electrical distance of the nodes in\nCluster 2 from the substation, which amplifies effects of load\nand generation on voltage. We highlight, that such an analysis\ncan be performed by the DSO to signal a minimum required\ndata quality to data providers or decide on whether datasets\nare worth obtaining.\n5) Nodal data provision\nFinally, Fig. 7 shows the application of our method for a\ncase where data for each node is supplied by an individual data\nprovider. These results corroborate our previous discussions by\nshowing higher marginal value of data quality at nodes with\nhigher PV capacity and increased distance from the substation,\nhighlighting the value of high-quality data from the grid edge\nin the presence of uncertain resources.\nV. CONCLUSION\nMotivated by the increasing significance of data-driven\ndecision-making in the power sector, this paper developed a\ndata-driven AC optimal power flow model for radial distri-\nbution systems that (i) can accommodate data from various\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n0\n10.2\n3\n9.85\n11.55\n14.08\n9.94\n15.71\n9.98\n0\n6.78\n22.67\n10.21\n10\n10\n5.25\n3.98\n39.37\n10\n9.94\n3\n5.12\n11.23\n10\n10\n9.91\n3\n0\n3\n10.11\n4.94\n9.97\n10.37\nFig. 7: Schematic of the IEEE 33-bus system showing the values of\n\u00b5f for each bus at \u03f5f \u2200f = 1, ..., 33 equal 0.01 when the number\nof clusters is equal to the number of buses in the High PV case at\n6pm. Nodes marked in red indicate locations with PV.\nsources and internalize information on data quality and (ii)\nprovides insights on data value via the marginal value of data\nquality in the final decision. Taking the perspective of an\noperator of a distribution system with controllable distributed\nresources and uncertain load and photovoltaic injections, we\nfirst formulated the operator\u2019s decision-making problem as a\nstochastic optimization problem. We then derived a data-driven\nversion of this problem that utilizes data from different data\nproviders (e.g., resource aggregators) and internalizes informa-\ntion on the data quality individual to each data provider. This\nextends previous results from [6], by allowing data on multiple\nuncertain parameters to be provided by a single data provider.\nWe then derive a tractable reformulation of the problem.\nOur case study on the IEEE 33-bus test system demonstrates\nthe application of the method and discusses the relationship\nbetween data value and data quality.\nAPPENDIX A\nFor\ngiven\n\u03b1,\nqc,\npB,\nand\nqB\nwe\ncan\nwrite\ng\u03c1(\u03b1, qc, pB, qB, \u03b4)\n=\ng\u03c1(\u03b4)\n=\nA\u03b4 + wvol\nwhere\nA\n=\n[R(I \u2212diag(\u03b1))\n\u2212R\n\u2212B]\n\u2208\nRN\u00d73N\nand\nwvol = \u2212RpB + B(qc + qB) + a \u2208RN\u00d71. Further defining\nK = 2N and ak, ck as the k-th row and k-th entry of the\nK \u00d7 3N matrix and K \u00d7 1 vector\n\u0014 A\n\u2212A\n\u0015\nand\n\u0014 wvol \u2212Vmax\n\u2212wvol + Vmin\n\u0015\n,\nthe joint chance constraint (4b) can be written as\nQ\n\b\nmax\nk=1,...,K[\u27e8ak, \u03b4\u27e9+ ck] \u22640\n\t\n\u22651 \u2212\u03b7vol.\n(A.1)\nUsing samples {b\n\u03b4i}I\ni=1 Eq. (A.1) can be solved using the data-\ndriven approach from [7], which leads to the result in (7).\nAPPENDIX B\nCHANCE CONSTRAINT REFORMULATION\nA. Derivation of (18)\nWe first reformulate (16) as [34]:\n\uf8f1\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f3\n\u03c6vol \u22640\n\u03d6vol + \u03c6vol \u22640\n\u03b7vol\u03d6vol \u2265supQ\u2208A EQ[maxk=1,...,K+1\u27e8a\u2032\nk, \u03b4\u27e9+ c\u2032\nk],\n(A.2)\nwhere a\u2032\nk = ak, k = 1, ..., K, a\u2032\nK+1 = 0D, c\u2032\nk = ck \u2212\u03c6vol\nk = 1, ..., K, c\u2032\nK+1 = 0 such that 0F denotes a vector of zeros\nof length F. Variable \u03d6vol is an auxiliary decision variable.\nWe then use (15) to reformulate the worst-case expectation\nappearing in (A.2) as\nF\nX\nf=1\n\u03bbvol\nf \u03f5f + 1\nI\nI\nX\ni=1\nsvol\ni\n\u2264\u03b7vol\u03d6vol\n(A.3)\nsvol\ni\n\u2265sup\n\u03b4\u2208\u039e\n\u0002\nmax\nk=1,...,K+1(\u27e8a\u2032\nk, \u03b4\u27e9+ c\u2032\nk)\u2212\nF\nX\nf=1\n\u03bbvol\nf \u2225\u03b4f \u2212\u02c6\n\u03b4f,i\u2225\n\u0003\ni = 1, . . . , I\n(A.4)\nWe have used p = 1 in this reformulation. Further, using\n\u03bbvol\nf \u2225\u03b4f \u2212b\n\u03b4f,i\u2225= P3Nf\nm=1 \u03bbvol\nf |\u03b4f,m \u2212b\n\u03b4f,i,m| and introducing\nzk,f,i as an auxiliary variable we can rewrite (A.4) as\nsvol\ni \u2265c\u2032\nk+ sup\n\u03b4f,m\u2208[\u03b4f,m,\u03b4f,m]\nF\nX\nf=1\n3Nf\nX\nm=1\n(\nzk,f,ib\n\u03b4f,i,m+(\na\u2032\nk,f,m\n\u2212zk,f,i)\u03b4f,m)\n(A.5)\nk = 1, ..., K + 1\ni = 1, . . . , I\n(A.6)\n|zk,f,i| \u2264\u03bbvol\nf\nk = 1, ..., K + 1\ni = 1, . . . , I\n(A.7)\nFinally, we resolve the inner supremum in (A.5) using\nsup\n\u03b4f,m\u2208[\u03b4f,m,\u03b4f,m]\n\u0000(a\u2032\nk,f,m \u2212zk,f,i)\u03b4f,m\n\u0001\n(A.8)\n=\ninf\nuk,f,i,m,lk,f,i,m\u22650:\n(a\u2032\nk,f,m\u2212zk,f,i)=(uk,f,i,m\u2212lk,f,i,m)\nuk,f,i,m\u03b4f,m \u2212lk,f,i,m\u03b4f,m,\nwhich result in (18).\nB. Derivation of (19)\nWe reformulate (17) similarly to (16) by introducing auxil-\niary variable \u03d6inv\nn\nand then writing\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3\n\u03c6inv\nn\n\u22640\nn = 1, ..., N\n\u03d6inv\nn\n+ \u03c6inv\nn\n\u22640\nn = 1, ..., N\n\u03b7inv\u03d6inv\nn\n\u2265supQ\u2208A EQ[max{((1 \u2212\u03b1n)pav,n)2 +winv\nn ]+\nn = 1, ..., N.\n(A.9)\nwhere winv\nn\n= q2\nc,n \u2212S2\nn \u2212\u03c6inv\nn , n = 1, ..., N. Using [6,\nPropostion 1], we write objective (11a) as: Applying [6,\nProposition 2] to the worst-case expectation in (A.9) then leads\nto (19).\nAPPENDIX C\nmin\nF\nX\nf=1\n\u03bbco\nf \u03f5f +\nN\nX\nn=1\n((1\nI\nI\nX\ni=1\nsco1\nn,i ) + en||qc,n| + |qB,n||\n+ (1\nI\nI\nX\ni=1\nsco2\nn,i ))\n(A.10a)\ns.t.\nn = 1, . . . , N\ni = 1, . . . , I :\nsco1\nn,i \u2265cn((rn\u03b4f(n))\u2212(1 \u2212\u03b1n)(mn\u03b4f(n)) \u2212pB) \u2212\u03bbf(n)\n(\n((rn\u03b4f(n))\u2212(rn\u02c6\n\u03b4f(n),i)) \u2212((mn\u03b4f(n),i) \u2212(mn\u02c6\n\u03b4f(n),i))\n)\n(A.10b)\nsco1\nn,i \u2265dn((1 \u2212\u03b1n)(mn\u03b4f(n)) \u2212(rn\u03b4f(n)) + pB) \u2212\u03bbf(n)\n((\u2212(rn\u03b4f(n))+ (rn\u02c6\n\u03b4f(n),i)) +((mn\u03b4f(n)) \u2212(mn\u02c6\n\u03b4f(n),i))\n)\n(A.10c)\nsco1\nn,i \u2265cn((rn\u02c6\n\u03b4f(n),i) \u2212(1 \u2212\u03b1n)(mn\u02c6\n\u03b4f(n),i) \u2212pB)\n(A.10d)\nsco1\nn,i \u2265dn((1 \u2212\u03b1n)(mn\u02c6\n\u03b4f(n),i) \u2212(rn\u02c6\n\u03b4f(n),i) + pB)\n(A.10e)\nsco1\nn,i \u22650\n(A.10f)\nsco2\nn,i \u2265hn\u03b1n(mn\u03b4f(n)) \u2212\u03bbf(n)((mn\u03b4f(n)) \u2212(mn\u02c6\n\u03b4f(n),i))\n(A.10g)\nsco2\nn,i \u2265hn\u03b1n(mn\u03b4f(n)) + \u03bbf(n)((mn\u03b4f(n)) \u2212(mn\u02c6\n\u03b4f(n),i))\n(A.10h)\nsco2\nn,i \u2265hn\u03b1n(mn\u02c6\n\u03b4f(n),i)\n(A.10i)\nsco2\nn,i \u22650.\n(A.10j)\nHere, rn and mn are column vectors with the same dimen-\nsions as \u03b4f(n). Vector rn has all zero entries except at the\nindex matching pl,n in \u03b4f(n). Similarly, vector \u03b4f(n) has all\nzero entries except at the index matching pav,n in \u03b4f(n).\nREFERENCES\n[1] R. Mieth and Y. Dvorkin, \u201cData-driven distributionally robust optimal\npower flow for distribution systems,\u201d IEEE Control Systems Letters,\nvol. 2, no. 3, pp. 363\u2013368, 2018.\n[2] G. Giaconi, D. Gunduz, and H. V. Poor, \u201cSmart meter data privacy,\u201d in\nAdvanced Data Analytics for Power Systems.\nCambridge University\nPress, 2021.\n[3] Z. Erkin et al., \u201cPrivacy-preserving data aggregation in smart metering\nsystems: An overview,\u201d IEEE Signal Processing Magazine, vol. 30,\nno. 2, pp. 75\u201386, 2013.\n[4] G. Le Ray and P. Pinson, \u201cThe ethical smart grid: Enabling a fruitful\nand long-lasting relationship between utilities and customers,\u201d Energy\nPolicy, vol. 140, p. 111258, 2020.\n[5] R. Currie et al., \u201cData privacy for the grid: Toward a data privacy\nstandard for inverter-based and distributed energy resources,\u201d IEEE\nPower and Energy Magazine, vol. 21, no. 5, pp. 48\u201357, 2023.\n[6] R. Mieth, J. M. Morales, and H. V. Poor, \u201cData valuation from data-\ndriven optimization,\u201d arXiv preprint arXiv:2305.01775, 2023.\n[7] E. Dall\u2019Anese, K. Baker, and T. Summers, \u201cChance-constrained ac\noptimal power flow for distribution systems with renewables,\u201d IEEE\nTransaction on Power Systems, vol. 32, no. 5, pp. 3427\u20133438, 2017.\n[8] Y. Guo et al., \u201cData-based distributionally robust stochastic optimal\npower flow\u2014part i: Methodologies,\u201d IEEE Transactions on Power\nSystems, vol. 34, no. 2, pp. 1483\u20131492, 2018.\n[9] A. Hassan et al., \u201cStochastic and distributionally robust load ensemble\ncontrol,\u201d IEEE Transactions on Power Systems, vol. 35, no. 6, pp. 4678\u2013\n4688, 2020.\n[10] L. A. Roald et al., \u201cPower systems optimization under uncertainty: A\nreview of methods and applications,\u201d Electric Power Systems Research,\nvol. 214, p. 108725, 2023.\n[11] X. Ren et al., \u201cDatum: Managing data purchasing and data placement in\na geo-distributed data market,\u201d IEEE/ACM Transactions on Networking,\nvol. 26, no. 2, pp. 893\u2013905, 2018.\n[12] R. J. Bessa et al., \u201cData economy for prosumers in a smart grid\necosystem,\u201d in Proc. of the Ninth International Conference on Future\nEnergy Systems, 2018, pp. 622\u2013630.\n[13] L. Han, J. Kazempour, and P. Pinson, \u201cMonetizing customer load data\nfor an energy retailer: A cooperative game approach,\u201d in Proc. of the\n2021 IEEE Madrid PowerTech.\nIEEE, 2021, pp. 1\u20136.\n[14] I. Koutsopoulos, A. Gionis, and M. Halkidi, \u201cAuctioning data for\nlearning,\u201d in Proc. of the 2015 IEEE International Conference on Data\nMining Workshop (ICDMW).\nIEEE, 2015, pp. 706\u2013713.\n[15] A. Agarwal, M. Dahleh, and T. Sarkar, \u201cA marketplace for data:\nAn algorithmic solution,\u201d in Proc. of the 2019 ACM Conference on\nEconomics and Computation, 2019, pp. 701\u2013726.\n[16] C. Goncalves, P. Pinson, and R. J. Bessa, \u201cTowards data markets\nin renewable energy forecasting,\u201d IEEE Transactions on Sustainable\nEnergy, vol. 12, no. 1, pp. 533\u2013542, 2020.\n[17] P. Pinson, L. Han, and J. Kazempour, \u201cRegression markets and applica-\ntion to energy forecasting,\u201d TOP, vol. 30, no. 3, pp. 533\u2013573, 2022.\n[18] A. Yassine, A. A. N. Shirehjini, and S. Shirmohammadi, \u201cSmart meters\nbig data: Game theoretic model for fair data sharing in deregulated smart\ngrids,\u201d IEEE Access, vol. 3, pp. 2743\u20132754, 2015.\n[19] A. Molina-Markham et al., \u201cPrivate memoirs of a smart meter,\u201d in Proc.\nof the 2nd ACM workshop on embedded sensing systems for energy-\nefficiency in building, 2010, pp. 61\u201366.\n[20] Parliament and Council of the EU, \u201cRegulation (EU) no 2016/679,\u201d\n2016, eur-lex.europa.eu/eli/reg/2016/679/oj.\n[21] U.S.\nDept.\nEnergy,\nWashington,\nDC,\nUSA,\n\u201cData\nprivacy\nand\nthe\nsmart\ngrid:\nA\nvoluntary\ncode\nof\nconduct,\u201d\nTech.\nRep.,\n2015.\n[Online].\nAvailable:\nwww.energy.gov/oe/downloads/\ndata-privacy-and-smart-grid-voluntary-code-conduct\n[22] J.-F. Toubeau et al., \u201cPrivacy-preserving probabilistic voltage forecasting\nin local energy communities,\u201d IEEE Transactions on Smart Grid, vol. 14,\nno. 1, pp. 798\u2013809, 2022.\n[23] V. Dvorkin et al., \u201cDifferentially private optimal power flow for distri-\nbution grids,\u201d IEEE Transactions on Power Systems, vol. 36, no. 3, pp.\n2186\u20132196, 2020.\n[24] M. E. Baran and F. F. Wu, \u201cOptimal capacitor placement on radial\ndistribution systems,\u201d IEEE Transactions on Power Delivery, vol. 4,\nno. 1, pp. 725\u2013734, 1989.\n[25] P. Li et al., \u201cDistribution system voltage control under uncertainties us-\ning tractable chance constraints,\u201d IEEE Transactions on Power Systems,\nvol. 34, no. 6, pp. 5208\u20135216, 2018.\n[26] P. Mohajerin Esfahani and D. Kuhn, \u201cData-driven distributionally robust\noptimization using the wasserstein metric: performance guarantees and\ntractable reformulations,\u201d Mathematical Programming, vol. 171, no. 1-2,\npp. 115\u2013166, 2018.\n[27] R. Gao, \u201cFinite-sample guarantees for wasserstein distributionally ro-\nbust optimization: Breaking the curse of dimensionality,\u201d Operations\nResearch, vol. 71, no. 6, pp. 2291\u20132306, 2023.\n[28] MATPOWER. (2016) CASE33BW Power flow data. [Online]. Available:\nhttps://matpower.org/docs/ref/matpower6.0/case33bw.html\n[29] Pecan Street Dataport. Pecan Street Dataport. [Online]. Available:\nhttps://www.pecanstreet.org/dataport/\n[30] Open Power System Data platform. Open Power System Data platform.\n[Online]. Available: https://data.open-power-system-data.org/\n[31] M. Lubin et al., \u201cJump 1.0: Recent improvements to a modeling\nlanguage for mathematical optimization,\u201d Mathematical Programming\nComputation, vol. 15, no. 3, pp. 581\u2013589, 2023.\n[32] B. O\u2019Donoghue et al., \u201cConic optimization via operator splitting and\nhomogeneous self-dual embedding,\u201d Journal of Optimization Theory and\nApplications, vol. 169, no. 3, pp. 1042\u20131068, June 2016.\n[33] T. Le and J. Malick, \u201cUniversal generalization guarantees for wasserstein\ndistributionally robust models,\u201d arXiv preprint arXiv:2402.11981, 2024.\n[34] R. T. Rockafellar, S. Uryasev et al., \u201cOptimization of conditional value-\nat-risk,\u201d Journal of risk, vol. 2, pp. 21\u201342, 2000.\n", "metadata": {"Published": "2024-06-19", "Title": "Data Value in Distribution System Operations", "Authors": "Mehrnoush Ghazanfariharandi, Robert Mieth", "Summary": "The rise of advanced data technologies in electric power distribution systems\nenables operators to optimize operations but raises concerns about data\nsecurity and consumer privacy. Resulting data protection mechanisms that alter\nor obfuscate datasets may invalidate the efficacy of data-driven\ndecision-support tools and impact the value of these datasets to the\ndecision-maker. This paper derives tools for distribution system operators to\nenrich data-driven operative decisions with information on data quality and,\nsimultaneously, assess data usefulness in the context of this decision. To this\nend, we derive an AC optimal power flow model for radial distribution systems\nwith data-informed stochastic parameters that internalize a data quality\nmetric. We derive a tractable reformulation and discuss the marginal\nsensitivity of the optimal solution as a proxy for data value. Our model can\ncapture clustered data provision, e.g., from resource aggregators, and\ninternalize individual data quality information from each data provider. We use\nthe IEEE 33-bus test system, examining scenarios with varying photovoltaic\npenetration, to demonstrate the application of our approach and discuss the\nrelationship between data quality and its value.", "entry_id": "http://arxiv.org/abs/2406.13148v1", "published_first_time": "2024-06-19", "comment": null, "journal_ref": null, "doi": null, "primary_category": "math.OC", "categories": ["math.OC"], "links": ["http://arxiv.org/abs/2406.13148v1", "http://arxiv.org/pdf/2406.13148v1"]}, "type": "Document"}
